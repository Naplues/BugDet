File,Line_number,SRC
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,803,future.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,805,LOG.warn("Got exception:" + e);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,484,+ ", but the table descriptors are not same when comapred with source cluster."
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeerZKImpl.java,211,LOG.fatal("The ReplicationPeer coresponding to peer " + peerConfig
hbase-server/src/main/java/org/apache/hadoop/hbase/HDFSBlocksDistribution.java,116,return "number of unique hosts in the disribution=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1446,HFile.LOG.warn("HDFS checksum verification suceeded for file " +
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,578,+ " cann't be found in hbase:meta.Please use hbck tool to fix it first.");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,583,+ " cann't be found in hbase:meta.Please use hbck tool to fix it first.");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentVerificationReport.java,463,System.err.println("[Error] Region assignment verfication report" +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java,975,opt.addOption("l", "locality", true, "enforce the maxium locality");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java,976,opt.addOption("m", "min-move", true, "enforce minium assignment move");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,859,server.abort("Aborting because error occoured while reading "
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/FavoredNodeAssignmentHelper.java,462,LOG.error("Cannot place the secondary and terinary" +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/FavoredNodeAssignmentHelper.java,500,LOG.error("Cannot place the secondary and terinary" +
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,205,String msg = "Data in for starting procuedure " + opName +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/HLogSplitterHandler.java,90,LOG.warn("task execution prempted " + wal);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,218,LOG.error("Error occured while updating the global cache", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,704,LOG.warn("Region's boundaries not alligned between stores and META for:");
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,738,LOG.warn("Attempt to adopt ophan hdfs region skipped becuase no files present in " +
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,913,LOG.info("Trying to sildeline reference file "
hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/HFileCorruptionChecker.java,253,LOG.warn("Failed to quaratine an HFile in regiondir "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1253,HFileBlock b = readBlockData(offset, -1, -1, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1364,private ThreadLocal<PrefetchedHeader> prefetchedHeaderForThread =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1365,new ThreadLocal<PrefetchedHeader>() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1367,public PrefetchedHeader initialValue() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1368,return new PrefetchedHeader();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1510,PrefetchedHeader prefetchedHeader = prefetchedHeaderForThread.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1511,ByteBuffer headerBuf = prefetchedHeader.offset == offset ?
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1512,prefetchedHeader.buf : null;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1556,+ prefetchedHeader.header.length
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1558,+ Bytes.toStringBinary(prefetchedHeader.header, 0,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1612,prefetchedHeader.offset = offset + b.getOnDiskSizeWithHeader();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1613,System.arraycopy(onDiskBlock, onDiskSizeWithHeader,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1614,prefetchedHeader.header, 0, hdrSize);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1150,if (this.closed) throw new IOException(toString() + " closed");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5380,long ts = Math.max(now, oldKv.getTimestamp());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5636,ts = Math.max(now, c.getTimestamp());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/replication/VerifyReplication.java,172,LOG.error(counter.toString() + ", rowkey=" + Bytes.toString(row.getRow()));
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3817,mergingRegions.remove(encodedName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3818,regionOnline(a, sn);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3819,regionOnline(b, sn);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3822,if (isTableDisabledOrDisabling(p.getTable())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3823,invokeUnAssign(a);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3824,invokeUnAssign(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,4204,case MERGE_REVERTED:
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/MetricsSource.java,84,globalSourceSource.setLastShippedAge(age);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/Replication.java,355,List<ReplicationSourceInterface> sources = this.replicationManager.getSources();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationLoad.java,62,this.replicationLoadSourceList = new ArrayList<ClusterStatusProtos.ReplicationLoadSource>();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationLoad.java,83,rLoadSourceBuild.setPeerID(sm.getPeerID());
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationLoad.java,89,this.replicationLoadSourceList.add(rLoadSourceBuild.build());
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,485,for (ReplicationSourceInterface src : this.sources) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,486,if (id.equals(src.getPeerClusterId())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java,337,keyRelOffset;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,46,private long initialSize;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1134,createRegionServerStatusStub();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2070,createRegionServerStatusStub() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2077,boolean refresh = false; // for the first time, use cached data
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2140,ServerName masterServerName = createRegionServerStatusStub();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,695,execOperation(coprocessors.isEmpty() ? null : new CoprocessorOperation() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,710,execOperation(coprocessors.isEmpty() ? null : new CoprocessorOperation() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,79,execOperation(coprocessors.isEmpty() ? null : new CoprocessorOperation() {
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,39,import javax.rmi.ssl.SslRMIClientSocketFactory;
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,40,import javax.rmi.ssl.SslRMIServerSocketFactory;
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,125,LocateRegistry.createRegistry(rmiRegistryPort);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1863,return new DelayedClosing(hci, stoppable);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/TruncateTableHandler.java,112,newRegions = regions.toArray(new HRegionInfo[regions.size()]);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java,47,import org.mortbay.jetty.security.SslSelectChannelConnector;
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java,192,SslSelectChannelConnector sslConnector = new SslSelectChannelConnector();
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,107,csf = new SslRMIClientSocketFactory();
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,108,ssf = new SslRMIServerSocketFactory();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HBaseReplicationEndpoint.java,220,LOG.fatal("Error reading slave addresses", e);
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,18,package org.apache.hadoop.hbase;
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,20,import java.lang.annotation.*;
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,22,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,31,public @interface VersionAnnotation {
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,37,String version();
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,42,String user();
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,48,String date();
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,53,String url();
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,59,String revision();
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,26,import org.apache.hadoop.hbase.VersionAnnotation;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,27,import org.apache.commons.logging.Log;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,37,private static Package myPackage;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,38,private static VersionAnnotation version;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,40,static {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,41,myPackage = VersionAnnotation.class.getPackage();
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,42,version = myPackage.getAnnotation(VersionAnnotation.class);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,49,static Package getPackage() {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,50,return myPackage;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,58,return version != null ? version.version() : "Unknown";
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,66,return version != null ? version.revision() : "Unknown";
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,74,return version != null ? version.date() : "Unknown";
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,82,return version != null ? version.user() : "Unknown";
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,90,return version != null ? version.url() : "Unknown";
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,380,boolean references = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,381,HTableDescriptor parentDescriptor = getTableDescriptor(parent.getTable());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,382,for (HColumnDescriptor family: parentDescriptor.getFamilies()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,383,if ((references = regionFs.hasReferences(family.getNameAsString()))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,384,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,241,FileStatus[] files = FSUtils.listStatus(fs, getStoreDir(familyName),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,242,new FSUtils.ReferenceFileFilter(fs));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,243,return files != null && files.length > 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1249,metaLocation = locateRegion(parentTable, metaKey, true, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java,303,snapshotInProgress.addAll(fileInspector.filesUnderSnapshot(run.getPath()));
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,83,SnapshotRegionManifest manifest = region.build();
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,84,FSDataOutputStream stream = fs.create(getRegionManifestPath(snapshotDir, manifest));
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,85,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,86,manifest.writeTo(stream);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,88,stream.close();
hbase-client/src/main/java/org/apache/hadoop/hbase/RegionLoad.java,53,return Bytes.toString(getName());
hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactory.java,50,if (serverName.contains("HMaster")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,906,this.rsHost = new RegionServerCoprocessorHost(this, this.conf);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,142,if(allTime) return true;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,144,return (minStamp <= timestamp && timestamp < maxStamp);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,59,import org.apache.hadoop.hbase.util.Writables;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,25,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,27,import org.apache.hadoop.hbase.KeyValue.Type;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,29,import org.apache.hadoop.hbase.util.Bytes;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,49,public TimeRangeTracker() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,63,this.minimumTimestamp = minimumTimestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,64,this.maximumTimestamp = maximumTimestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,73,public void includeTimestamp(final KeyValue kv) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,74,includeTimestamp(kv.getTimestamp());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,75,if (kv.isDeleteColumnOrFamily()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,76,includeTimestamp(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,86,public void includeTimestamp(final byte[] key) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,87,includeTimestamp(Bytes.toLong(key,key.length-KeyValue.TIMESTAMP_TYPE_SIZE));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,88,int type = key[key.length - 1];
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,89,if (type == Type.DeleteColumn.getCode() ||
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,90,type == Type.DeleteFamily.getCode()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,100,if (maximumTimestamp == -1) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,101,minimumTimestamp = timestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,102,maximumTimestamp = timestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,104,else if (minimumTimestamp > timestamp) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,105,minimumTimestamp = timestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,107,else if (maximumTimestamp < timestamp) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,108,maximumTimestamp = timestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,110,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,119,return (this.minimumTimestamp < tr.getMax() &&
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,120,this.maximumTimestamp >= tr.getMin());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2570,public void shutdown() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2575,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2576,cpHost.preShutdown();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2578,LOG.error("Error call master coprocessor preShutdown()", ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2600,shutdown();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2604,public void stopMaster() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2606,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2607,cpHost.preStopMaster();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2609,LOG.error("Error call master coprocessor preStopMaster()", ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2619,stopMaster();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,242,t.master.stopMaster();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,249,activeMaster.master.shutdown();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4177,boolean moreRows = nextRow(currentRow, offset, length);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java,802,throw new IllegalArgumentException("Invald maximum index block size");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java,838,while (rootChunk.getRootSize() > maxChunkSize) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java,181,LocalHBaseCluster cluster = new LocalHBaseCluster(conf, conf.getInt("hbase.masters", 1),
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java,182,conf.getInt("hbase.regionservers", 1), LocalHMaster.class, HRegionServer.class);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,188,if (System.currentTimeMillis() > startTime + 30000) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,189,throw new RuntimeException("Master not active after 30 seconds");
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/BufferChain.java,60,System.arraycopy(bb.array(), bb.arrayOffset(), bytes, offset, bb.limit());
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/BufferChain.java,61,offset += bb.capacity();
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,292,return (int)(this.getStartcode() - other.getStartcode());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,695,if(this.overflow() == that.overflow()) return 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,696,return this.overflow() > that.overflow() ? 1 : -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,931,diff = (int)(this.getOffset() - other.getOffset());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,937,return (int)(other.getCachedTime() - this.getCachedTime());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1186,return 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1187,return this.overflow() > that.overflow() ? 1 : -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1334,diff = (int)(this.getOffset() - other.getOffset());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1340,return (int)(other.getCachedTime() - this.getCachedTime());
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,3016,return (int)(k1.getTimestamp() - k2.getTimestamp());
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2064,if (e instanceof ServiceException) e = e.getCause();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,193,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,226,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,258,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,300,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,332,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,365,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,398,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,434,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,536,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,570,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,626,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesZKImpl.java,224,private boolean lockOtherRS(String znode) {
hbase-client/src/main/java/org/apache/hadoop/hbase/executor/ExecutorType.java,48,RS_LOG_REPLAY_OPS          (27);
hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java,261,private ConcurrentMap<Thread, Runnable> running = Maps.newConcurrentMap();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3921,this.service.submit(new OpenRegionHandler(this, this, region, htd,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3760,regionOffline(a);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,3761,regionOffline(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,3168,getNamespaceDescriptor(dstTable.getNamespaceAsString());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/DefaultVisibilityExpressionResolver.java,75,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/PutSortReducer.java,68,KeyValue kv = KeyValueUtil.ensureKeyValue(cell);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TextSortReducer.java,101,doSetup(context);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TextSortReducer.java,116,protected void doSetup(Context context) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TextSortReducer.java,117,Configuration conf = context.getConfiguration();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesZKImpl.java,302,LOG.warn("Peer " + peerId + " didn't exist, skipping the replay");
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesZKImpl.java,304,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,59,import com.google.common.util.concurrent.ThreadFactoryBuilder;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,469,ReplicationSourceInterface srcToRemove = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,473,for (ReplicationSourceInterface src : oldsources) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,474,if (id.equals(src.getPeerClusterId())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,475,oldSourcesToDelete.add(src);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,478,for (ReplicationSourceInterface src : oldSourcesToDelete) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,479,src.terminate(terminateMessage);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,480,closeRecoveredQueue((src));
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,487,srcToRemove = src;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,488,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,491,if (srcToRemove == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,495,srcToRemove.terminate(terminateMessage);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,496,this.sources.remove(srcToRemove);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,599,if (!this.rp.getPeerIds().contains((src.getPeerClusterId()))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,600,src.terminate("Recovered queue doesn't belong to any current peer");
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,601,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,603,oldsources.add(src);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,604,SortedSet<String> hlogsSet = entry.getValue();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,605,for (String hlog : hlogsSet) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,606,src.enqueueLog(new Path(oldLogDir, hlog));
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,608,src.startup();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,609,hlogsByIdRecoveredQueues.put(peerId, hlogsSet);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperImpl.java,414,cacheStats = blockCache.getStats();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4001,final HRegion region = this.getFromOnlineRegions(encodedRegionName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4002,if ((region  != null) && (region .getCoprocessorHost() != null)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4003,region.getCoprocessorHost().preClose(false);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,164,System.err.println("Invalid row is specified.");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,178,System.out.println("region dir -> " + regionDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,182,System.out.println("Number of region files found -> "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,188,System.out.println("Found file[" + i++ + "] -> " + p);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,220,processFile(fileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,223,System.exit(-2);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,228,System.out.println("Scanned kv count -> " + count);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,234,private void processFile(Path file) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,236,System.out.println("Scanning -> " + file);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,239,System.err.println("ERROR, file doesnt exist: " + file);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,240,System.exit(-2);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,271,System.out.println("Block Index:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,272,System.out.println(reader.getDataBlockIndexReader());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,276,System.out.println("Block Headers:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,292,System.out.println(block);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,298,System.out.println("Stats:\n" + fileStats);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,323,System.out.print("K: " + kv);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,325,System.out.print(" V: " + Bytes.toStringBinary(kv.getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,329,System.out
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,330,.print(String.format(" T[%d]: %s", i++, Bytes.toStringBinary(tag.getValue())));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,333,System.out.println();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,338,System.err.println("WARNING, previous row is greater then"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,348,System.err.println("WARNING, filename does not match kv family,"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,354,System.err.println("WARNING, previous kv has different family"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,376,System.out.println("Block index size as per heapsize: "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,378,System.out.println(asSeparateLines(reader.toString()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,379,System.out.println("Trailer:\n    "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,381,System.out.println("Fileinfo:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,383,System.out.print(FOUR_SPACES + Bytes.toString(e.getKey()) + " = ");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,386,System.out.println(seqid);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,394,System.out.println(Bytes.toInt(e.getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,396,System.out.println(Bytes.toStringBinary(e.getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,401,System.out.println("Mid-key: " + Bytes.toStringBinary(reader.midkey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,403,System.out.println ("Unable to retrieve the midkey");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,412,System.out.println("Bloom filter:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,414,System.out.println(FOUR_SPACES + bloomFilter.toString().replaceAll(
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,417,System.out.println(FOUR_SPACES + "Not present");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,426,System.out.println("Delete Family Bloom filter:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,428,System.out.println(FOUR_SPACES
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,432,System.out.println(FOUR_SPACES + "Not present");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2597,HRegion region = getRegion(s.getRegionInfo().getRegionName());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2602,s.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2603,if (region != null && region.getCoprocessorHost() != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2604,region.getCoprocessorHost().postScannerClose(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2607,LOG.error("Closing scanner for "
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2608,+ s.getRegionInfo().getRegionNameAsString(), e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3961,if (additionalScanners != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3965,for (Map.Entry<byte[], NavigableSet<byte[]>> entry :
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3966,scan.getFamilyMap().entrySet()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3967,Store store = stores.get(entry.getKey());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3970,|| this.filter.isFamilyEssential(entry.getKey())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3971,scanners.add(scanner);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3973,joinedScanners.add(scanner);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3976,initializeKVHeap(scanners, joinedScanners, region);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,181,List<KeyValueScanner> scanners = getScannersNoCompaction();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,187,seekScanners(scanners, matcher.getStartKey(), explicitColumnQuery
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,188,&& lazySeekEnabledGlobally, isParallelSeekEnabled);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,191,this.storeLimit = scan.getMaxResultsPerColumnFamily();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,194,this.storeOffset = scan.getRowOffsetPerColumnFamily();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,197,resetKVHeap(scanners, store.getComparator());
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,168,createBaseZNodes();
hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/StabilityOptions.java,31,String opt = option.toLowerCase();
hbase-annotations/src/main/java/org/apache/hadoop/hbase/classification/tools/StabilityOptions.java,41,String opt = options[i][0].toLowerCase();
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,446,valueOf(compression.toUpperCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,448,valueOf(dataBlockEncoding.toUpperCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,450,valueOf(bloomFilter.toUpperCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,569,return Compression.Algorithm.valueOf(n.toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,579,return Compression.Algorithm.valueOf(n.toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,650,return setValue(COMPRESSION, type.getName().toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,737,return setValue(COMPRESSION_COMPACT, type.getName().toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,763,return KeepDeletedCells.valueOf(value.toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,848,return BloomType.valueOf(n.toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java,386,cause.getMessage().toLowerCase().contains("connection reset")) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SubstringComparator.java,55,super(Bytes.toBytes(substr.toLowerCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SubstringComparator.java,56,this.substr = substr.toLowerCase();
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SubstringComparator.java,66,return Bytes.toString(value, offset, length).toLowerCase().contains(substr) ? 0
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,411,serverPrincipal = SecurityUtil.getServerPrincipal(
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,412,conf.get(serverKey), server.getAddress().getCanonicalHostName().toLowerCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,769,QualityOfProtection.AUTHENTICATION.name().toLowerCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/util/PoolMap.java,266,return name != null ? name.replaceAll("-", "").trim().toLowerCase() : "";
hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/KeyStoreKeyProvider.java,145,store = KeyStore.getInstance(storeType.toUpperCase());
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactoryImpl.java,48,context.toLowerCase(),
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactoryImpl.java,51,context.toLowerCase(),
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/filter/GzipFilter.java,68,(contentEncoding.toLowerCase().indexOf("gzip") > -1)) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/filter/GzipFilter.java,72,(acceptEncoding.toLowerCase().indexOf("gzip") > -1)) ||
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java,224,durability = Durability.valueOf(durabilityStr.toUpperCase());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/BaseRowProcessor.java,64,return this.getClass().getSimpleName().toLowerCase();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,6327,if (!args[1].toLowerCase().startsWith("major")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,53,QualityOfProtection.AUTHENTICATION.name().toLowerCase()));
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/CreateSnapshot.java,66,type = HBaseProtos.SnapshotDescription.Type.valueOf(snapshotName.toUpperCase());
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1837,if (!regionName.toLowerCase().matches("[0-9a-f]+")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,3630,if (!encodedName.toLowerCase().matches("[0-9a-f]+")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/ServerCommandLine.java,106,String key = entry.getKey().toLowerCase();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/ServerCommandLine.java,107,String value = entry.getValue().toLowerCase();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/HThreadedSelectorServerArgs.java,82,ACCEPT_POLICY_CONF_KEY, getAcceptPolicy().toString()).toUpperCase());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftUtilities.java,58,Compression.getCompressionAlgorithmByName(in.compression.toLowerCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,115,if(id.contains("-")){
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RegionServerCallable.java,138,long sleep = ConnectionUtils.getPauseTime(pause, tries + 1);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,136,expectedSleep = callable.sleep(pause, tries + 1);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1048,if (!timeRange.isAllTime()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1049,HBaseProtos.TimeRange.Builder timeRangeBuilder =
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1050,HBaseProtos.TimeRange.newBuilder();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1051,timeRangeBuilder.setFrom(timeRange.getMin());
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1052,timeRangeBuilder.setTo(timeRange.getMax());
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1053,builder.setTimeRange(timeRangeBuilder.build());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/MultiRowResource.java,89,LOG.trace("The row : " + rk + " not found in the table.");
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ProtobufStreamingUtil.java,52,LOG.debug("Created ScanStreamingUtil with content type = " + this.contentType + " user limit : "
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ProtobufStreamingUtil.java,53,+ this.limit + " scan fetch size : " + this.fetchSize);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ProtobufStreamingUtil.java,85,LOG.trace("Wrote " + model.getRows().size() + " rows to stream successfully.");
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java,130,.setInt("hbase.rest.port", Integer.valueOf(val));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java,131,LOG.debug("port set to " + val);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java,137,LOG.debug("readonly set to true");
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java,144,.setInt("hbase.rest.info.port", Integer.valueOf(val));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java,145,LOG.debug("Web UI port set to " + val);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RegionsResource.java,72,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RegionsResource.java,73,LOG.debug("GET " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RootResource.java,75,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RootResource.java,76,LOG.debug("GET " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,88,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,89,LOG.debug("GET " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,133,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,134,LOG.debug("GET " + uriInfo.getAbsolutePath() + " as "+ MIMETYPE_BINARY);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,224,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,225,LOG.debug("PUT " + put.toString());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,293,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,294,LOG.debug("PUT " + put.toString());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,305,LOG.debug(ioe);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,315,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,326,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,327,LOG.debug("PUT " + uriInfo.getAbsolutePath() + " as "+ MIMETYPE_BINARY);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,337,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,348,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,349,LOG.debug("POST " + uriInfo.getAbsolutePath() + " as "+MIMETYPE_BINARY);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,356,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,357,LOG.debug("DELETE " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,401,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,402,LOG.debug("DELETE " + delete.toString());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,411,LOG.debug(ioe);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,483,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,484,LOG.debug("CHECK-AND-PUT " + put.toString() + ", returns " + retValue);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,572,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,573,LOG.debug("CHECK-AND-DELETE " + delete.toString() + ", returns "
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,65,public ScannerInstanceResource(String table, String id,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,75,public Response get(final @Context UriInfo uriInfo,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,77,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,78,LOG.debug("GET " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,111,LOG.info("generator exhausted");
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,126,if (maxRows > 0) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,137,new CellModel(CellUtil.cloneFamily(value), CellUtil.cloneQualifier(value),
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,150,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,151,LOG.debug("GET " + uriInfo.getAbsolutePath() + " as " +
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,158,LOG.info("generator exhausted");
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,163,response.header("X-Row", Base64.encodeBytes(CellUtil.cloneRow(value)));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,164,response.header("X-Column",
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,185,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerInstanceResource.java,186,LOG.debug("DELETE " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,34,import javax.ws.rs.core.MultivaluedMap;
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,94,MultivaluedMap<String, String> params = uriInfo.getQueryParameters();
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,106,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,107,LOG.debug("new scanner: " + id);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,133,public Response put(final ScannerModel model,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,135,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,136,LOG.debug("PUT " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,146,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/ScannerResource.java,147,LOG.debug("POST " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,90,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,91,LOG.debug("GET " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,202,public Response put(final TableSchemaModel model,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,204,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,205,LOG.debug("PUT " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,214,public Response post(final TableSchemaModel model,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,216,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,217,LOG.debug("PUT " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,225,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,226,LOG.debug("DELETE " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/StorageClusterStatusResource.java,66,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/StorageClusterStatusResource.java,67,LOG.debug("GET " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/StorageClusterVersionResource.java,61,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/StorageClusterVersionResource.java,62,LOG.debug("GET " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,140,LOG.debug("Query parameters  : Table Name = > " + this.table + " Start Row => " + startRow
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,141,+ " End Row => " + endRow + " Columns => " + column + " Start Time => " + startTime
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,142,+ " End Time => " + endTime + " Cache Blocks => " + cacheBlocks + " Max Versions => "
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,143,+ maxVersions + " Batch Size => " + batchSize);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,155,LOG.debug("Scan family and column : " + familysplit[0] + "  " + familysplit[1]);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,159,LOG.debug("Scan family : " + familysplit[0] + " and empty qualifier.");
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,163,LOG.debug("Scan family : " + familysplit[0]);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/VersionResource.java,76,public Response get(final @Context ServletContext context,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/VersionResource.java,78,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/VersionResource.java,79,LOG.debug("GET " + uriInfo.getAbsolutePath());
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,107,MultiThreadedHttpConnectionManager manager =
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,212,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,213,LOG.debug(method.getName() + " " + uri + " " + code + " " +
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,385,public Response put(Cluster cluster, String path, String contentType,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,416,public Response put(Cluster cluster, String path, Header[] headers,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,452,public Response post(Cluster cluster, String path, String contentType,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,483,public Response post(Cluster cluster, String path, Header[] headers,
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/filter/AuthFilter.java,75,LOG.debug("Setting property " + name + "=" + value);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/provider/consumer/ProtobufMessageBodyConsumer.java,48,public class ProtobufMessageBodyConsumer
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/provider/consumer/ProtobufMessageBodyConsumer.java,76,if (LOG.isDebugEnabled()) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/provider/consumer/ProtobufMessageBodyConsumer.java,77,LOG.debug(getClass() + ": read " + baos.size() + " bytes from " +
hbase-server/src/main/java/org/apache/hadoop/hbase/util/ConnectionCache.java,37,import org.apache.log4j.Logger;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/ConnectionCache.java,47,private static Logger LOG = Logger.getLogger(ConnectionCache.class);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,196,hfs.next();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,198,if (this.stopSkippingKVsIfNextRow
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,199,&& getComparator().compareRows(cur.getBuffer(), cur.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,200,cur.getRowLength(), startKV.getBuffer(), startKV.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,716,cpHost.preRestoreSnapshot(reqSnapshot, snapshotTableDesc);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,722,cpHost.postRestoreSnapshot(reqSnapshot, snapshotTableDesc);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,727,cpHost.preCloneSnapshot(reqSnapshot, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,733,cpHost.postCloneSnapshot(reqSnapshot, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,505,for (Map.Entry<String, TablePermission> entry : allPerms.entries()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,506,UserPermission up = new UserPermission(Bytes.toBytes(entry.getKey()),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,507,entry.getValue().getTableName(), entry.getValue().getFamily(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,508,entry.getValue().getQualifier(), entry.getValue().getActions());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,509,perms.add(up);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,656,return entryName.charAt(0) == NAMESPACE_PREFIX;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,660,return entryName[0] == NAMESPACE_PREFIX;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,221,HTable ht = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,222,HBaseAdmin ha = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,224,ha = new HBaseAdmin(conf);
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,225,ht = new HTable(conf, ACL_TABLE_NAME);
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,226,CoprocessorRpcChannel service = ht.coprocessorService(HConstants.EMPTY_START_ROW);
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,229,HTableDescriptor[] htds = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,231,if (tableRegex == null || tableRegex.isEmpty()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,232,permList = ProtobufUtil.getUserPermissions(protocol);
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,234,String namespace = tableRegex.substring(1);
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,235,permList = ProtobufUtil.getUserPermissions(protocol, Bytes.toBytes(namespace));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,237,htds = ha.listTables(Pattern.compile(tableRegex));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,238,for (HTableDescriptor hd : htds) {
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,239,permList.addAll(ProtobufUtil.getUserPermissions(protocol, hd.getTableName()));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,243,if (ht != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,244,ht.close();
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,246,if (ha != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,247,ha.close();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,66,private RecoverableZooKeeper recoverableZooKeeper;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,123,private final Exception constructorCaller;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,154,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,155,throw new Exception("ZKW CONSTRUCTOR STACK TRACE FOR DEBUGGING");
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,157,this.constructorCaller = e;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,166,this.recoverableZooKeeper = ZKUtil.connect(conf, quorum, this, identifier);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,382,long finished = System.currentTimeMillis() +
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,383,this.conf.getLong("hbase.zookeeper.watcher.sync.connected.wait", 2000);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,384,while (System.currentTimeMillis() < finished) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,385,Threads.sleep(1);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,386,if (this.recoverableZooKeeper != null) break;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,388,if (this.recoverableZooKeeper == null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,389,LOG.error("ZK is null on connection event -- see stack trace " +
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,391,this.constructorCaller);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,392,throw new NullPointerException("ZK is null");
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,482,if (recoverableZooKeeper != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,483,recoverableZooKeeper.close();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,1691,final User ticket, final int rpcTimeout) {
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,1706,final User ticket, final int rpcTimeout) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java,32,import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java,75,public class SnapshotDescriptionUtils {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java,81,static String getWALCellCodecClass(Configuration conf) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RetriesExhaustedWithDetailsException.java,119,return s;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,26,import org.apache.hadoop.metrics2.lib.Interns;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,25,import org.apache.hadoop.metrics2.lib.Interns;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java,26,import org.apache.hadoop.metrics2.lib.Interns;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java,30,import org.apache.hadoop.metrics2.lib.Interns;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MetricMutableQuantiles.java,21,import static org.apache.hadoop.metrics2.lib.Interns.info;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,119,final Snapshot s = sample.getSnapshot();
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,120,metricsRecordBuilder.addCounter(Interns.info(name + NUM_OPS_METRIC_NAME, desc), count.get());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,122,metricsRecordBuilder.addGauge(Interns.info(name + MIN_METRIC_NAME, desc), getMin());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,123,metricsRecordBuilder.addGauge(Interns.info(name + MAX_METRIC_NAME, desc), getMax());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,124,metricsRecordBuilder.addGauge(Interns.info(name + MEAN_METRIC_NAME, desc), getMean());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,126,metricsRecordBuilder.addGauge(Interns.info(name + MEDIAN_METRIC_NAME, desc), s.getMedian());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,127,metricsRecordBuilder.addGauge(Interns.info(name + SEVENTY_FIFTH_PERCENTILE_METRIC_NAME, desc),
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,128,s.get75thPercentile());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,129,metricsRecordBuilder.addGauge(Interns.info(name + NINETY_FIFTH_PERCENTILE_METRIC_NAME, desc),
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,130,s.get95thPercentile());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,131,metricsRecordBuilder.addGauge(Interns.info(name + NINETY_NINETH_PERCENTILE_METRIC_NAME, desc),
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,41,private boolean allTime = false;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,79,if(maxStamp < minStamp) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,129,if(allTime) return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,390,System.out.println(timeRangeTracker.getMinimumTimestamp() + "...."
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,391,+ timeRangeTracker.getMaximumTimestamp());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,665,&& (Math.max(timeRangeTracker.getMaximumTimestamp(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,666,snapshotTimeRangeTracker.getMaximumTimestamp()) >=
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,667,oldestUnexpiredTS);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,453,byte [] timerangeBytes = metadataMap.get(TIMERANGE_KEY);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,454,if (timerangeBytes != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,455,this.reader.timeRangeTracker = new TimeRangeTracker();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,456,Writables.copyWritable(timerangeBytes, this.reader.timeRangeTracker);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,461,this.reader.timeRangeTracker = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,664,return (getReader().timeRangeTracker == null) ?
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,732,boolean isTimeRangeTrackerSet = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,821,isTimeRangeTrackerSet = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,835,if (!isTimeRangeTrackerSet) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1034,protected TimeRangeTracker timeRangeTracker = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1145,if (timeRangeTracker == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1146,return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1149,timeRangeTracker.getMaximumTimestamp() >= oldestUnexpiredTS;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1541,return timeRangeTracker == null ? Long.MAX_VALUE : timeRangeTracker.getMaximumTimestamp();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,42,long minimumTimestamp = -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,43,long maximumTimestamp = -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,58,this.minimumTimestamp = trt.getMinimumTimestamp();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,59,this.maximumTimestamp = trt.getMaximumTimestamp();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,126,public synchronized long getMinimumTimestamp() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,133,public synchronized long getMaximumTimestamp() {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,402,kv.updateLatestStamp(Bytes.toBytes(Long.MIN_VALUE));
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,250,int workerThreads, ThriftMetrics metrics) {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,251,CallQueue callQueue = new CallQueue(
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,252,new LinkedBlockingQueue<Call>(), metrics);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,241,serverArgs.getWorkerThreads(), metrics);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,256,return new ThreadPoolExecutor(workerThreads, workerThreads,
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,440,server = getTNonBlockingServer(protocolFactory, processor, transportFactory, inetSocketAddress);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,442,server = getTHsHaServer(protocolFactory, processor, transportFactory, inetSocketAddress, metrics);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotHFileCleaner.java,65,return Collections.emptyList();
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,62,private static final String SNAPSHOT_MANIFEST_PREFIX = "region-manifest.";
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,156,IOException ex = new IOException();
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,157,ex.initCause(e.getCause());
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV2.java,158,throw ex;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,176,+ tablename, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifestV1.java,120,LOG.info("No regions under directory:" + snapshotDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,48,public class ReplicationLogCleaner extends BaseLogCleanerDelegate implements Abortable {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,53,private boolean aborted;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,120,this.zkw = new ZooKeeperWatcher(conf, "replicationLogCleaner", null);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,121,this.replicationQueues = ReplicationFactory.getReplicationQueuesClient(zkw, conf, this);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,126,LOG.error("Error while configuring " + this.getClass().getName(), e);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,146,public void abort(String why, Throwable e) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,147,LOG.warn("Aborting ReplicationLogCleaner because " + why, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,148,this.aborted = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,149,stop(why);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,153,public boolean isAborted() {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,154,return this.aborted;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3630,Get get = ProtobufUtil.toGet(action.getGet());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3631,r = region.get(get);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java,21,import java.io.IOException;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java,33,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java,67,private static final String DATA_MANIFEST_NAME = "data.manifest";
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotManifest.java,433,return SnapshotDataManifest.parseFrom(in);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,540,CellModel valueToDeleteCell = rowModel.getCells().get(0);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,552,byte[][] parts = KeyValue.parseColumn(valueToDeleteColumn);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,555,delete.deleteColumns(parts[0], parts[1]);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,560,delete.deleteColumns(parts[0], Bytes.toBytes(StringUtils.EMPTY));
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,570,delete.deleteColumns(parts[0], parts[1]);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,460,if(Bytes.equals(cellModels.get(i).getColumn(),
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,461,valueToCheckCell.getColumn())) {
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,462,valueToPutCell = cellModels.get(i);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,463,break;
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,471,put.addImmutable(valueToPutParts[0], valueToPutParts[1], valueToPutCell.getTimestamp(),
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RowResource.java,472,valueToPutCell.getValue());
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java,73,if(cmp < 0) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java,74,done = true;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,27,import java.lang.reflect.Field;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,33,import java.security.AccessController;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,34,import java.security.PrivilegedAction;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1344,return theUnsafe != null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,55,import org.apache.zookeeper.KeeperException;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,56,import org.apache.zookeeper.data.Stat;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,58,import com.google.common.annotations.VisibleForTesting;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,462,List<ReplicationPeer> repPeers = listValidReplicationPeers();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,506,List<ReplicationPeer> validPeers = new ArrayList<ReplicationPeer>(peers.size());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,511,Stat s = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,516,s =
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,517,zkw.getRecoverableZooKeeper().exists(peerConf.get(HConstants.ZOOKEEPER_ZNODE_PARENT),
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,518,null);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,519,if (null == s) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,521,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,523,validPeers.add(peer);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,526,+ "Error connecting to peer cluster with peerId=" + peerId);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,527,LOG.debug("Failure details to get valid replication peers.", e);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,528,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,530,LOG.warn("Failed to get valid replication peers. KeeperException code="
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,531,+ e.code().intValue());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,532,LOG.debug("Failure details to get valid replication peers.", e);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,533,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,535,LOG.warn("Failed to get valid replication peers due to InterruptedException.");
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,537,Thread.currentThread().interrupt();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,545,return validPeers;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java,77,scanner.nextRaw(values, -1); // pass -1 as limit so that we see the whole row.
hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java,78,if (values == null || values.isEmpty()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,138,Pair<Message, CellScanner> ret = rpc.call(blocking, method, request, null, timestamp,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,139,status);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,140,if (ret.getSecond() != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,141,PayloadCarryingRpcController rpcc = (PayloadCarryingRpcController) controller;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,22,import java.util.Collections;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,26,import org.apache.hadoop.conf.Configuration;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,130,if (connection == null) return true; // Default is to do cellblocks.
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,131,Configuration configuration = connection.getConfiguration();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,132,if (configuration == null) return true;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,133,String codec = configuration.get(HConstants.RPC_CODEC_CONF_KEY, "");
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,134,return codec != null && codec.length() > 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1133,if(cell.getTagsLengthUnsigned() > 0) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1134,valueBuilder.setTags(ByteStringer.wrap(kv.getTagsArray(), kv.getTagsOffset(),
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1135,kv.getTagsLengthUnsigned()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,666,continue; // ignore RowMutations
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/client/Cluster.java,50,nodes.addAll(nodes);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,806,HRegionInfo hri = new HRegionInfo(template.getTableName(), orphanRegionRange.getFirst(), orphanRegionRange.getSecond());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/AuthenticationTokenSecretManager.java,322,if (lastKeyUpdate + keyUpdateInterval < now) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,61,protected int countPerRow = 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,496,Put put = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,516,if (proto.hasRow()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,517,put = new Put(proto.getRow().asReadOnlyByteBuffer(), timestamp);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,595,byte [] row = proto.hasRow()? proto.getRow().toByteArray(): null;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,596,long timestamp = HConstants.LATEST_TIMESTAMP;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,597,if (proto.hasTimestamp()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,598,timestamp = proto.getTimestamp();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,600,Delete delete = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,623,delete = new Delete(row, timestamp);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,33,import org.apache.hadoop.hbase.codec.KeyValueCodec;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,63,static class EncryptedKvDecoder extends KeyValueCodec.KeyValueDecoder {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,149,static class EncryptedKvEncoder extends KeyValueCodec.KeyValueEncoder {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java,33,import org.apache.hadoop.hbase.codec.KeyValueCodec;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java,352,? new KeyValueCodec.KeyValueDecoder(is) : new CompressedKvDecoder(is, compression);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogFactory.java,64,return new FSHLog(fs, root, logName, HConstants.HREGION_OLDLOGDIR_NAME,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogFactory.java,157,throw e;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,846,private long getTS(Path p) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,847,String[] parts = p.getName().split("\\.");
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,848,return Long.parseLong(parts[parts.length-1]);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2352,if (call != null && call.connection.socket != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,78,import org.apache.hadoop.hbase.io.hfile.CacheConfig;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,79,import org.apache.hadoop.hbase.io.hfile.HFile;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,80,import org.apache.hadoop.hbase.io.hfile.HFileContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,81,import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,396,this.metrics.setAgeOfLastShippedOp(System.currentTimeMillis());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1828,synchronized (masterAndZKLock) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1829,if (keepAliveZookeeperUserCount.decrementAndGet() <= 0 ){
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1830,keepZooKeeperWatcherAliveUntil = System.currentTimeMillis() + keepAlive;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3460,CompactionDescriptor compaction = WALEdit.getCompaction(kv);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3461,if (compaction != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3463,completeCompactionMarker(compaction);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java,41,private boolean includesTags;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,581,if (UnsafeComparer.isAvailable()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,622,if (UnsafeComparer.isAvailable()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,777,if (UnsafeComparer.isAvailable()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,873,if (UnsafeComparer.isAvailable()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,947,if (UnsafeComparer.isAvailable()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,985,if (UnsafeComparer.isAvailable()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1285,theUnsafe = (Unsafe) AccessController.doPrivileged(
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1286,new PrivilegedAction<Object>() {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1288,public Object run() {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1289,try {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1290,Field f = Unsafe.class.getDeclaredField("theUnsafe");
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1291,f.setAccessible(true);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1292,return f.get(null);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1296,throw new Error();
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1298,throw new Error();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,170,request = RequestConverter.buildScanRequest(scannerId, caching, false, nextCallSeq);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,519,final boolean closeScanner, final long nextCallSeq) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,31676,new java.lang.String[] { "Region", "Scan", "ScannerId", "NumberOfRows", "CloseScanner", "NextCallSeq", });
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,132,return coprocessorNames;
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,743,for (HTableInterface table: openTables) {
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,744,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,745,((HTableWrapper)table).internalClose();
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,748,LOG.warn("Failed to close " +
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,749,Bytes.toStringBinary(table.getTableName()), e);
hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java,226,LOG.error("Caught throwable while processing event " + eventType, t);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java,229,return this.durability == Durability.SKIP_WAL;
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcControllerFactory.java,56,return ReflectionUtils.instantiateWithCustomCtor(rpcControllerFactoryClazz,
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcControllerFactory.java,57,new Class[] { Configuration.class }, new Object[] { configuration });
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,363,String ensemble = conf.get(HConstants.ZOOKEEPER_QUORUM.replaceAll(
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,964,String superUser = zkw.getConfiguration().get("hbase.superuser");
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,967,if (superUser != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,968,acls.add(new ACL(Perms.ALL, new Id("auth", superUser)));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1162,this.closing.set(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1163,status.setStatus("Disabling writes for close");
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java,196,conf.set(
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java,197,ThriftServerRunner.BIND_CONF_KEY, cmd.getOptionValue(BIND_OPTION));
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,462,TServerTransport serverTransport = new TServerSocket(
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,463,new InetSocketAddress(listenAddress, listenPort));
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,472,+ "; " + serverArgs);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,260,private static TServer getTThreadPoolServer(TProtocolFactory protocolFactory, TProcessor processor,
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,261,TTransportFactory transportFactory, InetSocketAddress inetSocketAddress) throws TTransportException {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,262,TServerTransport serverTransport = new TServerSocket(inetSocketAddress);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,444,server = getTThreadPoolServer(protocolFactory, processor, transportFactory, inetSocketAddress);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,145,Scan tableScan = new Scan();
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/TableResource.java,149,tableScan.setStartRow(Bytes.toBytes(startRow));
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,26,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseEncoder.java,23,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/CompressionContext.java,34,static final String ENABLE_WAL_TAGS_COMPRESSION =
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogPrettyPrinter.java,232,FileSystem fs = FileSystem.get(conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java,25,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,547,if (file != null) file.closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1122,sf.closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1578,compactedFile.closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,476,this.closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,511,closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,218,false
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,257,float multiFactor, float memoryFactor, boolean forceInMemory) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,859,(3 * Bytes.SIZEOF_LONG) + (9 * ClassSize.REFERENCE) +
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,860,(5 * Bytes.SIZEOF_FLOAT) + Bytes.SIZEOF_BOOLEAN
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,153,private final AtomicLong failedBlockAdditions = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,513,long cacheSize = this.realCacheSize.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1747,totalRequestSize,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4213,checkOpen();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4221,return ReplicateWALEntryResponse.newBuilder().build();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,122,case DeleteFamily:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,123,List<Tag> delTags = new ArrayList<Tag>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,124,if (visibilityTagsDeleteFamily != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,125,Byte deleteCellVisTagsFormat = VisibilityUtils.extractVisibilityTags(delCell, delTags);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,126,if (!delTags.isEmpty()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,131,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,132,case DeleteFamilyVersion:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,133,delTags = new ArrayList<Tag>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,134,Byte deleteCellVisTagsFormat = VisibilityUtils.extractVisibilityTags(delCell, delTags);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,135,if (!delTags.isEmpty()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,139,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,140,case DeleteColumn:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,141,if (visibilityTagsDeleteColumns == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,142,visibilityTagsDeleteColumns = new ArrayList<Pair<List<Tag>, Byte>>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,144,delTags = new ArrayList<Tag>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,145,deleteCellVisTagsFormat = VisibilityUtils.extractVisibilityTags(delCell, delTags);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,146,if (!delTags.isEmpty()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,147,visibilityTagsDeleteColumns.add(new Pair<List<Tag>, Byte>(delTags,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,148,deleteCellVisTagsFormat));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,150,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,151,case Delete:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,152,if (visiblityTagsDeleteColumnVersion == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,153,visiblityTagsDeleteColumnVersion = new ArrayList<Pair<List<Tag>, Byte>>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,155,delTags = new ArrayList<Tag>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,156,deleteCellVisTagsFormat = VisibilityUtils.extractVisibilityTags(delCell, delTags);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,157,if (!delTags.isEmpty()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,158,visiblityTagsDeleteColumnVersion.add(new Pair<List<Tag>, Byte>(delTags,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,159,deleteCellVisTagsFormat));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,161,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,162,default:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,163,throw new IllegalArgumentException("Invalid delete type");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,166,switch (type) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,167,case DeleteFamily:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,168,visibilityTagsDeleteFamily = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,169,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,170,case DeleteFamilyVersion:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,171,visibilityTagsDeleteFamilyVersion = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,172,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,173,case DeleteColumn:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,174,visibilityTagsDeleteColumns = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,175,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,176,case Delete:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,177,visiblityTagsDeleteColumnVersion = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,178,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,179,default:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,180,throw new IllegalArgumentException("Invalid delete type");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,199,List<Tag> putVisTags = new ArrayList<Tag>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,200,Byte putCellVisTagsFormat = VisibilityUtils.extractVisibilityTags(cell, putVisTags);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,201,boolean matchFound = VisibilityLabelServiceManager
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,205,if (matchFound) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,206,return DeleteResult.FAMILY_VERSION_DELETED;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,247,for (Pair<List<Tag>, Byte> tags : visibilityTagsDeleteColumns) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,248,List<Tag> putVisTags = new ArrayList<Tag>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,249,Byte putCellVisTagsFormat = VisibilityUtils.extractVisibilityTags(cell, putVisTags);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,250,boolean matchFound = VisibilityLabelServiceManager
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,253,.matchVisibility(putVisTags, putCellVisTagsFormat, tags.getFirst(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,254,tags.getSecond());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,255,if (matchFound) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,270,for (Pair<List<Tag>, Byte> tags : visiblityTagsDeleteColumnVersion) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,271,List<Tag> putVisTags = new ArrayList<Tag>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,272,Byte putCellVisTagsFormat = VisibilityUtils.extractVisibilityTags(cell, putVisTags);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,273,boolean matchFound = VisibilityLabelServiceManager
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,276,.matchVisibility(putVisTags, putCellVisTagsFormat, tags.getFirst(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,277,tags.getSecond());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,278,if (matchFound) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,410,return result;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MultiTableOutputFormat.java,105,HTable table = new HTable(conf, tableName.get());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableOutputFormat.java,206,this.table = new HTable(this.conf, tableName);
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,28,import org.apache.commons.logging.Log;
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,29,import org.apache.commons.logging.LogFactory;
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,58,private static Log LOG = LogFactory.getLog(User.class);
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,285,private static class SecureHadoopUser extends User {
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,288,private SecureHadoopUser() throws IOException {
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,292,private SecureHadoopUser(UserGroupInformation ugi) {
hbase-common/src/main/java/org/apache/hadoop/hbase/security/UserProvider.java,98,return User.create(ugi);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,25,import org.apache.hadoop.hbase.monitoring.TaskMonitor;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,86,if (RpcServer.LOG.isDebugEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,87,UserGroupInformation remoteUser = call.connection.user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,88,RpcServer.LOG.debug(call.toShortString() + " executing as " +
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1151,protected UserGroupInformation user = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1353,user = getAuthorizedUgi(saslServer.getAuthorizationID());
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1356,+ user + ". Negotiated QoP is "
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1360,AUDITLOG.info(AUTH_SUCCESSFUL_FOR + user);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1555,user = protocolUser;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1556,if (user != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1557,user.setAuthenticationMethod(AuthMethod.SIMPLE.authenticationMethod);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1561,user.setAuthenticationMethod(authMethod.authenticationMethod);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1566,&& (!protocolUser.getUserName().equals(user.getUserName()))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1569,throw new AccessDeniedException("Authenticated user (" + user
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1576,UserGroupInformation realUser = user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1577,user = UserGroupInformation.createProxyUser(protocolUser
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1580,user.setAuthenticationMethod(AuthenticationMethod.PROXY);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1659,connectionHeader.getServiceName() + " is unauthorized for user: " + user);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1758,if (user != null && user.getRealUser() != null
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1760,ProxyUsers.authorize(user, this.getHostAddress(), conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1762,authorize(user, connectionHeader, getHostInetAddress());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2427,boolean shouldBlock = numReadyToWrite == 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2430,rowLock = getRowLockInternal(mutation.getRow(), shouldBlock);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2437,assert !shouldBlock : "Should never fail to get lock when blocking";
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2438,break; // stop acquiring more rows for this batch
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,58,this.status = getStatus();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,72,this.status = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,160,MonitoredRPCHandler getStatus() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,162,MonitoredRPCHandler status = RpcServer.MONITORED_RPC.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,163,if (status != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,164,return status;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,166,status = TaskMonitor.get().createRPCStatus(Thread.currentThread().getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,167,status.pause("Waiting for a call");
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,168,RpcServer.MONITORED_RPC.set(status);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,169,return status;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/FifoRpcScheduler.java,27,import org.apache.hadoop.hbase.ipc.CallRunner;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,34,import org.apache.hadoop.hbase.errorhandling.ForeignExceptionListener;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,35,import org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,39,import org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,55,private final TimeoutExceptionInjector timeoutInjector;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,66,timeoutInjector = getMasterTimerAndBindToMonitor(snapshot, conf, monitor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,80,timeoutInjector.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,120,timeoutInjector.complete();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,132,private TimeoutExceptionInjector getMasterTimerAndBindToMonitor(SnapshotDescription snapshot,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,133,Configuration conf, ForeignExceptionListener monitor) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,134,long maxTime = SnapshotDescriptionUtils.getMaxMasterTimeout(conf, snapshot.getType(),
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,135,SnapshotDescriptionUtils.DEFAULT_MAX_WAIT_TIME);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,136,return new TimeoutExceptionInjector(monitor, maxTime);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,122,private static final int SNAPSHOT_TIMEOUT_MILLIS_DEFAULT = 60000;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,128,private static final String SNAPSHOT_TIMEOUT_MILLIS_KEY = "hbase.snapshot.master.timeoutMillis";
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,1031,long timeoutMillis = conf.getLong(SNAPSHOT_TIMEOUT_MILLIS_KEY, SNAPSHOT_TIMEOUT_MILLIS_DEFAULT);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,90,public static final long SNAPSHOT_TIMEOUT_MILLIS_DEFAULT = 60000;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java,114,public static final long DEFAULT_MAX_WAIT_TIME = 60000;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java,143,return conf.getLong(confKey, defaultMaxWaitTime);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,611,seekToBlock.getOffset() - previousBlockOffset, cacheBlocks,
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,99,+ " is not running yet");
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1720,String msg = getListenerAddress() + " is unable to read call parameter from client " +
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1721,getHostAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,24,import java.util.LinkedList;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,25,import java.util.List;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,175,private List<Bucket> bucketList, freeBuckets, completelyFreeBuckets;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,179,bucketList = new LinkedList<Bucket>();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,180,freeBuckets = new LinkedList<Bucket>();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,181,completelyFreeBuckets = new LinkedList<Bucket>();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,188,bucketList.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,189,freeBuckets.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,190,completelyFreeBuckets.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,203,if (freeBuckets.size() > 0) // Use up an existing one first...
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,204,b = freeBuckets.get(freeBuckets.size() - 1);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,229,b = completelyFreeBuckets.get(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,243,assert bucketList.contains(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,245,assert (!completelyFreeBuckets.contains(b));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,247,if (!freeBuckets.contains(b)) freeBuckets.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,248,if (b.isCompletelyFree()) completelyFreeBuckets.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,253,for (Bucket b : bucketList) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,67,if ( (buf.position() + extra) > buf.limit()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,70,int newSize = (int)Math.min((((long)buf.capacity()) * 2),
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,71,(long)(Integer.MAX_VALUE));
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,72,newSize = Math.max(newSize, buf.position() + extra);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,748,f.closeReader(true);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,221,public ByteBuffer getKeyValueBuffer() {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,222,ByteBuffer kvBuffer = createKVBuffer();
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,223,kvBuffer.putInt(current.keyLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,224,kvBuffer.putInt(current.valueLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,225,kvBuffer.put(current.keyBuffer, 0, current.keyLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,226,kvBuffer.put(currentBuffer.array(),
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,227,currentBuffer.arrayOffset() + current.valueOffset,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,228,current.valueLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,231,kvBuffer.put((byte)(current.tagsLength >> 8 & 0xff));
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,232,kvBuffer.put((byte)(current.tagsLength & 0xff));
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,236,kvBuffer.put(currentBuffer.array(), currentBuffer.arrayOffset() + current.tagsOffset,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,237,current.tagsLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,241,kvBuffer.put(current.tagsBuffer, 0, current.tagsLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,244,return kvBuffer;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,247,protected ByteBuffer createKVBuffer() {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,248,int kvBufSize = (int) KeyValue.getKeyValueDataStructureSize(current.keyLength,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,249,current.valueLength, current.tagsLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,250,ByteBuffer kvBuffer = ByteBuffer.allocate(kvBufSize);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,251,return kvBuffer;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,255,public KeyValue getKeyValue() {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,256,ByteBuffer kvBuf = getKeyValueBuffer();
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java,143,ByteBuffer getKeyValueBuffer();
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeSeeker.java,87,public ByteBuffer getKeyValueBuffer() {
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeSeeker.java,88,return KeyValueUtil.copyToNewByteBuffer(ptSearcher.current());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/DefaultVisibilityExpressionResolver.java,114,return labels.get(label);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,52,private static final int NON_EXIST_LABEL_ORDINAL = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,178,return NON_EXIST_LABEL_ORDINAL;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,707,return scale(0, cluster.numRegions + META_MOVE_COST_MULT, moveCost);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java,26,import org.apache.hadoop.net.DNS;
hbase-common/src/main/java/org/apache/hadoop/hbase/AuthUtil.java,32,import org.apache.hadoop.net.DNS;
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/RESTServer.java,43,import org.apache.hadoop.net.DNS;
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/filter/AuthFilter.java,36,import org.apache.hadoop.net.DNS;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,256,import org.apache.hadoop.net.DNS;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,247,import org.apache.hadoop.net.DNS;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,97,import org.apache.hadoop.net.DNS;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,62,import org.apache.hadoop.net.DNS;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,68,if (region.shouldForceSplit()) return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,92,return foundABigStore;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2812,if (bytesRead == 0) return null; // EOF at start is ok
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,35,protected final InputStream in;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,36,private boolean hasNext = true;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,40,this.in = in;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,45,if (!this.hasNext) return this.hasNext;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,46,if (this.in.available() == 0) {
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,47,this.hasNext = false;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,48,return this.hasNext;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,55,return this.hasNext;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,22,import java.io.EOFException;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,86,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,87,ivLength = StreamUtils.readRawVarint32(in);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,90,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,595,Path refPath = StoreFileInfo.getReferredToFile(new Path(new Path(new Path(
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,596,snapshotTable.getNameAsString(), regionInfo.getEncodedName()), familyDir.getName()),
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,597,hfileName));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,962,public synchronized boolean seekToPreviousRow(KeyValue key) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,963,KeyValue firstKeyOnRow = KeyValue.createFirstOnRow(key.getRow());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,964,SortedSet<KeyValue> kvHead = kvsetAtCreation.headSet(firstKeyOnRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,965,KeyValue kvsetBeforeRow = kvHead.isEmpty() ? null : kvHead.last();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,966,SortedSet<KeyValue> snapshotHead = snapshotAtCreation
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,967,.headSet(firstKeyOnRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,968,KeyValue snapshotBeforeRow = snapshotHead.isEmpty() ? null : snapshotHead
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,969,.last();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,970,KeyValue lastKVBeforeRow = getHighest(kvsetBeforeRow, snapshotBeforeRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,971,if (lastKVBeforeRow == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,972,theNext = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,973,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,975,KeyValue firstKeyOnPreviousRow = KeyValue
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,976,.createFirstOnRow(lastKVBeforeRow.getRow());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,977,this.stopSkippingKVsIfNextRow = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,978,seek(firstKeyOnPreviousRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,979,this.stopSkippingKVsIfNextRow = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,980,if (peek() == null
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,981,|| comparator.compareRows(peek(), firstKeyOnPreviousRow) > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,982,return seekToPreviousRow(lastKVBeforeRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,408,public boolean seekToPreviousRow(KeyValue key) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,411,KeyValue seekKey = KeyValue.createFirstOnRow(key.getRow());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,412,if (seekCount != null) seekCount.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,413,if (!hfs.seekBefore(seekKey.getBuffer(), seekKey.getKeyOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,414,seekKey.getKeyLength())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,415,close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,416,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,418,KeyValue firstKeyOfPreviousRow = KeyValue.createFirstOnRow(hfs
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,419,.getKeyValue().getRow());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,421,if (seekCount != null) seekCount.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,422,if (!seekAtOrAfter(hfs, firstKeyOfPreviousRow)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,423,close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,424,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,427,cur = hfs.getKeyValue();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,428,this.stopSkippingKVsIfNextRow = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,429,boolean resultOfSkipKVs;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,430,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,431,resultOfSkipKVs = skipKVsNewerThanReadpoint();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,433,this.stopSkippingKVsIfNextRow = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,435,if (!resultOfSkipKVs
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,436,|| getComparator().compareRows(cur.getBuffer(), cur.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,437,cur.getRowLength(), firstKeyOfPreviousRow.getBuffer(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,438,firstKeyOfPreviousRow.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,439,firstKeyOfPreviousRow.getRowLength()) > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,440,return seekToPreviousRow(firstKeyOfPreviousRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,449,+ key, ioe);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/DynamicClassLoader.java,123,synchronized (getClassLoadingLock(name)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/LocalHBaseCluster.java,146,conf.set(HConstants.REGIONSERVER_INFO_PORT, "0");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,147,return Collections.unmodifiableMap(regionAssignments);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java,72,ZKUtil.loginServer(conf, "hbase.zookeeper.server.keytab.file",
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,525,ZKUtil.loginClient(this.conf, "hbase.zookeeper.client.keytab.file",
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java,162,ZKUtil.loginServer(conf, "hbase.zookeeper.server.keytab.file",
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,638,ZKUtil.loginClient(this.conf, "hbase.zookeeper.client.keytab.file",
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,237,this.splits.execute(new SplitRequest(r, midKey, this.server));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,255,return requestCompaction(r, why, Store.NO_PRIORITY, requests);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,261,return requestCompaction(r, s, why, Store.NO_PRIORITY, request);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,266,int p, List<Pair<CompactionRequest, Store>> requests) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,267,return requestCompactionInternal(r, why, p, requests, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,271,int p, List<Pair<CompactionRequest, Store>> requests, boolean selectNow) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,277,CompactionRequest cr = requestCompactionInternal(r, s, why, p, null, selectNow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,284,ret.add(requestCompaction(r, pair.getSecond(), why, p, pair.getFirst()));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,291,final String why, int priority, CompactionRequest request) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,292,return requestCompactionInternal(r, s, why, priority, request, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,297,requestCompactionInternal(r, why, Store.NO_PRIORITY, null, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,302,requestCompactionInternal(r, s, why, Store.NO_PRIORITY, null, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,332,pool.execute(new CompactionRunner(s, r, compaction, pool));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,436,CompactionContext compaction, ThreadPoolExecutor parent) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,453,public void run() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,454,Preconditions.checkNotNull(server);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,456,|| (region.getTableDesc() != null && !region.getTableDesc().isCompactionEnabled())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,457,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactionRequestor.java,80,final HRegion r, final String why, int pri, List<Pair<CompactionRequest, Store>> requests
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactionRequestor.java,94,final HRegion r, final Store s, final String why, int pri, CompactionRequest request
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1520,this.majorCompactPriority, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4095,compactSplitThread.requestSplit(region, region.checkSplit());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4188,Store.PRIORITY_USER, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4191,Store.PRIORITY_USER, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,46,SplitRequest(HRegion region, byte[] midKey, HRegionServer hrs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,59,public void run() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,60,if (this.server.isStopping() || this.server.isStopped()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,61,LOG.debug("Skipping split because server is stopping=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,62,this.server.isStopping() + " or stopped=" + this.server.isStopped());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,63,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2296,deleteNodeInStates(encodedName, "offline", sn, EventType.M_ZK_REGION_OFFLINE);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FSDataInputStreamWrapper.java,26,import org.apache.hadoop.hbase.io.FileLink;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FSDataInputStreamWrapper.java,79,this(fs, null, path);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FSDataInputStreamWrapper.java,83,this(fs, link, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FSDataInputStreamWrapper.java,86,private FSDataInputStreamWrapper(FileSystem fs, FileLink link, Path path) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheConfig.java,202,);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheConfig.java,222,final boolean cacheDataCompressed, final boolean prefetchOnOpen) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheConfig.java,242,cacheConf.cacheDataCompressed, cacheConf.prefetchOnOpen);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFlusher.java,70,writer = store.createWriterInTmp(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFlusher.java,71,snapshot.size(), store.getFamily().getCompression(), false, true, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1017,List<StoreFileScanner> sfScanners = StoreFileScanner
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1018,.getScannersForStoreFiles(storeFilesToScan, cacheBlocks, usePread, isCompaction, matcher,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1019,readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1091,CompactionRequest cr = compaction.getRequest();;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,2028,private class StoreFlusherImpl implements StoreFlushContext {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java,170,boolean includesTags
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,370,private Reader open() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,376,this.reader = fileInfo.open(this.fs, this.cacheConf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,470,public Reader createReader() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,473,this.reader = open();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,38,import org.apache.hadoop.hbase.io.encoding.DataBlockEncoding;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,178,final CacheConfig cacheConf) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,184,in = new FSDataInputStreamWrapper(fs, this.link);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,189,in = new FSDataInputStreamWrapper(fs, referencePath);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,192,in = new FSDataInputStreamWrapper(fs, this.getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,89,usePread, false, readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,99,null, readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,113,StoreFile.Reader r = file.createReader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFlusher.java,118,kvCount, store.getFamily().getCompression(), false, true, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,165,final Collection<StoreFile> filesToCompact, long smallestReadPoint) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,166,return StoreFileScanner.getScannersForStoreFiles(filesToCompact, false, false, true,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,63,if (this.conf.getBoolean("hbase.regionserver.compaction.private.readers", false)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,70,scanners = createFileScanners(readersToClose, smallestReadPoint);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,73,scanners = createFileScanners(request.getFiles(), smallestReadPoint);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,97,fd.maxMVCCReadpoint >= smallestReadPoint, fd.maxTagsLength > 0);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,104,throw new InterruptedIOException( "Aborting compaction of store " + store +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactor.java,84,private List<Path> compactInternal(StripeMultiFileWriter mw, CompactionRequest request,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactor.java,92,List<StoreFileScanner> scanners = createFileScanners(filesToCompact, smallestReadPoint);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactor.java,120,fd.maxKeyCount, compression, true, needMvcc, fd.maxTagsLength > 0);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,69,import org.apache.hadoop.hbase.ipc.PayloadCarryingRpcController;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,73,import org.apache.hadoop.hbase.protobuf.ResponseConverter;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,85,import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ClientService;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,86,import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,87,import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,673,HRegionLocation firstMetaServer = getFirstMetaServerForTable(tableName);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,674,Scan scan = MetaReader.getScanForTableName(tableName);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,675,scan.addColumn(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,676,ScanRequest request = RequestConverter.buildScanRequest(
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,677,firstMetaServer.getRegionInfo().getRegionName(), scan, 1, true);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,678,Result[] values = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,680,ClientService.BlockingInterface server = connection.getClient(firstMetaServer
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,681,.getServerName());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,682,PayloadCarryingRpcController controller = new PayloadCarryingRpcController();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,683,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,684,controller.setPriority(tableName);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,685,ScanResponse response = server.scan(controller, request);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,686,values = ResponseConverter.getResults(controller.cellScanner(), response);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,688,throw ProtobufUtil.getRemoteException(se);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,693,if (values == null || values.length == 0) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,713,if(failures == numRetries - 1) {           // no more tries left
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,715,throw ((RemoteException) ex).unwrapRemoteException();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,717,throw ex;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,283,outputFs.mkdirs(outputPath.getParent());
hbase-client/src/main/java/org/apache/hadoop/hbase/security/SaslUtil.java,69,static void initSaslProperties(String rpcProtection) {
hbase-client/src/main/java/org/apache/hadoop/hbase/security/SaslUtil.java,70,QualityOfProtection saslQOP = QualityOfProtection.AUTHENTICATION;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/SaslUtil.java,72,.equals(rpcProtection)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/security/SaslUtil.java,73,saslQOP = QualityOfProtection.INTEGRITY;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/SaslUtil.java,75,rpcProtection)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/security/SaslUtil.java,76,saslQOP = QualityOfProtection.PRIVACY;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,160,String qop, String name, String host, boolean framed, int frameSize) {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,172,saslProperties.put(Sasl.QOP, qop);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,350,String qop = conf.get(THRIFT_QOP_KEY);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,351,if (qop != null) {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,353,&& !qop.equals("auth-conf")) {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,354,throw new IOException("Invalid " + THRIFT_QOP_KEY + ": " + qop
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,355,+ ", it must be 'auth', 'auth-int', or 'auth-conf'");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2037,final boolean setOfflineInZK, final boolean forceNewPlan) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,881,this.authManager = TableAuthManager.get(zk, env.getConfiguration());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,48,public class TableAuthManager {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,95,private static TableAuthManager instance;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,735,static Map<ZooKeeperWatcher,TableAuthManager> managerMap =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,738,public synchronized static TableAuthManager get(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,740,instance = managerMap.get(watcher);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,46,public class ZKPermissionWatcher extends ZooKeeperListener {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,66,List<ZKUtil.NodeAndData> existing =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,67,ZKUtil.getChildDataAndWatchForNewChildren(watcher, aclZNode);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,68,if (existing != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,69,refreshNodes(existing);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,81,LOG.warn("Interrupted while waiting", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,90,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,91,List<ZKUtil.NodeAndData> nodes =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,92,ZKUtil.getChildDataAndWatchForNewChildren(watcher, aclZNode);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,93,refreshNodes(nodes);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,95,LOG.error("Error reading data from zookeeper", ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,97,watcher.abort("Zookeeper error obtaining acl node children", ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,103,public void nodeDeleted(String path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,106,String table = ZKUtil.getNodeName(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,107,if(AccessControlLists.isNamespaceEntry(table)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,108,authManager.removeNamespace(Bytes.toBytes(table));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,110,authManager.removeTable(TableName.valueOf(table));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,116,public void nodeDataChanged(String path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,120,String entry = ZKUtil.getNodeName(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,121,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,122,byte[] data = ZKUtil.getDataAndWatch(watcher, path);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,123,refreshAuthManager(entry, data);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,125,LOG.error("Error reading data from zookeeper for node " + entry, ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,127,watcher.abort("Zookeeper error getting data for node " + entry, ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,129,LOG.error("Error reading permissions writables", ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,135,public void nodeChildrenChanged(String path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,140,List<ZKUtil.NodeAndData> nodes =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,142,refreshNodes(nodes);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,150,private void refreshNodes(List<ZKUtil.NodeAndData> nodes) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1325,int ret = istream.read(fileOffset, dest, destOffset, size + extraSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1326,if (ret < size) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1327,throw new IOException("Positional read of " + size + " bytes " +
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1331,if (ret == size || ret < size + extraSize) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1193,if (hasCoprocessor(className)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1194,throw new IOException("Coprocessor " + className + " already exists.");
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1227,maxCoprocessorNumber = Math.max(Integer.parseInt(keyMatcher.group(1)),
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1228,maxCoprocessorNumber);
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1233,String value = ((jarFilePath == null)? "" : jarFilePath.toString()) +
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1235,kvString.toString();
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1236,setValue(key, value);
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1246,public boolean hasCoprocessor(String className) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1257,valueMatcher =
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1258,HConstants.CP_HTD_ATTR_VALUE_PATTERN.matcher(
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1259,Bytes.toString(e.getValue().get()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1260,if (!valueMatcher.matches()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1261,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1264,String clazz = valueMatcher.group(2).trim(); // classname is the 2nd field
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1265,if (clazz.equals(className.trim())) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1286,valueMatcher = HConstants.CP_HTD_ATTR_VALUE_PATTERN.matcher(Bytes
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1287,.toString(e.getValue().get()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1288,if (!valueMatcher.matches()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1289,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1291,result.add(valueMatcher.group(2).trim()); // classname is the 2nd field
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,144,for(CoprocessorEnvironment e: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,169,List<E> configured = new ArrayList<E>();
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,179,configured.add(loadInstance(implClass, Coprocessor.PRIORITY_SYSTEM, conf));
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,189,coprocessors.addAll(configured);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java,570,LOG.warn("#" + id + ", the task was rejected by the pool. This is unexpected." +
hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java,574,receiveGlobalFailure(initialActions, multiAction, loc, numAttempt, ree, errorsByServer);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1749,List<StoreFlushContext> storeFlushCtxs = new ArrayList<StoreFlushContext>(stores.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1771,storeFlushCtxs.add(s.createFlushContext(flushSeqId));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1775,for (StoreFlushContext flush : storeFlushCtxs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1814,for (StoreFlushContext flush : storeFlushCtxs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1820,for (StoreFlushContext flush : storeFlushCtxs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,2085,if (HStore.this.getCoprocessorHost() != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,2086,for (StoreFile sf : storeFiles) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,451,KeyValue peeked = this.heap.peek();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,452,if (peeked == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,459,byte[] row = peeked.getBuffer();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,460,int offset = peeked.getRowOffset();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,461,short length = peeked.getRowLength();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,468,KeyValue kv;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,475,LOOP: while((kv = this.heap.peek()) != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,296,return create(conf, fs, dstFamilyPath, linkedTable, linkedRegion, hfileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,331,Path backRefssDir = getBackReferencesDir(archiveStoreDir, hfileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,332,fs.mkdirs(backRefssDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,335,Path backRefPath = new Path(backRefssDir, refName);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,336,fs.createNewFile(backRefPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,343,fs.delete(backRefPath, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,362,final Path dstFamilyPath, final String hfileLinkName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,368,m.group(3), m.group(4));
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,439,restoreStoreFile(familyDir, regionInfo, storeFile);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,460,restoreStoreFile(familyDir, regionInfo, storeFile);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,543,restoreStoreFile(familyDir, snapshotRegionInfo, storeFile);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,561,final SnapshotRegionManifest.StoreFile storeFile) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,564,HFileLink.createFromHFileLink(conf, fs, familyDir, hfileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,568,HFileLink.create(conf, fs, familyDir, regionInfo, hfileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,735,manifest, manifest.getTableDescriptor(), restoreDir, monitor, status);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1212,assert abort? true: store.getFlushableSize() == 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/IncrementCoalescer.java,38,import org.apache.hadoop.hbase.client.HTable;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/IncrementCoalescer.java,268,HTable table = handler.getTable(row.getTable());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,542,private static ThreadLocal<Map<String, HTable>> threadLocalTables =
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,543,new ThreadLocal<Map<String, HTable>>() {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,545,protected Map<String, HTable> initialValue() {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,546,return new TreeMap<String, HTable>();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,580,public HTable getTable(final byte[] tableName) throws
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,583,Map<String, HTable> tables = threadLocalTables.get();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,584,if (!tables.containsKey(table)) {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,585,tables.put(table, (HTable)connectionCache.getTable(table));
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,587,return tables.get(table);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,590,public HTable getTable(final ByteBuffer tableName) throws IOException {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,729,HTable table;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,735,Map<HRegionInfo, ServerName> regionLocations =
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,736,table.getRegionLocations();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,792,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,804,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,834,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,847,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,877,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,891,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,925,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,948,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,988,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1013,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1032,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1045,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1061,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1067,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1125,HTable table = null;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1169,throw new IllegalArgument(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1227,HTable table = null;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1240,throw new IllegalArgument(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1259,HTable table;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1266,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1317,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1356,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1365,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1381,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1391,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1407,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1418,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1437,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1446,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1463,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1473,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1491,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1502,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1512,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1520,HTable table = getTable(getBytes(tableName));
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1532,HTable table = getTable(TableName.META_TABLE_NAME.getName());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1565,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1586,HTable table = getTable(tincrement.getTable());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1591,throw new IOError(e.getMessage());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,209,List<String> auths = EMPTY_LIST;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,210,Set<Integer> authOrdinals = getUserAuthsAsOrdinals(user);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,211,if (!authOrdinals.equals(EMPTY_SET)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,212,auths = new ArrayList<String>(authOrdinals.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,213,for (Integer authOrdinal : authOrdinals) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,214,auths.add(ordinalVsLabels.get(authOrdinal));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,217,return auths;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,221,List<String> auths = EMPTY_LIST;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,222,Set<Integer> authOrdinals = getGroupAuthsAsOrdinals(groups);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,223,if (!authOrdinals.equals(EMPTY_SET)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,224,auths = new ArrayList<String>(authOrdinals.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,225,for (Integer authOrdinal : authOrdinals) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,226,auths.add(ordinalVsLabels.get(authOrdinal));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,229,return auths;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelsCache.java,273,public void writeToZookeeper(byte[] data, boolean labelsOrUserAuths) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,92,for (Class<?> c : implClass.getInterfaces()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,362,for (Class<?> c : implClass.getInterfaces()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,304,for (Class c : implClass.getInterfaces()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,306,this.regionServerServices.registerService(((SingletonCoprocessorService) impl).getService());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,121,if (realIn.getClass().getName().endsWith("DFSInputStream")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,122,Method getFileLength = realIn.getClass().
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,123,getDeclaredMethod("getFileLength", new Class<?> []{});
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,124,getFileLength.setAccessible(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,125,long realLength = ((Long)getFileLength.
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,126,invoke(realIn, new Object []{})).longValue();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,127,assert(realLength >= this.length);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,128,adjust = realLength - this.length;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,130,LOG.info("Input stream class: " + realIn.getClass().getName() +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,134,SequenceFileLogReader.LOG.warn(
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClient.java,43,List<String> getListOfReplicators();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClient.java,51,List<String> getLogsInQueue(String serverName, String queueId);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClient.java,58,List<String> getAllQueues(String serverName);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClientZKImpl.java,49,public List<String> getLogsInQueue(String serverName, String queueId) {
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClientZKImpl.java,63,public List<String> getAllQueues(String serverName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,64,final Set<String> hlogs = loadHLogsFromQueues();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,69,boolean logInReplicationQueue = hlogs.contains(hlog);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,84,private Set<String> loadHLogsFromQueues() {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,85,List<String> rss = replicationQueues.getListOfReplicators();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,86,if (rss == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,87,LOG.debug("Didn't find any region server that replicates, won't prevent any deletions.");
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,88,return ImmutableSet.of();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,90,Set<String> hlogs = Sets.newHashSet();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,91,for (String rs: rss) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,92,List<String> listOfPeers = replicationQueues.getAllQueues(rs);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,94,if (listOfPeers == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,95,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,97,for (String id : listOfPeers) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,98,List<String> peersHlogs = replicationQueues.getLogsInQueue(rs, id);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,99,if (peersHlogs != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,100,hlogs.addAll(peersHlogs);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,104,return hlogs;
hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterId.java,21,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterId.java,69,cid = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,49,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,1259,cfs = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,50,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,948,HBaseProtos.RegionInfo ri =
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,949,HBaseProtos.RegionInfo.newBuilder().
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,950,mergeFrom(bytes, pblen + offset, len - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,58,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,59,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1444,ts = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,39,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1768,callback.update(region, row.getRow(),
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1769,(R) responsePrototype.newBuilderForType().mergeFrom(
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1770,serviceResult.getValue().getValue()).build());
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/MasterCoprocessorRpcChannel.java,72,.mergeFrom(result.getValue().getValue()).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionCoprocessorRpcChannel.java,101,.mergeFrom(result.getValue().getValue()).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionServerCoprocessorRpcChannel.java,66,response =
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionServerCoprocessorRpcChannel.java,67,responsePrototype.newBuilderForType().mergeFrom(result.getValue().getValue()).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,1111,builder.mergeDelimitedFrom(in);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2692,proto = builder.mergeFrom(protoBytes).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2734,proto = builder.mergeFrom(protoBytes).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeerZKImpl.java,43,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeerZKImpl.java,251,state = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,50,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,482,peer = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/security/token/AuthenticationTokenIdentifier.java,139,AuthenticationProtos.TokenIdentifier identifier =
hbase-client/src/main/java/org/apache/hadoop/hbase/security/token/AuthenticationTokenIdentifier.java,140,AuthenticationProtos.TokenIdentifier.newBuilder().mergeFrom(inBytes).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTableReadOnly.java,22,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTableReadOnly.java,157,ZooKeeperProtos.Table t = builder.mergeFrom(data, magicLen, data.length - magicLen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTableReadOnly.java,158,return t.getState();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,75,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1706,String clusterKey = ZooKeeperProtos.ReplicationPeer.newBuilder().
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1707,mergeFrom(data, pblen, data.length - pblen).getClusterkey();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1708,sb.append("\n").append(znodeToProcess).append(": ").append(clusterKey);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1710,appendPeerState(zkw, znodeToProcess, sb);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1718,StringBuilder sb) throws KeeperException, InvalidProtocolBufferException {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1728,.mergeFrom(peerStateData, pblen, peerStateData.length - pblen).getState().name());
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1945,position = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,2001,storeIds = regionSequenceIdsBuilder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/model/CellModel.java,199,builder.mergeFrom(message);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java,136,builder.mergeFrom(message);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java,812,builder.mergeFrom(message);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/model/StorageClusterStatusModel.java,751,builder.mergeFrom(message);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/model/TableInfoModel.java,149,builder.mergeFrom(message);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/model/TableListModel.java,107,builder.mergeFrom(message);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/model/TableSchemaModel.java,312,builder.mergeFrom(message);
hbase-rest/src/main/java/org/apache/hadoop/hbase/rest/model/VersionModel.java,191,builder.mergeFrom(message);
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogTask.java,30,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogTask.java,165,ZooKeeperProtos.SplitLogTask slt = ZooKeeperProtos.SplitLogTask.newBuilder().
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogTask.java,166,mergeFrom(data, prefixLen, data.length - prefixLen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogTask.java,167,return new SplitLogTask(slt);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,123,import com.google.protobuf.Message.Builder;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1678,RequestHeader header = RequestHeader.newBuilder().mergeFrom(buf, offset, headerSize).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1705,Builder builder = this.service.getRequestPrototype(md).newBuilderForType();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1711,param = builder.mergeFrom(buf, offset, paramSize).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MutationSerialization.java,28,import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MutationSerialization.java,60,MutationProto proto = MutationProto.parseDelimitedFrom(in);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ResultSerialization.java,128,ClientProtos.Result proto = ClientProtos.Result.parseDelimitedFrom(in);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2972,.mergeFrom(call.getRequest()).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,45,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,217,ZooKeeperProtos.TableLock data = ZooKeeperProtos.TableLock.newBuilder().mergeFrom(
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,218,bytes, pblen, bytes.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,219,return data;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5899,.mergeFrom(call.getRequest()).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3476,Message request =
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3478,.build();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,24,import java.io.InputStream;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,36,import org.apache.hadoop.hbase.HBaseInterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,45,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,295,final InputStream limitedInput = new LimitInputStream(this.inputStream, size);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,296,builder.mergeFrom(limitedInput);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,72,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,602,AccessControlProtos.UsersAndPermissions perms =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,603,AccessControlProtos.UsersAndPermissions.newBuilder().mergeFrom(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,604,data, pblen, data.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,605,return ProtobufUtil.toUserTablePermissions(perms);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,701,ListMultimap<String,Permission> kvPerms = ProtobufUtil.toUsersAndPermissions(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,702,AccessControlProtos.UsersAndPermissions.newBuilder().mergeFrom(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,703,tag.getBuffer(), tag.getTagOffset(), tag.getTagLength()).build());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1816,ListMultimap<String,Permission> kvPerms = ProtobufUtil.toUsersAndPermissions(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1817,AccessControlProtos.UsersAndPermissions.newBuilder().mergeFrom(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1818,tag.getBuffer(), tag.getTagOffset(), tag.getTagLength()).build());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/HbaseObjectWritableFor96Migration.java,671,instance = ProtobufUtil.toScan(scanProto.mergeFrom(scanBytes).build());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,68,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,169,.mergeFrom(data, pblen, data.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,170,return request.getVisLabelList();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,190,.mergeFrom(data, pblen, data.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,191,return multiUserAuths;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,84,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,544,FSProtos.HBaseVersionFileContent fileContent;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,546,fileContent = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,547,return fileContent.getVersion();
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/LoadBalancerTracker.java,30,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/LoadBalancerTracker.java,88,builder.mergeFrom(pbBytes, magicLen, pbBytes.length - magicLen);
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RegionServerTracker.java,92,rsInfoBuilder.mergeFrom(data, magicLen, data.length - magicLen);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,687,conf.getLong("hbase.hregion.memstore.block.multiplier", 2);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,352,if (useLock) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,353,lockEntry = offsetLock.getLockEntry(dataBlockOffset);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,357,if (cacheConf.isBlockCacheEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,385,if (!useLock) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,387,useLock = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,388,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,656,int sleepMultiplier = 1;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1148,writeToWAL? Durability.SKIP_WAL: Durability.USE_DEFAULT);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1781,this.dataLengthBuffer = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,23,import java.security.SecureRandom;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,130,salter = new SecureRandom();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java,33,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java,34,import org.apache.hadoop.hbase.classification.InterfaceStability;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java,441,if (hfileOutPath != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1245,LOG.fatal("should never happen: has unsynced writes but writer is null!");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1255,LOG.fatal("Error while AsyncSyncer sync, request close of hlog ", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1532,LOG.fatal("Could not append. Requesting close of hlog", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1717,this.leases.setName(n + ".leaseChecker");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1718,this.leases.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5851,LOG.error("Coprocessor service "+serviceDesc.getFullName()+
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3458,public CoprocessorServiceResponse execRegionServerService(final RpcController controller,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3461,ServerRpcController execController = new ServerRpcController();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3481,service.callMethod(methodDesc, controller, request, new RpcCallback<Message>() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3489,Message execResult = responseBuilder.build();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3490,if (execController.getFailedOn() != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3491,throw execController.getFailedOn();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,222,String compactionName =
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,223,store.getRegionInfo().getRegionNameAsString() + "#" + store.getFamily().getNameAsString();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1138,ClusterStatusProtos.ServerLoad buildServerLoad(long reportStartTime, long reportEndTime) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1157,Set<String> coprocessors = this.hlog.getCoprocessorHost().getCoprocessors();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1159,serverLoad.addCoprocessors(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1160,Coprocessor.newBuilder().setName(coprocessor).build());
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,232,name.append(hostName);
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,317,return left.getHostname().equals(right.getHostname()) &&
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,822,int nbFiles = hstoreFilesToSplit.size();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,827,LOG.info("Preparing to split " + nbFiles + " storefiles for region " + this.parent);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,832,(ThreadPoolExecutor) Executors.newFixedThreadPool(nbFiles, factory);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,884,private Pair<Path, Path> splitStoreFile(final byte[] family, final StoreFile sf) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1971,AuthenticationTokenSecretManager mgr = createSecretManager();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1972,if (mgr != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1973,setSecretManager(mgr);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1974,mgr.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java,347,kvScanner.enforceSeek();
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValueUtil.java,85,buffer.position(buffer.limit());//make it look as if each field were appended
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValueUtil.java,129,buffer.position(buffer.limit());//make it look as if each field were appended
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java,21494,new java.lang.String[] { "RegionA", "RegionB", "Forcible", });
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/VisibilityLabelsProtos.java,5095,com.google.protobuf.ByteString bs =
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/VisibilityLabelsProtos.java,5111,com.google.protobuf.ByteString b =
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/VisibilityLabelsProtos.java,5417,com.google.protobuf.ByteString b =
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,79,Delete delete = new Delete(regionInfo.getRegionName());
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,314,ServerName sn) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,320,Put putOfMerged = makePutFromRegionInfo(copyOfMerged);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,327,Delete deleteA = makeDeleteFromRegionInfo(regionA);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,328,Delete deleteB = makeDeleteFromRegionInfo(regionB);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,425,updateLocation(catalogTracker, regionInfo, sn, openSeqNum);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,443,updateLocation(catalogTracker, regionInfo, sn, updateSeqNum);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,462,Put put = new Put(regionInfo.getRegionName());
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,575,long now = EnvironmentEdgeManager.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,576,p.addImmutable(HConstants.CATALOG_FAMILY, HConstants.SERVER_QUALIFIER, now,
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,578,p.addImmutable(HConstants.CATALOG_FAMILY, HConstants.STARTCODE_QUALIFIER, now,
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,580,p.addImmutable(HConstants.CATALOG_FAMILY, HConstants.SEQNUM_QUALIFIER, now,
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,581,Bytes.toBytes(openSeqNum));
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStateStore.java,35,import org.apache.hadoop.hbase.client.HTable;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStateStore.java,235,MetaEditor.mergeRegions(catalogTracker, p, a, b, sn);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,202,final HRegion b, final boolean forcible) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,204,mergePool.execute(new RegionMergeRequest(a, b, this.server, forcible));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4136,compactSplitThread.requestRegionsMerge(regionA, regionB, forcible);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeRequest.java,45,RegionMergeRequest(HRegion a, HRegion b, HRegionServer hrs, boolean forcible) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeRequest.java,69,region_b, forcible);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,45,import org.apache.hadoop.hbase.client.HTable;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,326,.getRegionInfo(), region_b.getRegionInfo(), server.getServerName());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,355,Put putOfMerged = MetaEditor.makePutFromRegionInfo(copyOfMerged);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,360,Delete deleteA = MetaEditor.makeDeleteFromRegionInfo(regionA);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,361,Delete deleteB = MetaEditor.makeDeleteFromRegionInfo(regionB);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java,132,if (!this.assignmentManager.getZKTable().checkAndSetEnablingTable(tableName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeRequest.java,134,LOG.error("Could not release the table lock (something is really wrong). "
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,151,LOG.error("Could not release the table lock (something is really wrong). "
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,187,new SnapshotSubprocedurePool(rss.getServerName().toString(), conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,199,new SnapshotSubprocedurePool(rss.getServerName().toString(), conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,265,SnapshotSubprocedurePool(String name, Configuration conf) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,325,if (e.getCause() instanceof ForeignException) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,365,this.executor.shutdownNow();
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureCoordinatorRpcs.java,235,if (!ProtobufUtil.isPBMagicPrefix(data)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,312,if (!ProtobufUtil.isPBMagicPrefix(data)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,607,return (data.length == 0);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,45,import org.apache.hadoop.hbase.util.Threads;
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,66,Put put = new Put(regionInfo.getRegionName());
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,276,puts.add(makePutFromRegionInfo(regionInfo));
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,493,deletes.add(new Delete(hri.getRegionName()));
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,537,deleteRegions(catalogTracker, regionInfos);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,542,Threads.sleep(20);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,543,addRegionsToMeta(catalogTracker, regionInfos);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,394,if (authorizeUser(user, action)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,436,public boolean authorizeUser(User user, Permission.Action action) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,437,return authorize(globalCache.getUser(user.getShortName()), action);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,257,KeyValue kv = new KeyValue(kvBuf.array(), kvBuf.arrayOffset(), kvBuf.array().length
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,258,- kvBuf.arrayOffset());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Get.java,107,this.familyMap = get.getFamilyMap();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,813,return ProtobufUtil.get(getStub(), getLocation().getRegionInfo().getRegionName(), get,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,814,controller);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1291,get.setCheckExistenceOnly(true);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1292,Result r = get(get);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1306,g.setCheckExistenceOnly(true);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1311,r1 = batch(gets);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,945,javax.security.auth.login.Configuration testConfig = javax.security.auth.login.Configuration.getConfiguration();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,946,if(testConfig.getAppConfigurationEntry("Client") == null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,955,return("kerberos".equalsIgnoreCase(conf.get("hbase.security.authentication")) &&
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,956,conf.get("hbase.zookeeper.client.keytab.file") != null);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,972,if ((node.equals(zkw.baseZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,973,(node.equals(zkw.metaServerZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,974,(node.equals(zkw.getMasterAddressZNode()) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,975,(node.equals(zkw.clusterIdZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,976,(node.equals(zkw.rsZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,977,(node.equals(zkw.backupMasterAddressesZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,978,(node.startsWith(zkw.assignmentZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,979,(node.startsWith(zkw.tableZNode) == true)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,35,import org.apache.hadoop.hbase.util.Threads;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,963,if (isSecureZooKeeper(zkw.getConfiguration())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,23,import java.util.HashMap;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,24,import java.util.Iterator;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,26,import java.util.Map;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,27,import java.util.Map.Entry;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,28,import java.util.Set;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,58,private Map<Long, Pair<List<Tag>, Byte>> visibilityTagsDeleteFamily =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,59,new HashMap<Long, Pair<List<Tag>, Byte>>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,62,private Map<Long,Pair<List<Tag>, Byte>> visibilityTagsDeleteFamilyVersion =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,63,new HashMap<Long,Pair<List<Tag>, Byte>>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,84,extractDeleteCellVisTags(delCell, KeyValue.Type.DeleteFamily);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,118,private void extractDeleteCellVisTags(Cell delCell, Type type) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,127,visibilityTagsDeleteFamily.put(delCell.getTimestamp(), new Pair<List<Tag>, Byte>(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,128,delTags, deleteCellVisTagsFormat));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,136,visibilityTagsDeleteFamilyVersion.put(delCell.getTimestamp(), new Pair<List<Tag>, Byte>(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,137,delTags, deleteCellVisTagsFormat));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,193,Set<Entry<Long, Pair<List<Tag>, Byte>>> deleteFamilies = visibilityTagsDeleteFamily
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,194,.entrySet();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,195,Iterator<Entry<Long, Pair<List<Tag>, Byte>>> iterator = deleteFamilies.iterator();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,196,while (iterator.hasNext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,197,Entry<Long, Pair<List<Tag>, Byte>> entry = iterator.next();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,198,if (timestamp <= entry.getKey()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,203,.matchVisibility(putVisTags, putCellVisTagsFormat, entry.getValue().getFirst(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,204,entry.getValue().getSecond());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,211,if (!VisibilityUtils.isVisibilityTagsPresent(cell)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,219,Pair<List<Tag>, Byte> tags = visibilityTagsDeleteFamilyVersion.get(Long
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,220,.valueOf(timestamp));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,221,if (tags != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,222,List<Tag> putVisTags = new ArrayList<Tag>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,223,Byte putCellVisTagsFormat = VisibilityUtils.extractVisibilityTags(cell, putVisTags);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,224,boolean matchFound = VisibilityLabelServiceManager
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,227,.matchVisibility(putVisTags, putCellVisTagsFormat, tags.getFirst(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,228,tags.getSecond());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,229,if (matchFound) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,230,return DeleteResult.FAMILY_VERSION_DELETED;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,311,visibilityTagsDeleteFamily = new HashMap<Long, Pair<List<Tag>, Byte>>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityScanDeleteTracker.java,312,visibilityTagsDeleteFamilyVersion = new HashMap<Long, Pair<List<Tag>, Byte>>();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,457,public static void sniff(final HBaseAdmin admin, TableName tableName) throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,136,this(new RegionServerStdOutSink());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,139,public Canary(Sink sink) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,235,do {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,237,monitor = this.newMonitor(index, args);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,238,monitorThread = new Thread(monitor);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,239,startTime = System.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,240,monitorThread.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,241,while (!monitor.isDone()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,243,Thread.sleep(1000);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,245,if (this.failOnError && monitor.hasError()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,246,monitorThread.interrupt();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,247,if (monitor.initialized) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,250,System.exit(INIT_ERROR_EXIT_CODE);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,253,currentTimeLength = System.currentTimeMillis() - startTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,254,if (currentTimeLength > this.timeout) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,255,LOG.error("The monitor is running too long (" + currentTimeLength
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,256,+ ") after timeout limit:" + this.timeout
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,257,+ " will be killed itself !!");
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,258,if (monitor.initialized) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,259,System.exit(TIMEOUT_ERROR_EXIT_CODE);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,261,System.exit(INIT_ERROR_EXIT_CODE);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,263,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,267,if (this.failOnError && monitor.hasError()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,268,monitorThread.interrupt();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,269,System.exit(monitor.errorCode);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,272,Thread.sleep(interval);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,303,public Monitor newMonitor(int index, String[] args) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,313,if(this.regionServerMode) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,314,monitor = new RegionServerMonitor(
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,315,this.conf,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,316,monitorTargets,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,317,this.useRegExp,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,318,(ExtendedSink)this.sink);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,320,monitor = new RegionMonitor(this.conf, monitorTargets, this.useRegExp, this.sink);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,326,public static abstract class Monitor implements Runnable {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,328,protected Configuration config;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,346,protected Monitor(Configuration config, String[] monitorTargets,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,347,boolean useRegExp, Sink sink) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,349,throw new IllegalArgumentException("config shall not be null");
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,351,this.config = config;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,362,this.admin = new HBaseAdmin(config);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,378,public RegionMonitor(Configuration config, String[] monitorTargets,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,379,boolean useRegExp, Sink sink) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,380,super(config, monitorTargets, useRegExp, sink);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,385,if(this.initAdmin()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,391,Canary.sniff(admin, sink, table);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,394,sniff();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,407,if(this.useRegExp) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,426,if(tmpTables.size() > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,429,String msg = "No HTable found, tablePattern:"
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,430,+ Arrays.toString(monitorTargets);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,445,private void sniff() throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,447,Canary.sniff(admin, sink, table);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,458,sniff(admin, new StdOutSink(), tableName.getNameAsString());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,466,throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,467,if (admin.isTableAvailable(tableName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,468,sniff(admin, sink, admin.getTableDescriptor(tableName.getBytes()));
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,470,LOG.warn(String.format("Table %s is not available", tableName));
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,478,throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,479,HTable table = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,482,table = new HTable(admin.getConfiguration(), tableDesc.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,484,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,488,for (HRegionInfo region : admin.getTableRegions(tableDesc.getName())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,489,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,490,sniffRegion(admin, sink, region, table);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,492,sink.publishReadFailure(region, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,493,LOG.debug("sniffRegion failed", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,509,HTable table) throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,557,public RegionServerMonitor(Configuration config, String[] monitorTargets,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,558,boolean useRegExp, ExtendedSink sink) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,559,super(config, monitorTargets, useRegExp, sink);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,607,String serverName = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,608,String tableName = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,609,HRegionInfo region = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,610,HTable table = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,611,Get get = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,612,byte[] startKey = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,613,Scan scan = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,614,StopWatch stopWatch = new StopWatch();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,617,stopWatch.reset();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,618,serverName = entry.getKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,620,region = entry.getValue().get(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,621,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,622,tableName = region.getTable().getNameAsString();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,623,table = new HTable(this.admin.getConfiguration(), tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,624,startKey = region.getStartKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,626,if(startKey.length > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,627,get = new Get(startKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,628,stopWatch.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,629,table.get(get);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,630,stopWatch.stop();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,632,scan = new Scan();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,633,scan.setCaching(1);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,634,scan.setMaxResultSize(1L);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,635,stopWatch.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,636,table.getScanner(scan);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,637,stopWatch.stop();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,639,this.getSink().publishReadTiming(tableName, serverName, stopWatch.getTime());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,644,LOG.debug("The targeted table was disabled.  Assuming success.");
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,646,this.getSink().publishReadFailure(tableName, serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,647,LOG.error(dnrioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,649,this.getSink().publishReadFailure(tableName, serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,650,LOG.error(e);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,651,this.errorCode = ERROR_EXIT_CODE;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,653,if (table != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,654,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,655,table.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,659,scan = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,660,get = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,661,startKey = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,674,HTable table = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,679,table = new HTable(this.admin.getConfiguration(), tableDesc.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,681,for (Map.Entry<HRegionInfo, ServerName> entry : table
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,682,.getRegionLocations().entrySet()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,683,ServerName rs = entry.getValue();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,685,HRegionInfo r = entry.getKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,729,for (Map.Entry<String,List<HRegionInfo>> entry : fullRsAndRMap.entrySet()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,757,int exitCode = ToolRunner.run(conf, new Canary(), args);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/ReplicationEndpoint.java,130,class ReplicateContext {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,130,private ReplicationEndpoint.ReplicateContext replicateContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,185,this.replicateContext = new ReplicationEndpoint.ReplicateContext();
hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java,278,public static final int DEFAULT_HBASE_CLIENT_OPERATION_TIMEOUT = Integer.MAX_VALUE;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,406,LOG.info("Waited " + (System.currentTimeMillis() - fqe.createTime) +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,535,long start = System.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,557,long took = System.currentTimeMillis() - start;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,633,this.createTime = System.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,642,return (System.currentTimeMillis() - this.createTime) > maximumWait;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,660,this.whenToExpire = System.currentTimeMillis() + when;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,667,return unit.convert(this.whenToExpire - System.currentTimeMillis(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3968,KeyValueScanner scanner = store.getScanner(scan, entry.getValue(), this.readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4102,do {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4103,heap.next(results, limit - results.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4104,if (limit > 0 && results.size() == limit) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4105,return KV_LIMIT;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4107,nextKv = heap.peek();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java,26,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3227,if (request.getNextCallSeq() != rsh.nextCallSeq) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3228,throw new OutOfOrderScannerNextException("Expected nextCallSeq: " + rsh.nextCallSeq
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3233,rsh.nextCallSeq++;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4838,private long nextCallSeq = 0L;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,22,import java.util.Collection;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,220,public void controllerConnectionFailure(final String message, final IOException cause) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,221,Collection<Subprocedure> toNotify = subprocs.values();
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,223,for (Subprocedure sub : toNotify) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,225,sub.cancel(message, cause);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,146,+ zkController.getAbortZnode(), new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,163,new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,195,+ ") for procedure :" + opName, new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,223,new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,251,+ procName + " and member: " + memberName, new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,268,+ " to join procedure barrier.", new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,295,+ " to abort procedure", new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,332,+ zkController.getAbortZnode(), new IOException(e));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/SecureBulkLoadUtil.java,40,return new Path(conf.get(BULKLOAD_STAGING_DIR, "/tmp/hbase-staging"));
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/HFileOutputFormat2.java,545,Path partitionsPath = new Path(conf.get("hadoop.tmp.dir"), "partitions_" + UUID.randomUUID());
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,54,public static int defMasterRMIRegistryPort = 10101;
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,55,public static int defRegionserverRMIRegistryPort = 10102;
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,161,conf.getInt("master" + RMI_REGISTRY_PORT_CONF_KEY,
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,162,defMasterRMIRegistryPort);
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,163,rmiConnectorPort =
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,164,conf.getInt("master" + RMI_CONNECTOR_PORT_CONF_KEY, rmiRegistryPort);
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,165,LOG.info("Master rmiRegistryPort:" + rmiRegistryPort
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,166,+ ",Master rmiConnectorPort:" + rmiConnectorPort);
hbase-server/src/main/java/org/apache/hadoop/hbase/JMXListener.java,176,+ ",RegionServer rmiConnectorPort:" + rmiConnectorPort);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,573,if (top) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,575,KeyValue splitKey = KeyValue.createFirstOnRow(splitRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,576,byte[] lastKey = f.createReader().getLastKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,578,if (lastKey == null) return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,579,if (f.getReader().getComparator().compareFlatKey(splitKey.getBuffer(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,580,splitKey.getKeyOffset(), splitKey.getKeyLength(), lastKey, 0, lastKey.length) > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,581,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,585,KeyValue splitKey = KeyValue.createLastOnRow(splitRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,586,byte[] firstKey = f.createReader().getFirstKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,588,if (firstKey == null) return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,589,if (f.getReader().getComparator().compareFlatKey(splitKey.getBuffer(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,590,splitKey.getKeyOffset(), splitKey.getKeyLength(), firstKey, 0, firstKey.length) < 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,591,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,596,f.closeReader(true);
hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java,162,hash = 31 * hash + (int)cell.getMvccVersion();
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1058,byte[] b = getBuffer();
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1059,int start = getOffset(), end = getOffset() + getLength();
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1060,int h = b[start++];
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1061,for (int i = start; i < end; i++) {
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1062,h = (h * 13) ^ b[i];
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1064,return h;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java,112,scan, getConnection(), getTable(), localStartKey, cacheNum, this.rpcControllerFactory);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,158,scan, getConnection(), getTable(), localStartKey, cacheNum, rpcControllerFactory);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,68,private boolean closed = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,265,private void updateResultsMetrics(Result[] rrs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2030,int processingTime = (int) (System.currentTimeMillis() - startTime);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,67,import com.yammer.metrics.core.MetricsRegistry;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,313,addDependencyJars(job.getConfiguration(), MetricsRegistry.class);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,705,org.cliffc.high_scale_lib.Counter.class); // needed for mapred over snapshots
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogFactory.java,118,FSDataInputStream stream = fs.open(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,280,Reader in = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java,184,long subsequentPause = conf.getInt("hbase.lease.recovery.dfs.timeout", 61 * 1000);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java,205,subsequentPause) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1781,String s = "Finished memstore snapshotting " + this +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1783,status.setStatus(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1784,if (LOG.isTraceEnabled()) LOG.trace(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1788,if (wal != null && !shouldSyncLog()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1789,wal.sync();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1797,mvcc.waitForRead(w);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1799,s = "Flushing stores of " + this;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1800,status.setStatus(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1801,if (LOG.isTraceEnabled()) LOG.trace(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,329,long size = selectNow ? compaction.getRequest().getSize() : 0;
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactoryImpl.java,25,private static enum SourceStorage {
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactoryImpl.java,28,private static enum SourceStorage {
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,53,AUTHORIZATION_SUCCESSES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,55,AUTHORIZATION_FAILURES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,58,AUTHENTICATION_SUCCESSES_NAME, AUTHENTICATION_SUCCESSES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,60,AUTHENTICATION_FAILURES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,62,SENT_BYTES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,64,RECEIVED_BYTES_DESC, 0l);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1692,setupResponse(responseBuffer, callTooBig, new CallQueueTooBigException(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3667,checkRow(row, "row lock");
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,349,private static byte[] getNextForFuzzyRule(boolean reverse, byte[] row, int offset, int length,
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,374,if (!order.isMax(row[i])) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileLinkCleaner.java,24,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileLinkCleaner.java,60,hfilePath = HFileLink.getHFileFromBackReference(getConf(), filePath);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactionPolicy.java,251,if (canDropDeletesWithoutL0 || includeL0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,113,IOEngine ioEngine;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,117,Map<BlockCacheKey, RAMQueueEntry> ramCache;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,119,private ConcurrentHashMap<BlockCacheKey, BucketEntry> backingMap;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,136,ArrayList<BlockingQueue<RAMQueueEntry>> writerQueues =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,139,WriterThread writerThreads[];
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,145,private Lock freeSpaceLock = new ReentrantLock();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,158,private final Object[] cacheWaitSignals;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,165,private BucketCacheStats cacheStats = new BucketCacheStats();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,167,private String persistencePath;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,168,private long cacheCapacity;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,188,private IdLock offsetLock = new IdLock();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,226,this.cacheWaitSignals = new Object[writerThreadNum];
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,241,this.cacheWaitSignals[i] = new Object();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,262,writerThreads[i] = new WriterThread(writerQueues.get(i), i);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,350,public void cacheBlockWithWait(BlockCacheKey cacheKey, Cacheable cachedItem,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,351,boolean inMemory, boolean wait) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,362,RAMQueueEntry re = new RAMQueueEntry(cacheKey, cachedItem,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,363,accessCount.incrementAndGet(), inMemory);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,364,ramCache.put(cacheKey, re);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,367,boolean successfulAddition = bq.offer(re);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,368,if (!successfulAddition && wait) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,369,synchronized (cacheWaitSignals[queueNum]) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,370,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,371,successfulAddition = bq.offer(re);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,372,if (!successfulAddition) cacheWaitSignals[queueNum].wait(DEFAULT_CACHE_WAIT_TIME);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,374,Thread.currentThread().interrupt();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,380,ramCache.remove(cacheKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,381,failedBlockAdditions.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,404,if (updateCacheMetrics) cacheStats.hit(caching);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,444,if (!repeat && updateCacheMetrics) cacheStats.miss(caching);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,450,if (!cacheEnabled) return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,468,if (bucketEntry.equals(backingMap.remove(cacheKey))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,469,bucketAllocator.freeBlock(bucketEntry.offset());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,470,realCacheSize.addAndGet(-1 * bucketEntry.getLength());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,471,blocksByHFile.remove(cacheKey.getHfileName(), cacheKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,472,if (removedBlock == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,473,this.blockNumber.decrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,705,private final int threadNO;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,708,WriterThread(BlockingQueue<RAMQueueEntry> queue, int threadNO) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,709,super();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,711,this.threadNO = threadNO;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,728,synchronized (cacheWaitSignals[threadNO]) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,729,cacheWaitSignals[threadNO].notifyAll();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,755,if (entries.isEmpty()) return;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1055,static class BucketEntry implements Serializable, Comparable<BucketEntry> {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1061,private volatile long accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1068,BucketEntry(long offset, int length, long accessTime, boolean inMemory) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1071,this.accessTime = accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1112,public void access(long accessTime) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1113,this.accessTime = accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1124,public int compareTo(BucketEntry that) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1125,if(this.accessTime == that.accessTime) return 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1126,return this.accessTime < that.accessTime ? 1 : -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1130,public boolean equals(Object that) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1131,return this == that;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1204,private long accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1207,public RAMQueueEntry(BlockCacheKey bck, Cacheable data, long accessTime,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1211,this.accessTime = accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1223,public void access(long accessTime) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1224,this.accessTime = accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1236,BucketEntry bucketEntry = new BucketEntry(offset, len, accessTime, inMemory);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,59,queue = MinMaxPriorityQueue
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,60,.orderedBy(new Comparator<Map.Entry<BlockCacheKey, BucketEntry>>() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,61,public int compare(Entry<BlockCacheKey, BucketEntry> entry1,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,62,Entry<BlockCacheKey, BucketEntry> entry2) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,63,return entry1.getValue().compareTo(entry2.getValue());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,86,if (entry.getValue().compareTo(head) > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,69,import org.apache.hadoop.hbase.coprocessor.MasterObserver;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,411,private void requirePermission(String request, TableName tableName, byte[] family, byte[] qualifier,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,412,Action... permissions) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,428,if (!result.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,458,if (!result.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,481,private void requirePermission(String request, Action perm,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,482,RegionCoprocessorEnvironment env,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,484,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,485,User user = getActiveUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,486,AuthResult result = permissionGranted(request, user, perm, env, families);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,487,logResult(result);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,489,if (!result.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,490,throw new AccessDeniedException("Insufficient permissions (table=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,491,env.getRegion().getTableDesc().getTableName()+
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,492,((families != null && families.size() > 0) ? ", family: " +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,493,result.toFamilyString() : "") + ", action=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,494,perm.toString() + ")");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,514,throw new AccessDeniedException("Insufficient permissions for user '" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,535,throw new AccessDeniedException("Insufficient permissions for user '" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1089,+ AccessControlLists.ACL_TABLE_NAME + " table.");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1313,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1314,throw new AccessDeniedException("Insufficient permissions " + authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1357,Filter ourFilter = new AccessControlFilter(authManager, user, table,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1358,AccessControlFilter.Strategy.CHECK_TABLE_AND_CF_ONLY,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1359,cfVsMaxVersions);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1361,if (filter != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1362,ourFilter = new FilterList(FilterList.Operator.MUST_PASS_ALL,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1363,Lists.newArrayList(ourFilter, filter));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1365,authResult.setAllowed(true);;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1367,switch (opType) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1368,case GET:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1369,case EXISTS:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1370,((Get)query).setFilter(ourFilter);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1371,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1372,case SCAN:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1373,((Scan)query).setFilter(ourFilter);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1374,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1375,default:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1376,throw new RuntimeException("Unhandled operation " + opType);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1384,Filter ourFilter = new AccessControlFilter(authManager, user, table,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1385,AccessControlFilter.Strategy.CHECK_CELL_DEFAULT, cfVsMaxVersions);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1387,if (filter != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1388,ourFilter = new FilterList(FilterList.Operator.MUST_PASS_ALL,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1389,Lists.newArrayList(ourFilter, filter));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1391,authResult.setAllowed(true);;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1393,switch (opType) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1394,case GET:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1395,case EXISTS:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1396,((Get)query).setFilter(ourFilter);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1397,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1398,case SCAN:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1399,((Scan)query).setFilter(ourFilter);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1400,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1401,default:
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1402,throw new RuntimeException("Unhandled operation " + opType);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1408,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1437,User user = getActiveUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1438,checkForReservedTagPresence(user, put);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1491,throw new AccessDeniedException("Insufficient permissions " + authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1514,if (checkCoveringPermission(opType, c.getEnvironment(), m.getRow(), m.getFamilyCellMap(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1515,m.getTimeStamp(), Action.WRITE)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1516,authResult = AuthResult.allow(opType.toString(), "Covering cell set", getActiveUser(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1517,Action.WRITE, table, m.getFamilyCellMap());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1519,authResult = AuthResult.deny(opType.toString(), "Covering cell set", getActiveUser(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1520,Action.WRITE, table, m.getFamilyCellMap());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1523,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1525,+ authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1559,throw new AccessDeniedException("Insufficient permissions " + authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1593,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1623,throw new AccessDeniedException("Insufficient permissions " + authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1650,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1675,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1695,throw new AccessDeniedException("Insufficient permissions " + authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1726,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1727,throw new AccessDeniedException("Insufficient permissions " + authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1750,throw new AccessDeniedException("Insufficient permissions " + authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1781,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1782,throw new AccessDeniedException("Insufficient permissions " + authResult.toContextString());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1875,if (user != null && user.getShortName() != null) {      // store reference to scanner owner for later checks
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,2007,perm.getQualifier(), Action.ADMIN);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,2011,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,2058,perm.getQualifier(), Action.ADMIN);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,2164,Map<byte[], Set<byte[]>> familyMap = new TreeMap<byte[], Set<byte[]>>(Bytes.BYTES_COMPARATOR);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,2175,requirePermission("checkPermissions", action, regionEnv, familyMap);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,2180,requirePermission("checkPermissions", action);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,130,private boolean acOn = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,249,this.acOn = CoprocessorHost.getLoadedCoprocessors().contains(AccessController.class.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,303,miniBatchOp.setOperationStatus(i, new OperationStatus(SANITY_CHECK_FAILURE,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,305,sanityFailure = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,324,boolean authCheck = this.checkAuths && !(isSystemOrSuperUser());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,620,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,622,throw new VisibilityControllerNotReadyException("VisibilityController not yet initialized!");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,705,boolean authCheck = this.checkAuths && !(isSystemOrSuperUser());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,753,checkCallingUserAuth();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,813,checkCallingUserAuth();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,889,if (this.acOn && !isSystemOrSuperUser()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,943,if (this.acOn && !isSystemOrSuperUser()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,948,checkCallingUserAuth(); // When AC is not in place the calling user should have SYSTEM_LABEL
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,993,if (this.acOn && !isSystemOrSuperUser()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,1017,if (!this.acOn) {
hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSource.java,268,String SPLIT_SUCCESS_KEY = "splitSuccessCounnt";
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,26,import org.apache.hadoop.hbase.security.UserProvider;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,45,private UserProvider userProvider;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,53,CallRunner(final RpcServerInterface rpcServer, final Call call, UserProvider userProvider) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,59,this.userProvider = userProvider;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,73,this.userProvider = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,104,RequestContext.set(userProvider.create(call.connection.user), RpcServer.getRemoteIp(),
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,105,call.connection.service);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,122,RequestContext.clear();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,21,package org.apache.hadoop.hbase.ipc;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,23,import org.apache.hadoop.hbase.classification.InterfaceAudience;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,24,import org.apache.hadoop.hbase.security.User;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,26,import com.google.protobuf.BlockingService;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,28,import org.apache.hadoop.hbase.util.Bytes;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,29,import org.cloudera.htrace.Trace;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,31,import java.net.InetAddress;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,40,public class RequestContext {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,41,private static ThreadLocal<RequestContext> instance =
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,42,new ThreadLocal<RequestContext>() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,43,protected RequestContext initialValue() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,44,return new RequestContext(null, null, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,48,public static RequestContext get() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,49,return instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,58,public static User getRequestUser() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,59,RequestContext ctx = instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,60,if (ctx != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,61,return ctx.getUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,63,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,70,public static String getRequestUserName() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,71,User user = getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,72,if (user != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,73,return user.getShortName();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,75,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,82,public static boolean isInRequestContext() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,83,RequestContext ctx = instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,84,if (ctx != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,85,return ctx.isInRequest();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,87,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,96,public static void set(User user,
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,97,InetAddress remoteAddress, BlockingService service) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,98,RequestContext ctx = instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,99,ctx.user = user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,100,ctx.remoteAddress = remoteAddress;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,101,ctx.service = service;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,102,ctx.inRequest = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,103,if (Trace.isTracing()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,104,if (user != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,105,Trace.currentSpan().addKVAnnotation(Bytes.toBytes("user"), Bytes.toBytes(user.getName()));
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,107,if (remoteAddress != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,108,Trace.currentSpan().addKVAnnotation(
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,109,Bytes.toBytes("remoteAddress"),
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,110,Bytes.toBytes(remoteAddress.getHostAddress()));
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,118,public static void clear() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,119,RequestContext ctx = instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,120,ctx.user = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,121,ctx.remoteAddress = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,122,ctx.service = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,123,ctx.inRequest = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,126,private User user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,127,private InetAddress remoteAddress;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,128,private BlockingService service;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,130,private boolean inRequest;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,132,private RequestContext(User user, InetAddress remoteAddr, BlockingService service) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,133,this.user = user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,134,this.remoteAddress = remoteAddr;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,135,this.service = service;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,138,public User getUser() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,139,return user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,142,public InetAddress getRemoteAddress() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,143,return remoteAddress;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,146,public BlockingService getService() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,147,return this.service;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,150,boolean isInRequest() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,151,return inRequest;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,296,long size, TraceInfo tinfo) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1165,null, null, null, this, null, 0, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1171,new Call(SASL_CALLID, this.service, null, null, null, null, this, null, 0, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1538,Call fakeCall = new Call(-1, null, null, null, null, null, this, responder, -1, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1690,responder, totalRequestSize, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1735,responder, totalRequestSize, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1748,traceInfo);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1749,scheduler.dispatch(new CallRunner(RpcServer.this, call, userProvider));
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2362,public static String getRemoteAddress() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2363,Call call = CurCall.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2364,if (call != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2365,return call.connection.getHostAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2367,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,89,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1672,return "Client=" + RequestContext.getRequestUserName() + "/" +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1673,RequestContext.get().getRemoteAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java,43,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java,102,if (RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java,103,this.activeUser = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,79,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,374,RequestContext ctx = RequestContext.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,375,InetAddress remoteAddr = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,376,if (ctx != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,377,remoteAddr = ctx.getRemoteAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,394,User user = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,395,if (!RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1908,throws AccessDeniedException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1909,if (RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1910,String requestUserName = RequestContext.getRequestUserName();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1911,String owner = scannerOwners.get(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1912,if (owner != null && !owner.equals(requestUserName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1913,throw new AccessDeniedException("User '"+ requestUserName +"' is not the scanner owner!");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,41,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,336,User user = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,337,if (!RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/TokenProvider.java,34,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/TokenProvider.java,114,User currentUser = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/TokenProvider.java,140,User requestUser = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,78,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,609,if (RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,610,String requestUName = RequestContext.getRequestUserName();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,611,String owner = scannerOwners.get(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,612,if (owner != null && !owner.equals(requestUName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,613,throw new AccessDeniedException("User '" + requestUName + "' is not the scanner owner!");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,847,RequestContext ctx = RequestContext.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,848,InetAddress remoteAddr = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,849,if (ctx != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,850,remoteAddr = ctx.getRemoteAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,47,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,329,User user = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,330,if (!RequestContext.isInRequestContext()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java,48,private byte[] skipRowOfFirstResult = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java,80,skipRowOfFirstResult = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java,99,localStartKey = this.lastResult.getRow();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java,100,skipRowOfFirstResult = this.lastResult.getRow();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java,101,cacheNum++;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallReversedScanner.java,114,if (this.scanMetrics != null && skipRowOfFirstResult == null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,57,private byte[] skipRowOfFirstResult = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,129,skipRowOfFirstResult = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,146,localStartKey = this.lastResult.getRow();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,147,skipRowOfFirstResult = this.lastResult.getRow();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,148,cacheNum++;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,159,if (this.scanMetrics != null && skipRowOfFirstResult == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,203,LOG.debug("start proc data length is " + data.length);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1205,LOG.info(namespace + "entry deleted in "+AccessControlLists.ACL_TABLE_NAME+" table.");
hbase-server/src/main/java/org/apache/hadoop/hbase/LocalHBaseCluster.java,177,this.regionServerClass, index);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2069,private synchronized ServerName
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,333,Result [] values = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,334,long remainingResultSize = maxScannerResultSize;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,335,int countdown = this.caching;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,338,callable.setCaching(this.caching);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,341,boolean skipFirst = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,342,boolean retryAfterOutOfOrderException  = true;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,343,do {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,344,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,345,if (skipFirst) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,348,callable.setCaching(1);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,349,values = this.caller.callWithRetries(callable);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,350,callable.setCaching(this.caching);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,351,skipFirst = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,356,values = this.caller.callWithRetries(callable);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,357,if (skipFirst && values != null && values.length == 1) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,358,skipFirst = false; // Already skipped, unset it before scanning again
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,359,values = this.caller.callWithRetries(callable);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,361,retryAfterOutOfOrderException  = true;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,365,if (e instanceof UnknownScannerException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,366,long timeout = lastNext + scannerTimeout;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,370,if (timeout < System.currentTimeMillis()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,371,long elapsed = System.currentTimeMillis() - lastNext;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,372,ScannerTimeoutException ex = new ScannerTimeoutException(
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,373,elapsed + "ms passed since the last invocation, " +
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,375,ex.initCause(e);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,376,throw ex;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,381,Throwable cause = e.getCause();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,382,if ((cause != null && cause instanceof NotServingRegionException) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,383,(cause != null && cause instanceof RegionServerStoppedException) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,384,e instanceof OutOfOrderScannerNextException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,389,throw e;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,393,if (this.lastResult != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,400,this.scan.setStartRow(this.lastResult.getRow());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,404,skipFirst = true;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,406,if (e instanceof OutOfOrderScannerNextException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,407,if (retryAfterOutOfOrderException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,408,retryAfterOutOfOrderException = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,411,throw new DoNotRetryIOException("Failed after retry of " +
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,416,this.currentRegion = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,419,callable = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,421,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,423,long currentTime = System.currentTimeMillis();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,424,if (this.scanMetrics != null ) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,425,this.scanMetrics.sumOfMillisSecBetweenNexts.addAndGet(currentTime-lastNext);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,427,lastNext = currentTime;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,428,if (values != null && values.length > 0) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,429,for (Result rs : values) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,430,cache.add(rs);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,431,for (Cell kv : rs.rawCells()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,433,remainingResultSize -= KeyValueUtil.ensureKeyValue(kv).heapSize();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,435,countdown--;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,436,this.lastResult = rs;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,50,import com.google.protobuf.RpcController;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,198,&& !response.getMoreResults()) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,31682,new java.lang.String[] { "CellsPerResult", "ScannerId", "MoreResults", "Ttl", "Results", });
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3282,boolean moreRows = scanner.nextRaw(values);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2839,Set<TableName> disabledOrEnablingTables = ZKTable.getDisabledTables(watcher);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,376,+ ", parent is: " + parent.getEncodedName());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,377,return new Pair<Boolean, Boolean>(Boolean.FALSE, Boolean.FALSE);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java,89,public static final Result EMPTY_RESULT = new Result();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java,106,super();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java,114,this.cells = cells;
hbase-common/src/main/java/org/apache/hadoop/hbase/AuthUtil.java,58,LOG.error("Error resolving host name");
hbase-common/src/main/java/org/apache/hadoop/hbase/AuthUtil.java,61,LOG.error("Error while trying to perform the initial login");
hbase-common/src/main/java/org/apache/hadoop/hbase/AuthUtil.java,91,LOG.info("Got exception while trying to refresh credentials ");
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,756,AuthUtil.launchAuthChore(conf);
hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java,581,public static final long DEFAULT_HBASE_CLIENT_SCANNER_MAX_RESULT_SIZE = 2 * 1024 * 1024;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3240,List<Result> results = new ArrayList<Result>(rows);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,56,import org.apache.hadoop.fs.FileUtil;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,185,if (!fs.exists(hfofDir)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,186,throw new FileNotFoundException("HFileOutputFormat dir " +
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,187,hfofDir + " not found");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,190,FileStatus[] familyDirStatuses = fs.listStatus(hfofDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,191,if (familyDirStatuses == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,192,throw new FileNotFoundException("No families found in " + hfofDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,195,for (FileStatus stat : familyDirStatuses) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,196,if (!stat.isDir()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,197,LOG.warn("Skipping non-directory " + stat.getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,198,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,200,Path familyDir = stat.getPath();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,201,if (familyDir.getName().equals("_logs")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,205,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,207,byte[] family = familyDir.getName().getBytes();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,208,FileStatus[] hfileStatuses = fs.listStatus(familyDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,209,for (FileStatus hfileStatus : hfileStatuses) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,210,long length = hfileStatus.getLen();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,211,Path hfile = hfileStatus.getPath();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,212,if (hfile.getName().startsWith("_")) continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,213,if(length > getConf().getLong(HConstants.HREGION_MAX_FILESIZE,
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,214,HConstants.DEFAULT_MAX_FILE_SIZE)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,215,LOG.warn("Trying to bulk load hfile " + hfofDir.toString() + " with size: " +
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,216,length + " bytes can be problematic as it may lead to oversplitting.");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,218,ret.add(new LoadQueueItem(family, hfile));
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,273,unmatchedFamilies.add(familyNameInHFile);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,276,queueIter.remove();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,829,Path hfofDir = new Path(dirPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,830,FileSystem fs = hfofDir.getFileSystem(getConf());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,832,if (!fs.exists(hfofDir)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,833,throw new FileNotFoundException("HFileOutputFormat dir " +
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,834,hfofDir + " not found");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,837,FileStatus[] familyDirStatuses = fs.listStatus(hfofDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,838,if (familyDirStatuses == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,839,throw new FileNotFoundException("No families found in " + hfofDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,842,HTableDescriptor htd = new HTableDescriptor(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,843,HColumnDescriptor hcd;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,847,byte[][] keys;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,848,TreeMap<byte[], Integer> map = new TreeMap<byte[], Integer>(Bytes.BYTES_COMPARATOR);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,850,for (FileStatus stat : familyDirStatuses) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,851,if (!stat.isDir()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,852,LOG.warn("Skipping non-directory " + stat.getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,853,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,855,Path familyDir = stat.getPath();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,856,if (familyDir.getName().equals("_logs")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,860,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,862,byte[] family = familyDir.getName().getBytes();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,864,hcd = new HColumnDescriptor(family);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,865,htd.addFamily(hcd);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,867,Path[] hfiles = FileUtil.stat2Paths(fs.listStatus(familyDir));
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,868,for (Path hfile : hfiles) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,869,if (hfile.getName().startsWith("_")) continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,872,final byte[] first, last;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,880,first = reader.getFirstRowKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,881,last =  reader.getLastRowKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,899,keys = LoadIncrementalHFiles.inferBoundaries(map);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,298,LOG.debug("No permissions found");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,491,return authorize(globalCache.getGroup(groupName), action);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,504,Permission.Action action) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,516,return authorize(getTablePermissions(table).getGroup(groupName), table, family, action);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,551,if (authorizeGroup(group, table, family, action)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,272,if (HFile.isHFileFormat(lqi.hfilePath.getFileSystem(getConf()), lqi.hfilePath)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,275,LOG.warn("the file " + lqi + " doesn't seems to be an hfile. skipping");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AuthResult.java,179,.append(namespace != null ? namespace : table == null ? "GLOBAL" : table);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,243,String.format("[tableName=%s, lockOwner=%s, threadId=%s, " +
hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/TableLockChecker.java,62,String.format("[tableName=%s, lockOwner=%s, threadId=%s, " +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,591,if (versionsVisible > 1) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,676,OpenRegionRequest request = RequestConverter.buildOpenRegionRequest(server,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,677,region, versionOfOfflineNode, favoredNodes,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,796,+ " of " + retryCounter.getMaxAttempts(), ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,471,if (!ZKSplitLog.isRescanNode(watcher, t)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,512,if (!ZKSplitLog.isRescanNode(watcher, t)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,1282,List<String> tasks = ZKUtil.listChildrenNoWatch(watcher, watcher.splitLogZNode);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,1283,if (tasks != null && !tasks.isEmpty()) {
