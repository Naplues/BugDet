File,Line_number,SRC
hbase-server/src/main/java/org/apache/hadoop/hbase/HDFSBlocksDistribution.java,116,return "number of unique hosts in the disribution=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1347,HFile.LOG.warn("HDFS checksum verification suceeded for file " +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentVerificationReport.java,463,System.err.println("[Error] Region assignment verfication report" +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java,975,opt.addOption("l", "locality", true, "enforce the maxium locality");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionPlacementMaintainer.java,976,opt.addOption("m", "min-move", true, "enforce minium assignment move");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,761,server.abort("Aborting because error occoured while reading "
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/FavoredNodeAssignmentHelper.java,462,LOG.error("Cannot place the secondary and terinary" +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/FavoredNodeAssignmentHelper.java,500,LOG.error("Cannot place the secondary and terinary" +
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,205,String msg = "Data in for starting procuedure " + opName +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/HLogSplitterHandler.java,87,LOG.warn("task execution prempted " + wal);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,217,LOG.error("Error occured while updating the global cache", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,596,LOG.warn("Region's boundaries not alligned between stores and META for:");
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,630,LOG.warn("Attempt to adopt ophan hdfs region skipped becuase no files present in " +
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,805,LOG.info("Trying to sildeline reference file "
hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/HFileCorruptionChecker.java,253,LOG.warn("Failed to quaratine an HFile in regiondir "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1151,HFileBlock b = readBlockData(offset, -1, -1, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1263,private ThreadLocal<PrefetchedHeader> prefetchedHeaderForThread =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1264,new ThreadLocal<PrefetchedHeader>() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1266,public PrefetchedHeader initialValue() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1267,return new PrefetchedHeader();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1411,PrefetchedHeader prefetchedHeader = prefetchedHeaderForThread.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1412,ByteBuffer headerBuf = prefetchedHeader.offset == offset ?
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1413,prefetchedHeader.buf : null;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1458,+ prefetchedHeader.header.length
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1460,+ Bytes.toStringBinary(prefetchedHeader.header, 0,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1546,prefetchedHeader.offset = offset + b.getOnDiskSizeWithHeader();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1547,System.arraycopy(onDiskBlock, onDiskSizeWithHeader,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1548,prefetchedHeader.header, 0, hdrSize);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1100,if (this.closed) throw new IOException(toString() + " closed");
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,413,for (ReplicationSourceInterface src : this.sources) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,414,if (id.equals(src.getPeerClusterId())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java,337,keyRelOffset;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1914,createRegionServerStatusStub() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1918,boolean refresh = false; // for the first time, use cached data
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1816,return new DelayedClosing(hci, stoppable);
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,18,package org.apache.hadoop.hbase;
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,20,import java.lang.annotation.*;
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,31,public @interface VersionAnnotation {
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,37,String version();
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,42,String user();
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,48,String date();
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,53,String url();
hbase-common/src/main/java/org/apache/hadoop/hbase/VersionAnnotation.java,59,String revision();
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,26,import org.apache.hadoop.hbase.VersionAnnotation;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,27,import org.apache.commons.logging.Log;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,37,private static Package myPackage;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,38,private static VersionAnnotation version;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,40,static {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,41,myPackage = VersionAnnotation.class.getPackage();
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,42,version = myPackage.getAnnotation(VersionAnnotation.class);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,49,static Package getPackage() {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,50,return myPackage;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,58,return version != null ? version.version() : "Unknown";
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,66,return version != null ? version.revision() : "Unknown";
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,74,return version != null ? version.date() : "Unknown";
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,82,return version != null ? version.user() : "Unknown";
hbase-common/src/main/java/org/apache/hadoop/hbase/util/VersionInfo.java,90,return version != null ? version.url() : "Unknown";
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,380,boolean references = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,381,HTableDescriptor parentDescriptor = getTableDescriptor(parent.getTable());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,382,for (HColumnDescriptor family: parentDescriptor.getFamilies()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,383,if ((references = regionFs.hasReferences(family.getNameAsString()))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,384,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,204,FileStatus[] files = FSUtils.listStatus(fs, getStoreDir(familyName),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,211,return files != null && files.length > 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1201,metaLocation = locateRegion(parentTable, metaKey, true, false);
hbase-client/src/main/java/org/apache/hadoop/hbase/RegionLoad.java,53,return Bytes.toString(getName());
hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactory.java,50,if (serverName.contains("HMaster")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,852,this.rsHost = new RegionServerCoprocessorHost(this, this.conf);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,142,if(allTime) return true;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,144,return (minStamp <= timestamp && timestamp < maxStamp);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,59,import org.apache.hadoop.hbase.util.Writables;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,73,public void includeTimestamp(final KeyValue kv) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,74,includeTimestamp(kv.getTimestamp());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,75,if (kv.isDeleteColumnOrFamily()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,76,includeTimestamp(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2324,public void shutdown() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2329,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2330,cpHost.preShutdown();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2332,LOG.error("Error call master coprocessor preShutdown()", ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2354,shutdown();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2358,public void stopMaster() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2360,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2361,cpHost.preStopMaster();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2363,LOG.error("Error call master coprocessor preStopMaster()", ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2373,stopMaster();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,243,t.master.stopMaster();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,250,activeMaster.master.shutdown();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3861,boolean moreRows = nextRow(currentRow, offset, length);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java,803,throw new IllegalArgumentException("Invald maximum index block size");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlockIndex.java,839,while (rootChunk.getRootSize() > maxChunkSize) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java,177,LocalHBaseCluster cluster = new LocalHBaseCluster(conf, conf.getInt("hbase.masters", 1),
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java,178,conf.getInt("hbase.regionservers", 1), LocalHMaster.class, HRegionServer.class);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,189,if (System.currentTimeMillis() > startTime + 30000) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,190,throw new RuntimeException("Master not active after 30 seconds");
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/BufferChain.java,60,System.arraycopy(bb.array(), bb.arrayOffset(), bytes, offset, bb.limit());
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/BufferChain.java,61,offset += bb.capacity();
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,274,return (int)(this.getStartcode() - other.getStartcode());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,637,if(this.overflow() == that.overflow()) return 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,638,return this.overflow() > that.overflow() ? 1 : -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1105,return 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1106,return this.overflow() > that.overflow() ? 1 : -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2818,return (int)(k1.getTimestamp() - k2.getTimestamp());
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2043,if (e instanceof ServiceException) e = e.getCause();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,170,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,203,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,235,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,277,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,309,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,342,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,375,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,411,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,513,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,547,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,603,case SESSIONEXPIRED:
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesZKImpl.java,222,private boolean lockOtherRS(String znode) {
hbase-client/src/main/java/org/apache/hadoop/hbase/executor/ExecutorType.java,48,RS_LOG_REPLAY_OPS          (27);
hbase-server/src/main/java/org/apache/hadoop/hbase/executor/ExecutorService.java,261,private ConcurrentMap<Thread, Runnable> running = Maps.newConcurrentMap();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3639,this.service.submit(new OpenRegionHandler(this, this, region, htd,
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/PutSortReducer.java,68,KeyValue kv = KeyValueUtil.ensureKeyValue(cell);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TextSortReducer.java,92,doSetup(context);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TextSortReducer.java,107,protected void doSetup(Context context) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TextSortReducer.java,108,Configuration conf = context.getConfiguration();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesZKImpl.java,300,LOG.warn("Peer " + peerId + " didn't exist, skipping the replay");
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesZKImpl.java,302,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,52,import com.google.common.util.concurrent.ThreadFactoryBuilder;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,397,ReplicationSourceInterface srcToRemove = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,401,for (ReplicationSourceInterface src : oldsources) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,402,if (id.equals(src.getPeerClusterId())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,403,oldSourcesToDelete.add(src);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,406,for (ReplicationSourceInterface src : oldSourcesToDelete) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,407,src.terminate(terminateMessage);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,408,closeRecoveredQueue((src));
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,415,srcToRemove = src;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,416,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,419,if (srcToRemove == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,423,srcToRemove.terminate(terminateMessage);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,424,this.sources.remove(srcToRemove);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,512,src.terminate("Recovered queue doesn't belong to any current peer");
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,513,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,515,oldsources.add(src);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,517,src.enqueueLog(new Path(oldLogDir, hlog));
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,519,src.startup();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperImpl.java,370,cacheStats = blockCache.getStats();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3710,final HRegion region = this.getFromOnlineRegions(encodedRegionName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3711,if ((region  != null) && (region .getCoprocessorHost() != null)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3712,region.getCoprocessorHost().preClose(false);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,142,System.err.println("Invalid row is specified.");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,156,System.out.println("region dir -> " + regionDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,160,System.out.println("Number of region files found -> "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,166,System.out.println("Found file[" + i++ + "] -> " + p);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,196,processFile(fileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,203,System.out.println("Scanned kv count -> " + count);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,209,private void processFile(Path file) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,211,System.out.println("Scanning -> " + file);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,214,System.err.println("ERROR, file doesnt exist: " + file);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,245,System.out.println("Block Index:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,246,System.out.println(reader.getDataBlockIndexReader());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,251,System.out.println("Stats:\n" + fileStats);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,276,System.out.print("K: " + kv);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,278,System.out.print(" V: " + Bytes.toStringBinary(kv.getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,282,System.out
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,283,.print(String.format(" T[%d]: %s", i++, Bytes.toStringBinary(tag.getValue())));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,286,System.out.println();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,291,System.err.println("WARNING, previous row is greater then"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,301,System.err.println("WARNING, filename does not match kv family,"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,307,System.err.println("WARNING, previous kv has different family"
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,329,System.out.println("Block index size as per heapsize: "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,331,System.out.println(asSeparateLines(reader.toString()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,332,System.out.println("Trailer:\n    "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,334,System.out.println("Fileinfo:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,336,System.out.print(FOUR_SPACES + Bytes.toString(e.getKey()) + " = ");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,339,System.out.println(seqid);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,347,System.out.println(Bytes.toInt(e.getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,349,System.out.println(Bytes.toStringBinary(e.getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,354,System.out.println("Mid-key: " + Bytes.toStringBinary(reader.midkey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,356,System.out.println ("Unable to retrieve the midkey");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,365,System.out.println("Bloom filter:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,367,System.out.println(FOUR_SPACES + bloomFilter.toString().replaceAll(
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,370,System.out.println(FOUR_SPACES + "Not present");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,379,System.out.println("Delete Family Bloom filter:");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,381,System.out.println(FOUR_SPACES
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,385,System.out.println(FOUR_SPACES + "Not present");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2440,HRegion region = getRegion(s.getRegionInfo().getRegionName());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2445,s.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2446,if (region != null && region.getCoprocessorHost() != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2447,region.getCoprocessorHost().postScannerClose(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2450,LOG.error("Closing scanner for "
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2451,+ s.getRegionInfo().getRegionNameAsString(), e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3648,if (additionalScanners != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3652,for (Map.Entry<byte[], NavigableSet<byte[]>> entry :
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3653,scan.getFamilyMap().entrySet()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3654,Store store = stores.get(entry.getKey());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3657,|| this.filter.isFamilyEssential(entry.getKey())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3658,scanners.add(scanner);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3660,joinedScanners.add(scanner);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3663,initializeKVHeap(scanners, joinedScanners, region);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,170,List<KeyValueScanner> scanners = getScannersNoCompaction();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,176,seekScanners(scanners, matcher.getStartKey(), explicitColumnQuery
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,177,&& lazySeekEnabledGlobally, isParallelSeekEnabled);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,180,this.storeLimit = scan.getMaxResultsPerColumnFamily();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,183,this.storeOffset = scan.getRowOffsetPerColumnFamily();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,186,resetKVHeap(scanners, store.getComparator());
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,167,createBaseZNodes();
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,429,valueOf(compression.toUpperCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,431,valueOf(dataBlockEncoding.toUpperCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,433,valueOf(bloomFilter.toUpperCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,552,return Compression.Algorithm.valueOf(n.toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,562,return Compression.Algorithm.valueOf(n.toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,633,return setValue(COMPRESSION, type.getName().toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,720,return setValue(COMPRESSION_COMPACT, type.getName().toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,818,return BloomType.valueOf(n.toUpperCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java,358,cause.getMessage().toLowerCase().contains("connection reset")) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SubstringComparator.java,55,super(Bytes.toBytes(substr.toLowerCase()));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SubstringComparator.java,56,this.substr = substr.toLowerCase();
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SubstringComparator.java,66,return Bytes.toString(value, offset, length).toLowerCase().contains(substr) ? 0
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,410,serverPrincipal = SecurityUtil.getServerPrincipal(
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,411,conf.get(serverKey), server.getAddress().getCanonicalHostName().toLowerCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/util/PoolMap.java,266,return name != null ? name.replaceAll("-", "").trim().toLowerCase() : "";
hbase-common/src/main/java/org/apache/hadoop/hbase/io/crypto/KeyStoreKeyProvider.java,145,store = KeyStore.getInstance(storeType.toUpperCase());
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactoryImpl.java,48,context.toLowerCase(),
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactoryImpl.java,51,context.toLowerCase(),
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java,200,durability = Durability.valueOf(durabilityStr.toUpperCase());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/BaseRowProcessor.java,51,return this.getClass().getSimpleName().toLowerCase();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5883,if (!args[1].toLowerCase().startsWith("major")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1810,if (!regionName.toLowerCase().matches("[0-9a-f]+")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,3432,if (!encodedName.toLowerCase().matches("[0-9a-f]+")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/ServerCommandLine.java,106,String key = entry.getKey().toLowerCase();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/ServerCommandLine.java,107,String value = entry.getValue().toLowerCase();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/HThreadedSelectorServerArgs.java,82,ACCEPT_POLICY_CONF_KEY, getAcceptPolicy().toString()).toUpperCase());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftUtilities.java,58,Compression.getCompressionAlgorithmByName(in.compression.toLowerCase());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RegionServerCallable.java,138,long sleep = ConnectionUtils.getPauseTime(pause, tries + 1);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,141,expectedSleep = callable.sleep(pause, tries + 1);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1027,if (!timeRange.isAllTime()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1028,HBaseProtos.TimeRange.Builder timeRangeBuilder =
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1029,HBaseProtos.TimeRange.newBuilder();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1030,timeRangeBuilder.setFrom(timeRange.getMin());
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1031,timeRangeBuilder.setTo(timeRange.getMax());
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1032,builder.setTimeRange(timeRangeBuilder.build());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,197,hfs.next();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,199,if (this.stopSkippingKVsIfNextRow
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,201,cur.getRowLength(), startKV.getBuffer(), startKV.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,727,cpHost.preRestoreSnapshot(reqSnapshot, snapshotTableDesc);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,733,cpHost.postRestoreSnapshot(reqSnapshot, snapshotTableDesc);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,738,cpHost.preCloneSnapshot(reqSnapshot, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,744,cpHost.postCloneSnapshot(reqSnapshot, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,509,for (Map.Entry<String, TablePermission> entry : allPerms.entries()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,510,UserPermission up = new UserPermission(Bytes.toBytes(entry.getKey()),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,511,entry.getValue().getTableName(), entry.getValue().getFamily(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,512,entry.getValue().getQualifier(), entry.getValue().getActions());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,513,perms.add(up);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,653,return entryName.charAt(0) == NAMESPACE_PREFIX;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,657,return entryName[0] == NAMESPACE_PREFIX;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,65,private RecoverableZooKeeper recoverableZooKeeper;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,123,private final Exception constructorCaller;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,154,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,155,throw new Exception("ZKW CONSTRUCTOR STACK TRACE FOR DEBUGGING");
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,157,this.constructorCaller = e;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,165,this.recoverableZooKeeper = ZKUtil.connect(conf, quorum, this, identifier);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,372,long finished = System.currentTimeMillis() +
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,373,this.conf.getLong("hbase.zookeeper.watcher.sync.connected.wait", 2000);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,374,while (System.currentTimeMillis() < finished) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,375,Threads.sleep(1);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,376,if (this.recoverableZooKeeper != null) break;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,378,if (this.recoverableZooKeeper == null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,379,LOG.error("ZK is null on connection event -- see stack trace " +
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,381,this.constructorCaller);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,382,throw new NullPointerException("ZK is null");
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,471,if (recoverableZooKeeper != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,472,recoverableZooKeeper.close();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,1679,final User ticket, final int rpcTimeout) {
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,1694,final User ticket, final int rpcTimeout) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java,33,import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java,74,public class SnapshotDescriptionUtils {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RetriesExhaustedWithDetailsException.java,119,return s;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,26,import org.apache.hadoop.metrics2.lib.Interns;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,25,import org.apache.hadoop.metrics2.lib.Interns;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java,26,import org.apache.hadoop.metrics2.lib.Interns;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionSourceImpl.java,27,import org.apache.hadoop.metrics2.lib.Interns;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MetricMutableQuantiles.java,21,import static org.apache.hadoop.metrics2.lib.Interns.info;
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,119,final Snapshot s = sample.getSnapshot();
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,120,metricsRecordBuilder.addCounter(Interns.info(name + NUM_OPS_METRIC_NAME, desc), count.get());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,122,metricsRecordBuilder.addGauge(Interns.info(name + MIN_METRIC_NAME, desc), getMin());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,123,metricsRecordBuilder.addGauge(Interns.info(name + MAX_METRIC_NAME, desc), getMax());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,124,metricsRecordBuilder.addGauge(Interns.info(name + MEAN_METRIC_NAME, desc), getMean());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,126,metricsRecordBuilder.addGauge(Interns.info(name + MEDIAN_METRIC_NAME, desc), s.getMedian());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,127,metricsRecordBuilder.addGauge(Interns.info(name + SEVENTY_FIFTH_PERCENTILE_METRIC_NAME, desc),
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,128,s.get75thPercentile());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,129,metricsRecordBuilder.addGauge(Interns.info(name + NINETY_FIFTH_PERCENTILE_METRIC_NAME, desc),
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,130,s.get95thPercentile());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableHistogram.java,131,metricsRecordBuilder.addGauge(Interns.info(name + NINETY_NINETH_PERCENTILE_METRIC_NAME, desc),
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,41,private boolean allTime = false;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,79,if(maxStamp < minStamp) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TimeRange.java,129,if(allTime) return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,343,System.out.println(timeRangeTracker.getMinimumTimestamp() + "...."
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFilePrettyPrinter.java,344,+ timeRangeTracker.getMaximumTimestamp());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,646,&& (Math.max(timeRangeTracker.getMaximumTimestamp(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,647,snapshotTimeRangeTracker.getMaximumTimestamp()) >=
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,648,oldestUnexpiredTS);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,425,byte [] timerangeBytes = metadataMap.get(TIMERANGE_KEY);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,426,if (timerangeBytes != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,427,this.reader.timeRangeTracker = new TimeRangeTracker();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,428,Writables.copyWritable(timerangeBytes, this.reader.timeRangeTracker);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,433,this.reader.timeRangeTracker = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,636,return (getReader().timeRangeTracker == null) ?
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,704,boolean isTimeRangeTrackerSet = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,793,isTimeRangeTrackerSet = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,807,if (!isTimeRangeTrackerSet) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1006,protected TimeRangeTracker timeRangeTracker = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1112,if (timeRangeTracker == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1113,return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1116,timeRangeTracker.getMaximumTimestamp() >= oldestUnexpiredTS;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,43,long maximumTimestamp = -1;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,181,int workerThreads, ThriftMetrics metrics) {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,182,CallQueue callQueue = new CallQueue(
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,183,new LinkedBlockingQueue<Call>(), metrics);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,172,serverArgs.getWorkerThreads(), metrics);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,187,return new ThreadPoolExecutor(workerThreads, workerThreads,
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,305,server = getTNonBlockingServer(protocolFactory, processor, transportFactory, inetSocketAddress);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,307,server = getTHsHaServer(protocolFactory, processor, transportFactory, inetSocketAddress, metrics);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,50,public class ReplicationLogCleaner extends BaseLogCleanerDelegate implements Abortable {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,55,private boolean aborted;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,122,this.zkw = new ZooKeeperWatcher(conf, "replicationLogCleaner", null);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,123,this.replicationQueues = ReplicationFactory.getReplicationQueuesClient(zkw, conf, this);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,128,LOG.error("Error while configuring " + this.getClass().getName(), e);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,150,public void abort(String why, Throwable e) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,151,LOG.warn("Aborting ReplicationLogCleaner because " + why, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,152,this.aborted = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,153,stop(why);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,157,public boolean isAborted() {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,158,return this.aborted;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3381,Get get = ProtobufUtil.toGet(action.getGet());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3382,r = region.get(get);
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java,66,if(cmp < 0) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java,67,done = true;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,27,import java.lang.reflect.Field;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,33,import java.security.AccessController;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,34,import java.security.PrivilegedAction;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java,77,scanner.nextRaw(values, -1); // pass -1 as limit so that we see the whole row.
hbase-server/src/main/java/org/apache/hadoop/hbase/client/ClientSideRegionScanner.java,78,if (values == null || values.isEmpty()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,22,import java.util.Collections;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,26,import org.apache.hadoop.conf.Configuration;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,126,if (connection == null) return true; // Default is to do cellblocks.
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,127,Configuration configuration = connection.getConfiguration();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,128,if (configuration == null) return true;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,129,String codec = configuration.get(HConstants.RPC_CODEC_CONF_KEY, "");
hbase-client/src/main/java/org/apache/hadoop/hbase/client/MultiServerCallable.java,130,return codec != null && codec.length() > 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,608,continue; // ignore RowMutations
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,698,HRegionInfo hri = new HRegionInfo(template.getTableName(), orphanRegionRange.getFirst(), orphanRegionRange.getSecond());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/AuthenticationTokenSecretManager.java,320,if (lastKeyUpdate + keyUpdateInterval < now) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,60,protected int countPerRow = 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,493,Put put = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,513,if (proto.hasRow()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,514,put = new Put(proto.getRow().asReadOnlyByteBuffer(), timestamp);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,580,byte [] row = proto.hasRow()? proto.getRow().toByteArray(): null;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,581,long timestamp = HConstants.LATEST_TIMESTAMP;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,582,if (proto.hasTimestamp()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,583,timestamp = proto.getTimestamp();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,585,Delete delete = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,608,delete = new Delete(row, timestamp);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,32,import org.apache.hadoop.hbase.codec.KeyValueCodec;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,58,static class EncryptedKvDecoder extends KeyValueCodec.KeyValueDecoder {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,139,static class EncryptedKvEncoder extends KeyValueCodec.KeyValueEncoder {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java,32,import org.apache.hadoop.hbase.codec.KeyValueCodec;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALCellCodec.java,324,? new KeyValueCodec.KeyValueDecoder(is) : new CompressedKvDecoder(is, compression);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogFactory.java,62,return new FSHLog(fs, root, logName, HConstants.HREGION_OLDLOGDIR_NAME,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogFactory.java,155,throw e;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,830,private long getTS(Path p) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,831,String[] parts = p.getName().split("\\.");
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,832,return Long.parseLong(parts[parts.length-1]);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2330,if (call != null && call.connection.socket != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,72,import org.apache.hadoop.hbase.io.hfile.CacheConfig;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,73,import org.apache.hadoop.hbase.io.hfile.HFile;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,74,import org.apache.hadoop.hbase.io.hfile.HFileContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,75,import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1780,synchronized (masterAndZKLock) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1783,keepZooKeeperWatcherAliveUntil = System.currentTimeMillis() + keepAlive;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3184,if (compaction != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3186,completeCompactionMarker(compaction);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileContextBuilder.java,41,private boolean includesTags;
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1116,theUnsafe = (Unsafe) AccessController.doPrivileged(
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1117,new PrivilegedAction<Object>() {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1119,public Object run() {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1120,try {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1121,Field f = Unsafe.class.getDeclaredField("theUnsafe");
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1122,f.setAccessible(true);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1123,return f.get(null);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1127,throw new Error();
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1129,throw new Error();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,163,request = RequestConverter.buildScanRequest(scannerId, caching, false, nextCallSeq);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,469,final boolean closeScanner, final long nextCallSeq) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,29247,new java.lang.String[] { "Region", "Scan", "ScannerId", "NumberOfRows", "CloseScanner", "NextCallSeq", });
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,123,return coprocessorNames;
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,682,for (HTableInterface table: openTables) {
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,683,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,684,((HTableWrapper)table).internalClose();
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,687,LOG.warn("Failed to close " +
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,688,Bytes.toStringBinary(table.getTableName()), e);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java,218,return this.durability == Durability.SKIP_WAL;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,361,String ensemble = conf.get(HConstants.ZOOKEEPER_QUORUM.replaceAll(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1051,this.closing.set(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1052,status.setStatus("Disabling writes for close");
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java,210,conf.set(
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java,211,ThriftServerRunner.BIND_CONF_KEY, cmd.getOptionValue(BIND_OPTION));
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,343,TServerTransport serverTransport = new TServerSocket(
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,344,new InetSocketAddress(listenAddress, listenPort));
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,353,+ "; " + serverArgs);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,192,TTransportFactory transportFactory, InetSocketAddress inetSocketAddress) throws TTransportException {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,193,TServerTransport serverTransport = new TServerSocket(inetSocketAddress);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,309,server = getTThreadPoolServer(protocolFactory, processor, transportFactory, inetSocketAddress);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/CompressionContext.java,34,static final String ENABLE_WAL_TAGS_COMPRESSION =
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogPrettyPrinter.java,232,FileSystem fs = FileSystem.get(conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,529,if (file != null) file.closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1087,sf.closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1501,compactedFile.closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,448,this.closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,483,closeReader(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,221,false
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,260,float multiFactor, float memoryFactor, boolean forceInMemory) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,798,(3 * Bytes.SIZEOF_LONG) + (9 * ClassSize.REFERENCE) +
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,799,(5 * Bytes.SIZEOF_FLOAT) + Bytes.SIZEOF_BOOLEAN
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,140,private final AtomicLong failedBlockAdditions = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,454,long cacheSize = this.realCacheSize.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1733,totalRequestSize,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3894,checkOpen();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3899,return ReplicateWALEntryResponse.newBuilder().build();
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,316,return result;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MultiTableOutputFormat.java,105,HTable table = new HTable(conf, tableName.get());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableOutputFormat.java,206,this.table = new HTable(this.conf, tableName);
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,27,import org.apache.commons.logging.Log;
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,28,import org.apache.commons.logging.LogFactory;
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,53,private static Log LOG = LogFactory.getLog(User.class);
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,236,private static class SecureHadoopUser extends User {
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,239,private SecureHadoopUser() throws IOException {
hbase-common/src/main/java/org/apache/hadoop/hbase/security/User.java,252,private SecureHadoopUser(UserGroupInformation ugi) {
hbase-common/src/main/java/org/apache/hadoop/hbase/security/UserProvider.java,95,return User.create(ugi);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,25,import org.apache.hadoop.hbase.monitoring.TaskMonitor;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,72,if (RpcServer.LOG.isDebugEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,73,UserGroupInformation remoteUser = call.connection.user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,74,RpcServer.LOG.debug(call.toShortString() + " executing as " +
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1143,protected UserGroupInformation user = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1345,user = getAuthorizedUgi(saslServer.getAuthorizationID());
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1348,+ user + ". Negotiated QoP is "
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1352,AUDITLOG.info(AUTH_SUCCESSFUL_FOR + user);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1547,user = protocolUser;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1548,if (user != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1549,user.setAuthenticationMethod(AuthMethod.SIMPLE.authenticationMethod);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1553,user.setAuthenticationMethod(authMethod.authenticationMethod);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1558,&& (!protocolUser.getUserName().equals(user.getUserName()))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1568,UserGroupInformation realUser = user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1569,user = UserGroupInformation.createProxyUser(protocolUser
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1572,user.setAuthenticationMethod(AuthenticationMethod.PROXY);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1651,connectionHeader.getServiceName() + " is unauthorized for user: " + user);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1744,if (user != null && user.getRealUser() != null
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1746,ProxyUsers.authorize(user, this.getHostAddress(), conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1748,authorize(user, connectionHeader, getHostInetAddress());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2270,boolean shouldBlock = numReadyToWrite == 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2280,assert !shouldBlock : "Should never fail to get lock when blocking";
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2281,break; // stop acquiring more rows for this batch
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,60,this.status = getStatus();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,139,MonitoredRPCHandler getStatus() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,141,MonitoredRPCHandler status = RpcServer.MONITORED_RPC.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,142,if (status != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,143,return status;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,145,status = TaskMonitor.get().createRPCStatus(Thread.currentThread().getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,146,status.pause("Waiting for a call");
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,147,RpcServer.MONITORED_RPC.set(status);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,148,return status;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/FifoRpcScheduler.java,27,import org.apache.hadoop.hbase.ipc.CallRunner;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,33,import org.apache.hadoop.hbase.errorhandling.TimeoutExceptionInjector;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,40,import org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,56,private final TimeoutExceptionInjector timeoutInjector;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,81,timeoutInjector.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/DisabledTableSnapshotHandler.java,125,timeoutInjector.complete();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,118,private static final int SNAPSHOT_TIMEOUT_MILLIS_DEFAULT = 60000;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,124,private static final String SNAPSHOT_TIMEOUT_MILLIS_KEY = "hbase.snapshot.master.timeoutMillis";
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,89,public static final long SNAPSHOT_TIMEOUT_MILLIS_DEFAULT = 60000;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java,111,public static final long DEFAULT_MAX_WAIT_TIME = 60000;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java,131,return conf.getLong(confKey, defaultMaxWaitTime);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,570,seekToBlock.getOffset() - previousBlockOffset, cacheBlocks,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,24,import java.util.List;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,167,private List<Bucket> bucketList, freeBuckets, completelyFreeBuckets;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,180,bucketList.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,181,freeBuckets.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,182,completelyFreeBuckets.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,195,if (freeBuckets.size() > 0) // Use up an existing one first...
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,196,b = freeBuckets.get(freeBuckets.size() - 1);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,221,b = completelyFreeBuckets.get(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,235,assert bucketList.contains(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,237,assert (!completelyFreeBuckets.contains(b));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,239,if (!freeBuckets.contains(b)) freeBuckets.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,240,if (b.isCompletelyFree()) completelyFreeBuckets.add(b);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,245,for (Bucket b : bucketList) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,67,if ( (buf.position() + extra) > buf.limit()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,70,int newSize = (int)Math.min((((long)buf.capacity()) * 2),
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,71,(long)(Integer.MAX_VALUE));
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,72,newSize = Math.max(newSize, buf.position() + extra);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,714,f.closeReader(true);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,209,public ByteBuffer getKeyValueBuffer() {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,210,ByteBuffer kvBuffer = createKVBuffer();
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,211,kvBuffer.putInt(current.keyLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,212,kvBuffer.putInt(current.valueLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,213,kvBuffer.put(current.keyBuffer, 0, current.keyLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,214,kvBuffer.put(currentBuffer.array(),
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,215,currentBuffer.arrayOffset() + current.valueOffset,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,216,current.valueLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,222,kvBuffer.put(currentBuffer.array(), currentBuffer.arrayOffset() + current.tagsOffset,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,223,current.tagsLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,227,kvBuffer.put(current.tagsBuffer, 0, current.tagsLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,230,return kvBuffer;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,233,protected ByteBuffer createKVBuffer() {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,234,int kvBufSize = (int) KeyValue.getKeyValueDataStructureSize(current.keyLength,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,235,current.valueLength, current.tagsLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,236,ByteBuffer kvBuffer = ByteBuffer.allocate(kvBufSize);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,237,return kvBuffer;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,241,public KeyValue getKeyValue() {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,242,ByteBuffer kvBuf = getKeyValueBuffer();
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/DataBlockEncoder.java,143,ByteBuffer getKeyValueBuffer();
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeSeeker.java,86,public ByteBuffer getKeyValueBuffer() {
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeSeeker.java,87,return KeyValueUtil.copyToNewByteBuffer(ptSearcher.current());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,681,return scale(0, cluster.numRegions + META_MOVE_COST_MULT, moveCost);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java,26,import org.apache.hadoop.net.DNS;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,233,import org.apache.hadoop.net.DNS;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,229,import org.apache.hadoop.net.DNS;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,62,if (region.shouldForceSplit()) return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,86,return foundABigStore;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2804,if (bytesRead == 0) return null; // EOF at start is ok
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,35,protected final InputStream in;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,36,private boolean hasNext = true;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,40,this.in = in;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,45,if (!this.hasNext) return this.hasNext;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,46,if (this.in.available() == 0) {
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,47,this.hasNext = false;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,48,return this.hasNext;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,55,return this.hasNext;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,22,import java.io.EOFException;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,76,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,77,ivLength = StreamUtils.readRawVarint32(in);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,80,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,558,Path refPath = StoreFileInfo.getReferredToFile(new Path(new Path(new Path(
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,559,snapshotTable.getNameAsString(), regionInfo.getEncodedName()), familyDir.getName()),
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,560,hfileName));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,940,public synchronized boolean seekToPreviousRow(KeyValue key) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,941,KeyValue firstKeyOnRow = KeyValue.createFirstOnRow(key.getRow());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,942,SortedSet<KeyValue> kvHead = kvsetAtCreation.headSet(firstKeyOnRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,943,KeyValue kvsetBeforeRow = kvHead.isEmpty() ? null : kvHead.last();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,944,SortedSet<KeyValue> snapshotHead = snapshotAtCreation
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,945,.headSet(firstKeyOnRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,946,KeyValue snapshotBeforeRow = snapshotHead.isEmpty() ? null : snapshotHead
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,947,.last();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,948,KeyValue lastKVBeforeRow = getHighest(kvsetBeforeRow, snapshotBeforeRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,949,if (lastKVBeforeRow == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,950,theNext = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,951,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,953,KeyValue firstKeyOnPreviousRow = KeyValue
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,954,.createFirstOnRow(lastKVBeforeRow.getRow());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,955,this.stopSkippingKVsIfNextRow = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,956,seek(firstKeyOnPreviousRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,957,this.stopSkippingKVsIfNextRow = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,958,if (peek() == null
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,959,|| comparator.compareRows(peek(), firstKeyOnPreviousRow) > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,960,return seekToPreviousRow(lastKVBeforeRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,405,public boolean seekToPreviousRow(KeyValue key) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,408,KeyValue seekKey = KeyValue.createFirstOnRow(key.getRow());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,409,if (seekCount != null) seekCount.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,410,if (!hfs.seekBefore(seekKey.getBuffer(), seekKey.getKeyOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,411,seekKey.getKeyLength())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,412,close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,413,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,415,KeyValue firstKeyOfPreviousRow = KeyValue.createFirstOnRow(hfs
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,416,.getKeyValue().getRow());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,418,if (seekCount != null) seekCount.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,419,if (!seekAtOrAfter(hfs, firstKeyOfPreviousRow)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,420,close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,421,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,424,cur = hfs.getKeyValue();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,425,this.stopSkippingKVsIfNextRow = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,426,boolean resultOfSkipKVs;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,427,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,428,resultOfSkipKVs = skipKVsNewerThanReadpoint();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,430,this.stopSkippingKVsIfNextRow = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,432,if (!resultOfSkipKVs
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,434,cur.getRowLength(), firstKeyOfPreviousRow.getBuffer(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,435,firstKeyOfPreviousRow.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,436,firstKeyOfPreviousRow.getRowLength()) > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,437,return seekToPreviousRow(firstKeyOfPreviousRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,446,+ key, ioe);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/DynamicClassLoader.java,123,synchronized (getClassLoadingLock(name)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/LocalHBaseCluster.java,146,conf.set(HConstants.REGIONSERVER_INFO_PORT, "0");
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java,72,ZKUtil.loginServer(conf, "hbase.zookeeper.server.keytab.file",
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,450,ZKUtil.loginClient(this.conf, "hbase.zookeeper.client.keytab.file",
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMasterCommandLine.java,161,ZKUtil.loginServer(conf, "hbase.zookeeper.server.keytab.file",
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,609,ZKUtil.loginClient(this.conf, "hbase.zookeeper.client.keytab.file",
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,221,this.splits.execute(new SplitRequest(r, midKey, this.server));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,239,return requestCompaction(r, why, Store.NO_PRIORITY, requests);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,245,return requestCompaction(r, s, why, Store.NO_PRIORITY, request);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,250,int p, List<Pair<CompactionRequest, Store>> requests) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,251,return requestCompactionInternal(r, why, p, requests, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,255,int p, List<Pair<CompactionRequest, Store>> requests, boolean selectNow) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,261,CompactionRequest cr = requestCompactionInternal(r, s, why, p, null, selectNow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,268,ret.add(requestCompaction(r, pair.getSecond(), why, p, pair.getFirst()));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,275,final String why, int priority, CompactionRequest request) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,276,return requestCompactionInternal(r, s, why, priority, request, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,281,requestCompactionInternal(r, why, Store.NO_PRIORITY, null, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,286,requestCompactionInternal(r, s, why, Store.NO_PRIORITY, null, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,316,pool.execute(new CompactionRunner(s, r, compaction, pool));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,413,CompactionContext compaction, ThreadPoolExecutor parent) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,430,public void run() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,431,Preconditions.checkNotNull(server);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,433,|| (region.getTableDesc() != null && !region.getTableDesc().isCompactionEnabled())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,434,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactionRequestor.java,80,final HRegion r, final String why, int pri, List<Pair<CompactionRequest, Store>> requests
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactionRequestor.java,94,final HRegion r, final Store s, final String why, int pri, CompactionRequest request
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1408,this.majorCompactPriority, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3786,compactSplitThread.requestSplit(region, region.checkSplit());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3869,Store.PRIORITY_USER, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3872,Store.PRIORITY_USER, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,44,SplitRequest(HRegion region, byte[] midKey, HRegionServer hrs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,57,public void run() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,58,if (this.server.isStopping() || this.server.isStopped()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,59,LOG.debug("Skipping split because server is stopping=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,60,this.server.isStopping() + " or stopped=" + this.server.isStopped());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,61,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2066,deleteNodeInStates(encodedName, "offline", sn, EventType.M_ZK_REGION_OFFLINE);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FSDataInputStreamWrapper.java,26,import org.apache.hadoop.hbase.io.FileLink;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FSDataInputStreamWrapper.java,79,this(fs, null, path);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FSDataInputStreamWrapper.java,83,this(fs, link, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FSDataInputStreamWrapper.java,86,private FSDataInputStreamWrapper(FileSystem fs, FileLink link, Path path) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFlusher.java,69,writer = store.createWriterInTmp(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFlusher.java,70,snapshot.size(), store.getFamily().getCompression(), false, true, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,987,List<StoreFileScanner> sfScanners = StoreFileScanner
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,988,.getScannersForStoreFiles(storeFilesToScan, cacheBlocks, usePread, isCompaction, matcher,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,989,readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1922,private class StoreFlusherImpl implements StoreFlushContext {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java,169,boolean includesTags
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,344,private Reader open() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,350,this.reader = fileInfo.open(this.fs, this.cacheConf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,442,public Reader createReader() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,445,this.reader = open();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,38,import org.apache.hadoop.hbase.io.encoding.DataBlockEncoding;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,178,final CacheConfig cacheConf) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,184,in = new FSDataInputStreamWrapper(fs, this.link);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,189,in = new FSDataInputStreamWrapper(fs, referencePath);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileInfo.java,192,in = new FSDataInputStreamWrapper(fs, this.getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,90,usePread, false, readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,100,null, readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,114,StoreFile.Reader r = file.createReader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFlusher.java,119,kvCount, store.getFamily().getCompression(), false, true, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,163,final Collection<StoreFile> filesToCompact, long smallestReadPoint) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,164,return StoreFileScanner.getScannersForStoreFiles(filesToCompact, false, false, true,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,75,fd.maxMVCCReadpoint >= smallestReadPoint, fd.maxTagsLength > 0);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,81,throw new InterruptedIOException( "Aborting compaction of store " + store +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactor.java,82,private List<Path> compactInternal(StripeMultiFileWriter mw, CompactionRequest request,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactor.java,89,List<StoreFileScanner> scanners = createFileScanners(filesToCompact, smallestReadPoint);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactor.java,117,fd.maxKeyCount, compression, true, needMvcc, fd.maxTagsLength > 0);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,72,import org.apache.hadoop.hbase.ipc.PayloadCarryingRpcController;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,75,import org.apache.hadoop.hbase.protobuf.ResponseConverter;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,87,import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ClientService;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,88,import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,89,import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,636,Scan scan = MetaReader.getScanForTableName(tableName);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,637,scan.addColumn(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,638,ScanRequest request = RequestConverter.buildScanRequest(
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,639,firstMetaServer.getRegionInfo().getRegionName(), scan, 1, true);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,640,Result[] values = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,642,ClientService.BlockingInterface server = connection.getClient(firstMetaServer
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,643,.getServerName());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,644,PayloadCarryingRpcController controller = new PayloadCarryingRpcController();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,645,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,646,controller.setPriority(tableName);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,647,ScanResponse response = server.scan(controller, request);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,648,values = ResponseConverter.getResults(controller.cellScanner(), response);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,650,throw ProtobufUtil.getRemoteException(se);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,655,if (values == null || values.length == 0) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,676,throw ((RemoteException) ex).unwrapRemoteException();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,678,throw ex;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,194,outputFs.mkdirs(outputPath.getParent());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1840,final boolean setOfflineInZK, final boolean forceNewPlan) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,677,this.authManager = TableAuthManager.get(zk, env.getConfiguration());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,47,public class TableAuthManager {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,94,private static TableAuthManager instance;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,697,static Map<ZooKeeperWatcher,TableAuthManager> managerMap =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,700,public synchronized static TableAuthManager get(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,702,instance = managerMap.get(watcher);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,43,public class ZKPermissionWatcher extends ZooKeeperListener {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,72,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,73,List<ZKUtil.NodeAndData> nodes =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,74,ZKUtil.getChildDataAndWatchForNewChildren(watcher, aclZNode);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,75,refreshNodes(nodes);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,77,LOG.error("Error reading data from zookeeper", ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,79,watcher.abort("Zookeeper error obtaining acl node children", ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,85,public void nodeDeleted(String path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,87,String table = ZKUtil.getNodeName(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,88,if(AccessControlLists.isNamespaceEntry(table)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,89,authManager.removeNamespace(Bytes.toBytes(table));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,91,authManager.removeTable(TableName.valueOf(table));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,97,public void nodeDataChanged(String path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,100,String entry = ZKUtil.getNodeName(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,101,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,102,byte[] data = ZKUtil.getDataAndWatch(watcher, path);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,103,refreshAuthManager(entry, data);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,105,LOG.error("Error reading data from zookeeper for node " + entry, ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,107,watcher.abort("Zookeeper error getting data for node " + entry, ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,109,LOG.error("Error reading permissions writables", ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,115,public void nodeChildrenChanged(String path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,119,List<ZKUtil.NodeAndData> nodes =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,121,refreshNodes(nodes);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,129,private void refreshNodes(List<ZKUtil.NodeAndData> nodes) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1224,int ret = istream.read(fileOffset, dest, destOffset, size + extraSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1225,if (ret < size) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1226,throw new IOException("Positional read of " + size + " bytes " +
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1230,if (ret == size || ret < size + extraSize) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1174,if (hasCoprocessor(className)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1175,throw new IOException("Coprocessor " + className + " already exists.");
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1208,maxCoprocessorNumber = Math.max(Integer.parseInt(keyMatcher.group(1)),
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1209,maxCoprocessorNumber);
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1214,String value = ((jarFilePath == null)? "" : jarFilePath.toString()) +
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1216,kvString.toString();
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1217,setValue(key, value);
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1227,public boolean hasCoprocessor(String className) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1238,valueMatcher =
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1239,HConstants.CP_HTD_ATTR_VALUE_PATTERN.matcher(
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1240,Bytes.toString(e.getValue().get()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1241,if (!valueMatcher.matches()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1242,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1245,String clazz = valueMatcher.group(2).trim(); // classname is the 2nd field
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1246,if (clazz.equals(className.trim())) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1267,valueMatcher = HConstants.CP_HTD_ATTR_VALUE_PATTERN.matcher(Bytes
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1268,.toString(e.getValue().get()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1269,if (!valueMatcher.matches()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1270,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1272,result.add(valueMatcher.group(2).trim()); // classname is the 2nd field
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,135,for(CoprocessorEnvironment e: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,154,List<E> configured = new ArrayList<E>();
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,164,configured.add(loadInstance(implClass, Coprocessor.PRIORITY_SYSTEM, conf));
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,174,coprocessors.addAll(configured);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1605,List<StoreFlushContext> storeFlushCtxs = new ArrayList<StoreFlushContext>(stores.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1625,storeFlushCtxs.add(s.createFlushContext(flushSeqId));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1629,for (StoreFlushContext flush : storeFlushCtxs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1668,for (StoreFlushContext flush : storeFlushCtxs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1674,for (StoreFlushContext flush : storeFlushCtxs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1977,if (HStore.this.getCoprocessorHost() != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1978,for (StoreFile sf : storeFiles) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,440,KeyValue peeked = this.heap.peek();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,441,if (peeked == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,448,byte[] row = peeked.getBuffer();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,449,int offset = peeked.getRowOffset();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,450,short length = peeked.getRowLength();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,457,KeyValue kv;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java,464,LOOP: while((kv = this.heap.peek()) != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,305,return create(conf, fs, dstFamilyPath, linkedTable, linkedRegion, hfileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,340,Path backRefssDir = getBackReferencesDir(archiveStoreDir, hfileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,341,fs.mkdirs(backRefssDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,344,Path backRefPath = new Path(backRefssDir, refName);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,345,fs.createNewFile(backRefPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,352,fs.delete(backRefPath, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,371,final Path dstFamilyPath, final String hfileLinkName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,377,m.group(3), m.group(4));
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,529,HFileLink.createFromHFileLink(conf, fs, familyDir, hfileName);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.java,533,HFileLink.create(conf, fs, familyDir, regionInfo, hfileName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/IncrementCoalescer.java,38,import org.apache.hadoop.hbase.client.HTable;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/IncrementCoalescer.java,268,HTable table = handler.getTable(row.getTable());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,422,private static ThreadLocal<Map<String, HTable>> threadLocalTables =
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,423,new ThreadLocal<Map<String, HTable>>() {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,425,protected Map<String, HTable> initialValue() {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,426,return new TreeMap<String, HTable>();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,457,public HTable getTable(final byte[] tableName) throws
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,460,Map<String, HTable> tables = threadLocalTables.get();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,461,if (!tables.containsKey(table)) {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,464,return tables.get(table);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,467,public HTable getTable(final ByteBuffer tableName) throws IOException {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,612,HTable table;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,618,Map<HRegionInfo, ServerName> regionLocations =
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,619,table.getRegionLocations();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,675,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,687,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,717,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,730,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,760,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,774,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,808,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,831,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,871,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,896,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,915,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,928,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,944,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,950,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1008,HTable table = null;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1052,throw new IllegalArgument(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1110,HTable table = null;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1123,throw new IllegalArgument(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1142,HTable table;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1149,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1200,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1236,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1245,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1261,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1271,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1287,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1298,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1317,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1326,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1343,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1353,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1371,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1382,HTable table = getTable(tableName);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1392,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1400,HTable table = getTable(getBytes(tableName));
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1412,HTable table = getTable(TableName.META_TABLE_NAME.getName());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1445,throw new IOError(e.getMessage());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1466,HTable table = getTable(tincrement.getTable());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,1471,throw new IOError(e.getMessage());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,73,for (Class<?> c : implClass.getInterfaces()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,241,for (Class<?> c : implClass.getInterfaces()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,120,if (realIn.getClass().getName().endsWith("DFSInputStream")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,121,Method getFileLength = realIn.getClass().
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,122,getDeclaredMethod("getFileLength", new Class<?> []{});
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,123,getFileLength.setAccessible(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,124,long realLength = ((Long)getFileLength.
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,125,invoke(realIn, new Object []{})).longValue();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,126,assert(realLength >= this.length);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,127,adjust = realLength - this.length;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,129,LOG.info("Input stream class: " + realIn.getClass().getName() +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SequenceFileLogReader.java,133,SequenceFileLogReader.LOG.warn(
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClient.java,40,List<String> getListOfReplicators();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClient.java,48,List<String> getLogsInQueue(String serverName, String queueId);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClient.java,55,List<String> getAllQueues(String serverName);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClientZKImpl.java,47,public List<String> getLogsInQueue(String serverName, String queueId) {
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationQueuesClientZKImpl.java,61,public List<String> getAllQueues(String serverName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,66,final Set<String> hlogs = loadHLogsFromQueues();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,71,boolean logInReplicationQueue = hlogs.contains(hlog);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,86,private Set<String> loadHLogsFromQueues() {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,87,List<String> rss = replicationQueues.getListOfReplicators();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,88,if (rss == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,89,LOG.debug("Didn't find any region server that replicates, won't prevent any deletions.");
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,90,return ImmutableSet.of();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,92,Set<String> hlogs = Sets.newHashSet();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,93,for (String rs: rss) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,94,List<String> listOfPeers = replicationQueues.getAllQueues(rs);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,96,if (listOfPeers == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,97,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,99,for (String id : listOfPeers) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,100,List<String> peersHlogs = replicationQueues.getLogsInQueue(rs, id);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,101,if (peersHlogs != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,102,hlogs.addAll(peersHlogs);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/master/ReplicationLogCleaner.java,106,return hlogs;
hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterId.java,21,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterId.java,69,cid = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,47,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,1198,cfs = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,50,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,948,HBaseProtos.RegionInfo ri =
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,949,HBaseProtos.RegionInfo.newBuilder().
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,950,mergeFrom(bytes, pblen + offset, len - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,57,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1420,ts = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/MasterCoprocessorRpcChannel.java,72,.mergeFrom(result.getValue().getValue()).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionCoprocessorRpcChannel.java,95,.mergeFrom(result.getValue().getValue()).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,1099,builder.mergeDelimitedFrom(in);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2535,proto = builder.mergeFrom(protoBytes).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2577,proto = builder.mergeFrom(protoBytes).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,49,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,443,peer = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/security/token/AuthenticationTokenIdentifier.java,137,AuthenticationProtos.TokenIdentifier identifier =
hbase-client/src/main/java/org/apache/hadoop/hbase/security/token/AuthenticationTokenIdentifier.java,138,AuthenticationProtos.TokenIdentifier.newBuilder().mergeFrom(inBytes).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTableReadOnly.java,22,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTableReadOnly.java,157,ZooKeeperProtos.Table t = builder.mergeFrom(data, magicLen, data.length - magicLen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTableReadOnly.java,158,return t.getState();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,73,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1688,String clusterKey = ZooKeeperProtos.ReplicationPeer.newBuilder().
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1689,mergeFrom(data, pblen, data.length - pblen).getClusterkey();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1690,sb.append("\n").append(znodeToProcess).append(": ").append(clusterKey);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1692,appendPeerState(zkw, znodeToProcess, sb);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1700,StringBuilder sb) throws KeeperException, InvalidProtocolBufferException {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1710,.mergeFrom(peerStateData, pblen, peerStateData.length - pblen).getState().name());
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1922,position = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1978,storeIds = regionSequenceIdsBuilder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogTask.java,27,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogTask.java,152,ZooKeeperProtos.SplitLogTask slt = ZooKeeperProtos.SplitLogTask.newBuilder().
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogTask.java,153,mergeFrom(data, prefixLen, data.length - prefixLen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/SplitLogTask.java,154,return new SplitLogTask(slt);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,121,import com.google.protobuf.Message.Builder;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1670,RequestHeader header = RequestHeader.newBuilder().mergeFrom(buf, offset, headerSize).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1696,Builder builder = this.service.getRequestPrototype(md).newBuilderForType();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1702,param = builder.mergeFrom(buf, offset, paramSize).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MutationSerialization.java,28,import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MutationSerialization.java,60,MutationProto proto = MutationProto.parseDelimitedFrom(in);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ResultSerialization.java,128,ClientProtos.Result proto = ClientProtos.Result.parseDelimitedFrom(in);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,2726,.mergeFrom(call.getRequest()).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,45,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,217,ZooKeeperProtos.TableLock data = ZooKeeperProtos.TableLock.newBuilder().mergeFrom(
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,218,bytes, pblen, bytes.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,219,return data;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5461,.mergeFrom(call.getRequest()).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,24,import java.io.InputStream;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,42,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,236,final InputStream limitedInput = new LimitInputStream(this.inputStream, size);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,237,builder.mergeFrom(limitedInput);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,73,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,606,AccessControlProtos.UsersAndPermissions perms =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,607,AccessControlProtos.UsersAndPermissions.newBuilder().mergeFrom(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,608,data, pblen, data.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,609,return ProtobufUtil.toUserTablePermissions(perms);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,694,ListMultimap<String,Permission> kvPerms = ProtobufUtil.toUsersAndPermissions(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,695,AccessControlProtos.UsersAndPermissions.newBuilder().mergeFrom(
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,696,tag.getBuffer(), tag.getTagOffset(), tag.getTagLength()).build());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/HbaseObjectWritableFor96Migration.java,671,instance = ProtobufUtil.toScan(scanProto.mergeFrom(scanBytes).build());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,37,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,98,.mergeFrom(data, pblen, data.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,99,return request.getVisLabelList();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,119,.mergeFrom(data, pblen, data.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,120,return multiUserAuths;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,83,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,518,FSProtos.HBaseVersionFileContent fileContent;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,520,fileContent = builder.mergeFrom(bytes, pblen, bytes.length - pblen).build();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,521,return fileContent.getVersion();
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/LoadBalancerTracker.java,30,import com.google.protobuf.InvalidProtocolBufferException;
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/LoadBalancerTracker.java,88,builder.mergeFrom(pbBytes, magicLen, pbBytes.length - magicLen);
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RegionServerTracker.java,95,rsInfoBuilder.mergeFrom(data, magicLen, data.length - magicLen);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,582,conf.getLong("hbase.hregion.memstore.block.multiplier", 2);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,318,if (useLock) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,319,lockEntry = offsetLock.getLockEntry(dataBlockOffset);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,323,if (cacheConf.isBlockCacheEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,345,if (!useLock) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,347,useLock = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,348,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,650,int sleepMultiplier = 1;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1080,writeToWAL? Durability.SKIP_WAL: Durability.USE_DEFAULT);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1766,this.dataLengthBuffer = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,23,import java.security.SecureRandom;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,128,salter = new SecureRandom();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/Import.java,409,if (hfileOutPath != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1235,LOG.fatal("should never happen: has unsynced writes but writer is null!");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1245,LOG.fatal("Error while AsyncSyncer sync, request close of hlog ", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1509,LOG.fatal("Could not append. Requesting close of hlog", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1605,this.leases.setName(n + ".leaseChecker");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1606,this.leases.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5413,LOG.error("Coprocessor service "+serviceDesc.getFullName()+
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1061,ClusterStatusProtos.ServerLoad buildServerLoad(long reportStartTime, long reportEndTime) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1080,Set<String> coprocessors = this.hlog.getCoprocessorHost().getCoprocessors();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1082,serverLoad.addCoprocessors(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1083,Coprocessor.newBuilder().setName(coprocessor).build());
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,214,name.append(hostName);
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,299,return left.getHostname().equals(right.getHostname()) &&
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,698,int nbFiles = hstoreFilesToSplit.size();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,707,(ThreadPoolExecutor) Executors.newFixedThreadPool(nbFiles, factory);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1950,AuthenticationTokenSecretManager mgr = createSecretManager();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1951,if (mgr != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1952,setSecretManager(mgr);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1953,mgr.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java,347,kvScanner.enforceSeek();
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValueUtil.java,85,buffer.position(buffer.limit());//make it look as if each field were appended
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValueUtil.java,129,buffer.position(buffer.limit());//make it look as if each field were appended
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java,21123,new java.lang.String[] { "RegionA", "RegionB", "Forcible", });
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,78,Delete delete = new Delete(regionInfo.getRegionName());
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,313,ServerName sn) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,319,Put putOfMerged = makePutFromRegionInfo(copyOfMerged);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,326,Delete deleteA = makeDeleteFromRegionInfo(regionA);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,327,Delete deleteB = makeDeleteFromRegionInfo(regionB);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,424,updateLocation(catalogTracker, regionInfo, sn, openSeqNum);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,442,updateLocation(catalogTracker, regionInfo, sn, updateSeqNum);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,461,Put put = new Put(regionInfo.getRegionName());
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,577,Bytes.toBytes(openSeqNum));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,189,final HRegion b, final boolean forcible) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,191,mergePool.execute(new RegionMergeRequest(a, b, this.server, forcible));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3817,compactSplitThread.requestRegionsMerge(regionA, regionB, forcible);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeRequest.java,45,RegionMergeRequest(HRegion a, HRegion b, HRegionServer hrs, boolean forcible) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeRequest.java,69,region_b, forcible);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,45,import org.apache.hadoop.hbase.client.HTable;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,321,.getRegionInfo(), region_b.getRegionInfo(), server.getServerName());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,342,Put putOfMerged = MetaEditor.makePutFromRegionInfo(copyOfMerged);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,347,Delete deleteA = MetaEditor.makeDeleteFromRegionInfo(regionA);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeTransaction.java,348,Delete deleteB = MetaEditor.makeDeleteFromRegionInfo(regionB);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java,119,if (!this.assignmentManager.getZKTable().checkAndSetEnablingTable(tableName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,205,new SnapshotSubprocedurePool(rss.getServerName().toString(), conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,270,SnapshotSubprocedurePool(String name, Configuration conf) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,330,if (e.getCause() instanceof ForeignException) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,373,this.executor.shutdownNow();
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureCoordinatorRpcs.java,235,if (!ProtobufUtil.isPBMagicPrefix(data)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,312,if (!ProtobufUtil.isPBMagicPrefix(data)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,605,return (data.length == 0);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,44,import org.apache.hadoop.hbase.util.Threads;
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,65,Put put = new Put(regionInfo.getRegionName());
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,275,puts.add(makePutFromRegionInfo(regionInfo));
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,492,deletes.add(new Delete(hri.getRegionName()));
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,536,deleteRegions(catalogTracker, regionInfos);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,541,Threads.sleep(20);
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,542,addRegionsToMeta(catalogTracker, regionInfos);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,414,if (authorizeUser(user, action)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,456,public boolean authorizeUser(User user, Permission.Action action) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,457,return authorize(globalCache.getUser(user.getShortName()), action);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,243,KeyValue kv = new KeyValue(kvBuf.array(), kvBuf.arrayOffset(), kvBuf.array().length
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,244,- kvBuf.arrayOffset());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1182,get.setCheckExistenceOnly(true);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1183,Result r = get(get);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1197,g.setCheckExistenceOnly(true);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,1202,r1 = batch(gets);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,943,javax.security.auth.login.Configuration testConfig = javax.security.auth.login.Configuration.getConfiguration();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,944,if(testConfig.getAppConfigurationEntry("Client") == null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,953,return("kerberos".equalsIgnoreCase(conf.get("hbase.security.authentication")) &&
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,954,conf.get("hbase.zookeeper.client.keytab.file") != null);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,961,if ((node.equals(zkw.baseZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,962,(node.equals(zkw.metaServerZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,963,(node.equals(zkw.getMasterAddressZNode()) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,964,(node.equals(zkw.clusterIdZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,965,(node.equals(zkw.rsZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,966,(node.equals(zkw.backupMasterAddressesZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,967,(node.startsWith(zkw.assignmentZNode) == true) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,968,(node.startsWith(zkw.tableZNode) == true)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,35,import org.apache.hadoop.hbase.util.Threads;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,958,if (isSecureZooKeeper(zkw.getConfiguration())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,456,public static void sniff(final HBaseAdmin admin, TableName tableName) throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,135,this(new RegionServerStdOutSink());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,138,public Canary(Sink sink) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,234,do {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,236,monitor = this.newMonitor(index, args);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,237,monitorThread = new Thread(monitor);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,238,startTime = System.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,239,monitorThread.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,240,while (!monitor.isDone()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,242,Thread.sleep(1000);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,244,if (this.failOnError && monitor.hasError()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,245,monitorThread.interrupt();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,246,if (monitor.initialized) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,249,System.exit(INIT_ERROR_EXIT_CODE);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,252,currentTimeLength = System.currentTimeMillis() - startTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,253,if (currentTimeLength > this.timeout) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,254,LOG.error("The monitor is running too long (" + currentTimeLength
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,255,+ ") after timeout limit:" + this.timeout
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,256,+ " will be killed itself !!");
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,257,if (monitor.initialized) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,258,System.exit(TIMEOUT_ERROR_EXIT_CODE);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,260,System.exit(INIT_ERROR_EXIT_CODE);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,262,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,266,if (this.failOnError && monitor.hasError()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,267,monitorThread.interrupt();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,268,System.exit(monitor.errorCode);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,271,Thread.sleep(interval);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,302,public Monitor newMonitor(int index, String[] args) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,312,if(this.regionServerMode) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,313,monitor = new RegionServerMonitor(
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,314,this.conf,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,315,monitorTargets,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,316,this.useRegExp,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,317,(ExtendedSink)this.sink);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,319,monitor = new RegionMonitor(this.conf, monitorTargets, this.useRegExp, this.sink);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,325,public static abstract class Monitor implements Runnable {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,327,protected Configuration config;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,345,protected Monitor(Configuration config, String[] monitorTargets,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,346,boolean useRegExp, Sink sink) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,348,throw new IllegalArgumentException("config shall not be null");
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,350,this.config = config;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,361,this.admin = new HBaseAdmin(config);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,377,public RegionMonitor(Configuration config, String[] monitorTargets,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,378,boolean useRegExp, Sink sink) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,379,super(config, monitorTargets, useRegExp, sink);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,384,if(this.initAdmin()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,390,Canary.sniff(admin, sink, table);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,393,sniff();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,406,if(this.useRegExp) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,425,if(tmpTables.size() > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,428,String msg = "No HTable found, tablePattern:"
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,429,+ Arrays.toString(monitorTargets);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,444,private void sniff() throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,446,Canary.sniff(admin, sink, table);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,457,sniff(admin, new StdOutSink(), tableName.getNameAsString());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,465,throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,466,if (admin.isTableAvailable(tableName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,467,sniff(admin, sink, admin.getTableDescriptor(tableName.getBytes()));
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,469,LOG.warn(String.format("Table %s is not available", tableName));
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,477,throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,478,HTable table = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,481,table = new HTable(admin.getConfiguration(), tableDesc.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,483,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,487,for (HRegionInfo region : admin.getTableRegions(tableDesc.getName())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,488,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,489,sniffRegion(admin, sink, region, table);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,491,sink.publishReadFailure(region, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,492,LOG.debug("sniffRegion failed", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,508,HTable table) throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,556,public RegionServerMonitor(Configuration config, String[] monitorTargets,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,557,boolean useRegExp, ExtendedSink sink) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,558,super(config, monitorTargets, useRegExp, sink);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,606,String serverName = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,607,String tableName = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,608,HRegionInfo region = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,609,HTable table = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,610,Get get = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,611,byte[] startKey = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,612,Scan scan = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,613,StopWatch stopWatch = new StopWatch();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,616,stopWatch.reset();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,617,serverName = entry.getKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,619,region = entry.getValue().get(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,620,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,621,tableName = region.getTable().getNameAsString();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,622,table = new HTable(this.admin.getConfiguration(), tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,623,startKey = region.getStartKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,625,if(startKey.length > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,626,get = new Get(startKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,627,stopWatch.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,628,table.get(get);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,629,stopWatch.stop();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,631,scan = new Scan();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,632,scan.setCaching(1);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,633,scan.setMaxResultSize(1L);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,634,stopWatch.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,635,table.getScanner(scan);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,636,stopWatch.stop();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,638,this.getSink().publishReadTiming(tableName, serverName, stopWatch.getTime());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,643,LOG.debug("The targeted table was disabled.  Assuming success.");
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,645,this.getSink().publishReadFailure(tableName, serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,646,LOG.error(dnrioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,648,this.getSink().publishReadFailure(tableName, serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,649,LOG.error(e);
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,650,this.errorCode = ERROR_EXIT_CODE;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,652,if (table != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,653,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,654,table.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,658,scan = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,659,get = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,660,startKey = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,673,HTable table = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,678,table = new HTable(this.admin.getConfiguration(), tableDesc.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,680,for (Map.Entry<HRegionInfo, ServerName> entry : table
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,681,.getRegionLocations().entrySet()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,682,ServerName rs = entry.getValue();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,684,HRegionInfo r = entry.getKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,728,for (Map.Entry<String,List<HRegionInfo>> entry : fullRsAndRMap.entrySet()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java,278,public static final int DEFAULT_HBASE_CLIENT_OPERATION_TIMEOUT = Integer.MAX_VALUE;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,401,LOG.info("Waited " + (System.currentTimeMillis() - fqe.createTime) +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,515,long start = System.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,537,long took = System.currentTimeMillis() - start;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,613,this.createTime = System.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,622,return (System.currentTimeMillis() - this.createTime) > maximumWait;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,640,this.whenToExpire = System.currentTimeMillis() + when;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,647,return unit.convert(this.whenToExpire - System.currentTimeMillis(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3655,KeyValueScanner scanner = store.getScanner(scan, entry.getValue(), this.readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3786,do {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3787,heap.next(results, limit - results.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3788,if (limit > 0 && results.size() == limit) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3789,return KV_LIMIT;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3791,nextKv = heap.peek();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3086,if (request.getNextCallSeq() != rsh.nextCallSeq) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3087,throw new OutOfOrderScannerNextException("Expected nextCallSeq: " + rsh.nextCallSeq
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3092,rsh.nextCallSeq++;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4457,private long nextCallSeq = 0L;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,22,import java.util.Collection;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,226,public void controllerConnectionFailure(final String message, final IOException cause) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,227,Collection<Subprocedure> toNotify = subprocs.values();
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,229,for (Subprocedure sub : toNotify) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,231,sub.cancel(message, cause);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,146,+ zkController.getAbortZnode(), new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,163,new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,195,+ ") for procedure :" + opName, new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,223,new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,251,+ procName + " and member: " + memberName, new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,268,+ " to join procedure barrier.", new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,295,+ " to abort procedure", new IOException(e));
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,332,+ zkController.getAbortZnode(), new IOException(e));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/SecureBulkLoadUtil.java,38,return new Path(conf.get(BULKLOAD_STAGING_DIR, "/tmp/hbase-staging"));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,541,splitKey.getKeyOffset(), splitKey.getKeyLength(), lastKey, 0, lastKey.length) > 0) {
hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java,157,hash = 31 * hash + (int)cell.getMvccVersion();
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1057,byte[] b = getBuffer();
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1058,int start = getOffset(), end = getOffset() + getLength();
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1059,int h = b[start++];
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1060,for (int i = start; i < end; i++) {
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1061,h = (h * 13) ^ b[i];
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1063,return h;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,66,private boolean closed = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,259,private void updateResultsMetrics(Result[] rrs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2009,int processingTime = (int) (System.currentTimeMillis() - startTime);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogFactory.java,116,FSDataInputStream stream = fs.open(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,277,Reader in = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java,97,long subsequentPause = conf.getInt("hbase.lease.recovery.dfs.timeout", 61 * 1000);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSHDFSUtils.java,118,subsequentPause) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1635,String s = "Finished memstore snapshotting " + this +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1637,status.setStatus(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1638,if (LOG.isTraceEnabled()) LOG.trace(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1642,if (wal != null && !shouldSyncLog()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1643,wal.sync();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1651,mvcc.waitForRead(w);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1653,s = "Flushing stores of " + this;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1654,status.setStatus(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1655,if (LOG.isTraceEnabled()) LOG.trace(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/CompactSplitThread.java,313,long size = selectNow ? compaction.getRequest().getSize() : 0;
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactoryImpl.java,25,private static enum SourceStorage {
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceFactoryImpl.java,28,private static enum SourceStorage {
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,53,AUTHORIZATION_SUCCESSES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,55,AUTHORIZATION_FAILURES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,58,AUTHENTICATION_SUCCESSES_NAME, AUTHENTICATION_SUCCESSES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,60,AUTHENTICATION_FAILURES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,62,SENT_BYTES_DESC, 0l);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,64,RECEIVED_BYTES_DESC, 0l);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1684,setupResponse(responseBuffer, callTooBig, new CallQueueTooBigException(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactionPolicy.java,251,if (canDropDeletesWithoutL0 || includeL0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,110,IOEngine ioEngine;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,115,private ConcurrentHashMap<BlockCacheKey, BucketEntry> backingMap;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,126,WriterThread writerThreads[];
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,132,private Lock freeSpaceLock = new ReentrantLock();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,145,private final Object[] cacheWaitSignals;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,152,private BucketCacheStats cacheStats = new BucketCacheStats();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,154,private String persistencePath;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,155,private long cacheCapacity;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,174,private IdLock offsetLock = new IdLock();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,212,this.cacheWaitSignals = new Object[writerThreadNum];
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,227,this.cacheWaitSignals[i] = new Object();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,248,writerThreads[i] = new WriterThread(writerQueues.get(i), i);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,306,public void cacheBlockWithWait(BlockCacheKey cacheKey, Cacheable cachedItem,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,307,boolean inMemory, boolean wait) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,318,RAMQueueEntry re = new RAMQueueEntry(cacheKey, cachedItem,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,319,accessCount.incrementAndGet(), inMemory);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,320,ramCache.put(cacheKey, re);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,323,boolean successfulAddition = bq.offer(re);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,324,if (!successfulAddition && wait) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,325,synchronized (cacheWaitSignals[queueNum]) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,326,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,329,Thread.currentThread().interrupt();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,335,ramCache.remove(cacheKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,336,failedBlockAdditions.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,397,if (!cacheEnabled) return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,649,WriterThread(BlockingQueue<RAMQueueEntry> queue, int threadNO) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,650,super();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,652,this.threadNO = threadNO;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,982,static class BucketEntry implements Serializable, Comparable<BucketEntry> {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,988,private volatile long accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,991,BucketEntry(long offset, int length, long accessTime, boolean inMemory) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,994,this.accessTime = accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1035,public void access(long accessTime) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1036,this.accessTime = accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1047,public int compareTo(BucketEntry that) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1048,if(this.accessTime == that.accessTime) return 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1049,return this.accessTime < that.accessTime ? 1 : -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1053,public boolean equals(Object that) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1054,return this == that;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1122,private long accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1125,public RAMQueueEntry(BlockCacheKey bck, Cacheable data, long accessTime,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1129,this.accessTime = accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1141,public void access(long accessTime) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1142,this.accessTime = accessTime;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,59,queue = MinMaxPriorityQueue
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,60,.orderedBy(new Comparator<Map.Entry<BlockCacheKey, BucketEntry>>() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,61,public int compare(Entry<BlockCacheKey, BucketEntry> entry1,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,62,Entry<BlockCacheKey, BucketEntry> entry2) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,63,return entry1.getValue().compareTo(entry2.getValue());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/CachedEntryQueue.java,86,if (entry.getValue().compareTo(head) > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,369,private void requirePermission(String request, TableName tableName, byte[] family, byte[] qualifier,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,370,Action... permissions) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,386,if (!result.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,410,RegionCoprocessorEnvironment env,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,412,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,413,User user = getActiveUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,414,AuthResult result = permissionGranted(request, user, perm, env, families);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,415,logResult(result);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,417,if (!result.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,418,throw new AccessDeniedException("Insufficient permissions (table=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,419,env.getRegion().getTableDesc().getTableName()+
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,420,((families != null && families.size() > 0) ? ", family: " +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,421,result.toFamilyString() : "") + ", action=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,422,perm.toString() + ")");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,441,throw new AccessDeniedException("Insufficient permissions for user '" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,461,throw new AccessDeniedException("Insufficient permissions for user '" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,848,+ AccessControlLists.ACL_TABLE_NAME + " table.");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1375,if (user != null && user.getShortName() != null) {      // store reference to scanner owner for later checks
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1530,perm.getQualifier(), Action.ADMIN);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1573,perm.getQualifier(), Action.ADMIN);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1658,Map<byte[], Set<byte[]>> familyMap = new TreeMap<byte[], Set<byte[]>>(Bytes.BYTES_COMPARATOR);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1669,requirePermission("checkPermissions", action, regionEnv, familyMap);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1674,requirePermission("checkPermissions", action);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,146,private boolean acOn = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,553,this.acOn = CoprocessorHost.getLoadedCoprocessors().contains(AccessController.class.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,941,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,1331,if (!this.acOn) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,26,import org.apache.hadoop.hbase.security.UserProvider;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,45,private UserProvider userProvider;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,55,CallRunner(final RpcServerInterface rpcServer, final Call call, UserProvider userProvider) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,61,this.userProvider = userProvider;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,89,RequestContext.set(userProvider.create(call.connection.user), RpcServer.getRemoteIp(),
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,90,call.connection.service);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,104,RequestContext.clear();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,21,package org.apache.hadoop.hbase.ipc;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,24,import org.apache.hadoop.hbase.security.User;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,26,import com.google.protobuf.BlockingService;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,28,import org.apache.hadoop.hbase.util.Bytes;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,29,import org.cloudera.htrace.Trace;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,31,import java.net.InetAddress;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,40,public class RequestContext {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,41,private static ThreadLocal<RequestContext> instance =
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,42,new ThreadLocal<RequestContext>() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,43,protected RequestContext initialValue() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,44,return new RequestContext(null, null, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,48,public static RequestContext get() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,49,return instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,58,public static User getRequestUser() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,59,RequestContext ctx = instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,60,if (ctx != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,61,return ctx.getUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,63,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,70,public static String getRequestUserName() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,71,User user = getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,72,if (user != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,73,return user.getShortName();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,75,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,82,public static boolean isInRequestContext() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,83,RequestContext ctx = instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,84,if (ctx != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,85,return ctx.isInRequest();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,87,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,96,public static void set(User user,
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,97,InetAddress remoteAddress, BlockingService service) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,98,RequestContext ctx = instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,99,ctx.user = user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,100,ctx.remoteAddress = remoteAddress;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,101,ctx.service = service;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,102,ctx.inRequest = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,103,if (Trace.isTracing()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,104,if (user != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,105,Trace.currentSpan().addKVAnnotation(Bytes.toBytes("user"), Bytes.toBytes(user.getName()));
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,107,if (remoteAddress != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,108,Trace.currentSpan().addKVAnnotation(
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,109,Bytes.toBytes("remoteAddress"),
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,110,Bytes.toBytes(remoteAddress.getHostAddress()));
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,118,public static void clear() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,119,RequestContext ctx = instance.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,120,ctx.user = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,121,ctx.remoteAddress = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,122,ctx.service = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,123,ctx.inRequest = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,126,private User user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,127,private InetAddress remoteAddress;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,128,private BlockingService service;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,130,private boolean inRequest;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,132,private RequestContext(User user, InetAddress remoteAddr, BlockingService service) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,133,this.user = user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,134,this.remoteAddress = remoteAddr;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,135,this.service = service;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,138,public User getUser() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,139,return user;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,142,public InetAddress getRemoteAddress() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,143,return remoteAddress;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,146,public BlockingService getService() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,147,return this.service;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,150,boolean isInRequest() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RequestContext.java,151,return inRequest;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,293,long size, TraceInfo tinfo) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1157,null, null, null, this, null, 0, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1163,new Call(SASL_CALLID, this.service, null, null, null, null, this, null, 0, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1530,Call fakeCall = new Call(-1, null, null, null, null, null, this, responder, -1, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1682,responder, totalRequestSize, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1721,responder, totalRequestSize, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1734,traceInfo);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1735,scheduler.dispatch(new CallRunner(RpcServer.this, call, userProvider));
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2340,public static String getRemoteAddress() {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2341,Call call = CurCall.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2342,if (call != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2343,return call.connection.getHostAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,2345,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,85,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1551,return "Client=" + RequestContext.getRequestUserName() + "/" +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1552,RequestContext.get().getRemoteAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,68,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,332,RequestContext ctx = RequestContext.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,333,InetAddress remoteAddr = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,334,if (ctx != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,335,remoteAddr = ctx.getRemoteAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,352,User user = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,353,if (!RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1408,throws AccessDeniedException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1409,if (RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1410,String requestUserName = RequestContext.getRequestUserName();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1411,String owner = scannerOwners.get(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1412,if (owner != null && !owner.equals(requestUserName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1413,throw new AccessDeniedException("User '"+ requestUserName +"' is not the scanner owner!");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,38,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,287,User user = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,288,if (!RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/TokenProvider.java,33,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/TokenProvider.java,112,User currentUser = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/TokenProvider.java,138,User requestUser = RequestContext.getRequestUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,81,import org.apache.hadoop.hbase.ipc.RequestContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,930,if (RequestContext.isInRequestContext()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,931,String requestUName = RequestContext.getRequestUserName();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,932,String owner = scannerOwners.get(s);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,933,if (owner != null && !owner.equals(requestUName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,934,throw new AccessDeniedException("User '" + requestUName + "' is not the scanner owner!");
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,59,private byte[] skipRowOfFirstResult = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,128,skipRowOfFirstResult = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,145,localStartKey = this.lastResult.getRow();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,146,skipRowOfFirstResult = this.lastResult.getRow();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,147,cacheNum++;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientSmallScanner.java,157,if (this.scanMetrics != null && skipRowOfFirstResult == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureMemberRpcs.java,203,LOG.debug("start proc data length is " + data.length);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1023,LOG.info(namespace + "entry deleted in "+AccessControlLists.ACL_TABLE_NAME+" table.");
hbase-server/src/main/java/org/apache/hadoop/hbase/LocalHBaseCluster.java,177,this.regionServerClass, index);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,313,Result [] values = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,314,long remainingResultSize = maxScannerResultSize;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,315,int countdown = this.caching;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,318,callable.setCaching(this.caching);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,321,boolean skipFirst = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,322,boolean retryAfterOutOfOrderException  = true;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,323,do {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,324,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,325,if (skipFirst) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,328,callable.setCaching(1);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,329,values = this.caller.callWithRetries(callable);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,330,callable.setCaching(this.caching);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,331,skipFirst = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,336,values = this.caller.callWithRetries(callable);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,337,if (skipFirst && values != null && values.length == 1) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,338,skipFirst = false; // Already skipped, unset it before scanning again
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,339,values = this.caller.callWithRetries(callable);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,341,retryAfterOutOfOrderException  = true;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,345,if (e instanceof UnknownScannerException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,346,long timeout = lastNext + scannerTimeout;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,350,if (timeout < System.currentTimeMillis()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,351,long elapsed = System.currentTimeMillis() - lastNext;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,352,ScannerTimeoutException ex = new ScannerTimeoutException(
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,353,elapsed + "ms passed since the last invocation, " +
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,355,ex.initCause(e);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,356,throw ex;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,361,Throwable cause = e.getCause();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,362,if ((cause != null && cause instanceof NotServingRegionException) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,363,(cause != null && cause instanceof RegionServerStoppedException) ||
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,364,e instanceof OutOfOrderScannerNextException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,369,throw e;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,373,if (this.lastResult != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,374,this.scan.setStartRow(this.lastResult.getRow());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,377,skipFirst = true;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,379,if (e instanceof OutOfOrderScannerNextException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,380,if (retryAfterOutOfOrderException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,381,retryAfterOutOfOrderException = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,384,throw new DoNotRetryIOException("Failed after retry of " +
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,389,this.currentRegion = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,392,callable = null;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,394,continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,396,long currentTime = System.currentTimeMillis();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,397,if (this.scanMetrics != null ) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,398,this.scanMetrics.sumOfMillisSecBetweenNexts.addAndGet(currentTime-lastNext);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,400,lastNext = currentTime;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,401,if (values != null && values.length > 0) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,402,for (Result rs : values) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,403,cache.add(rs);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,404,for (Cell kv : rs.rawCells()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,406,remainingResultSize -= KeyValueUtil.ensureKeyValue(kv).heapSize();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,408,countdown--;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ClientScanner.java,409,this.lastResult = rs;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/ScannerCallable.java,192,&& !response.getMoreResults()) {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,29253,new java.lang.String[] { "CellsPerResult", "ScannerId", "MoreResults", "Ttl", "Results", });
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3135,boolean moreRows = scanner.nextRaw(values);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2601,Set<TableName> disabledOrEnablingTables = ZKTable.getDisabledTables(watcher);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,376,+ ", parent is: " + parent.getEncodedName());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,377,return new Pair<Boolean, Boolean>(Boolean.FALSE, Boolean.FALSE);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java,86,public static final Result EMPTY_RESULT = new Result();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java,95,super();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java,103,this.cells = cells;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3099,List<Result> results = new ArrayList<Result>(rows);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,53,import org.apache.hadoop.fs.FileUtil;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,158,if (!fs.exists(hfofDir)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,159,throw new FileNotFoundException("HFileOutputFormat dir " +
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,160,hfofDir + " not found");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,163,FileStatus[] familyDirStatuses = fs.listStatus(hfofDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,164,if (familyDirStatuses == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,165,throw new FileNotFoundException("No families found in " + hfofDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,168,for (FileStatus stat : familyDirStatuses) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,169,if (!stat.isDir()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,170,LOG.warn("Skipping non-directory " + stat.getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,171,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,173,Path familyDir = stat.getPath();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,176,byte[] family = familyDir.getName().getBytes();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,179,if (hfile.getName().startsWith("_")) continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,180,ret.add(new LoadQueueItem(family, hfile));
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,735,Path hfofDir = new Path(dirPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,736,FileSystem fs = hfofDir.getFileSystem(getConf());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,738,if (!fs.exists(hfofDir)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,739,throw new FileNotFoundException("HFileOutputFormat dir " +
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,740,hfofDir + " not found");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,743,FileStatus[] familyDirStatuses = fs.listStatus(hfofDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,744,if (familyDirStatuses == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,745,throw new FileNotFoundException("No families found in " + hfofDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,748,HTableDescriptor htd = new HTableDescriptor(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,749,HColumnDescriptor hcd;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,753,byte[][] keys;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,754,TreeMap<byte[], Integer> map = new TreeMap<byte[], Integer>(Bytes.BYTES_COMPARATOR);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,756,for (FileStatus stat : familyDirStatuses) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,757,if (!stat.isDir()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,758,LOG.warn("Skipping non-directory " + stat.getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,759,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,761,Path familyDir = stat.getPath();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,764,byte[] family = familyDir.getName().getBytes();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,766,hcd = new HColumnDescriptor(family);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,767,htd.addFamily(hcd);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,769,Path[] hfiles = FileUtil.stat2Paths(fs.listStatus(familyDir));
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,770,for (Path hfile : hfiles) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,771,if (hfile.getName().startsWith("_")) continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,774,final byte[] first, last;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,782,first = reader.getFirstRowKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,783,last =  reader.getLastRowKey();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,801,keys = LoadIncrementalHFiles.inferBoundaries(map);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,297,LOG.debug("No permissions found");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,492,return authorize(globalCache.getGroup(groupName), action);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,505,Permission.Action action) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,517,return authorize(getTablePermissions(table).getGroup(groupName), table, family, action);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,529,if (authorizeGroup(group, table, family, action)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AuthResult.java,171,.append(namespace != null ? namespace : table == null ? "GLOBAL" : table);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/TableLockManager.java,243,String.format("[tableName=%s, lockOwner=%s, threadId=%s, " +
hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/TableLockChecker.java,62,String.format("[tableName=%s, lockOwner=%s, threadId=%s, " +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,572,if (versionsVisible > 1) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,468,if (!ZKSplitLog.isRescanNode(watcher, t)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,510,if (!ZKSplitLog.isRescanNode(watcher, t)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,990,pcrc.setPriority(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1268,byte[] rowBloomKey = bloomFilter.createBloomKey(row, 0, row.length,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,101,this.replicationPeers = ReplicationFactory.getReplicationPeers(zkw, conf, this.connection);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,102,this.replicationPeers.init();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,103,this.replicationQueuesClient =
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,104,ReplicationFactory.getReplicationQueuesClient(zkw, conf, this.connection);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,105,this.replicationQueuesClient.init();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,108,throw new IOException("Error initializing the replication admin client.", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogReader.java,61,key = EncryptionUtil.unwrapKey(conf, walKeyName, keyBytes);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogReader.java,74,key = EncryptionUtil.unwrapKey(conf, masterKeyName, keyBytes);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogReader.java,85,key = EncryptionUtil.unwrapKey(conf, alternateKeyName, keyBytes);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,62,import org.apache.hadoop.hbase.regionserver.StoreFile;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,404,if (bucketEntry != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,405,IdLock.Entry lockEntry = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,406,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,407,lockEntry = offsetLock.getLockEntry(bucketEntry.offset());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,408,if (bucketEntry.equals(backingMap.remove(cacheKey))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,409,bucketAllocator.freeBlock(bucketEntry.offset());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,410,realCacheSize.addAndGet(-1 * bucketEntry.getLength());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,411,blocksByHFile.remove(cacheKey.getHfileName(), cacheKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,412,if (removedBlock == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,413,this.blockNumber.decrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,416,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,419,LOG.warn("Failed evicting block " + cacheKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,422,if (lockEntry != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,423,offsetLock.releaseLockEntry(lockEntry);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,481,private long minSize() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,482,return (long) Math.floor(bucketAllocator.getTotalSize() * DEFAULT_MIN_FACTOR);
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,111,.setContext(metricsContext);
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,78,.setContext(metricsContext);
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionAggregateSourceImpl.java,83,.setContext(metricsContext);
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java,145,.setContext(metricsContext);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,116,.setContext(metricsContext);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,72,.setContext(metricsContext);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionAggregateSourceImpl.java,84,.setContext(metricsContext);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java,152,.setContext(metricsContext);
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,196,public static void isLegalNamespaceName(byte[] namespaceName, int offset, int length) {
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,197,for (int i = offset; i < length; i++) {
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,204,offset, length));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5211,idx++;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5341,4 * Bytes.SIZEOF_BOOLEAN);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKTable.java,151,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2741,TableLockChecker checker = new TableLockChecker(createZooKeeperWatcher(), errors);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2742,checker.checkTableLocks();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2744,if (this.fixTableLocks) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2745,checker.fixExpiredTableLocks();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,3192,WRONG_USAGE, EMPTY_META_CELL, EXPIRED_TABLE_LOCK, BOUNDARIES_ERROR
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,224,ArrayList<String> familyNames = new ArrayList<String>();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,229,for (LoadQueueItem lqi : queue) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,232,unmatchedFamilies.add(familyNameInHFile);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,144,if (limit >= 0.9f || limit < 0.1f) {
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,170,throw new IllegalArgumentException("Illegal first character <" + qualifierName[0] +
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/Filter.java,59,protected boolean reversed;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,260,regionStates.put(encodedName, regionState);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,473,public synchronized List<HRegionInfo> serverOffline(
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,474,final ZooKeeperWatcher watcher, final ServerName sn) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,477,Set<HRegionInfo> assignedRegions = serverHoldings.get(sn);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,478,if (assignedRegions == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,479,assignedRegions = new HashSet<HRegionInfo>();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,483,Set<HRegionInfo> regionsToOffline = new HashSet<HRegionInfo>();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,484,for (HRegionInfo region : assignedRegions) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,486,if (isRegionOnline(region)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,487,regionsToOffline.add(region);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,489,if (isRegionInState(region, State.SPLITTING, State.MERGING)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,490,LOG.debug("Offline splitting/merging region " + getRegionState(region));
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,491,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,493,ZKAssign.deleteNodeFailSilent(watcher, region);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,494,regionsToOffline.add(region);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,496,server.abort("Unexpected ZK exception deleting node " + region, ke);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,506,for (RegionState state : regionsInTransition.values()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,507,HRegionInfo hri = state.getRegion();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,508,if (assignedRegions.contains(hri)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,512,LOG.info("Transitioning " + state + " will be handled by SSH for " + sn);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,521,if (state.isPendingOpenOrOpening() || state.isFailedClose() || state.isOffline()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,522,LOG.info("Found region in " + state + " to be reassigned by SSH for " + sn);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,523,rits.add(hri);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,525,LOG.warn("THIS SHOULD NOT HAPPEN: unexpected " + state);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,530,this.notifyAll();
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerLoad.java,49,private int readRequestsCount = 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerLoad.java,50,private int writeRequestsCount = 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerLoad.java,142,public int getReadRequestsCount() {
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerLoad.java,146,public int getWriteRequestsCount() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3896,this.replicationSinkHandler.replicateLogEntries(request.getEntryList(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3897,((PayloadCarryingRpcController)controller).cellScanner());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,20,import java.util.Collections;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1437,User requestUser = getActiveUser();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1441,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1446,return AuthResult.allow(method, "Access allowed", requestUser,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1452,return authResult;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1464,logResult(authResult);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1465,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1466,throw new AccessDeniedException("Insufficient permissions (table=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1480,logResult(authResult);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1481,if (!authResult.isAllowed()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1482,throw new AccessDeniedException("Insufficient permissions (table=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,479,if (authorize(user, table.getNamespaceAsString(), action)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,573,interface FlushQueueEntry extends Delayed {}
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,653,return Long.valueOf(getDelay(TimeUnit.MILLISECONDS) -
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1463,AuthResult authResult = hasSomeAccess(e, "prePrepareBulkLoad", Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1467,e.getRegion().getTableDesc().getTableName() + ", action=WRITE)");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1479,AuthResult authResult = hasSomeAccess(e, "preCleanupBulkLoad", Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1483,e.getRegion().getTableDesc().getTableName() + ", action=WRITE)");
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,99,ZooKeeperWatcher zkw = createZooKeeperWatcher();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,113,return new ZooKeeperWatcher(connection.getConfiguration(),
hbase-client/src/main/java/org/apache/hadoop/hbase/client/replication/ReplicationAdmin.java,118,System.exit(1);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ByteBufferOutputStream.java,74,ByteBuffer newBuf = ByteBuffer.allocate(newSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,737,int maximumAttempts = Math.max(1, master.getConfiguration().getInt(
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,739,for (int i = 0; i < maximumAttempts; i++) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,748,LOG.debug("Couldn't reach " + server + ", try=" + i
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,749,+ " of " + maximumAttempts, ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,62,if (ZKUtil.watchAndCheckExists(watcher, labelZnode)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,63,byte[] data = ZKUtil.getDataAndWatch(watcher, labelZnode);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,64,if (data != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,65,refreshVisibilityLabelsCache(data);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,68,if (ZKUtil.watchAndCheckExists(watcher, userAuthsZnode)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,69,byte[] data = ZKUtil.getDataAndWatch(watcher, userAuthsZnode);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,70,if (data != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,71,refreshUserAuthsCache(data);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/ZKVisibilityLabelWatcher.java,146,ZKUtil.createWithParents(watcher, znode);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,502,for (HRegionInfo hri : regionsToOffline) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,503,regionOffline(hri);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,512,if (authorize(getNamespacePermissions(table.getNamespaceAsString()).getGroup(groupName),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/TableAuthManager.java,513,table, family, action)) {
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java,1506,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,223,overwriteHeader();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1037,DONT_FILL_HEADER, startOffset,
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,278,InetSocketAddress inetSocketAddress = bindToPort(cmd.getOptionValue("bind"), listenPort);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,189,return this.delegate.seekBefore(splitkey, 0, splitkey.length);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HalfStoreFileReader.java,192,return this.delegate.seekBefore(key, offset, length);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,201,Cluster cluster = new Cluster(clusterState, loads, regionFinder);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,162,this.identifier = identifier;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,384,this.identifier = this.identifier + "-0x" +
hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterStatus.java,163,count += e.getValue().getTotalNumberOfRequests();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,293,if (currentPath != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,233,Long existingValue = flushedSequenceIdByRegion.get(entry.getKey());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,244,continue; // Don't let smaller sequence ids override greater
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,248,flushedSequenceIdByRegion.put(entry.getKey(), l);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,379,public long getLastFlushedSequenceId(byte[] regionName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,380,long seqId = -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,381,if (flushedSequenceIdByRegion.containsKey(regionName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,382,seqId = flushedSequenceIdByRegion.get(regionName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2013,public long getLastSequenceId(byte[] region) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2014,Long lastFlushedSequenceId = -1l;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2017,.buildGetLastFlushedSequenceIdRequest(region);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2021,lastFlushedSequenceId = -1l;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LastSequenceId.java,32,long getLastSequenceId(byte[] regionName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,556,f.getReader().close(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1180,&& (rs.isOpened() || rs.isSplitting())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1181,regionOnline(regionInfo, serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1182,if (disabled) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1184,LOG.info("Opened " + regionNameStr
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1185,+ "but this table is disabled, triggering close of region");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1186,unassign(regionInfo);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,789,requirePermission("modifyColumn", tableName, null, null, Action.ADMIN, Action.CREATE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,807,requirePermission("deleteColumn", tableName, null, null, Action.ADMIN, Action.CREATE);
hbase-common/src/main/java/org/apache/hadoop/hbase/util/Threads.java,119,ReflectionUtils.printThreadInfo(new PrintWriter(System.out),
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterDumpServlet.java,37,import org.apache.hadoop.util.ReflectionUtils;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterDumpServlet.java,80,ReflectionUtils.printThreadInfo(out, "");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSDumpServlet.java,34,import org.apache.hadoop.util.ReflectionUtils;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSDumpServlet.java,81,ReflectionUtils.printThreadInfo(out, "");
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,22,import java.io.PrintWriter;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/JVMClusterUtil.java,219,ReflectionUtils.printThreadInfo(new PrintWriter(System.out),
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java,922,coordinator.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1344,boolean didPerformCompaction = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1403,if (!didPerformCompaction) store.cancelRequestedCompaction(compaction);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1058,assert compaction != null && compaction.hasSelection();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1059,CompactionRequest cr = compaction.getRequest();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1060,Collection<StoreFile> filesToCompact = cr.getFiles();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1061,assert !filesToCompact.isEmpty();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1062,synchronized (filesCompacting) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1065,Preconditions.checkArgument(filesCompacting.containsAll(filesToCompact));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1069,LOG.info("Starting compaction of " + filesToCompact.size() + " file(s) in "
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1071,+ " into tmpdir=" + fs.getTempDir() + ", totalSize="
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1072,+ StringUtils.humanReadableInt(cr.getSize()));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1074,long compactionStartTime = EnvironmentEdgeManager.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1101,logCompactionEndMessage(cr, sfs, compactionStartTime);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1102,return sfs;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,118,? r.getFilterEntries() : r.getEntries();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,283,LOG.error("Retry attempted " + count +  " times without completing, bailing out");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,284,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2121,while (!batchOp.isDone()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2122,if (!batchOp.isInReplay()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2123,checkReadOnly();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2125,checkResources();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2127,long newSize;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2128,Operation op = Operation.BATCH_MUTATE;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2129,if (batchOp.isInReplay()) op = Operation.REPLAY_BATCH_MUTATE;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2130,startRegionOperation(op);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2132,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2141,newSize = this.addAndGetGlobalMemstoreSize(addedSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2143,closeRegionOperation(op);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2145,if (isFlushSize(newSize)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2146,requestFlush();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2273,rowLock = getRowLock(mutation.getRow(), shouldBlock);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3376,checkRow(row, "row lock");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3379,HashedBytes rowKey = new HashedBytes(row);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3380,RowLockContext rowLockContext = new RowLockContext(rowKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3383,while (true) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3384,RowLockContext existingContext = lockedRows.putIfAbsent(rowKey, rowLockContext);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3385,if (existingContext == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3387,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3390,rowLockContext = existingContext;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3391,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3394,if (!waitForLock) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3395,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3397,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3398,if (!existingContext.latch.await(this.rowLockWaitDuration, TimeUnit.MILLISECONDS)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3399,throw new IOException("Timed out waiting for lock for row: " + rowKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3402,LOG.warn("Thread interrupted waiting for lock on row: " + rowKey);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3403,InterruptedIOException iie = new InterruptedIOException();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3404,iie.initCause(ie);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3405,throw iie;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3411,return rowLockContext.newLock();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3413,closeRegionOperation();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,457,if (authManager.authorize(user, perm)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1004,requireGlobalPermission("createNamespace", Action.ADMIN, ns.getName());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Result.java,84,private static byte [] buffer = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3172,if (firstSeqIdInLog == -1) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3173,firstSeqIdInLog = key.getLogSeqNum();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3216,if (flush) internalFlushcache(null, currentEditSeqId, status);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,938,regionState = regionStates.updateRegionState(rt, State.OPEN);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/AbstractHBaseTool.java,139,HelpFormatter helpFormatter = new HelpFormatter();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/AbstractHBaseTool.java,140,helpFormatter.setWidth(80);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/AbstractHBaseTool.java,141,String usageHeader = "Options:";
hbase-server/src/main/java/org/apache/hadoop/hbase/util/AbstractHBaseTool.java,142,String usageFooter = "";
hbase-server/src/main/java/org/apache/hadoop/hbase/util/AbstractHBaseTool.java,143,String usageStr = "bin/hbase " + getClass().getName() + " <options>";
hbase-server/src/main/java/org/apache/hadoop/hbase/util/AbstractHBaseTool.java,145,helpFormatter.printHelp(usageStr, usageHeader, options,
hbase-server/src/main/java/org/apache/hadoop/hbase/util/AbstractHBaseTool.java,146,usageFooter);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1711,String msg = "Unable to read call parameter from client " + getHostAddress();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,837,for (Enumeration<URL> itr = loader.getResources(class_file); itr.hasMoreElements();) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,838,URL url = itr.nextElement();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,839,if ("jar".equals(url.getProtocol())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,840,String toReturn = url.getPath();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,841,if (toReturn.startsWith("file:")) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,842,toReturn = toReturn.substring("file:".length());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,850,toReturn = toReturn.replaceAll("\\+", "%2B");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,851,toReturn = URLDecoder.decode(toReturn, "UTF-8");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,852,return toReturn.replaceAll("!.*$", "");
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,58,return
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,59,table.coprocessorService(SecureBulkLoadProtos.SecureBulkLoadService.class,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,60,EMPTY_START_ROW,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,61,LAST_ROW,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,62,new Batch.Call<SecureBulkLoadProtos.SecureBulkLoadService,String>() {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,64,public String call(SecureBulkLoadProtos.SecureBulkLoadService instance) throws IOException {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,65,ServerRpcController controller = new ServerRpcController();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,67,BlockingRpcCallback<SecureBulkLoadProtos.PrepareBulkLoadResponse> rpcCallback =
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,68,new BlockingRpcCallback<SecureBulkLoadProtos.PrepareBulkLoadResponse>();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,70,SecureBulkLoadProtos.PrepareBulkLoadRequest request =
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,72,.setTableName(ProtobufUtil.toProtoTableName(tableName)).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,74,instance.prepareBulkLoad(controller,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,75,request,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,76,rpcCallback);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,78,SecureBulkLoadProtos.PrepareBulkLoadResponse response = rpcCallback.get();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,79,if (controller.failedOnException()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,80,throw controller.getFailedOn();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,82,return response.getBulkToken();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,92,table.coprocessorService(SecureBulkLoadProtos.SecureBulkLoadService.class,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,93,EMPTY_START_ROW,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,94,LAST_ROW,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,95,new Batch.Call<SecureBulkLoadProtos.SecureBulkLoadService, String>() {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,98,public String call(SecureBulkLoadProtos.SecureBulkLoadService instance) throws IOException {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,99,ServerRpcController controller = new ServerRpcController();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,101,BlockingRpcCallback<SecureBulkLoadProtos.CleanupBulkLoadResponse> rpcCallback =
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,102,new BlockingRpcCallback<SecureBulkLoadProtos.CleanupBulkLoadResponse>();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,104,SecureBulkLoadProtos.CleanupBulkLoadRequest request =
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,106,.setBulkToken(bulkToken).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,108,instance.cleanupBulkLoad(controller,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,109,request,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,110,rpcCallback);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,112,if (controller.failedOnException()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,113,throw controller.getFailedOn();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,115,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,172,fs.delete(createStagingDir(baseStagingDir,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,173,getActiveUser(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,175,new Path(request.getBulkToken()).getName()),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,176,true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4416,HRegion createDaughterRegionFromSplits(final HRegionInfo hri) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4418,fs.commitDaughterRegion(hri);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,40,import org.apache.hadoop.fs.PathFilter;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,205,new PathFilter () {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,206,public boolean accept(Path path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,207,return StoreFileInfo.isReference(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,210,);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,483,Path commitDaughterRegion(final HRegionInfo regionInfo) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,355,splitStoreFiles(hstoreFilesToSplit);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,362,HRegion a = this.parent.createDaughterRegionFromSplits(this.hri_a);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,366,HRegion b = this.parent.createDaughterRegionFromSplits(this.hri_b);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,701,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,708,List<Future<Void>> futures = new ArrayList<Future<Void>>(nbFiles);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,738,for (Future<Void> future: futures) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,740,future.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,742,throw (InterruptedIOException)new InterruptedIOException().initCause(e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,749,private void splitStoreFile(final byte[] family, final StoreFile sf) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,752,fs.splitStoreFile(this.hri_a, familyName, sf, this.splitrow, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,753,fs.splitStoreFile(this.hri_b, familyName, sf, this.splitrow, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,760,class StoreFileSplitter implements Callable<Void> {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,774,public Void call() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,775,splitStoreFile(family, sf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitTransaction.java,776,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1451,final public static Pattern hfilePattern = Pattern.compile("^([0-9a-f]+)$");
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1461,if (!hfilePattern.matcher(rd.getName()).matches()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1467,return !fs.getFileStatus(rd).isDir();
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,358,MetaRegionServer rss =
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,359,MetaRegionServer.PARSER.parseFrom(data, prefixLen, data.length - prefixLen);
hbase-client/src/main/java/org/apache/hadoop/hbase/ServerName.java,360,org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName sn = rss.getServer();
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,59,MERGING_NEW     // new region to be created when RS merges two
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,265,ClusterStatusProtos.RegionState.State rs;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,267,case OFFLINE:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,268,rs = ClusterStatusProtos.RegionState.State.OFFLINE;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,269,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,270,case PENDING_OPEN:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,271,rs = ClusterStatusProtos.RegionState.State.PENDING_OPEN;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,272,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,273,case OPENING:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,274,rs = ClusterStatusProtos.RegionState.State.OPENING;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,275,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,276,case OPEN:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,277,rs = ClusterStatusProtos.RegionState.State.OPEN;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,278,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,279,case PENDING_CLOSE:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,280,rs = ClusterStatusProtos.RegionState.State.PENDING_CLOSE;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,281,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,282,case CLOSING:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,283,rs = ClusterStatusProtos.RegionState.State.CLOSING;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,284,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,285,case CLOSED:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,286,rs = ClusterStatusProtos.RegionState.State.CLOSED;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,287,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,288,case SPLITTING:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,289,rs = ClusterStatusProtos.RegionState.State.SPLITTING;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,290,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,291,case SPLIT:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,292,rs = ClusterStatusProtos.RegionState.State.SPLIT;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,293,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,294,case FAILED_OPEN:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,295,rs = ClusterStatusProtos.RegionState.State.FAILED_OPEN;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,296,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,297,case FAILED_CLOSE:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,298,rs = ClusterStatusProtos.RegionState.State.FAILED_CLOSE;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,299,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,300,case MERGING:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,301,rs = ClusterStatusProtos.RegionState.State.MERGING;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,302,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,303,case MERGED:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,304,rs = ClusterStatusProtos.RegionState.State.MERGED;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,305,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,306,case SPLITTING_NEW:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,307,rs = ClusterStatusProtos.RegionState.State.SPLITTING_NEW;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,308,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,309,case MERGING_NEW:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,310,rs = ClusterStatusProtos.RegionState.State.MERGING_NEW;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,311,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,312,default:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,313,throw new IllegalStateException("");
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,316,regionState.setState(rs);
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,327,RegionState.State state;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,328,switch (proto.getState()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,329,case OFFLINE:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,330,state = State.OFFLINE;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,331,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,332,case PENDING_OPEN:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,333,state = State.PENDING_OPEN;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,334,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,335,case OPENING:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,336,state = State.OPENING;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,337,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,338,case OPEN:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,339,state = State.OPEN;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,340,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,341,case PENDING_CLOSE:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,342,state = State.PENDING_CLOSE;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,343,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,344,case CLOSING:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,345,state = State.CLOSING;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,346,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,347,case CLOSED:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,348,state = State.CLOSED;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,349,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,350,case SPLITTING:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,351,state = State.SPLITTING;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,352,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,353,case SPLIT:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,354,state = State.SPLIT;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,355,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,356,case FAILED_OPEN:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,357,state = State.FAILED_OPEN;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,358,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,359,case FAILED_CLOSE:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,360,state = State.FAILED_CLOSE;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,361,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,362,case MERGING:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,363,state = State.MERGING;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,364,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,365,case MERGED:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,366,state = State.MERGED;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,367,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,368,case SPLITTING_NEW:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,369,state = State.SPLITTING_NEW;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,370,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,371,case MERGING_NEW:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,372,state = State.MERGING_NEW;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,373,break;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,374,default:
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,375,throw new IllegalStateException("");
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,378,return new RegionState(HRegionInfo.convert(proto.getRegionInfo()),state,proto.getStamp(),null);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,54,return super.getData(true) != null;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,62,public ServerName getMetaRegionLocation() throws InterruptedException {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,63,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,64,return ServerName.parseFrom(super.getData(true));
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,66,LOG.warn("Failed parse", e);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,67,return null;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,79,throws KeeperException {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,80,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,81,return ServerName.parseFrom(ZKUtil.getData(zkw, zkw.metaServerZNode));
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,83,throw ZKUtil.convert(e);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,106,return ServerName.parseFrom(super.blockUntilAvailable(timeout, true));
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,108,LOG.warn("Failed parse", e);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,109,return null;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,126,byte [] data = toByteArray(location);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,140,static byte [] toByteArray(final ServerName sn) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,184,if (data == null) return null;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/MetaRegionTracker.java,186,return ServerName.parseFrom(data);
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ZooKeeperProtos.java,9436,new java.lang.String[] { "Server", "RpcVersion", });
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,640,MetaRegionTracker.setMetaLocation(watcher, sn);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,991,regionStates.createRegionState(HRegionInfo.FIRST_META_REGIONINFO);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,992,boolean rit = this.assignmentManager
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,993,.processRegionInTransitionAndBlockUntilAssigned(HRegionInfo.FIRST_META_REGIONINFO);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,995,ServerName currentMetaServer = this.catalogTracker.getMetaLocation();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,996,if (!metaRegionLocation) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1000,if (!rit) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1766,if (r.getRegionInfo().isMetaRegion()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1767,MetaRegionTracker.setMetaLocation(getZooKeeper(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1768,this.serverNameFromMasterPOV);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1770,MetaEditor.updateRegionLocation(ct, r.getRegionInfo(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1771,this.serverNameFromMasterPOV, openSeqNum);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/DefaultScanLabelGenerator.java,35,public class DefaultScanLabelGenerator implements ScanLabelGenerator {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/DefaultScanLabelGenerator.java,37,private static final Log LOG = LogFactory.getLog(DefaultScanLabelGenerator.class);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/DefaultScanLabelGenerator.java,43,public DefaultScanLabelGenerator() {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,1860,closeRegion(hbi);// Close region will cause RS to abort.
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2017,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,2313,LOG.info("Plugged hold by creating new empty region: "+ newRegion + " " +region);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java,43,import org.apache.hadoop.hbase.regionserver.wal.HLog;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java,190,HRegion region = HRegion.createHRegion(hri, root, conf, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java,191,HLog hlog = region.getLog();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java,195,hlog.closeAndDelete();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1868,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1869,Thread.sleep(this.sleepTimeBeforeRetryingMetaAssignment);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1870,if (i == maximumAttempts) i = 1;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1873,LOG.error("Got exception while waiting for hbase:meta assignment");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1874,Thread.currentThread().interrupt();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,2012,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileLinkCleaner.java,58,Path hfilePath = HFileLink.getHFileFromBackReference(getConf(), filePath);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileLinkCleaner.java,61,LOG.error("Couldn't verify if the referenced file still exists, keep it just in case");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileLinkCleaner.java,68,Path backRefDir = HFileLink.getBackReferencesDir(parentDir, filePath.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileLinkCleaner.java,71,LOG.error("Couldn't get the references, not deleting file, just in case");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/HFileLinkCleaner.java,84,LOG.error("Couldn't instantiate the file system, not deleting file, just in case");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,132,AccessControlService.Interface, CoprocessorService, EndpointObserver {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1462,public void prePrepareBulkLoad(RegionCoprocessorEnvironment e) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1478,public void preCleanupBulkLoad(RegionCoprocessorEnvironment e) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,263,private AccessController getAccessController() {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,265,.getCoprocessorHost().findCoprocessor(AccessController.class.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5010,kv.getQualifierLength(), now, KeyValue.Type.Put,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5219,KeyValue newKV = new KeyValue(row.length, family.getKey().length, q.length, now,
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,756,int exitCode = ToolRunner.run(HBaseConfiguration.create(), new Canary(), args);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,76,LOG.info("No regions under directory:" + tableDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,97,LOG.info("No families under region directory:" + regionDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,109,LOG.debug("No hfiles found for family: " + familyDir + ", skipping.");
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,176,LOG.info("No logs under directory:" + logsDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,185,LOG.debug("No hfiles found for server: " + serverName + ", skipping.");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1381,didPerformCompaction = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1436,finishCompactionRequest(compaction.getRequest());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java,498,this.rsServices.removeFromOnlineRegions(region, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java,499,region.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,209,int bytesWritten = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,214,int closeCheckInterval = HStore.getCloseCheckInterval();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/Compactor.java,229,bytesWritten += kv.getLength();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/AlreadyExists.java,232,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/BatchMutation.java,320,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/ColumnDescriptor.java,735,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,3825,public static class
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,3826,createTable<I extends Iface> extends org.apache.thrift.ProcessFunction<I, createTable_args> {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,4912,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,5266,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,5644,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,5998,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,6376,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,6791,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,7196,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,7550,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,7916,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,8270,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,8561,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,8951,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9063,org.apache.thrift.protocol.TList _list26 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9064,struct.success = new ArrayList<ByteBuffer>(_list26.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9067,ByteBuffer _elem28; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9068,_elem28 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9069,struct.success.add(_elem28);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9108,oprot.writeBinary(_iter29);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9149,oprot.writeBinary(_iter30);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9164,org.apache.thrift.protocol.TList _list31 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9165,struct.success = new ArrayList<ByteBuffer>(_list31.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9168,ByteBuffer _elem33; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9169,_elem33 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9170,struct.success.add(_elem33);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9402,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9840,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9952,org.apache.thrift.protocol.TMap _map34 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9953,struct.success = new HashMap<ByteBuffer,ColumnDescriptor>(2*_map34.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9956,ByteBuffer _key36; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9957,ColumnDescriptor _val37; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9958,_key36 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9959,_val37 = new ColumnDescriptor();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9960,_val37.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,9961,struct.success.put(_key36, _val37);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10000,oprot.writeBinary(_iter38.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10001,_iter38.getValue().write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10042,oprot.writeBinary(_iter39.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10043,_iter39.getValue().write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10058,org.apache.thrift.protocol.TMap _map40 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10059,struct.success = new HashMap<ByteBuffer,ColumnDescriptor>(2*_map40.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10062,ByteBuffer _key42; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10063,ColumnDescriptor _val43; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10064,_key42 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10065,_val43 = new ColumnDescriptor();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10066,_val43.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10067,struct.success.put(_key42, _val43);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10299,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10732,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10844,org.apache.thrift.protocol.TList _list44 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10845,struct.success = new ArrayList<TRegionInfo>(_list44.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10848,TRegionInfo _elem46; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10849,_elem46 = new TRegionInfo();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10850,_elem46.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10851,struct.success.add(_elem46);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10890,_iter47.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10931,_iter48.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10946,org.apache.thrift.protocol.TList _list49 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10947,struct.success = new ArrayList<TRegionInfo>(_list49.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10950,TRegionInfo _elem51; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10951,_elem51 = new TRegionInfo();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10952,_elem51.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,10953,struct.success.add(_elem51);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11276,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11396,org.apache.thrift.protocol.TList _list52 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11397,struct.columnFamilies = new ArrayList<ColumnDescriptor>(_list52.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11400,ColumnDescriptor _elem54; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11401,_elem54 = new ColumnDescriptor();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11402,_elem54.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11403,struct.columnFamilies.add(_elem54);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11438,_iter55.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11477,_iter56.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11493,org.apache.thrift.protocol.TList _list57 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11494,struct.columnFamilies = new ArrayList<ColumnDescriptor>(_list57.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11497,ColumnDescriptor _elem59; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11498,_elem59 = new ColumnDescriptor();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11499,_elem59.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11500,struct.columnFamilies.add(_elem59);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,11823,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,12287,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,12641,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13277,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13449,org.apache.thrift.protocol.TMap _map60 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13450,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map60.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13453,ByteBuffer _key62; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13454,ByteBuffer _val63; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13455,_key62 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13456,_val63 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13457,struct.attributes.put(_key62, _val63);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13502,oprot.writeBinary(_iter64.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13503,oprot.writeBinary(_iter64.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13554,oprot.writeBinary(_iter65.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13555,oprot.writeBinary(_iter65.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13579,org.apache.thrift.protocol.TMap _map66 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13580,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map66.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13583,ByteBuffer _key68; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13584,ByteBuffer _val69; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13585,_key68 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13586,_val69 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13587,struct.attributes.put(_key68, _val69);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13871,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13983,org.apache.thrift.protocol.TList _list70 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13984,struct.success = new ArrayList<TCell>(_list70.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13987,TCell _elem72; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13988,_elem72 = new TCell();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13989,_elem72.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,13990,struct.success.add(_elem72);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14029,_iter73.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14070,_iter74.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14085,org.apache.thrift.protocol.TList _list75 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14086,struct.success = new ArrayList<TCell>(_list75.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14089,TCell _elem77; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14090,_elem77 = new TCell();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14091,_elem77.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14092,struct.success.add(_elem77);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14655,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14851,org.apache.thrift.protocol.TMap _map78 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14852,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map78.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14855,ByteBuffer _key80; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14856,ByteBuffer _val81; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14857,_key80 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14858,_val81 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14859,struct.attributes.put(_key80, _val81);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14907,oprot.writeBinary(_iter82.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14908,oprot.writeBinary(_iter82.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14965,oprot.writeBinary(_iter83.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14966,oprot.writeBinary(_iter83.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14994,org.apache.thrift.protocol.TMap _map84 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14995,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map84.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14998,ByteBuffer _key86; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,14999,ByteBuffer _val87; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15000,_key86 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15001,_val87 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15002,struct.attributes.put(_key86, _val87);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15286,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15398,org.apache.thrift.protocol.TList _list88 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15399,struct.success = new ArrayList<TCell>(_list88.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15402,TCell _elem90; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15403,_elem90 = new TCell();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15404,_elem90.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15405,struct.success.add(_elem90);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15444,_iter91.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15485,_iter92.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15500,org.apache.thrift.protocol.TList _list93 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15501,struct.success = new ArrayList<TCell>(_list93.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15504,TCell _elem95; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15505,_elem95 = new TCell();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15506,_elem95.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,15507,struct.success.add(_elem95);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16141,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16359,org.apache.thrift.protocol.TMap _map96 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16360,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map96.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16363,ByteBuffer _key98; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16364,ByteBuffer _val99; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16365,_key98 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16366,_val99 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16367,struct.attributes.put(_key98, _val99);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16418,oprot.writeBinary(_iter100.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16419,oprot.writeBinary(_iter100.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16482,oprot.writeBinary(_iter101.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16483,oprot.writeBinary(_iter101.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16515,org.apache.thrift.protocol.TMap _map102 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16516,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map102.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16519,ByteBuffer _key104; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16520,ByteBuffer _val105; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16521,_key104 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16522,_val105 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16523,struct.attributes.put(_key104, _val105);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16807,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16919,org.apache.thrift.protocol.TList _list106 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16920,struct.success = new ArrayList<TCell>(_list106.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16923,TCell _elem108; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16924,_elem108 = new TCell();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16925,_elem108.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16926,struct.success.add(_elem108);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,16965,_iter109.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17006,_iter110.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17021,org.apache.thrift.protocol.TList _list111 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17022,struct.success = new ArrayList<TCell>(_list111.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17025,TCell _elem113; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17026,_elem113 = new TCell();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17027,_elem113.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17028,struct.success.add(_elem113);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17437,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17583,org.apache.thrift.protocol.TMap _map114 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17584,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map114.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17587,ByteBuffer _key116; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17588,ByteBuffer _val117; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17589,_key116 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17590,_val117 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17591,struct.attributes.put(_key116, _val117);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17631,oprot.writeBinary(_iter118.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17632,oprot.writeBinary(_iter118.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17677,oprot.writeBinary(_iter119.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17678,oprot.writeBinary(_iter119.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17698,org.apache.thrift.protocol.TMap _map120 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17699,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map120.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17702,ByteBuffer _key122; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17703,ByteBuffer _val123; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17704,_key122 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17705,_val123 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17706,struct.attributes.put(_key122, _val123);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,17990,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18102,org.apache.thrift.protocol.TList _list124 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18103,struct.success = new ArrayList<TRowResult>(_list124.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18106,TRowResult _elem126; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18107,_elem126 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18108,_elem126.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18109,struct.success.add(_elem126);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18148,_iter127.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18189,_iter128.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18204,org.apache.thrift.protocol.TList _list129 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18205,struct.success = new ArrayList<TRowResult>(_list129.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18208,TRowResult _elem131; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18209,_elem131 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18210,_elem131.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18211,struct.success.add(_elem131);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18711,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18875,org.apache.thrift.protocol.TList _list132 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18876,struct.columns = new ArrayList<ByteBuffer>(_list132.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18879,ByteBuffer _elem134; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18880,_elem134 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18881,struct.columns.add(_elem134);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18893,org.apache.thrift.protocol.TMap _map135 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18894,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map135.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18897,ByteBuffer _key137; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18898,ByteBuffer _val138; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18899,_key137 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18900,_val138 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18901,struct.attributes.put(_key137, _val138);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18941,oprot.writeBinary(_iter139);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18953,oprot.writeBinary(_iter140.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,18954,oprot.writeBinary(_iter140.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19002,oprot.writeBinary(_iter141);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19011,oprot.writeBinary(_iter142.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19012,oprot.writeBinary(_iter142.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19032,org.apache.thrift.protocol.TList _list143 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19033,struct.columns = new ArrayList<ByteBuffer>(_list143.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19036,ByteBuffer _elem145; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19037,_elem145 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19038,struct.columns.add(_elem145);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19045,org.apache.thrift.protocol.TMap _map146 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19046,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map146.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19049,ByteBuffer _key148; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19050,ByteBuffer _val149; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19051,_key148 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19052,_val149 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19053,struct.attributes.put(_key148, _val149);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19337,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19449,org.apache.thrift.protocol.TList _list150 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19450,struct.success = new ArrayList<TRowResult>(_list150.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19453,TRowResult _elem152; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19454,_elem152 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19455,_elem152.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19456,struct.success.add(_elem152);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19495,_iter153.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19536,_iter154.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19551,org.apache.thrift.protocol.TList _list155 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19552,struct.success = new ArrayList<TRowResult>(_list155.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19555,TRowResult _elem157; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19556,_elem157 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19557,_elem157.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,19558,struct.success.add(_elem157);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20040,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20210,org.apache.thrift.protocol.TMap _map158 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20211,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map158.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20214,ByteBuffer _key160; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20215,ByteBuffer _val161; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20216,_key160 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20217,_val161 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20218,struct.attributes.put(_key160, _val161);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20261,oprot.writeBinary(_iter162.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20262,oprot.writeBinary(_iter162.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20313,oprot.writeBinary(_iter163.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20314,oprot.writeBinary(_iter163.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20338,org.apache.thrift.protocol.TMap _map164 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20339,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map164.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20342,ByteBuffer _key166; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20343,ByteBuffer _val167; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20344,_key166 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20345,_val167 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20346,struct.attributes.put(_key166, _val167);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20630,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20742,org.apache.thrift.protocol.TList _list168 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20743,struct.success = new ArrayList<TRowResult>(_list168.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20746,TRowResult _elem170; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20747,_elem170 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20748,_elem170.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20749,struct.success.add(_elem170);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20788,_iter171.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20829,_iter172.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20844,org.apache.thrift.protocol.TList _list173 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20845,struct.success = new ArrayList<TRowResult>(_list173.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20848,TRowResult _elem175; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20849,_elem175 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20850,_elem175.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,20851,struct.success.add(_elem175);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21412,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21592,org.apache.thrift.protocol.TList _list176 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21593,struct.columns = new ArrayList<ByteBuffer>(_list176.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21596,ByteBuffer _elem178; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21597,_elem178 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21598,struct.columns.add(_elem178);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21618,org.apache.thrift.protocol.TMap _map179 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21619,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map179.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21622,ByteBuffer _key181; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21623,ByteBuffer _val182; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21624,_key181 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21625,_val182 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21626,struct.attributes.put(_key181, _val182);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21666,oprot.writeBinary(_iter183);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21681,oprot.writeBinary(_iter184.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21682,oprot.writeBinary(_iter184.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21733,oprot.writeBinary(_iter185);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21745,oprot.writeBinary(_iter186.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21746,oprot.writeBinary(_iter186.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21766,org.apache.thrift.protocol.TList _list187 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21767,struct.columns = new ArrayList<ByteBuffer>(_list187.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21770,ByteBuffer _elem189; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21771,_elem189 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21772,struct.columns.add(_elem189);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21783,org.apache.thrift.protocol.TMap _map190 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21784,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map190.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21787,ByteBuffer _key192; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21788,ByteBuffer _val193; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21789,_key192 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21790,_val193 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,21791,struct.attributes.put(_key192, _val193);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22075,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22187,org.apache.thrift.protocol.TList _list194 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22188,struct.success = new ArrayList<TRowResult>(_list194.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22191,TRowResult _elem196; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22192,_elem196 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22193,_elem196.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22194,struct.success.add(_elem196);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22233,_iter197.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22274,_iter198.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22289,org.apache.thrift.protocol.TList _list199 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22290,struct.success = new ArrayList<TRowResult>(_list199.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22293,TRowResult _elem201; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22294,_elem201 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22295,_elem201.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22296,struct.success.add(_elem201);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22715,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22853,org.apache.thrift.protocol.TList _list202 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22854,struct.rows = new ArrayList<ByteBuffer>(_list202.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22857,ByteBuffer _elem204; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22858,_elem204 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22859,struct.rows.add(_elem204);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22871,org.apache.thrift.protocol.TMap _map205 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22872,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map205.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22875,ByteBuffer _key207; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22876,ByteBuffer _val208; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22877,_key207 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22878,_val208 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22879,struct.attributes.put(_key207, _val208);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22914,oprot.writeBinary(_iter209);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22926,oprot.writeBinary(_iter210.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22927,oprot.writeBinary(_iter210.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22969,oprot.writeBinary(_iter211);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22978,oprot.writeBinary(_iter212.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22979,oprot.writeBinary(_iter212.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22995,org.apache.thrift.protocol.TList _list213 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22996,struct.rows = new ArrayList<ByteBuffer>(_list213.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,22999,ByteBuffer _elem215; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23000,_elem215 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23001,struct.rows.add(_elem215);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23008,org.apache.thrift.protocol.TMap _map216 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23009,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map216.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23012,ByteBuffer _key218; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23013,ByteBuffer _val219; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23014,_key218 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23015,_val219 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23016,struct.attributes.put(_key218, _val219);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23300,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23412,org.apache.thrift.protocol.TList _list220 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23413,struct.success = new ArrayList<TRowResult>(_list220.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23416,TRowResult _elem222; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23417,_elem222 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23418,_elem222.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23419,struct.success.add(_elem222);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23458,_iter223.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23499,_iter224.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23514,org.apache.thrift.protocol.TList _list225 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23515,struct.success = new ArrayList<TRowResult>(_list225.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23518,TRowResult _elem227; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23519,_elem227 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23520,_elem227.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,23521,struct.success.add(_elem227);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24031,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24187,org.apache.thrift.protocol.TList _list228 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24188,struct.rows = new ArrayList<ByteBuffer>(_list228.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24191,ByteBuffer _elem230; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24192,_elem230 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24193,struct.rows.add(_elem230);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24205,org.apache.thrift.protocol.TList _list231 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24206,struct.columns = new ArrayList<ByteBuffer>(_list231.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24209,ByteBuffer _elem233; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24210,_elem233 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24211,struct.columns.add(_elem233);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24223,org.apache.thrift.protocol.TMap _map234 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24224,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map234.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24227,ByteBuffer _key236; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24228,ByteBuffer _val237; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24229,_key236 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24230,_val237 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24231,struct.attributes.put(_key236, _val237);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24266,oprot.writeBinary(_iter238);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24278,oprot.writeBinary(_iter239);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24290,oprot.writeBinary(_iter240.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24291,oprot.writeBinary(_iter240.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24336,oprot.writeBinary(_iter241);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24345,oprot.writeBinary(_iter242);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24354,oprot.writeBinary(_iter243.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24355,oprot.writeBinary(_iter243.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24371,org.apache.thrift.protocol.TList _list244 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24372,struct.rows = new ArrayList<ByteBuffer>(_list244.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24375,ByteBuffer _elem246; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24376,_elem246 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24377,struct.rows.add(_elem246);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24384,org.apache.thrift.protocol.TList _list247 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24385,struct.columns = new ArrayList<ByteBuffer>(_list247.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24388,ByteBuffer _elem249; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24389,_elem249 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24390,struct.columns.add(_elem249);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24397,org.apache.thrift.protocol.TMap _map250 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24398,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map250.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24401,ByteBuffer _key252; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24402,ByteBuffer _val253; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24403,_key252 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24404,_val253 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24405,struct.attributes.put(_key252, _val253);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24689,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24801,org.apache.thrift.protocol.TList _list254 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24802,struct.success = new ArrayList<TRowResult>(_list254.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24805,TRowResult _elem256; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24806,_elem256 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24807,_elem256.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24808,struct.success.add(_elem256);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24847,_iter257.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24888,_iter258.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24903,org.apache.thrift.protocol.TList _list259 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24904,struct.success = new ArrayList<TRowResult>(_list259.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24907,TRowResult _elem261; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24908,_elem261 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24909,_elem261.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,24910,struct.success.add(_elem261);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25402,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25556,org.apache.thrift.protocol.TList _list262 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25557,struct.rows = new ArrayList<ByteBuffer>(_list262.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25560,ByteBuffer _elem264; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25561,_elem264 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25562,struct.rows.add(_elem264);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25582,org.apache.thrift.protocol.TMap _map265 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25583,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map265.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25586,ByteBuffer _key267; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25587,ByteBuffer _val268; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25588,_key267 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25589,_val268 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25590,struct.attributes.put(_key267, _val268);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25625,oprot.writeBinary(_iter269);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25640,oprot.writeBinary(_iter270.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25641,oprot.writeBinary(_iter270.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25686,oprot.writeBinary(_iter271);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25698,oprot.writeBinary(_iter272.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25699,oprot.writeBinary(_iter272.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25715,org.apache.thrift.protocol.TList _list273 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25716,struct.rows = new ArrayList<ByteBuffer>(_list273.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25719,ByteBuffer _elem275; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25720,_elem275 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25721,struct.rows.add(_elem275);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25732,org.apache.thrift.protocol.TMap _map276 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25733,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map276.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25736,ByteBuffer _key278; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25737,ByteBuffer _val279; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25738,_key278 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25739,_val279 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,25740,struct.attributes.put(_key278, _val279);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26024,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26136,org.apache.thrift.protocol.TList _list280 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26137,struct.success = new ArrayList<TRowResult>(_list280.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26140,TRowResult _elem282; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26141,_elem282 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26142,_elem282.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26143,struct.success.add(_elem282);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26182,_iter283.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26223,_iter284.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26238,org.apache.thrift.protocol.TList _list285 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26239,struct.success = new ArrayList<TRowResult>(_list285.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26242,TRowResult _elem287; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26243,_elem287 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26244,_elem287.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26245,struct.success.add(_elem287);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26816,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26988,org.apache.thrift.protocol.TList _list288 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26989,struct.rows = new ArrayList<ByteBuffer>(_list288.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26992,ByteBuffer _elem290; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26993,_elem290 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,26994,struct.rows.add(_elem290);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27006,org.apache.thrift.protocol.TList _list291 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27007,struct.columns = new ArrayList<ByteBuffer>(_list291.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27010,ByteBuffer _elem293; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27011,_elem293 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27012,struct.columns.add(_elem293);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27032,org.apache.thrift.protocol.TMap _map294 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27033,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map294.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27036,ByteBuffer _key296; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27037,ByteBuffer _val297; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27038,_key296 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27039,_val297 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27040,struct.attributes.put(_key296, _val297);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27075,oprot.writeBinary(_iter298);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27087,oprot.writeBinary(_iter299);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27102,oprot.writeBinary(_iter300.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27103,oprot.writeBinary(_iter300.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27151,oprot.writeBinary(_iter301);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27160,oprot.writeBinary(_iter302);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27172,oprot.writeBinary(_iter303.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27173,oprot.writeBinary(_iter303.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27189,org.apache.thrift.protocol.TList _list304 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27190,struct.rows = new ArrayList<ByteBuffer>(_list304.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27193,ByteBuffer _elem306; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27194,_elem306 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27195,struct.rows.add(_elem306);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27202,org.apache.thrift.protocol.TList _list307 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27203,struct.columns = new ArrayList<ByteBuffer>(_list307.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27206,ByteBuffer _elem309; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27207,_elem309 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27208,struct.columns.add(_elem309);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27219,org.apache.thrift.protocol.TMap _map310 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27220,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map310.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27223,ByteBuffer _key312; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27224,ByteBuffer _val313; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27225,_key312 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27226,_val313 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27227,struct.attributes.put(_key312, _val313);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27511,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27623,org.apache.thrift.protocol.TList _list314 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27624,struct.success = new ArrayList<TRowResult>(_list314.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27627,TRowResult _elem316; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27628,_elem316 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27629,_elem316.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27630,struct.success.add(_elem316);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27669,_iter317.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27710,_iter318.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27725,org.apache.thrift.protocol.TList _list319 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27726,struct.success = new ArrayList<TRowResult>(_list319.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27729,TRowResult _elem321; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27730,_elem321 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27731,_elem321.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,27732,struct.success.add(_elem321);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28232,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28396,org.apache.thrift.protocol.TList _list322 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28397,struct.mutations = new ArrayList<Mutation>(_list322.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28400,Mutation _elem324; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28401,_elem324 = new Mutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28402,_elem324.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28403,struct.mutations.add(_elem324);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28415,org.apache.thrift.protocol.TMap _map325 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28416,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map325.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28419,ByteBuffer _key327; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28420,ByteBuffer _val328; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28421,_key327 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28422,_val328 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28423,struct.attributes.put(_key327, _val328);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28463,_iter329.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28475,oprot.writeBinary(_iter330.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28476,oprot.writeBinary(_iter330.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28524,_iter331.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28533,oprot.writeBinary(_iter332.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28534,oprot.writeBinary(_iter332.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28554,org.apache.thrift.protocol.TList _list333 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28555,struct.mutations = new ArrayList<Mutation>(_list333.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28558,Mutation _elem335; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28559,_elem335 = new Mutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28560,_elem335.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28561,struct.mutations.add(_elem335);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28568,org.apache.thrift.protocol.TMap _map336 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28569,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map336.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28572,ByteBuffer _key338; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28573,ByteBuffer _val339; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28574,_key338 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28575,_val339 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28576,struct.attributes.put(_key338, _val339);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,28840,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29602,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29782,org.apache.thrift.protocol.TList _list340 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29783,struct.mutations = new ArrayList<Mutation>(_list340.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29786,Mutation _elem342; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29787,_elem342 = new Mutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29788,_elem342.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29789,struct.mutations.add(_elem342);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29809,org.apache.thrift.protocol.TMap _map343 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29810,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map343.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29813,ByteBuffer _key345; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29814,ByteBuffer _val346; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29815,_key345 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29816,_val346 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29817,struct.attributes.put(_key345, _val346);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29857,_iter347.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29872,oprot.writeBinary(_iter348.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29873,oprot.writeBinary(_iter348.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29924,_iter349.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29936,oprot.writeBinary(_iter350.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29937,oprot.writeBinary(_iter350.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29957,org.apache.thrift.protocol.TList _list351 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29958,struct.mutations = new ArrayList<Mutation>(_list351.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29961,Mutation _elem353; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29962,_elem353 = new Mutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29963,_elem353.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29964,struct.mutations.add(_elem353);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29975,org.apache.thrift.protocol.TMap _map354 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29976,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map354.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29979,ByteBuffer _key356; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29980,ByteBuffer _val357; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29981,_key356 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29982,_val357 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,29983,struct.attributes.put(_key356, _val357);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,30247,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,30855,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,30993,org.apache.thrift.protocol.TList _list358 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,30994,struct.rowBatches = new ArrayList<BatchMutation>(_list358.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,30997,BatchMutation _elem360; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,30998,_elem360 = new BatchMutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,30999,_elem360.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31000,struct.rowBatches.add(_elem360);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31012,org.apache.thrift.protocol.TMap _map361 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31013,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map361.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31016,ByteBuffer _key363; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31017,ByteBuffer _val364; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31018,_key363 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31019,_val364 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31020,struct.attributes.put(_key363, _val364);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31055,_iter365.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31067,oprot.writeBinary(_iter366.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31068,oprot.writeBinary(_iter366.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31110,_iter367.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31119,oprot.writeBinary(_iter368.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31120,oprot.writeBinary(_iter368.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31136,org.apache.thrift.protocol.TList _list369 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31137,struct.rowBatches = new ArrayList<BatchMutation>(_list369.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31140,BatchMutation _elem371; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31141,_elem371 = new BatchMutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31142,_elem371.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31143,struct.rowBatches.add(_elem371);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31150,org.apache.thrift.protocol.TMap _map372 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31151,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map372.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31154,ByteBuffer _key374; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31155,ByteBuffer _val375; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31156,_key374 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31157,_val375 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31158,struct.attributes.put(_key374, _val375);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,31422,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32103,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32257,org.apache.thrift.protocol.TList _list376 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32258,struct.rowBatches = new ArrayList<BatchMutation>(_list376.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32261,BatchMutation _elem378; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32262,_elem378 = new BatchMutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32263,_elem378.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32264,struct.rowBatches.add(_elem378);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32284,org.apache.thrift.protocol.TMap _map379 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32285,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map379.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32288,ByteBuffer _key381; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32289,ByteBuffer _val382; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32290,_key381 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32291,_val382 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32292,struct.attributes.put(_key381, _val382);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32327,_iter383.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32342,oprot.writeBinary(_iter384.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32343,oprot.writeBinary(_iter384.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32388,_iter385.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32400,oprot.writeBinary(_iter386.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32401,oprot.writeBinary(_iter386.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32417,org.apache.thrift.protocol.TList _list387 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32418,struct.rowBatches = new ArrayList<BatchMutation>(_list387.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32421,BatchMutation _elem389; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32422,_elem389 = new BatchMutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32423,_elem389.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32424,struct.rowBatches.add(_elem389);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32435,org.apache.thrift.protocol.TMap _map390 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32436,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map390.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32439,ByteBuffer _key392; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32440,ByteBuffer _val393; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32441,_key392 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32442,_val393 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32443,struct.attributes.put(_key392, _val393);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,32707,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,33363,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,33956,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34674,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34846,org.apache.thrift.protocol.TMap _map394 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34847,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map394.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34850,ByteBuffer _key396; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34851,ByteBuffer _val397; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34852,_key396 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34853,_val397 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34854,struct.attributes.put(_key396, _val397);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34899,oprot.writeBinary(_iter398.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34900,oprot.writeBinary(_iter398.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34951,oprot.writeBinary(_iter399.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34952,oprot.writeBinary(_iter399.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34976,org.apache.thrift.protocol.TMap _map400 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34977,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map400.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34980,ByteBuffer _key402; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34981,ByteBuffer _val403; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34982,_key402 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34983,_val403 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,34984,struct.attributes.put(_key402, _val403);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,35189,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,35898,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36094,org.apache.thrift.protocol.TMap _map404 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36095,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map404.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36098,ByteBuffer _key406; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36099,ByteBuffer _val407; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36100,_key406 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36101,_val407 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36102,struct.attributes.put(_key406, _val407);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36150,oprot.writeBinary(_iter408.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36151,oprot.writeBinary(_iter408.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36208,oprot.writeBinary(_iter409.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36209,oprot.writeBinary(_iter409.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36237,org.apache.thrift.protocol.TMap _map410 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36238,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map410.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36241,ByteBuffer _key412; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36242,ByteBuffer _val413; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36243,_key412 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36244,_val413 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36245,struct.attributes.put(_key412, _val413);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,36450,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37005,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37151,org.apache.thrift.protocol.TMap _map414 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37152,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map414.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37155,ByteBuffer _key416; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37156,ByteBuffer _val417; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37157,_key416 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37158,_val417 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37159,struct.attributes.put(_key416, _val417);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37199,oprot.writeBinary(_iter418.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37200,oprot.writeBinary(_iter418.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37245,oprot.writeBinary(_iter419.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37246,oprot.writeBinary(_iter419.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37266,org.apache.thrift.protocol.TMap _map420 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37267,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map420.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37270,ByteBuffer _key422; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37271,ByteBuffer _val423; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37272,_key422 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37273,_val423 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37274,struct.attributes.put(_key422, _val423);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37479,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,37847,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38206,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38594,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38688,org.apache.thrift.protocol.TList _list424 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38689,struct.increments = new ArrayList<TIncrement>(_list424.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38692,TIncrement _elem426; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38693,_elem426 = new TIncrement();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38694,_elem426.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38695,struct.increments.add(_elem426);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38725,_iter427.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38758,_iter428.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38770,org.apache.thrift.protocol.TList _list429 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38771,struct.increments = new ArrayList<TIncrement>(_list429.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38774,TIncrement _elem431; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38775,_elem431 = new TIncrement();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38776,_elem431.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38777,struct.increments.add(_elem431);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,38982,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39610,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39780,org.apache.thrift.protocol.TMap _map432 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39781,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map432.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39784,ByteBuffer _key434; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39785,ByteBuffer _val435; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39786,_key434 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39787,_val435 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39788,struct.attributes.put(_key434, _val435);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39831,oprot.writeBinary(_iter436.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39832,oprot.writeBinary(_iter436.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39883,oprot.writeBinary(_iter437.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39884,oprot.writeBinary(_iter437.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39908,org.apache.thrift.protocol.TMap _map438 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39909,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map438.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39912,ByteBuffer _key440; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39913,ByteBuffer _val441; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39914,_key440 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39915,_val441 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,39916,struct.attributes.put(_key440, _val441);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40121,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40666,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40816,org.apache.thrift.protocol.TMap _map442 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40817,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map442.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40820,ByteBuffer _key444; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40821,ByteBuffer _val445; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40822,_key444 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40823,_val445 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40824,struct.attributes.put(_key444, _val445);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40864,oprot.writeBinary(_iter446.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40865,oprot.writeBinary(_iter446.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40910,oprot.writeBinary(_iter447.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40911,oprot.writeBinary(_iter447.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40932,org.apache.thrift.protocol.TMap _map448 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40933,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map448.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40936,ByteBuffer _key450; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40937,ByteBuffer _val451; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40938,_key450 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40939,_val451 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,40940,struct.attributes.put(_key450, _val451);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,41206,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,41903,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42067,org.apache.thrift.protocol.TList _list452 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42068,struct.columns = new ArrayList<ByteBuffer>(_list452.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42071,ByteBuffer _elem454; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42072,_elem454 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42073,struct.columns.add(_elem454);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42085,org.apache.thrift.protocol.TMap _map455 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42086,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map455.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42089,ByteBuffer _key457; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42090,ByteBuffer _val458; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42091,_key457 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42092,_val458 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42093,struct.attributes.put(_key457, _val458);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42133,oprot.writeBinary(_iter459);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42145,oprot.writeBinary(_iter460.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42146,oprot.writeBinary(_iter460.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42194,oprot.writeBinary(_iter461);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42203,oprot.writeBinary(_iter462.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42204,oprot.writeBinary(_iter462.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42224,org.apache.thrift.protocol.TList _list463 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42225,struct.columns = new ArrayList<ByteBuffer>(_list463.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42228,ByteBuffer _elem465; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42229,_elem465 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42230,struct.columns.add(_elem465);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42237,org.apache.thrift.protocol.TMap _map466 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42238,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map466.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42241,ByteBuffer _key468; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42242,ByteBuffer _val469; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42243,_key468 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42244,_val469 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42245,struct.attributes.put(_key468, _val469);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,42511,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43293,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43483,org.apache.thrift.protocol.TList _list470 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43484,struct.columns = new ArrayList<ByteBuffer>(_list470.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43487,ByteBuffer _elem472; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43488,_elem472 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43489,struct.columns.add(_elem472);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43501,org.apache.thrift.protocol.TMap _map473 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43502,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map473.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43505,ByteBuffer _key475; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43506,ByteBuffer _val476; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43507,_key475 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43508,_val476 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43509,struct.attributes.put(_key475, _val476);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43554,oprot.writeBinary(_iter477);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43566,oprot.writeBinary(_iter478.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43567,oprot.writeBinary(_iter478.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43621,oprot.writeBinary(_iter479);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43630,oprot.writeBinary(_iter480.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43631,oprot.writeBinary(_iter480.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43655,org.apache.thrift.protocol.TList _list481 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43656,struct.columns = new ArrayList<ByteBuffer>(_list481.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43659,ByteBuffer _elem483; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43660,_elem483 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43661,struct.columns.add(_elem483);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43668,org.apache.thrift.protocol.TMap _map484 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43669,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map484.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43672,ByteBuffer _key486; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43673,ByteBuffer _val487; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43674,_key486 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43675,_val487 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43676,struct.attributes.put(_key486, _val487);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,43942,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44627,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44791,org.apache.thrift.protocol.TList _list488 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44792,struct.columns = new ArrayList<ByteBuffer>(_list488.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44795,ByteBuffer _elem490; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44796,_elem490 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44797,struct.columns.add(_elem490);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44809,org.apache.thrift.protocol.TMap _map491 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44810,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map491.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44813,ByteBuffer _key493; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44814,ByteBuffer _val494; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44815,_key493 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44816,_val494 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44817,struct.attributes.put(_key493, _val494);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44857,oprot.writeBinary(_iter495);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44869,oprot.writeBinary(_iter496.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44870,oprot.writeBinary(_iter496.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44918,oprot.writeBinary(_iter497);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44927,oprot.writeBinary(_iter498.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44928,oprot.writeBinary(_iter498.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44948,org.apache.thrift.protocol.TList _list499 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44949,struct.columns = new ArrayList<ByteBuffer>(_list499.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44952,ByteBuffer _elem501; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44953,_elem501 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44954,struct.columns.add(_elem501);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44961,org.apache.thrift.protocol.TMap _map502 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44962,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map502.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44965,ByteBuffer _key504; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44966,ByteBuffer _val505; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44967,_key504 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44968,_val505 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,44969,struct.attributes.put(_key504, _val505);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,45235,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46005,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46185,org.apache.thrift.protocol.TList _list506 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46186,struct.columns = new ArrayList<ByteBuffer>(_list506.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46189,ByteBuffer _elem508; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46190,_elem508 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46191,struct.columns.add(_elem508);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46211,org.apache.thrift.protocol.TMap _map509 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46212,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map509.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46215,ByteBuffer _key511; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46216,ByteBuffer _val512; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46217,_key511 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46218,_val512 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46219,struct.attributes.put(_key511, _val512);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46259,oprot.writeBinary(_iter513);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46274,oprot.writeBinary(_iter514.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46275,oprot.writeBinary(_iter514.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46326,oprot.writeBinary(_iter515);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46338,oprot.writeBinary(_iter516.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46339,oprot.writeBinary(_iter516.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46359,org.apache.thrift.protocol.TList _list517 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46360,struct.columns = new ArrayList<ByteBuffer>(_list517.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46363,ByteBuffer _elem519; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46364,_elem519 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46365,struct.columns.add(_elem519);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46376,org.apache.thrift.protocol.TMap _map520 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46377,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map520.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46380,ByteBuffer _key522; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46381,ByteBuffer _val523; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46382,_key522 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46383,_val523 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46384,struct.attributes.put(_key522, _val523);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,46650,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47505,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47711,org.apache.thrift.protocol.TList _list524 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47712,struct.columns = new ArrayList<ByteBuffer>(_list524.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47715,ByteBuffer _elem526; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47716,_elem526 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47717,struct.columns.add(_elem526);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47737,org.apache.thrift.protocol.TMap _map527 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47738,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map527.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47741,ByteBuffer _key529; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47742,ByteBuffer _val530; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47743,_key529 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47744,_val530 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47745,struct.attributes.put(_key529, _val530);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47790,oprot.writeBinary(_iter531);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47805,oprot.writeBinary(_iter532.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47806,oprot.writeBinary(_iter532.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47863,oprot.writeBinary(_iter533);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47875,oprot.writeBinary(_iter534.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47876,oprot.writeBinary(_iter534.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47900,org.apache.thrift.protocol.TList _list535 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47901,struct.columns = new ArrayList<ByteBuffer>(_list535.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47904,ByteBuffer _elem537; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47905,_elem537 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47906,struct.columns.add(_elem537);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47917,org.apache.thrift.protocol.TMap _map538 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47918,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map538.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47921,ByteBuffer _key540; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47922,ByteBuffer _val541; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47923,_key540 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47924,_val541 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,47925,struct.attributes.put(_key540, _val541);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,48191,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,48600,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49088,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49218,org.apache.thrift.protocol.TList _list542 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49219,struct.success = new ArrayList<TRowResult>(_list542.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49222,TRowResult _elem544; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49223,_elem544 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49224,_elem544.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49225,struct.success.add(_elem544);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49273,_iter545.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49322,_iter546.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49340,org.apache.thrift.protocol.TList _list547 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49341,struct.success = new ArrayList<TRowResult>(_list547.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49344,TRowResult _elem549; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49345,_elem549 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49346,_elem549.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49347,struct.success.add(_elem549);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,49647,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50170,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50300,org.apache.thrift.protocol.TList _list550 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50301,struct.success = new ArrayList<TRowResult>(_list550.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50304,TRowResult _elem552; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50305,_elem552 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50306,_elem552.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50307,struct.success.add(_elem552);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50355,_iter553.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50404,_iter554.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50422,org.apache.thrift.protocol.TList _list555 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50423,struct.success = new ArrayList<TRowResult>(_list555.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50426,TRowResult _elem557; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50427,_elem557 = new TRowResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50428,_elem557.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50429,struct.success.add(_elem557);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,50658,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,51067,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,51650,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52165,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52277,org.apache.thrift.protocol.TList _list558 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52278,struct.success = new ArrayList<TCell>(_list558.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52281,TCell _elem560; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52282,_elem560 = new TCell();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52283,_elem560.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52284,struct.success.add(_elem560);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52323,_iter561.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52364,_iter562.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52379,org.apache.thrift.protocol.TList _list563 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52380,struct.success = new ArrayList<TCell>(_list563.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52383,TCell _elem565; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52384,_elem565 = new TCell();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52385,_elem565.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52386,struct.success.add(_elem565);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,52618,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Hbase.java,53031,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/IOError.java,233,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/IllegalArgument.java,232,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/Mutation.java,434,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TCell.java,305,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TColumn.java,300,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TIncrement.java,441,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TRegionInfo.java,627,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TRowResult.java,401,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/TScan.java,672,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TAppend.java,533,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TAuthorization.java,242,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TCellVisibility.java,222,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TColumn.java,371,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TColumnIncrement.java,373,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TColumnValue.java,509,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,634,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,837,org.apache.thrift.protocol.TList _list44 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,838,struct.columns = new ArrayList<TColumn>(_list44.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,841,TColumn _elem46; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,842,_elem46 = new TColumn();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,843,_elem46.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,844,struct.columns.add(_elem46);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,872,org.apache.thrift.protocol.TMap _map47 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,873,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map47.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,876,ByteBuffer _key49; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,877,ByteBuffer _val50; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,878,_key49 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,879,_val50 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,880,struct.attributes.put(_key49, _val50);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,924,_iter51.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,950,oprot.writeBinary(_iter52.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,951,oprot.writeBinary(_iter52.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1005,_iter53.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1020,oprot.writeBinary(_iter54.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1021,oprot.writeBinary(_iter54.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1038,org.apache.thrift.protocol.TList _list55 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1039,struct.columns = new ArrayList<TColumn>(_list55.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1042,TColumn _elem57; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1043,_elem57 = new TColumn();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1044,_elem57.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1045,struct.columns.add(_elem57);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1060,org.apache.thrift.protocol.TMap _map58 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1061,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map58.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1064,ByteBuffer _key60; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1065,ByteBuffer _val61; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1066,_key60 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1067,_val61 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TDelete.java,1068,struct.attributes.put(_key60, _val61);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,18,import org.apache.thrift.async.AsyncMethodCallback;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,19,import org.apache.thrift.server.AbstractNonblockingServer.*;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,48,public class TGet implements org.apache.thrift.TBase<TGet, TGet._Fields>, java.io.Serializable, Cloneable, Comparable<TGet> {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,205,List<TColumn> __this__columns = new ArrayList<TColumn>(other.columns.size());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,221,Map<ByteBuffer,ByteBuffer> __this__attributes = new HashMap<ByteBuffer,ByteBuffer>(other.attributes);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,699,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,710,lastComparison = Boolean.valueOf(isSetRow()).compareTo(other.isSetRow());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,715,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.row, other.row);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,720,lastComparison = Boolean.valueOf(isSetColumns()).compareTo(other.isSetColumns());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,725,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.columns, other.columns);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,730,lastComparison = Boolean.valueOf(isSetTimestamp()).compareTo(other.isSetTimestamp());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,735,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timestamp, other.timestamp);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,740,lastComparison = Boolean.valueOf(isSetTimeRange()).compareTo(other.isSetTimeRange());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,745,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timeRange, other.timeRange);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,750,lastComparison = Boolean.valueOf(isSetMaxVersions()).compareTo(other.isSetMaxVersions());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,755,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.maxVersions, other.maxVersions);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,760,lastComparison = Boolean.valueOf(isSetFilterString()).compareTo(other.isSetFilterString());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,765,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.filterString, other.filterString);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,770,lastComparison = Boolean.valueOf(isSetAttributes()).compareTo(other.isSetAttributes());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,775,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.attributes, other.attributes);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,780,lastComparison = Boolean.valueOf(isSetAuthorizations()).compareTo(other.isSetAuthorizations());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,785,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.authorizations, other.authorizations);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,948,TColumn _elem18;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1000,ByteBuffer _key21;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1001,ByteBuffer _val22;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1191,TColumn _elem29;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1222,ByteBuffer _key32;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TGet.java,1223,ByteBuffer _val33;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,2030,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,2480,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,2969,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,3417,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,3941,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4067,org.apache.thrift.protocol.TList _list124 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4068,struct.gets = new ArrayList<TGet>(_list124.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4071,TGet _elem126; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4072,_elem126 = new TGet();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4073,_elem126.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4074,struct.gets.add(_elem126);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4109,_iter127.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4137,_iter128.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4148,org.apache.thrift.protocol.TList _list129 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4149,struct.gets = new ArrayList<TGet>(_list129.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4152,TGet _elem131; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4153,_elem131 = new TGet();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4154,_elem131.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4155,struct.gets.add(_elem131);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4438,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4550,org.apache.thrift.protocol.TList _list132 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4551,struct.success = new ArrayList<TResult>(_list132.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4554,TResult _elem134; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4555,_elem134 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4556,_elem134.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4557,struct.success.add(_elem134);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4596,_iter135.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4637,_iter136.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4652,org.apache.thrift.protocol.TList _list137 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4653,struct.success = new ArrayList<TResult>(_list137.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4656,TResult _elem139; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4657,_elem139 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4658,_elem139.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4659,struct.success.add(_elem139);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,4963,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,5352,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,6138,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,6743,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7252,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7378,org.apache.thrift.protocol.TList _list140 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7379,struct.puts = new ArrayList<TPut>(_list140.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7382,TPut _elem142; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7383,_elem142 = new TPut();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7384,_elem142.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7385,struct.puts.add(_elem142);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7420,_iter143.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7448,_iter144.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7459,org.apache.thrift.protocol.TList _list145 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7460,struct.puts = new ArrayList<TPut>(_list145.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7463,TPut _elem147; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7464,_elem147 = new TPut();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7465,_elem147.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7466,struct.puts.add(_elem147);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,7670,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,8120,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,8509,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,8979,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9105,org.apache.thrift.protocol.TList _list148 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9106,struct.deletes = new ArrayList<TDelete>(_list148.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9109,TDelete _elem150; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9110,_elem150 = new TDelete();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9111,_elem150.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9112,struct.deletes.add(_elem150);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9147,_iter151.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9175,_iter152.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9186,org.apache.thrift.protocol.TList _list153 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9187,struct.deletes = new ArrayList<TDelete>(_list153.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9190,TDelete _elem155; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9191,_elem155 = new TDelete();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9192,_elem155.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9193,struct.deletes.add(_elem155);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9476,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9588,org.apache.thrift.protocol.TList _list156 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9589,struct.success = new ArrayList<TDelete>(_list156.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9592,TDelete _elem158; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9593,_elem158 = new TDelete();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9594,_elem158.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9595,struct.success.add(_elem158);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9634,_iter159.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9675,_iter160.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9690,org.apache.thrift.protocol.TList _list161 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9691,struct.success = new ArrayList<TDelete>(_list161.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9694,TDelete _elem163; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9695,_elem163 = new TDelete();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9696,_elem163.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,9697,struct.success.add(_elem163);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,10337,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,10942,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,11431,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,11879,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,12375,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,12823,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,13319,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,13769,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14251,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14783,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14913,org.apache.thrift.protocol.TList _list164 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14914,struct.success = new ArrayList<TResult>(_list164.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14917,TResult _elem166; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14918,_elem166 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14919,_elem166.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14920,struct.success.add(_elem166);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,14968,_iter167.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15017,_iter168.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15035,org.apache.thrift.protocol.TList _list169 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15036,struct.success = new ArrayList<TResult>(_list169.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15039,TResult _elem171; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15040,_elem171 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15041,_elem171.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15042,struct.success.add(_elem171);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15271,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,15686,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,16179,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,16568,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17093,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17601,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17713,org.apache.thrift.protocol.TList _list172 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17714,struct.success = new ArrayList<TResult>(_list172.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17717,TResult _elem174; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17718,_elem174 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17719,_elem174.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17720,struct.success.add(_elem174);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17759,_iter175.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17800,_iter176.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17815,org.apache.thrift.protocol.TList _list177 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17816,struct.success = new ArrayList<TResult>(_list177.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17819,TResult _elem179; // required
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17820,_elem179 = new TResult();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17821,_elem179.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/THBaseService.java,17822,struct.success.add(_elem179);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TIOError.java,227,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TIllegalArgument.java,226,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TIncrement.java,540,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TMutation.java,339,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,18,import org.apache.thrift.async.AsyncMethodCallback;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,19,import org.apache.thrift.server.AbstractNonblockingServer.*;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,47,public class TPut implements org.apache.thrift.TBase<TPut, TPut._Fields>, java.io.Serializable, Cloneable, Comparable<TPut> {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,199,List<TColumnValue> __this__columnValues = new ArrayList<TColumnValue>(other.columnValues.size());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,207,Map<ByteBuffer,ByteBuffer> __this__attributes = new HashMap<ByteBuffer,ByteBuffer>(other.attributes);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,592,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,603,lastComparison = Boolean.valueOf(isSetRow()).compareTo(other.isSetRow());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,608,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.row, other.row);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,613,lastComparison = Boolean.valueOf(isSetColumnValues()).compareTo(other.isSetColumnValues());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,618,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.columnValues, other.columnValues);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,623,lastComparison = Boolean.valueOf(isSetTimestamp()).compareTo(other.isSetTimestamp());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,628,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timestamp, other.timestamp);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,633,lastComparison = Boolean.valueOf(isSetAttributes()).compareTo(other.isSetAttributes());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,638,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.attributes, other.attributes);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,643,lastComparison = Boolean.valueOf(isSetDurability()).compareTo(other.isSetDurability());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,648,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.durability, other.durability);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,653,lastComparison = Boolean.valueOf(isSetCellVisibility()).compareTo(other.isSetCellVisibility());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,658,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.cellVisibility, other.cellVisibility);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,803,TColumnValue _elem36;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,830,ByteBuffer _key39;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,831,ByteBuffer _val40;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,996,TColumnValue _elem47;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,1014,ByteBuffer _key50;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TPut.java,1015,ByteBuffer _val51;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TResult.java,320,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,321,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,447,org.apache.thrift.protocol.TList _list98 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,448,struct.mutations = new ArrayList<TMutation>(_list98.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,451,TMutation _elem100; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,452,_elem100 = new TMutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,453,_elem100.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,454,struct.mutations.add(_elem100);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,489,_iter101.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,517,_iter102.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,528,org.apache.thrift.protocol.TList _list103 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,529,struct.mutations = new ArrayList<TMutation>(_list103.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,532,TMutation _elem105; // optional
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,533,_elem105 = new TMutation();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,534,_elem105.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TRowMutations.java,535,struct.mutations.add(_elem105);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,18,import org.apache.thrift.async.AsyncMethodCallback;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,19,import org.apache.thrift.server.AbstractNonblockingServer.*;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,39,public class TScan implements org.apache.thrift.TBase<TScan, TScan._Fields>, java.io.Serializable, Cloneable, Comparable<TScan> {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,210,List<TColumn> __this__columns = new ArrayList<TColumn>(other.columns.size());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,227,Map<ByteBuffer,ByteBuffer> __this__attributes = new HashMap<ByteBuffer,ByteBuffer>(other.attributes);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,809,return 0;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,820,lastComparison = Boolean.valueOf(isSetStartRow()).compareTo(other.isSetStartRow());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,825,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.startRow, other.startRow);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,830,lastComparison = Boolean.valueOf(isSetStopRow()).compareTo(other.isSetStopRow());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,835,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.stopRow, other.stopRow);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,840,lastComparison = Boolean.valueOf(isSetColumns()).compareTo(other.isSetColumns());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,845,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.columns, other.columns);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,850,lastComparison = Boolean.valueOf(isSetCaching()).compareTo(other.isSetCaching());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,855,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.caching, other.caching);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,860,lastComparison = Boolean.valueOf(isSetMaxVersions()).compareTo(other.isSetMaxVersions());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,865,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.maxVersions, other.maxVersions);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,870,lastComparison = Boolean.valueOf(isSetTimeRange()).compareTo(other.isSetTimeRange());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,875,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.timeRange, other.timeRange);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,880,lastComparison = Boolean.valueOf(isSetFilterString()).compareTo(other.isSetFilterString());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,885,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.filterString, other.filterString);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,890,lastComparison = Boolean.valueOf(isSetBatchSize()).compareTo(other.isSetBatchSize());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,895,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.batchSize, other.batchSize);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,900,lastComparison = Boolean.valueOf(isSetAttributes()).compareTo(other.isSetAttributes());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,905,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.attributes, other.attributes);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,910,lastComparison = Boolean.valueOf(isSetAuthorizations()).compareTo(other.isSetAuthorizations());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,915,lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.authorizations, other.authorizations);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1097,org.apache.thrift.protocol.TList _list88 = iprot.readListBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1098,struct.columns = new ArrayList<TColumn>(_list88.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1101,TColumn _elem90;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1102,_elem90 = new TColumn();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1103,_elem90.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1104,struct.columns.add(_elem90);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1157,org.apache.thrift.protocol.TMap _map91 = iprot.readMapBegin();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1158,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map91.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1161,ByteBuffer _key93;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1162,ByteBuffer _val94;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1163,_key93 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1164,_val94 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1165,struct.attributes.put(_key93, _val94);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1219,_iter95.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1262,oprot.writeBinary(_iter96.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1263,oprot.writeBinary(_iter96.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1337,_iter97.write(oprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1361,oprot.writeBinary(_iter98.getKey());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1362,oprot.writeBinary(_iter98.getValue());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1385,org.apache.thrift.protocol.TList _list99 = new org.apache.thrift.protocol.TList(org.apache.thrift.protocol.TType.STRUCT, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1386,struct.columns = new ArrayList<TColumn>(_list99.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1389,TColumn _elem101;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1390,_elem101 = new TColumn();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1391,_elem101.read(iprot);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1392,struct.columns.add(_elem101);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1420,org.apache.thrift.protocol.TMap _map102 = new org.apache.thrift.protocol.TMap(org.apache.thrift.protocol.TType.STRING, org.apache.thrift.protocol.TType.STRING, iprot.readI32());
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1421,struct.attributes = new HashMap<ByteBuffer,ByteBuffer>(2*_map102.size);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1424,ByteBuffer _key104;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1425,ByteBuffer _val105;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1426,_key104 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1427,_val105 = iprot.readBinary();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TScan.java,1428,struct.attributes.put(_key104, _val105);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/generated/TTimeRange.java,289,return 0;
hbase-common/src/main/java/org/apache/hadoop/hbase/codec/BaseDecoder.java,66,LOG.error("Partial cell read caused by EOF: " + ioEx);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,340,int i = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,341,for (Path location: locations) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,342,if (i++ > 0) str.append(", ");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,343,str.append(location.toString());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,353,for (Path path: locations) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,354,if (fs.exists(path)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,355,return path;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,369,for (Path path: locations) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,371,return fs.getFileStatus(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,251,public boolean exists(final FileSystem fs) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,252,return fs.exists(this.originPath) ||
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,253,fs.exists(this.tempPath) ||
hbase-server/src/main/java/org/apache/hadoop/hbase/io/HFileLink.java,254,fs.exists(this.archivePath);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2547,throw new NotServingRegionException("The region " + encodedName +
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionKey.java,51,HConstants.RPC_CODEC_CONF_KEY };
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,59,watcher.registerListener(this);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,60,if (ZKUtil.watchAndCheckExists(watcher, aclZNode)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,61,List<ZKUtil.NodeAndData> existing =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,62,ZKUtil.getChildDataAndWatchForNewChildren(watcher, aclZNode);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,63,if (existing != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/ZKPermissionWatcher.java,64,refreshNodes(existing);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerWrapperImpl.java,32,if (this.server == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerWrapperImpl.java,67,if (this.server == null || this.server.connectionList == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,88,private final Map<TableName, TableDescriptorAndModtime> cache =
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,89,new ConcurrentHashMap<TableName, TableDescriptorAndModtime>();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,94,private static class TableDescriptorAndModtime {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,95,private final HTableDescriptor htd;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,96,private final long modtime;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,98,TableDescriptorAndModtime(final long modtime, final HTableDescriptor htd) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,99,this.htd = htd;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,100,this.modtime = modtime;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,103,long getModtime() {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,104,return this.modtime;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,107,HTableDescriptor getTableDescriptor() {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,108,return this.htd;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,154,throw new IOException("No descriptor found for non table = " + tablename);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,158,TableDescriptorAndModtime cachedtdm = this.cache.get(tablename);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,160,if (cachedtdm != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,162,if (getTableInfoModtime(tablename) <= cachedtdm.getModtime()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,164,return cachedtdm.getTableDescriptor();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,168,TableDescriptorAndModtime tdmt = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,170,tdmt = getTableDescriptorAndModtime(tablename);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,173,+ tablename, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,176,+ tablename, ioe);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,179,if (tdmt != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,182,return tdmt == null ? null : tdmt.getTableDescriptor();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,192,List<Path> tableDirs = FSUtils.getTableDirs(fs, rootdir);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,193,for (Path d: tableDirs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,194,HTableDescriptor htd = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,195,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,196,htd = get(FSUtils.getTableName(d));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,199,LOG.warn("Trouble retrieving htd", fnfe);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,201,if (htd == null) continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,202,htds.put(htd.getTableName().getNameAsString(), htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,247,long modtime = getTableInfoModtime(htd.getTableName());
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,248,this.cache.put(htd.getTableName(), new TableDescriptorAndModtime(modtime, htd));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,268,TableDescriptorAndModtime tdm = this.cache.remove(tablename);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,269,return tdm == null ? null : tdm.getTableDescriptor();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,456,private long getTableInfoModtime(final TableName tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,457,FileStatus status = getTableInfoPath(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,458,return status == null ? 0 : status.getModificationTime();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,467,Path hbaseRootDir, TableName tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,478,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,479,FileStatus status = getTableInfoPath(fs, tableDir, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,480,if (status == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,481,throw new TableInfoMissingException("No table descriptor file under " + tableDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,483,return readTableDescriptor(fs, status, false);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,494,if (tableName.equals(TableName.META_TABLE_NAME)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,495,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,497,return getTableDescriptorAndModtime(getTableDir(tableName));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,508,FileStatus status = getTableInfoPath(tableDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,510,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,512,HTableDescriptor htd = readTableDescriptor(fs, status, !fsreadonly);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,513,return new TableDescriptorAndModtime(status.getModificationTime(), htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,517,boolean rewritePb) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,530,throw new IOException("content=" + Bytes.toShort(content), e);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,534,Path tableInfoDir = status.getPath().getParent();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,535,Path tableDir = tableInfoDir.getParent();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,536,writeTableDescriptor(fs, htd, tableDir, status);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,603,private static Path writeTableDescriptor(final FileSystem fs,
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,606,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,175,if (familyDir.getName().startsWith("_")) continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,763,if (familyDir.getName().startsWith("_")) continue;
hbase-client/src/main/java/org/apache/hadoop/hbase/catalog/CatalogTracker.java,115,private boolean stopped = false;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,130,import org.apache.hadoop.hbase.snapshot.ClientSnapshotDescriptionUtils;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,221,ct.start();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,229,private void cleanupCatalogTracker(final CatalogTracker ct) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/CellCounter.java,245,if (otherArgs.length < 1) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1360,throw new IOException(e);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/CellCounter.java,125,context.write(new Text("Total Families Across all Rows"),
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/CellCounter.java,126,new IntWritable(1));
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/CellCounter.java,127,context.write(new Text(thisRowFamilyName), new IntWritable(1));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2167,List<UserPermission> perms = new ArrayList<UserPermission>();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2195,List<UserPermission> perms = new ArrayList<UserPermission>();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,464,if (entryName == null) entryName = ACL_TABLE_NAME.getName();
hbase-client/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityClient.java,94,return rpcCallback.get();
hbase-client/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityClient.java,142,return rpcCallback.get();
hbase-client/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityClient.java,193,return rpcCallback.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3730,public boolean nextRaw(List<Cell> outResults, int limit) throws IOException {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,28774,getDescriptor().getMethods().get(5),
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,28894,getDescriptor().getMethods().get(5),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1893,ReplicationSourceService getReplicationSourceService() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1894,return replicationSourceHandler;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1901,ReplicationSinkService getReplicationSinkService() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1902,return replicationSinkHandler;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1327,zkw.getRecoverableZooKeeper().delete(node, -1);
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,87,satisfies(rowKey, fuzzyData.getFirst(), fuzzyData.getSecond());
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,115,byte[] nextRowKeyCandidate = getNextForFuzzyRule(rowKey,
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,120,if (nextRowKey == null || Bytes.compareTo(nextRowKeyCandidate, nextRowKey) < 0) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,125,if (nextRowKey == null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,134,return KeyValue.createFirstOnRow(nextRowKey);
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,206,static SatisfiesCode satisfies(byte[] row,
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,207,byte[] fuzzyKeyBytes, byte[] fuzzyKeyMeta) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,208,return satisfies(row, 0, row.length, fuzzyKeyBytes, fuzzyKeyMeta);
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,211,private static SatisfiesCode satisfies(byte[] row, int offset, int length,
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,234,return  rowByteLessThanFixed ? SatisfiesCode.NEXT_EXISTS : SatisfiesCode.NO_NEXT;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,243,if (fuzzyKeyMeta[i] == 1 && !isMax(fuzzyKeyBytes[i])) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,251,private static boolean isMax(byte fuzzyKeyByte) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,252,return (fuzzyKeyByte & 0xFF) == 255;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,255,static byte[] getNextForFuzzyRule(byte[] row, byte[] fuzzyKeyBytes, byte[] fuzzyKeyMeta) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,256,return getNextForFuzzyRule(row, 0, row.length, fuzzyKeyBytes, fuzzyKeyMeta);
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,263,private static byte[] getNextForFuzzyRule(byte[] row, int offset, int length,
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,281,if (!isMax(row[i])) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,286,if ((row[i + offset] & 0xFF) < (fuzzyKeyBytes[i] & 0xFF)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,292,if ((row[i + offset] & 0xFF) > (fuzzyKeyBytes[i] & 0xFF)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,305,result[toInc]++;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,311,result[i] = 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTableMultiplexer.java,91,this.conf = conf;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTableMultiplexer.java,96,this.retryNum = this.conf.getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1164,LOG.warn("Encountered problems when prefetch hbase:meta table: ", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFlusher.java,33,import org.apache.hadoop.hbase.util.CollectionBackedScanner;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DefaultStoreFlusher.java,75,finalizeWriter(writer, cacheFlushId, status);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,29,import org.apache.hadoop.hbase.regionserver.Store;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,92,writer.appendMetadata(fd.maxSeqId, request.isMajor());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,93,writer.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/DefaultCompactor.java,94,newFiles.add(writer.getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,74,public Client(Cluster cluster) {
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,76,MultiThreadedHttpConnectionManager manager =
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/client/Client.java,159,sb.append("http://");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java,188,LOG.info("Splitting logs for " + serverName + " before assignment.");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java,190,LOG.info("Mark regions in recovery before assignment.");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5663,if (this.isRecovering() && (this.disallowWritesInRecovering ||
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5665,throw new RegionInRecoveryException(this.getRegionNameAsString() + " is recovering");
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoveringRegionWatcher.java,66,LOG.info(path + " znode deleted. Region: " + regionName + " completes recovery.");
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RegionServerTracker.java,90,if (LOG.isDebugEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RegionServerTracker.java,91,LOG.debug("RS node: " + nodePath + " data: " + Bytes.toString(data));
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1855,if (cpHost.preAddColumn(tableName, column)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1860,new TableAddFamilyHandler(tableName, column, this, this).prepare().process();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1862,cpHost.postAddColumn(tableName, column);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,103,ZKUtil.createAndWatch(this.zookeeper, ZKUtil.joinZNode(this.peersZNode, id),
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,104,toByteArray(clusterKey));
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,108,ZKUtil.createNodeIfNotExistsAndWatch(this.zookeeper, getPeerStateNode(id),
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,109,ENABLED_ZNODE_BYTES);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,112,throw new ReplicationException("Could not add peer with id=" + id
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,113,+ ", clusterKey=" + clusterKey, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,217,done.run(null);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,256,done.run(null);
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,430,if (Arrays.equals(tn.getQualifier(), namespace) &&
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArraySearcher.java,96,int insertionPoint = -fanIndex;
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArraySearcher.java,145,int insertionPoint = -fanIndex;
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/row/RowNodeReader.java,235,return fanIndexInBlock + fanOffset + 1;// didn't find it, so compensate in reverse
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,600,for (double n : stats) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,605,double scaled =  scale(0, max, totalCost);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,632,return Math.max(0d, Math.min(1d, (value - min) / max));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureWALCellCodec.java,70,this.iv = new byte[decryptor.getIvLength()];
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1159,ByteBuffer sliceBuf = ((HFileBlock) data).getBufferReadOnlyWithHeader();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1161,assert len == sliceBuf.limit() + HFileBlock.EXTRA_SERIALIZATION_SPACE;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1163,((HFileBlock) data).serializeExtraInfo(extraInfoBuffer);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,437,if (authManager.authorize(user, perm)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,254,if (userProvider.isHBaseSecurityEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,300,if (userProvider.isHBaseSecurityEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,308,if(bulkToken != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,309,new SecureBulkLoadClient(table).cleanupBulkLoad(bulkToken);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,568,if(!userProvider.isHBaseSecurityEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,156,getAccessController().prePrepareBulkLoad(env);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,171,getAccessController().preCleanupBulkLoad(env);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,192,final Token userToken =
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,193,new Token(request.getFsToken().getIdentifier().toByteArray(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,194,request.getFsToken().getPassword().toByteArray(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,195,new Text(request.getFsToken().getKind()),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,196,new Text(request.getFsToken().getService()));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,293,if("simple".equalsIgnoreCase(conf.get(User.HBASE_SECURITY_CONF_KEY))) {
hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java,894,Collections.unmodifiableList(Arrays.asList(new String[] { HREGION_LOGDIR_NAME,
hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java,895,HREGION_OLDLOGDIR_NAME, CORRUPT_DIR_NAME, SPLIT_LOGDIR_NAME,
hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java,896,HBCK_SIDELINEDIR_NAME, HFILE_ARCHIVE_DIRECTORY, SNAPSHOT_DIR_NAME, HBASE_TEMP_DIRECTORY,
hbase-common/src/main/java/org/apache/hadoop/hbase/HConstants.java,897,OLD_SNAPSHOT_DIR_NAME, BASE_NAMESPACE_DIR, MIGRATION_NAME, LIB_DIR}));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSRegionScanner.java,82,FileStatus[] cfList = fs.listStatus(regionPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSRegionScanner.java,93,if (cfStatus.getPath().getName().startsWith(".") ||
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSRegionScanner.java,94,HConstants.HBASE_NON_USER_TABLE_DIRS.contains(cfStatus.getPath().getName())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSRegionScanner.java,95,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,950,FileStatus[] regionDirs = fs.listStatus(d, new DirFilter(fs));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,953,if (dd.getName().equals(HConstants.HREGION_COMPACTIONDIR_NAME)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,954,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,957,FileStatus[] familyDirs = fs.listStatus(dd, new DirFilter(fs));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1023,DirFilter df = new DirFilter(fs);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1028,FileStatus[] regionDirs = fs.listStatus(d, df);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1031,if (dd.getName().equals(HConstants.HREGION_COMPACTIONDIR_NAME)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1032,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1035,FileStatus[] familyDirs = fs.listStatus(dd, df);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1064,public static boolean isPre020FileLayout(final FileSystem fs,
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1066,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1067,Path mapfiles = new Path(new Path(new Path(new Path(hbaseRootDir, "-ROOT-"),
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1069,return fs.exists(mapfiles);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1083,public static boolean isMajorCompactedPre020(final FileSystem fs,
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1085,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1087,List<Path> tableDirs = getTableDirs(fs, hbaseRootDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1088,for (Path d: tableDirs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1093,if (d.getName().equals(HConstants.HREGION_LOGDIR_NAME)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1094,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1096,FileStatus[] regionDirs = fs.listStatus(d, new DirFilter(fs));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1097,for (FileStatus regionDir : regionDirs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1098,Path dd = regionDir.getPath();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1099,if (dd.getName().equals(HConstants.HREGION_COMPACTIONDIR_NAME)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1100,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1103,FileStatus[] familyDirs = fs.listStatus(dd, new DirFilter(fs));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1104,for (FileStatus familyDir : familyDirs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1105,Path family = familyDir.getPath();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1106,FileStatus[] infoAndMapfile = fs.listStatus(family);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1108,if (infoAndMapfile.length != 0 && infoAndMapfile.length != 2) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1109,LOG.debug(family.toString() +
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1111,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1114,for (int ll = 0; ll < 2; ll++) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1115,if (infoAndMapfile[ll].getPath().getName().equals("info") ||
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1117,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1118,LOG.debug("Unexpected directory name: " +
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1119,infoAndMapfile[ll].getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1120,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1124,FileStatus[] familyStatus =
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1125,fs.listStatus(new Path(family, "mapfiles"));
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1126,if (familyStatus.length > 1) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1127,LOG.debug(family.toString() + " has " + familyStatus.length +
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1129,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1134,return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1221,if (blacklist.contains(p.getName().toString())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1222,isValid = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1513,PathFilter df = new BlackListDirFilter(fs, HConstants.HBASE_NON_TABLE_DIRS);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1514,FileStatus[] regionDirs = fs.listStatus(tableDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1517,if (dd.getName().equals(HConstants.HREGION_COMPACTIONDIR_NAME)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1518,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1521,FileStatus[] familyDirs = fs.listStatus(dd, df);
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,234,boolean success = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,235,for (int i = 0; i < 10; i++) try {
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,237,success = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,238,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,241,if (!success) {
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/SchemaResource.java,242,throw new IOException("could not disable table");
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/ResourceBase.java,53,throw new SecurityException("Unauthorized" + CRLF +
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/ResourceBase.java,54,StringUtils.stringifyException(exp) + CRLF);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java,529,HTableDescriptor.META_TABLEDESC);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/PutCombiner.java,83,LOG.info(String.format("Combined %d Put(s) into %d.", cnt, 1));
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/PutCombiner.java,91,LOG.info(String.format("Combined %d Put(s) into %d.", cnt, 1));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,698,buildOpenRegionRequest(final List<Triple<HRegionInfo, Integer,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Query.java,31,import org.apache.hadoop.hbase.util.Bytes;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,86,private static final String ISOLATION_LEVEL = "_isolationlevel_";
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,727,public void setIsolationLevel(IsolationLevel level) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,728,setAttribute(ISOLATION_LEVEL, level.toBytes());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,736,public IsolationLevel getIsolationLevel() {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,737,byte[] attr = getAttribute(ISOLATION_LEVEL);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,738,return attr == null ? IsolationLevel.READ_COMMITTED :
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,739,IsolationLevel.fromBytes(attr);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/RegionStates.java,669,if (regionCount > 0 || serverManager.isServerOnline(serverName)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,320,return metadataMap.containsKey(BULKLOAD_TIME_KEY);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,327,return Bytes.toLong(metadataMap.get(BULKLOAD_TIME_KEY));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,373,int startPos = fileName.indexOf("SeqId_");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1063,!isCompaction, reader.hasMVCCInfo(), readPt);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,174,env.getRegion().getTableDesc().getTableName(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,271,String randomDir = user.getShortName()+"__"+ tableName +"__"+
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,273,return createStagingDir(baseDir, user, tableName, randomDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.java,278,TableName tableName,
hbase-server/src/main/java/org/apache/hadoop/hbase/coprocessor/CoprocessorHost.java,700,return impl.getClass().getClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java,151,MasterCoprocessorHost cpHost = ((HMaster) this.server).getCoprocessorHost();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/CreateTableHandler.java,158,cpHost.postCreateTableHandler(this.hTableDescriptor, this.newRegions);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,42,private final Call call;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,43,private final RpcServerInterface rpcServer;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,44,private final MonitoredRPCHandler status;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3110,for (Cell kv : r.rawCells()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3112,currentScanResultSize += KeyValueUtil.ensureKeyValue(kv).heapSize();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3132,for (; i < rows
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3133,&& currentScanResultSize < maxResultSize; ) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3137,if (maxScannerResultSize < Long.MAX_VALUE){
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3138,for (Cell kv : values) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3139,currentScanResultSize += KeyValueUtil.ensureKeyValue(kv).heapSize();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,130,private final AtomicLong failedTxid = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3717,return nextRaw(outResults, limit);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3745,if (region != null && region.metricsRegion != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3746,long totalSize = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3747,for(Cell c:outResults) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3749,KeyValue kv = KeyValueUtil.ensureKeyValue(c);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3750,totalSize += kv.getLength();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3752,region.metricsRegion.updateScanNext(totalSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterFileSystem.java,56,import org.apache.hadoop.hbase.regionserver.wal.HLogSplitter;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,165,this(zkw, conf, stopper, master, serverName, false, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,1187,setExceptionResults(auths.size(), new CoprocessorException(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1354,if (txid <= this.failedTxid.get()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1355,assert asyncIOE != null :
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1357,throw asyncIOE;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,122,return rpc.call(blocking, method, request, null, timestamp, status).getFirst();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,495,LOG.info("Updating the hbase.version file format with version=" + version);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,496,setVersion(fs, rootdir, version, 0, HConstants.DEFAULT_VERSION_FILE_WRITE_ATTEMPTS);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,582,+ "  You have version " + version
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,584,+ ".  Is your hbase.rootdir valid?  If so, you may need to run "
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,21,import static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType.REGION_NAME;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,23,import java.io.ByteArrayOutputStream;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,24,import java.io.IOException;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,25,import java.lang.reflect.Constructor;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,26,import java.lang.reflect.InvocationTargetException;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,27,import java.lang.reflect.Method;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,28,import java.lang.reflect.ParameterizedType;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,29,import java.lang.reflect.Type;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,30,import java.nio.ByteBuffer;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,31,import java.util.ArrayList;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,32,import java.util.Collection;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,33,import java.util.HashMap;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,34,import java.util.List;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,35,import java.util.Map;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,36,import java.util.Map.Entry;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,37,import java.util.NavigableSet;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,135,import com.google.common.collect.ArrayListMultimap;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,136,import com.google.common.collect.ListMultimap;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,137,import com.google.common.collect.Lists;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,138,import com.google.protobuf.ByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,139,import com.google.protobuf.InvalidProtocolBufferException;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,140,import com.google.protobuf.Message;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,141,import com.google.protobuf.Parser;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,142,import com.google.protobuf.RpcChannel;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,143,import com.google.protobuf.Service;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,144,import com.google.protobuf.ServiceException;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,145,import com.google.protobuf.TextFormat;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,542,put.addImmutable(family, qualifier, ts, value, tagArray);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,544,put.addImmutable(family, qualifier, ts, value);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1113,if (type == MutationType.DELETE) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,112,this.zk = new ZooKeeper(quorumServers, sessionTimeout, watcher);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,132,throws IOException, InterruptedException {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,133,LOG.info("Closing dead ZooKeeper connection, session" +
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,135,zk.close();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,136,this.zk = new ZooKeeper(this.quorumServers,
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,137,this.sessionTimeout, this.watcher);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,156,zk.delete(path, version);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,199,return zk.exists(path, watcher);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,231,return zk.exists(path, watch);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,273,return zk.getChildren(path, watcher);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,305,return zk.getChildren(path, watch);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,337,byte[] revData = zk.getData(path, watcher, stat);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,370,byte[] revData = zk.getData(path, watch, stat);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,407,return zk.setData(path, newData, version);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,420,byte[] revData = zk.getData(path, false, stat);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,489,return zk.create(path, data, acl, createMode);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,497,byte[] currentData = zk.getData(path, false, null);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,543,return zk.create(newPath, data, acl, createMode);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,599,return zk.multi(multiOps);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,626,List<String> nodes = zk.getChildren(parent, false);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,630,Stat stat = zk.exists(nodePath, false);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,674,return zk.getSessionId();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,678,zk.close();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,682,return zk.getState();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,690,return zk.getSessionPasswd();
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,693,public void sync(String path, AsyncCallback.VoidCallback cb, Object ctx) {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java,694,this.zk.sync(path, null, null);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKConfig.java,217,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKConfig.java,219,InetAddress.getByName(host);
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKConfig.java,220,anyValid = true;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKConfig.java,222,LOG.warn(StringUtils.stringifyException(e));
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,290,public void reconnectAfterExpiration() throws IOException, InterruptedException {
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperWatcher.java,426,public void sync(String path) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,572,static class HConnectionImplementation implements HConnection, Closeable {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,21,import java.util.List;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,22,import java.util.concurrent.ExecutorService;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,28,import org.apache.hadoop.hbase.HRegionLocation;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,29,import org.apache.hadoop.hbase.HTableDescriptor;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,30,import org.apache.hadoop.hbase.MasterNotRunningException;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,32,import org.apache.hadoop.hbase.TableName;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,33,import org.apache.hadoop.hbase.ZooKeeperConnectionException;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,34,import org.apache.hadoop.hbase.client.HConnection;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,35,import org.apache.hadoop.hbase.client.HConnectionManager;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,36,import org.apache.hadoop.hbase.client.HTableInterface;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,37,import org.apache.hadoop.hbase.client.Row;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,38,import org.apache.hadoop.hbase.client.coprocessor.Batch.Callback;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,65,public class CoprocessorHConnection implements HConnection {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,77,HConnection connection = HConnectionManager.createConnection(env.getConfiguration());
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,83,return new CoprocessorHConnection(connection, (HRegionServer) services);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,86,return connection;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,89,private HConnection delegate;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,90,private ServerName serverName;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,91,private HRegionServer server;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,93,public CoprocessorHConnection(HConnection delegate, HRegionServer server) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,96,this.delegate = delegate;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,103,return delegate.getClient(serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,110,final MonitoredRPCHandler status =
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,111,TaskMonitor.get().createRPCStatus(Thread.currentThread().getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,131,public void abort(String why, Throwable e) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,132,delegate.abort(why, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,135,public boolean isAborted() {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,136,return delegate.isAborted();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,139,public Configuration getConfiguration() {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,140,return delegate.getConfiguration();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,143,public HTableInterface getTable(String tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,144,return delegate.getTable(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,147,public HTableInterface getTable(byte[] tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,148,return delegate.getTable(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,151,public HTableInterface getTable(TableName tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,152,return delegate.getTable(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,155,public HTableInterface getTable(String tableName, ExecutorService pool) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,156,return delegate.getTable(tableName, pool);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,159,public HTableInterface getTable(byte[] tableName, ExecutorService pool) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,160,return delegate.getTable(tableName, pool);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,163,public HTableInterface getTable(TableName tableName, ExecutorService pool) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,164,return delegate.getTable(tableName, pool);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,167,public boolean isMasterRunning() throws MasterNotRunningException, ZooKeeperConnectionException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,168,return delegate.isMasterRunning();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,171,public boolean isTableEnabled(TableName tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,172,return delegate.isTableEnabled(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,175,public boolean isTableEnabled(byte[] tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,176,return delegate.isTableEnabled(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,179,public boolean isTableDisabled(TableName tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,180,return delegate.isTableDisabled(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,183,public boolean isTableDisabled(byte[] tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,184,return delegate.isTableDisabled(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,187,public boolean isTableAvailable(TableName tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,188,return delegate.isTableAvailable(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,191,public boolean isTableAvailable(byte[] tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,192,return delegate.isTableAvailable(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,195,public boolean isTableAvailable(TableName tableName, byte[][] splitKeys) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,196,return delegate.isTableAvailable(tableName, splitKeys);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,199,public boolean isTableAvailable(byte[] tableName, byte[][] splitKeys) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,200,return delegate.isTableAvailable(tableName, splitKeys);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,203,public HTableDescriptor[] listTables() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,204,return delegate.listTables();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,207,public String[] getTableNames() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,208,return delegate.getTableNames();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,211,public TableName[] listTableNames() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,212,return delegate.listTableNames();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,215,public HTableDescriptor getHTableDescriptor(TableName tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,216,return delegate.getHTableDescriptor(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,219,public HTableDescriptor getHTableDescriptor(byte[] tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,220,return delegate.getHTableDescriptor(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,223,public HRegionLocation locateRegion(TableName tableName, byte[] row) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,224,return delegate.locateRegion(tableName, row);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,227,public HRegionLocation locateRegion(byte[] tableName, byte[] row) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,228,return delegate.locateRegion(tableName, row);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,231,public void clearRegionCache() {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,232,delegate.clearRegionCache();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,235,public void clearRegionCache(TableName tableName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,236,delegate.clearRegionCache(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,239,public void clearRegionCache(byte[] tableName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,240,delegate.clearRegionCache(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,243,public HRegionLocation relocateRegion(TableName tableName, byte[] row) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,244,return delegate.relocateRegion(tableName, row);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,247,public HRegionLocation relocateRegion(byte[] tableName, byte[] row) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,248,return delegate.relocateRegion(tableName, row);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,251,public void updateCachedLocations(TableName tableName, byte[] rowkey, Object exception,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,252,HRegionLocation source) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,253,delegate.updateCachedLocations(tableName, rowkey, exception, source);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,256,public void updateCachedLocations(byte[] tableName, byte[] rowkey, Object exception,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,257,HRegionLocation source) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,258,delegate.updateCachedLocations(tableName, rowkey, exception, source);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,261,public HRegionLocation locateRegion(byte[] regionName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,262,return delegate.locateRegion(regionName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,265,public List<HRegionLocation> locateRegions(TableName tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,266,return delegate.locateRegions(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,269,public List<HRegionLocation> locateRegions(byte[] tableName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,270,return delegate.locateRegions(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,273,public List<HRegionLocation>
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,274,locateRegions(TableName tableName, boolean useCache, boolean offlined) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,275,return delegate.locateRegions(tableName, useCache, offlined);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,279,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,280,return delegate.locateRegions(tableName, useCache, offlined);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,284,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,285,return delegate.getMaster();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,288,public org.apache.hadoop.hbase.protobuf.generated.AdminProtos.AdminService.BlockingInterface
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,289,getAdmin(ServerName serverName) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,290,return delegate.getAdmin(serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,293,public org.apache.hadoop.hbase.protobuf.generated.AdminProtos.AdminService.BlockingInterface
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,294,getAdmin(ServerName serverName, boolean getMaster) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,295,return delegate.getAdmin(serverName, getMaster);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,299,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,300,return delegate.getRegionLocation(tableName, row, reload);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,304,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,305,return delegate.getRegionLocation(tableName, row, reload);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,308,public void processBatch(List<? extends Row> actions, TableName tableName, ExecutorService pool,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,309,Object[] results) throws IOException, InterruptedException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,310,delegate.processBatch(actions, tableName, pool, results);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,313,public void processBatch(List<? extends Row> actions, byte[] tableName, ExecutorService pool,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,314,Object[] results) throws IOException, InterruptedException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,315,delegate.processBatch(actions, tableName, pool, results);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,318,public <R> void processBatchCallback(List<? extends Row> list, TableName tableName,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,319,ExecutorService pool, Object[] results, Callback<R> callback) throws IOException,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,320,InterruptedException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,321,delegate.processBatchCallback(list, tableName, pool, results, callback);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,324,public <R> void processBatchCallback(List<? extends Row> list, byte[] tableName,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,325,ExecutorService pool, Object[] results, Callback<R> callback) throws IOException,
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,326,InterruptedException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,327,delegate.processBatchCallback(list, tableName, pool, results, callback);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,330,public void setRegionCachePrefetch(TableName tableName, boolean enable) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,331,delegate.setRegionCachePrefetch(tableName, enable);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,334,public void setRegionCachePrefetch(byte[] tableName, boolean enable) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,335,delegate.setRegionCachePrefetch(tableName, enable);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,338,public boolean getRegionCachePrefetch(TableName tableName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,339,return delegate.getRegionCachePrefetch(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,342,public boolean getRegionCachePrefetch(byte[] tableName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,343,return delegate.getRegionCachePrefetch(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,346,public int getCurrentNrHRS() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,347,return delegate.getCurrentNrHRS();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,351,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,352,return delegate.getHTableDescriptorsByTableName(tableNames);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,355,public HTableDescriptor[] getHTableDescriptors(List<String> tableNames) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,356,return delegate.getHTableDescriptors(tableNames);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,359,public boolean isClosed() {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,360,return delegate.isClosed();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,363,public void clearCaches(ServerName sn) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,364,delegate.clearCaches(sn);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,367,public void close() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,368,delegate.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,371,public void deleteCachedRegionLocation(HRegionLocation location) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,372,delegate.deleteCachedRegionLocation(location);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,376,throws MasterNotRunningException {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,377,return delegate.getKeepAliveMasterService();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,380,public boolean isDeadServer(ServerName serverName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,381,return delegate.isDeadServer(serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,385,public NonceGenerator getNonceGenerator() {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/CoprocessorHConnection.java,386,return null; // don't use nonces for coprocessor connection
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,197,if (this.cellScanner == null) {
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,198,if (!this.iterator.hasNext()) return false;
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,199,this.cellScanner = this.iterator.next().cellScanner();
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,201,if (this.cellScanner.advance()) return true;
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,202,this.cellScanner = null;
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,203,return advance();
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,271,public static CellScanner createCellScanner(final NavigableMap<byte [],
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,272,List<Cell>> map) {
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,274,private final Iterator<Entry<byte[], List<Cell>>> entries =
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,275,map.entrySet().iterator();
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,286,if (this.currentIterator == null) {
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,287,if (!this.entries.hasNext()) return false;
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,288,this.currentIterator = this.entries.next().getValue().iterator();
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,290,if (this.currentIterator.hasNext()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,291,this.currentCell = this.currentIterator.next();
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,292,return true;
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,294,this.currentCell = null;
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,295,this.currentIterator = null;
hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java,296,return advance();
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/metrics/BaseSourceImpl.java,51,jvmMetricsSource = JvmMetrics.create(name, "", DefaultMetricsSystem.instance());
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,572,p.addImmutable(HConstants.CATALOG_FAMILY, HConstants.SERVER_QUALIFIER,
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,574,p.addImmutable(HConstants.CATALOG_FAMILY, HConstants.STARTCODE_QUALIFIER,
hbase-server/src/main/java/org/apache/hadoop/hbase/catalog/MetaEditor.java,576,p.addImmutable(HConstants.CATALOG_FAMILY, HConstants.SEQNUM_QUALIFIER,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFlusher.java,63,List<Path> result = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFlusher.java,92,if (result != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StripeStoreFlusher.java,93,result.clear();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/MetricsSink.java,50,lastTimestampForAge = timestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/MetricsSink.java,51,long age = System.currentTimeMillis() - lastTimestampForAge;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,30,import java.io.IOException;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,31,import java.util.ArrayList;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,32,import java.util.HashMap;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,33,import java.util.List;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,34,import java.util.Map;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,35,import java.util.NavigableSet;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,36,import java.util.TreeMap;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,37,import java.util.TreeSet;
hbase-client/src/main/java/org/apache/hadoop/hbase/master/RegionState.java,266,switch (regionState.getState()) {
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/PrefixTreeSeeker.java,122,return ptSearcher.advance();
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArrayScanner.java,263,discardCurrentRowNode(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,83,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,84,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,85,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,86,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,87,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,88,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,89,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,90,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,91,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,92,((MasterObserver)env.getInstance()).preCreateNamespace(ctx, ns);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,94,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,96,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,98,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,99,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,100,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,104,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,108,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,109,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,110,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,111,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,112,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,113,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,114,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,115,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,116,((MasterObserver)env.getInstance()).postCreateNamespace(ctx, ns);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,118,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,120,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,122,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,123,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,130,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,131,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,132,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,133,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,134,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,135,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,136,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,137,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,138,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,139,((MasterObserver)env.getInstance()).preDeleteNamespace(ctx, namespaceName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,141,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,143,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,145,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,146,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,147,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,151,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,155,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,156,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,157,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,158,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,159,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,160,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,161,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,162,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,163,((MasterObserver)env.getInstance()).postDeleteNamespace(ctx, namespaceName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,165,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,167,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,169,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,170,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,177,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,178,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,179,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,180,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,181,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,182,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,183,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,184,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,185,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,186,((MasterObserver)env.getInstance()).preModifyNamespace(ctx, ns);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,188,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,190,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,192,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,193,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,194,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,198,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,202,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,203,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,204,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,205,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,206,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,207,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,208,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,209,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,210,((MasterObserver)env.getInstance()).postModifyNamespace(ctx, ns);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,212,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,214,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,216,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,217,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,226,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,227,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,228,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,229,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,230,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,231,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,232,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,233,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,234,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,235,((MasterObserver)env.getInstance()).preCreateTable(ctx, htd, regions);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,237,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,239,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,241,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,242,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,249,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,250,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,251,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,252,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,253,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,254,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,255,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,256,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,257,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,258,((MasterObserver)env.getInstance()).postCreateTable(ctx, htd, regions);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,260,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,262,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,264,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,265,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,273,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,274,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,275,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,276,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,277,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,278,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,279,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,280,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,281,((MasterObserver) env.getInstance()).preCreateTableHandler(ctx, htd, regions);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,283,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,285,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,287,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,288,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,296,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,297,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,298,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,299,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,300,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,301,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,302,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,303,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,304,((MasterObserver) env.getInstance()).postCreateTableHandler(ctx, htd, regions);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,306,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,308,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,310,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,311,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,318,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,319,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,320,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,321,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,322,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,323,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,324,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,325,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,326,((MasterObserver)env.getInstance()).preDeleteTable(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,328,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,330,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,332,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,333,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,340,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,341,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,342,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,343,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,344,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,345,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,346,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,347,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,348,((MasterObserver)env.getInstance()).postDeleteTable(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,350,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,352,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,354,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,355,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,362,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,363,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,364,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,365,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,366,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,367,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,368,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,369,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,370,((MasterObserver) env.getInstance()).preDeleteTableHandler(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,372,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,374,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,376,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,377,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,384,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,385,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,386,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,387,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,388,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,389,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,390,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,391,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,392,((MasterObserver) env.getInstance()).postDeleteTableHandler(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,394,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,396,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,398,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,399,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,407,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,408,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,409,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,410,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,411,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,412,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,413,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,414,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,415,((MasterObserver)env.getInstance()).preModifyTable(ctx, tableName, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,417,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,419,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,421,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,422,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,430,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,431,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,432,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,433,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,434,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,435,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,436,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,437,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,438,((MasterObserver)env.getInstance()).postModifyTable(ctx, tableName, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,440,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,442,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,444,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,445,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,453,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,454,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,455,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,456,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,457,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,458,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,459,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,460,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,461,((MasterObserver) env.getInstance()).preModifyTableHandler(ctx, tableName, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,463,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,465,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,467,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,468,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,476,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,477,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,478,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,479,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,480,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,481,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,482,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,483,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,484,((MasterObserver) env.getInstance()).postModifyTableHandler(ctx, tableName, htd);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,486,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,488,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,490,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,491,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,499,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,500,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,501,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,502,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,503,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,504,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,505,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,506,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,507,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,508,((MasterObserver)env.getInstance()).preAddColumn(ctx, tableName, column);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,510,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,512,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,514,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,515,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,516,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,520,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,525,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,526,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,527,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,528,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,529,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,530,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,531,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,532,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,533,((MasterObserver)env.getInstance()).postAddColumn(ctx, tableName, column);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,535,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,537,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,539,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,540,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,548,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,549,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,550,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,551,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,552,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,553,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,554,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,555,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,556,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,557,((MasterObserver) env.getInstance()).preAddColumnHandler(ctx, tableName, column);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,559,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,561,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,563,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,564,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,565,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,569,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,574,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,575,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,576,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,577,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,578,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,579,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,580,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,581,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,582,((MasterObserver) env.getInstance()).postAddColumnHandler(ctx, tableName, column);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,584,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,586,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,588,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,589,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,597,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,598,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,599,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,600,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,601,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,602,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,603,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,604,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,605,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,606,((MasterObserver)env.getInstance()).preModifyColumn(ctx, tableName, descriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,608,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,610,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,612,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,613,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,614,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,618,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,623,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,624,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,625,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,626,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,627,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,628,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,629,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,630,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,631,((MasterObserver)env.getInstance()).postModifyColumn(ctx, tableName, descriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,633,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,635,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,637,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,638,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,646,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,647,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,648,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,649,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,650,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,651,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,652,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,653,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,654,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,655,((MasterObserver) env.getInstance()).preModifyColumnHandler(ctx, tableName, descriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,657,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,659,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,661,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,662,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,663,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,667,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,672,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,673,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,674,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,675,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,676,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,677,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,678,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,679,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,680,((MasterObserver) env.getInstance()).postModifyColumnHandler(ctx, tableName, descriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,682,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,684,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,686,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,687,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,694,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,695,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,696,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,697,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,698,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,699,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,700,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,701,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,702,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,703,((MasterObserver)env.getInstance()).preDeleteColumn(ctx, tableName, c);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,705,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,707,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,709,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,710,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,711,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,715,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,719,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,720,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,721,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,722,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,723,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,724,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,725,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,726,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,727,((MasterObserver)env.getInstance()).postDeleteColumn(ctx, tableName, c);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,729,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,731,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,733,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,734,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,742,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,743,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,744,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,745,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,746,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,747,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,748,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,749,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,750,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,751,((MasterObserver) env.getInstance()).preDeleteColumnHandler(ctx, tableName, c);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,753,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,755,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,757,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,758,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,759,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,763,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,768,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,769,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,770,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,771,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,772,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,773,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,774,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,775,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,776,((MasterObserver) env.getInstance()).postDeleteColumnHandler(ctx, tableName, c);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,778,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,780,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,782,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,783,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,790,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,791,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,792,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,793,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,794,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,795,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,796,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,797,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,798,((MasterObserver)env.getInstance()).preEnableTable(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,800,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,802,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,804,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,805,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,812,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,813,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,814,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,815,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,816,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,817,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,818,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,819,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,820,((MasterObserver)env.getInstance()).postEnableTable(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,822,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,824,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,826,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,827,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,834,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,835,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,836,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,837,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,838,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,839,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,840,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,841,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,842,((MasterObserver) env.getInstance()).preEnableTableHandler(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,844,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,846,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,848,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,849,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,856,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,857,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,858,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,859,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,860,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,861,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,862,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,863,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,864,((MasterObserver) env.getInstance()).postEnableTableHandler(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,866,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,868,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,870,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,871,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,878,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,879,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,880,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,881,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,882,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,883,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,884,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,885,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,886,((MasterObserver)env.getInstance()).preDisableTable(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,888,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,890,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,892,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,893,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,900,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,901,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,902,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,903,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,904,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,905,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,906,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,907,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,908,((MasterObserver)env.getInstance()).postDisableTable(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,910,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,912,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,914,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,915,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,922,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,923,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,924,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,925,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,926,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,927,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,928,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,929,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,930,((MasterObserver) env.getInstance()).preDisableTableHandler(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,932,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,934,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,936,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,937,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,944,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,945,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,946,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,947,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,948,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,949,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,950,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,951,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,952,((MasterObserver) env.getInstance()).postDisableTableHandler(ctx, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,954,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,956,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,958,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,959,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,967,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,968,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,969,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,970,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,971,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,972,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,973,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,974,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,975,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,976,((MasterObserver)env.getInstance()).preMove(ctx, region, srcServer, destServer);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,978,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,980,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,982,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,983,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,984,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,988,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,993,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,994,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,995,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,996,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,997,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,998,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,999,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1000,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1001,((MasterObserver)env.getInstance()).postMove(ctx, region, srcServer, destServer);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1003,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1005,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1007,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1008,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1015,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1016,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1017,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1018,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1019,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1020,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1021,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1022,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1023,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1024,((MasterObserver) env.getInstance()).preAssign(ctx, regionInfo);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1026,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1028,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1030,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1031,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1032,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1036,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1040,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1041,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1042,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1043,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1044,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1045,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1046,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1047,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1048,((MasterObserver)env.getInstance()).postAssign(ctx, regionInfo);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1050,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1052,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1054,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1055,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1063,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1064,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1065,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1066,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1067,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1068,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1069,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1070,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1071,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1072,((MasterObserver)env.getInstance()).preUnassign(ctx, regionInfo, force);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1074,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1076,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1078,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1079,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1080,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1084,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1088,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1089,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1090,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1091,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1092,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1093,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1094,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1095,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1096,((MasterObserver)env.getInstance()).postUnassign(ctx, regionInfo, force);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1098,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1100,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1102,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1103,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1110,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1111,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1112,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1113,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1114,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1115,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1116,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1117,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1118,((MasterObserver) env.getInstance()).preRegionOffline(ctx, regionInfo);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1120,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1122,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1124,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1125,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1131,public void postRegionOffline(final HRegionInfo regionInfo) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1132,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1133,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1134,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1135,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1136,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1137,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1138,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1139,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1140,((MasterObserver) env.getInstance()).postRegionOffline(ctx, regionInfo);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1142,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1144,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1146,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1147,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1153,public boolean preBalance() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1154,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1155,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1156,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1157,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1158,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1159,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1160,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1161,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1162,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1163,((MasterObserver)env.getInstance()).preBalance(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1165,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1167,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1169,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1170,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1171,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1175,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1178,public void postBalance(final List<RegionPlan> plans) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1179,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1180,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1181,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1182,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1183,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1184,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1185,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1186,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1187,((MasterObserver)env.getInstance()).postBalance(ctx, plans);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1189,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1191,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1193,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1194,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1201,boolean balance = b;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1202,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1203,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1204,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1205,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1206,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1207,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1208,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1209,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1210,balance = ((MasterObserver)env.getInstance()).preBalanceSwitch(ctx, balance);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1212,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1214,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1216,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1217,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1221,return balance;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1226,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1227,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1228,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1229,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1230,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1231,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1232,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1233,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1234,((MasterObserver)env.getInstance()).postBalanceSwitch(ctx, oldValue, newValue);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1236,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1238,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1240,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1241,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1248,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1249,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1250,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1251,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1252,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1253,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1254,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1255,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1256,((MasterObserver)env.getInstance()).preShutdown(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1258,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1260,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1262,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1263,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1270,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1271,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1272,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1273,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1274,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1275,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1276,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1277,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1278,((MasterObserver)env.getInstance()).preStopMaster(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1280,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1282,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1284,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1285,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1292,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1293,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1294,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1295,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1296,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1297,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1298,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1299,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1300,((MasterObserver) env.getInstance()).preMasterInitialization(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1302,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1304,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1306,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1307,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1314,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1315,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1316,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1317,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1318,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1319,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1320,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1321,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1322,((MasterObserver)env.getInstance()).postStartMaster(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1324,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1326,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1328,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1329,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1337,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1338,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1339,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1340,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1341,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1342,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1343,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1344,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1345,((MasterObserver)env.getInstance()).preSnapshot(ctx, snapshot, hTableDescriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1347,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1349,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1351,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1352,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1360,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1361,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1362,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1363,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1364,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1365,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1366,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1367,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1368,((MasterObserver)env.getInstance()).postSnapshot(ctx, snapshot, hTableDescriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1370,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1372,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1374,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1375,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1383,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1384,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1385,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1386,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1387,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1388,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1389,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1390,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1391,((MasterObserver)env.getInstance()).preCloneSnapshot(ctx, snapshot,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1392,hTableDescriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1394,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1396,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1398,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1399,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1407,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1408,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1409,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1410,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1411,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1412,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1413,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1414,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1415,((MasterObserver)env.getInstance()).postCloneSnapshot(ctx, snapshot,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1416,hTableDescriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1418,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1420,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1422,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1423,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1431,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1432,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1433,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1434,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1435,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1436,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1437,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1438,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1439,((MasterObserver)env.getInstance()).preRestoreSnapshot(ctx, snapshot,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1440,hTableDescriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1442,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1444,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1446,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1447,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1455,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1456,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1457,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1458,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1459,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1460,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1461,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1462,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1463,((MasterObserver)env.getInstance()).postRestoreSnapshot(ctx, snapshot,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1464,hTableDescriptor);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1466,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1468,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1470,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1471,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1478,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1479,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1480,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1481,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1482,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1483,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1484,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1485,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1486,((MasterObserver)env.getInstance()).preDeleteSnapshot(ctx, snapshot);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1488,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1490,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1492,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1493,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1500,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1501,for (MasterEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1502,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1503,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1504,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1505,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1506,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1507,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1508,((MasterObserver)env.getInstance()).postDeleteSnapshot(ctx, snapshot);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1510,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1512,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1514,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1515,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1523,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1524,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1525,for (MasterEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1526,if (env.getInstance() instanceof MasterObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1527,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1528,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1529,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1530,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1531,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1532,((MasterObserver) env.getInstance()).preGetTableDescriptors(ctx,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1533,tableNamesList, descriptors);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1535,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1537,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1539,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1540,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1541,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1545,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1550,ObserverContext<MasterCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1553,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterCoprocessorHost.java,1558,((MasterObserver)env.getInstance()).postGetTableDescriptors(ctx, descriptors);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,292,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,293,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,294,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,295,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,296,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,297,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,298,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,299,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,300,((RegionObserver) env.getInstance()).preOpen(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,302,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,304,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,306,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,307,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,317,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,318,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,319,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,320,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,321,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,322,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,323,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,324,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,325,((RegionObserver) env.getInstance()).postOpen(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,327,handleCoprocessorThrowableNoRethrow(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,329,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,331,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,332,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,342,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,343,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,344,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,345,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,346,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,347,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,348,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,349,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,350,((RegionObserver) env.getInstance()).postLogReplay(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,352,handleCoprocessorThrowableNoRethrow(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,354,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,356,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,357,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,368,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,369,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,370,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,371,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,372,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,373,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,374,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,375,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,376,((RegionObserver) env.getInstance()).preClose(ctx, abortRequested);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,378,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,380,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,391,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,392,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,393,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,394,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,395,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,396,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,397,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,398,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,399,((RegionObserver) env.getInstance()).postClose(ctx, abortRequested);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,401,handleCoprocessorThrowableNoRethrow(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,403,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,406,shutdown(env);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,417,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,418,InternalScanner s = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,419,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,420,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,421,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,422,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,423,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,424,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,425,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,426,s = ((RegionObserver) env.getInstance()).preCompactScannerOpen(ctx, store,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,427,scanners, scanType, earliestPutTs, s, request);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,429,handleCoprocessorThrowable(env,e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,431,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,433,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,434,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,438,return s;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,452,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,453,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,454,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,455,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,456,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,457,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,458,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,459,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,460,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,461,((RegionObserver) env.getInstance()).preCompactSelection(ctx, store, candidates,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,462,request);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,464,handleCoprocessorThrowable(env,e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,466,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,468,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,469,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,470,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,474,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,486,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,487,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,488,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,489,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,490,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,491,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,492,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,493,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,494,((RegionObserver) env.getInstance()).postCompactSelection(ctx, store, selected,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,495,request);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,497,handleCoprocessorThrowableNoRethrow(env,e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,499,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,501,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,502,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,518,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,519,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,520,InternalScanner s = scanner;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,521,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,522,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,523,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,524,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,525,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,526,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,527,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,528,s = ((RegionObserver) env.getInstance()).preCompact(ctx, store, s, scanType,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,529,request);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,531,handleCoprocessorThrowable(env,e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,533,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,535,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,536,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,537,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,541,return bypass ? null : s;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,553,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,554,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,555,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,556,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,557,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,558,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,559,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,560,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,561,((RegionObserver) env.getInstance()).postCompact(ctx, store, resultFile, request);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,563,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,565,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,567,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,568,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,578,public InternalScanner preFlush(final Store store, final InternalScanner scanner) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,579,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,580,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,581,InternalScanner s = scanner;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,582,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,583,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,584,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,585,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,586,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,587,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,588,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,589,s = ((RegionObserver)env.getInstance()).preFlush(ctx, store, s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,591,handleCoprocessorThrowable(env,e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,593,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,595,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,596,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,597,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,601,return bypass ? null : s;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,609,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,610,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,611,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,612,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,613,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,614,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,615,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,616,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,617,((RegionObserver)env.getInstance()).preFlush(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,619,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,621,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,623,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,624,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,637,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,638,InternalScanner s = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,639,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,640,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,641,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,642,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,643,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,644,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,645,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,646,s = ((RegionObserver) env.getInstance()).preFlushScannerOpen(ctx, store,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,647,memstoreScanner, s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,649,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,651,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,653,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,654,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,658,return s;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,666,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,667,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,668,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,669,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,670,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,671,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,672,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,673,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,674,((RegionObserver)env.getInstance()).postFlush(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,676,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,678,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,680,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,681,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,692,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,693,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,694,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,695,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,696,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,697,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,698,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,699,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,700,((RegionObserver)env.getInstance()).postFlush(ctx, store, storeFile);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,702,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,704,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,706,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,707,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,718,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,719,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,720,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,721,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,722,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,723,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,724,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,725,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,726,((RegionObserver)env.getInstance()).preSplit(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,728,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,730,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,732,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,733,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,744,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,745,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,746,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,747,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,748,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,749,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,750,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,751,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,752,((RegionObserver)env.getInstance()).preSplit(ctx, splitRow);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,754,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,756,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,758,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,759,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,772,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,773,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,774,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,775,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,776,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,777,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,778,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,779,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,780,((RegionObserver)env.getInstance()).postSplit(ctx, l, r);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,782,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,784,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,786,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,787,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,793,public boolean preSplitBeforePONR(final byte[] splitKey,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,795,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,796,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,797,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,798,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,799,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,800,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,801,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,802,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,803,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,804,((RegionObserver) env.getInstance()).preSplitBeforePONR(ctx, splitKey, metaEntries);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,806,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,808,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,810,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,811,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,812,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,816,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,820,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,821,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,822,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,823,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,824,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,825,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,826,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,827,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,828,((RegionObserver) env.getInstance()).preSplitAfterPONR(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,830,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,832,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,834,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,835,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,846,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,847,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,848,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,849,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,850,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,851,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,852,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,853,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,854,((RegionObserver) env.getInstance()).preRollBackSplit(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,856,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,858,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,860,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,861,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,872,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,873,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,874,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,875,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,876,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,877,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,878,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,879,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,880,((RegionObserver) env.getInstance()).postRollBackSplit(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,882,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,884,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,886,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,887,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,898,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,899,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,900,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,901,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,902,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,903,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,904,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,905,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,906,((RegionObserver) env.getInstance()).postCompleteSplit(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,908,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,910,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,912,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,913,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,930,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,931,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,932,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,933,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,934,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,935,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,936,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,937,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,938,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,939,((RegionObserver)env.getInstance()).preGetClosestRowBefore(ctx, row, family, result);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,941,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,943,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,945,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,946,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,947,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,951,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,962,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,963,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,964,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,965,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,966,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,967,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,968,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,969,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,970,((RegionObserver)env.getInstance()).postGetClosestRowBefore(ctx, row, family, result);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,972,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,974,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,976,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,977,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,990,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,991,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,992,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,993,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,994,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,995,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,996,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,997,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,998,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,999,((RegionObserver)env.getInstance()).preGetOp(ctx, get, results);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1001,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1003,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1005,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1006,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1007,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1011,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1020,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1021,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1022,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1023,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1024,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1025,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1026,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1027,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1028,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1029,((RegionObserver)env.getInstance()).postGetOp(ctx, get, results);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1031,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1033,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1035,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1036,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1049,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1050,boolean exists = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1051,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1052,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1053,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1054,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1055,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1056,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1057,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1058,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1059,exists = ((RegionObserver)env.getInstance()).preExists(ctx, get, exists);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1061,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1063,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1065,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1066,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1067,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1071,return bypass ? exists : null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1082,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1083,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1084,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1085,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1086,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1087,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1088,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1089,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1090,exists = ((RegionObserver)env.getInstance()).postExists(ctx, get, exists);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1092,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1094,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1096,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1097,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1101,return exists;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1113,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1114,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1115,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1116,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1117,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1118,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1119,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1120,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1121,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1122,((RegionObserver)env.getInstance()).prePut(ctx, put, edit, durability);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1124,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1126,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1128,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1145,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1146,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1147,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1148,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1149,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1150,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1151,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1152,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1153,((RegionObserver)env.getInstance()).postPut(ctx, put, edit, durability);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1155,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1157,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1159,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1160,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1175,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1176,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1177,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1178,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1179,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1180,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1181,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1182,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1183,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1184,((RegionObserver)env.getInstance()).preDelete(ctx, delete, edit, durability);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1186,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1188,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1190,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1191,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1192,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1196,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1207,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1208,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1209,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1210,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1211,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1212,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1213,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1214,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1215,((RegionObserver)env.getInstance()).postDelete(ctx, delete, edit, durability);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1217,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1219,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1221,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1222,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1235,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1236,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1237,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1238,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1239,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1240,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1241,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1242,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1243,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1244,((RegionObserver) env.getInstance()).preBatchMutate(ctx, miniBatchOp);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1246,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1248,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1250,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1251,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1252,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1256,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1265,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1266,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1267,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1268,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1269,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1270,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1271,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1272,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1273,((RegionObserver) env.getInstance()).postBatchMutate(ctx, miniBatchOp);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1275,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1277,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1279,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1280,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1289,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1290,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1291,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1292,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1293,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1294,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1295,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1296,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1297,((RegionObserver) env.getInstance()).postBatchMutateIndispensably(ctx, miniBatchOp,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1298,success);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1300,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1302,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1304,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1305,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1325,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1326,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1327,boolean result = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1328,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1329,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1330,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1331,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1332,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1333,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1334,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1335,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1336,result = ((RegionObserver)env.getInstance()).preCheckAndPut(ctx, row, family, qualifier,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1337,compareOp, comparator, put, result);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1339,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1341,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1343,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1365,throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1366,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1367,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1368,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1369,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1370,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1371,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1372,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1373,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1374,result = ((RegionObserver)env.getInstance()).postCheckAndPut(ctx, row, family,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1375,qualifier, compareOp, comparator, put, result);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1377,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1379,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1381,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1382,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1386,return result;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1404,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1405,boolean result = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1406,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1407,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1408,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1409,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1410,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1411,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1412,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1413,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1414,result = ((RegionObserver)env.getInstance()).preCheckAndDelete(ctx, row, family,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1415,qualifier, compareOp, comparator, delete, result);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1417,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1419,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1421,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1443,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1444,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1445,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1446,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1447,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1448,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1449,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1450,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1451,result = ((RegionObserver)env.getInstance()).postCheckAndDelete(ctx, row, family,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1452,qualifier, compareOp, comparator, delete, result);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1454,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1456,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1458,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1459,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1463,return result;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1473,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1474,Result result = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1475,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1476,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1477,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1478,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1479,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1480,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1481,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1482,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1483,result = ((RegionObserver)env.getInstance()).preAppend(ctx, append);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1485,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1487,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1489,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1505,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1506,Result result = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1507,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1508,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1509,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1510,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1511,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1512,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1513,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1514,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1515,result = ((RegionObserver)env.getInstance()).preIncrement(ctx, increment);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1517,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1519,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1521,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1536,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1537,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1538,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1539,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1540,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1541,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1542,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1543,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1544,((RegionObserver)env.getInstance()).postAppend(ctx, append, result);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1546,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1548,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1550,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1551,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1563,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1564,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1565,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1566,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1567,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1568,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1569,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1570,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1571,result = ((RegionObserver)env.getInstance()).postIncrement(ctx, increment, result);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1573,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1575,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1577,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1578,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1582,return result;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1592,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1593,RegionScanner s = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1594,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1595,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1596,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1597,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1598,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1599,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1600,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1601,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1602,s = ((RegionObserver)env.getInstance()).preScannerOpen(ctx, scan, s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1604,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1606,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1608,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1609,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1610,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1614,return bypass ? s : null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1624,KeyValueScanner s = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1625,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1626,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1627,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1628,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1629,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1630,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1631,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1632,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1633,s = ((RegionObserver) env.getInstance()).preStoreScannerOpen(ctx, store, scan,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1634,targetCols, s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1636,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1638,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1640,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1641,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1645,return s;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1655,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1656,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1657,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1658,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1659,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1660,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1661,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1662,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1663,s = ((RegionObserver)env.getInstance()).postScannerOpen(ctx, scan, s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1665,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1667,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1669,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1670,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1674,return s;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1687,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1688,boolean hasNext = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1689,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1690,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1691,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1692,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1693,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1694,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1695,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1696,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1697,hasNext = ((RegionObserver)env.getInstance()).preScannerNext(ctx, s, results, limit,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1698,hasNext);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1700,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1702,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1704,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1705,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1706,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1710,return bypass ? hasNext : null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1724,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1725,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1726,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1727,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1728,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1729,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1730,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1731,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1732,hasMore = ((RegionObserver)env.getInstance()).postScannerNext(ctx, s, results, limit,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1733,hasMore);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1735,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1737,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1739,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1740,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1744,return hasMore;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1759,boolean hasMore = true; // By default assume more rows there.
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1760,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1761,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1762,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1763,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1764,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1765,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1766,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1767,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1768,hasMore = ((RegionObserver) env.getInstance()).postScannerFilterRow(ctx, s, currentRow,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1769,offset, length, hasMore);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1771,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1773,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1775,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1776,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1780,return hasMore;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1789,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1790,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1791,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1792,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1793,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1794,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1795,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1796,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1797,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1798,((RegionObserver)env.getInstance()).preScannerClose(ctx, s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1800,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1802,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1804,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1805,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1806,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1810,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1818,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1819,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1820,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1821,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1822,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1823,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1824,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1825,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1826,((RegionObserver)env.getInstance()).postScannerClose(ctx, s);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1828,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1830,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1832,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1833,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1848,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1849,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1850,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1851,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1852,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1853,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1854,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1855,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1856,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1857,((RegionObserver)env.getInstance()).preWALRestore(ctx, info, logKey, logEdit);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1859,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1861,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1863,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1864,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1865,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1869,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1880,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1881,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1882,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1883,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1884,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1885,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1886,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1887,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1888,((RegionObserver)env.getInstance()).postWALRestore(ctx, info, logKey, logEdit);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1890,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1892,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1894,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1895,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1907,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1908,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1909,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1910,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1911,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1912,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1913,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1914,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1915,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1916,((RegionObserver)env.getInstance()).preBulkLoadHFile(ctx, familyPaths);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1918,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1920,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1922,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1923,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1924,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1928,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1939,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1940,for (RegionEnvironment env: coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1941,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1942,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1943,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1944,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1945,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1946,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1947,hasLoaded = ((RegionObserver)env.getInstance()).postBulkLoadHFile(ctx, familyPaths,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1948,hasLoaded);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1950,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1952,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1954,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1955,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1959,return hasLoaded;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1963,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1964,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1965,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1966,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1967,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1968,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1969,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1970,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1971,((RegionObserver) env.getInstance()).postStartRegionOperation(ctx, op);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1973,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1975,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1977,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1978,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1985,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1986,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1987,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1988,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1989,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1990,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1991,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1992,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1993,((RegionObserver) env.getInstance()).postCloseRegionOperation(ctx, op);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1995,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1997,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,1999,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2000,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2020,StoreFile.Reader reader = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2021,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2022,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2023,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2024,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2025,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2026,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2027,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2028,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2029,reader = ((RegionObserver) env.getInstance()).preStoreFileReaderOpen(ctx, fs, p, in,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2030,size, cacheConf, r, reader);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2032,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2034,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2036,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2037,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2041,return reader;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2057,final Reference r, StoreFile.Reader reader) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2058,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2059,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2060,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2061,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2062,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2063,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2064,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2065,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2066,reader = ((RegionObserver) env.getInstance()).postStoreFileReaderOpen(ctx, fs, p, in,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2067,size, cacheConf, r, reader);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2069,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2071,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2073,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2074,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2078,return reader;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2083,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2084,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2085,if (env.getInstance() instanceof RegionObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2086,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2087,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2088,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2089,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2090,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2091,newCell = ((RegionObserver) env.getInstance()).postMutationBeforeWAL(ctx, opType,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2092,mutation, oldCell, newCell);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2094,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2096,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2098,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2099,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2103,return newCell;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2108,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2109,for (RegionEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2110,if (env.getInstance() instanceof EndpointObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2111,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2112,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2113,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2114,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2115,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2116,request = ((EndpointObserver) env.getInstance()).preEndpointInvocation(ctx, service,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2117,methodName, request);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2119,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2121,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2123,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2124,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2128,return request;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2133,ObserverContext<RegionCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2135,if (env.getInstance() instanceof EndpointObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2136,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2137,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2138,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2139,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2140,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2141,((EndpointObserver) env.getInstance()).postEndpointInvocation(ctx, service,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2142,methodName, request, responseBuilder);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2144,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionCoprocessorHost.java,2146,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,57,ObserverContext<RegionServerCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,58,for (RegionServerEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,59,if (env.getInstance() instanceof RegionServerObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,60,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,61,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,62,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,63,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,64,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,65,((RegionServerObserver) env.getInstance()).preStopRegionServer(ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,67,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,69,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,71,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,72,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,79,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,80,ObserverContext<RegionServerCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,81,for (RegionServerEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,82,if (env.getInstance() instanceof RegionServerObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,83,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,84,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,85,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,86,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,87,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,88,((RegionServerObserver) env.getInstance()).preMerge(ctx, regionA, regionB);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,90,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,92,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,94,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,95,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,96,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,100,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,105,ObserverContext<RegionServerCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,106,for (RegionServerEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,107,if (env.getInstance() instanceof RegionServerObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,108,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,109,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,110,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,111,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,112,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,113,((RegionServerObserver) env.getInstance()).postMerge(ctx, regionA, regionB, mergedRegion);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,115,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,117,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,119,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,120,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,128,boolean bypass = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,129,ObserverContext<RegionServerCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,130,for (RegionServerEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,131,if (env.getInstance() instanceof RegionServerObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,132,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,133,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,134,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,135,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,136,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,137,((RegionServerObserver) env.getInstance()).preMergeCommit(ctx, regionA, regionB,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,138,metaEntries);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,140,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,142,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,144,bypass |= ctx.shouldBypass();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,145,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,146,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,150,return bypass;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,155,ObserverContext<RegionServerCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,156,for (RegionServerEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,157,if (env.getInstance() instanceof RegionServerObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,158,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,159,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,160,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,161,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,162,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,163,((RegionServerObserver) env.getInstance()).postMergeCommit(ctx, regionA, regionB,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,164,mergedRegion);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,166,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,168,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,170,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,171,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,178,ObserverContext<RegionServerCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,179,for (RegionServerEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,180,if (env.getInstance() instanceof RegionServerObserver) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,181,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,182,Thread currentThread = Thread.currentThread();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,183,ClassLoader cl = currentThread.getContextClassLoader();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,184,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,185,currentThread.setContextClassLoader(env.getClassLoader());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,186,((RegionServerObserver) env.getInstance()).preRollBackMerge(ctx, regionA, regionB);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,188,handleCoprocessorThrowable(env, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,190,currentThread.setContextClassLoader(cl);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,192,if (ctx.shouldComplete()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,193,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,200,ObserverContext<RegionServerCoprocessorEnvironment> ctx = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,201,for (RegionServerEnvironment env : coprocessors) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,203,ctx = ObserverContext.createAndPrepare(env, ctx);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionServerCoprocessorHost.java,208,((RegionServerObserver) env.getInstance()).postRollBackMerge(ctx, regionA, regionB);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,444,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java,540,finished = splitScan(outstanding, table, splitAlgo);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java,541,if (finished.isEmpty()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java,544,outstanding.removeAll(finished);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java,587,LOG.debug("Avg Time / Split = "
hbase-server/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java,588,+ org.apache.hadoop.util.StringUtils.formatTime(tDiff / splitCount));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,237,retrieveFromFile();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,781,private void retrieveFromFile() throws IOException, BucketAllocatorException,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1973,maxWaitTime = this.server.getConfiguration().
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1974,getLong("hbase.regionserver.rpc.startup.waittime", 60000);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,101,import org.apache.hadoop.security.AccessControlException;
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1242,throw new AccessControlException(
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1272,throw new AccessControlException(
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1289,throw new AccessControlException(
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1304,throw new AccessControlException(
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1448,AccessControlException ae = new AccessControlException("Authentication is required");
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1561,throw new AccessControlException("Authenticated user (" + user
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1650,throw new AccessControlException("Connection from " + this + " for service " +
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1756,setupResponse(authFailedResponse, authFailedCall, ae, ae.getMessage());
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,76,import org.apache.hadoop.security.AccessControlException;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1641,FsAction action) throws AccessControlException {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,1653,throw new AccessControlException("Permission denied:" + " action=" + action
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,108,import org.apache.hadoop.security.AccessControlException;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,1559,private void preCheckPermission() throws IOException, AccessControlException {
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,1573,LOG.warn("Got AccessControlException when preCheckPermission ", ace);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,1577,throw new AccessControlException(ace);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/CallRunner.java,107,this.rpcServer.addCallSize(call.getSize() * -1);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,497,BlockBucket bucketSingle = new BlockBucket(bytesToFree, blockSize,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,498,singleSize());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,499,BlockBucket bucketMulti = new BlockBucket(bytesToFree, blockSize,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,500,multiSize());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,501,BlockBucket bucketMemory = new BlockBucket(bytesToFree, blockSize,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,502,memorySize());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,647,return compareTo(( BlockBucket)that) == 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,720,this.wait();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,724,if(cache == null) break;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/LruBlockCache.java,731,this.notifyAll(); // FindBugs NN_NAKED_NOTIFY
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,400,throw new BucketAllocatorException("Allocation too big size=" + blockSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,113,private ConcurrentHashMap<BlockCacheKey, RAMQueueEntry> ramCache;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,124,private ArrayList<BlockingQueue<RAMQueueEntry>> writerQueues =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,505,private void freeSpace() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,514,StringBuffer msgBuffer = new StringBuffer();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,526,msgBuffer.append("Free for bucketSize(" + stats[i].itemSize() + ")="
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,530,msgBuffer.append("Free for total="
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,531,+ StringUtils.byteDesc(bytesToFreeWithoutExtra) + ", ");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,541,+ ",total=" + StringUtils.byteDesc(totalSize));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,618,/ remainingBuckets;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,628,LOG.debug("Bucket cache free space completed; " + "freed="
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,644,private class WriterThread extends HasThread {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,645,BlockingQueue<RAMQueueEntry> inputQueue;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,646,final int threadNO;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,647,boolean writerEnabled = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,653,setDaemon(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,690,throws InterruptedException {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,691,BucketEntry[] bucketEntries = new BucketEntry[entries.size()];
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,692,RAMQueueEntry[] ramEntries = new RAMQueueEntry[entries.size()];
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,693,int done = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,694,while (entries.size() > 0 && cacheEnabled) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,696,RAMQueueEntry ramEntry = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,698,ramEntry = entries.remove(entries.size() - 1);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,699,if (ramEntry == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,700,LOG.warn("Couldn't get the entry from RAM queue, who steals it?");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,703,BucketEntry bucketEntry = ramEntry.writeToCache(ioEngine,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,704,bucketAllocator, deserialiserMap, realCacheSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,705,ramEntries[done] = ramEntry;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,706,bucketEntries[done++] = bucketEntry;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,711,LOG.warn("Failed allocating for block "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,712,+ (ramEntry == null ? "" : ramEntry.getKey()), fle);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,715,freeSpace();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,730,LOG.error("Faild syncing IO engine", ioex);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,733,for (int i = 0; i < done; ++i) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,738,done = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,741,for (int i = 0; i < done; ++i) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,743,backingMap.put(ramEntries[i].getKey(), bucketEntries[i]);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,745,RAMQueueEntry ramCacheEntry = ramCache.remove(ramEntries[i].getKey());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,747,heapSize.addAndGet(-1 * ramEntries[i].getData().heapSize());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,751,if (bucketAllocator.getUsedSize() > acceptableSize()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,752,freeSpace();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,835,if (cacheEnabled
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,836,&& (now - ioErrorStartTime) > this.ioErrorsTolerationDuration) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,837,LOG.error("IO errors duration time has exceeded "
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,838,+ ioErrorsTolerationDuration
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,839,+ "ms, disabing cache, please check your IOEngine");
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1119,private static class RAMQueueEntry {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1154,BucketEntry bucketEntry = new BucketEntry(offset, len, accessTime,
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,1155,inMemory);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,23,import java.util.ArrayList;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,171,bucketList = new ArrayList<Bucket>();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,172,freeBuckets = new ArrayList<Bucket>();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,173,completelyFreeBuckets = new ArrayList<Bucket>();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,177,public void instantiateBucket(Bucket b) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,227,private void removeBucket(Bucket b) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocator.java,243,public IndexStatistics statistics() {
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,80,this.peerClusters = new HashMap<String, ReplicationPeer>();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,144,if (!this.peerClusters.containsKey(id)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,147,return this.peerClusters.get(id).getPeerEnabled().get();
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,182,this.peerClusters.put(peerId, peer);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,192,this.peerClusters.remove(peerId);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,311,if (!peerClusters.containsKey(peerId)) {
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,314,return peerClusters.get(peerId).getLastRegionserverUpdate();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,5550,void clearSplit_TESTS_ONLY() {
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/WALProtos.java,5208,new java.lang.String[] { "HasCompression", "EncryptionKey", "HasTagCompression", });
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,98,protected boolean readHeader(Builder builder, FSDataInputStream stream) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,99,return builder.mergeDelimitedFrom(stream);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,102,private void initInternal(FSDataInputStream stream, boolean isFirst) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,114,boolean hasHeader = readHeader(builder, stream);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/ProtobufLogReader.java,115,if (!hasHeader) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogReader.java,45,boolean result = super.readHeader(builder, stream);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogReader.java,49,if (result && builder.hasEncryptionKey()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4502,long lastRecordedFlushedSequenceId = -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4503,String nodePath = ZKUtil.joinZNode(this.zooKeeper.recoveringRegionsZNode,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4504,region.getEncodedName());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4506,byte[] data = ZKUtil.getData(zkw, nodePath);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4507,if (data != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4508,lastRecordedFlushedSequenceId = SplitLogManager.parseLastFlushedSequenceIdFrom(data);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4510,if (data == null || lastRecordedFlushedSequenceId < minSeqIdForLogReplay) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4511,ZKUtil.setData(zkw, nodePath, ZKUtil.positionToByteArray(minSeqIdForLogReplay));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4513,if (previousRSName != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4515,nodePath = ZKUtil.joinZNode(nodePath, previousRSName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4516,ZKUtil.setData(zkw, nodePath,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4517,ZKUtil.regionSequenceIdsToByteArray(minSeqIdForLogReplay, maxSeqIdInStores));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4518,LOG.debug("Update last flushed sequence id of region " + region.getEncodedName() + " for "
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4519,+ previousRSName);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4521,LOG.warn("Can't find failed region server for recovering region " + region.getEncodedName());
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/ClientProtos.java,29241,new java.lang.String[] { "Column", "Attribute", "StartRow", "StopRow", "Filter", "TimeRange", "MaxVersions", "CacheBlocks", "BatchSize", "MaxResultSize", "StoreLimit", "StoreOffset", "LoadColumnFamiliesOnDemand", "Small", "Reversed", });
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,667,entries.add(inputQueue.take());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,668,inputQueue.drainTo(entries);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,669,synchronized (cacheWaitSignals[threadNO]) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,670,cacheWaitSignals[threadNO].notifyAll();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,673,if (!cacheEnabled) break;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,675,doDrain(entries);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,101,static final AtomicLong regionCount = new AtomicLong(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,429,String getUniqueName(TableName tableName) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,430,String name = tableName + "," + regionCount.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,431,return name;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,446,String uniqueName = getUniqueName(table.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerWrapperImpl.java,422,lastRan = currentTime - (period * 1000);
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeer.java,72,public ReplicationPeer(Configuration conf, String key, String id) throws ReplicationException {
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeer.java,74,this.clusterKey = key;
hbase-client/src/main/java/org/apache/hadoop/hbase/replication/ReplicationPeersZKImpl.java,420,new ReplicationPeer(peerConf, peerId, ZKUtil.getZooKeeperClusterKey(peerConf));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,186,private static final AtomicInteger readOps = new AtomicInteger();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,187,private static final AtomicLong readTimeNano = new AtomicLong();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,188,private static final AtomicInteger writeOps = new AtomicInteger();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,189,private static final AtomicLong writeTimeNano = new AtomicLong();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,192,private static final AtomicInteger preadOps = new AtomicInteger();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,193,private static final AtomicLong preadTimeNano = new AtomicLong();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,203,private static final int LATENCY_BUFFER_SIZE = 5000;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,204,private static final BlockingQueue<Long> fsReadLatenciesNanos =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,205,new ArrayBlockingQueue<Long>(LATENCY_BUFFER_SIZE);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,206,private static final BlockingQueue<Long> fsWriteLatenciesNanos =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,207,new ArrayBlockingQueue<Long>(LATENCY_BUFFER_SIZE);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,208,private static final BlockingQueue<Long> fsPreadLatenciesNanos =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,209,new ArrayBlockingQueue<Long>(LATENCY_BUFFER_SIZE);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,211,public static final void offerReadLatency(long latencyNanos, boolean pread) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,212,if (pread) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,213,fsPreadLatenciesNanos.offer(latencyNanos); // might be silently dropped, if the queue is full
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,214,preadOps.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,215,preadTimeNano.addAndGet(latencyNanos);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,217,fsReadLatenciesNanos.offer(latencyNanos); // might be silently dropped, if the queue is full
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,218,readTimeNano.addAndGet(latencyNanos);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,219,readOps.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,223,public static final void offerWriteLatency(long latencyNanos) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,224,fsWriteLatenciesNanos.offer(latencyNanos); // might be silently dropped, if the queue is full
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,226,writeTimeNano.addAndGet(latencyNanos);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,227,writeOps.incrementAndGet();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,230,public static final Collection<Long> getReadLatenciesNanos() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,231,final List<Long> latencies =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,232,Lists.newArrayListWithCapacity(fsReadLatenciesNanos.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,233,fsReadLatenciesNanos.drainTo(latencies);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,234,return latencies;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,237,public static final Collection<Long> getPreadLatenciesNanos() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,238,final List<Long> latencies =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,239,Lists.newArrayListWithCapacity(fsPreadLatenciesNanos.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,240,fsPreadLatenciesNanos.drainTo(latencies);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,241,return latencies;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,244,public static final Collection<Long> getWriteLatenciesNanos() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,245,final List<Long> latencies =
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,246,Lists.newArrayListWithCapacity(fsWriteLatenciesNanos.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,247,fsWriteLatenciesNanos.drainTo(latencies);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,248,return latencies;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,255,public static final int getReadOps() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,256,return readOps.getAndSet(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,259,public static final long getReadTimeMs() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,260,return readTimeNano.getAndSet(0) / 1000000;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,264,public static final int getPreadOps() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,265,return preadOps.getAndSet(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,268,public static final long getPreadTimeMs() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,269,return preadTimeNano.getAndSet(0) / 1000000;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,272,public static final int getWriteOps() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,273,return writeOps.getAndSet(0);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,276,public static final long getWriteTimeMs() {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,277,return writeTimeNano.getAndSet(0) / 1000000;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,234,long startTimeNs = System.nanoTime();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,260,final long delta = System.nanoTime() - startTimeNs;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,261,HFile.offerReadLatency(delta, true);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,354,long startTimeNs = System.nanoTime();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,359,final long delta = System.nanoTime() - startTimeNs;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileReaderV2.java,360,HFile.offerReadLatency(delta, pread);
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java,152,long startTimeNs = System.nanoTime();
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileWriterV2.java,165,HFile.offerWriteLatency(System.nanoTime() - startTimeNs);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/CopyTable.java,247,if (startTime > endTime) {
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,1050,markClosed(e);
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,139,if (namespaceDelimIndex == 0 || namespaceDelimIndex == -1){
hbase-common/src/main/java/org/apache/hadoop/hbase/io/ImmutableBytesWritable.java,74,this(ibw.get(), ibw.getOffset(), ibw.getSize());
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,140,final private static String PING_INTERVAL_NAME = "ipc.ping.interval";
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,141,final private static String SOCKET_TIMEOUT = "ipc.socket.timeout";
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,246,return conf.getInt(PING_INTERVAL_NAME, DEFAULT_PING_INTERVAL);
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,262,return conf.getInt(SOCKET_TIMEOUT, DEFAULT_SOCKET_TIMEOUT);
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1780,static int getRequiredDelimiterInReverse(final byte [] b,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1781,final int offset, final int length, final int delimiter) {
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1782,int index = getDelimiterInReverse(b, offset, length, delimiter);
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1783,if (index < 0) {
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1784,throw new IllegalArgumentException("hbase:meta key must have two '" + (char)delimiter + "' "
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1785,+ "delimiters and have the following format: '<table>,<key>,<etc>'");
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1787,return index;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1848,if (leftDelimiter < 0 && rightDelimiter >= 0) {
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1850,return -1;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1852,return 1;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1854,return 0;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1857,int result = Bytes.compareTo(left, loffset, leftDelimiter - loffset,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1858,right, roffset, rightDelimiter - roffset);
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1866,int leftFarDelimiter = getRequiredDelimiterInReverse(left, leftDelimiter,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1868,int rightFarDelimiter = getRequiredDelimiterInReverse(right,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1872,result = super.compareRows(left, leftDelimiter,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1873,leftFarDelimiter - leftDelimiter, right, rightDelimiter,
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,1874,rightFarDelimiter - rightDelimiter);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,27,import java.util.concurrent.Future;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,148,synchronized (procedures) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,149,Procedure oldProc = procedures.get(procName);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,150,if (oldProc != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,152,if (oldProc.completedLatch.getCount() != 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,153,LOG.warn("Procedure " + procName + " currently running.  Rejecting new request");
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,156,LOG.debug("Procedure " + procName + " was in running list but was completed.  Accepting new attempt.");
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,157,procedures.remove(procName);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,162,Future<Void> f = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,164,synchronized (procedures) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,165,this.procedures.put(procName, proc);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,166,f = this.pool.submit(proc);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,168,return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,170,LOG.warn("Procedure " + procName + " rejected by execution pool.  Propagating error and " +
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,173,this.procedures.remove(procName);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,178,if (f != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,179,f.cancel(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,211,synchronized(procedures) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,212,Procedure proc = procedures.get(procName);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,213,if (proc == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,214,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureCoordinator.java,216,proc.receive(reason);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,25,import java.util.concurrent.Future;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,142,Subprocedure rsub;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,143,synchronized (subprocs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,144,rsub = subprocs.get(procName);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,152,subprocs.remove(procName);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,158,Future<Void> future = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,160,synchronized (subprocs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,161,subprocs.put(procName, subproc);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,163,future = this.pool.submit(subproc);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,164,return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,166,synchronized (subprocs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,167,subprocs.remove(procName);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,174,if (future != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,175,future.cancel(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,174,public void cleanOldLogs(String key,
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,175,String id,
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,176,boolean queueRecovered) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,177,synchronized (this.hlogsById) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,178,SortedSet<String> hlogs = this.hlogsById.get(id);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,179,if (queueRecovered || hlogs.first().equals(key)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,180,return;
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,182,SortedSet<String> hlogSet = hlogs.headSet(key);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,183,for (String hlog : hlogSet) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,184,this.replicationQueues.removeLog(id, hlog);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,186,hlogSet.clear();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,516,for (String hlog : entry.getValue()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,117,this.sources = new ArrayList<ReplicationSourceInterface>();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSourceManager.java,123,this.oldsources = new ArrayList<ReplicationSourceInterface>();
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/FifoRpcScheduler.java,42,this.maxQueueLength = conf.getInt("ipc.server.max.callqueue.length",
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/FifoRpcScheduler.java,43,handlerCount * RpcServer.DEFAULT_MAX_CALLQUEUE_LENGTH_PER_HANDLER);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,513,private int backlogLength = conf.getInt("ipc.server.listen.queue.size", 128);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1846,this.maxQueueSize =
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1847,this.conf.getInt("ipc.server.max.callqueue.size", DEFAULT_MAX_CALLQUEUE_SIZE);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1848,this.readThreads = conf.getInt("ipc.server.read.threadpool.size", 10);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1849,this.maxIdleTime = 2*conf.getInt("ipc.client.connection.maxidletime", 1000);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1850,this.maxConnectionsToNuke = conf.getInt("ipc.client.kill.max", 10);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1851,this.thresholdIdleConnections = conf.getInt("ipc.client.idlethreshold", 4000);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1852,this.purgeTimeout = conf.getLong("ipc.client.call.purge.timeout",
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1853,2 * HConstants.DEFAULT_HBASE_RPC_TIMEOUT);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1862,this.tcpNoDelay = conf.getBoolean("ipc.server.tcpnodelay", true);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/RpcServer.java,1863,this.tcpKeepAlive = conf.getBoolean("ipc.server.tcpkeepalive", true);
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/SimpleRpcScheduler.java,69,int maxQueueLength = conf.getInt("ipc.server.max.callqueue.length",
hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/SimpleRpcScheduler.java,70,handlerCount * RpcServer.DEFAULT_MAX_CALLQUEUE_LENGTH_PER_HANDLER);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,521,this.maxBusyWaitDuration = conf.getLong("ipc.client.call.purge.timeout",
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,522,2 * HConstants.DEFAULT_HBASE_RPC_TIMEOUT);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,1051,if (tag.getType() != VisibilityUtils.VISIBILITY_TAG_TYPE) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,39,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterStatus.java,29,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterStatus.java,337,spec.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(rit.getKey())));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,46,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,1229,builder.setName(HBaseZeroCopyByteString.wrap(getName()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,1232,aBuilder.setFirst(HBaseZeroCopyByteString.wrap(e.getKey().get()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,1233,aBuilder.setSecond(HBaseZeroCopyByteString.wrap(e.getValue().get()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,32,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,845,builder.setStartKey(HBaseZeroCopyByteString.wrap(info.getStartKey()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,848,builder.setEndKey(HBaseZeroCopyByteString.wrap(info.getEndKey()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,37,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1435,aBuilder.setFirst(HBaseZeroCopyByteString.wrap(e.getKey().get()));
hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java,1436,aBuilder.setSecond(HBaseZeroCopyByteString.wrap(e.getValue().get()));
hbase-client/src/main/java/org/apache/hadoop/hbase/RegionTransition.java,20,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/RegionTransition.java,107,setEventTypeCode(type.getCode()).setRegionName(HBaseZeroCopyByteString.wrap(regionName)).
hbase-client/src/main/java/org/apache/hadoop/hbase/RegionTransition.java,110,if (payload != null) builder.setPayload(HBaseZeroCopyByteString.wrap(payload));
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/BigDecimalColumnInterpreter.java,25,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/BigDecimalColumnInterpreter.java,124,return builder.setBigdecimalMsg(HBaseZeroCopyByteString.wrap(Bytes.toBytes(t))).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java,24,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java,21,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java,56,if (value != null) builder.setValue(HBaseZeroCopyByteString.wrap(value));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java,23,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java,178,builder.setColumnOffset(HBaseZeroCopyByteString.wrap(this.columnOffset));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPrefixFilter.java,24,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPrefixFilter.java,98,if (this.prefix != null) builder.setPrefix(HBaseZeroCopyByteString.wrap(this.prefix));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnRangeFilter.java,25,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnRangeFilter.java,176,if (this.minColumn != null) builder.setMinColumn(HBaseZeroCopyByteString.wrap(this.minColumn));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnRangeFilter.java,178,if (this.maxColumn != null) builder.setMaxColumn(HBaseZeroCopyByteString.wrap(this.maxColumn));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/DependentColumnFilter.java,28,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/DependentColumnFilter.java,228,builder.setColumnFamily(HBaseZeroCopyByteString.wrap(this.columnFamily));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/DependentColumnFilter.java,231,builder.setColumnQualifier(HBaseZeroCopyByteString.wrap(this.columnQualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FirstKeyValueMatchingQualifiersFilter.java,22,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FirstKeyValueMatchingQualifiersFilter.java,92,if (qualifier != null) builder.addQualifiers(HBaseZeroCopyByteString.wrap(qualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,20,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,150,bbpBuilder.setFirst(HBaseZeroCopyByteString.wrap(fuzzyData.getFirst()));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java,151,bbpBuilder.setSecond(HBaseZeroCopyByteString.wrap(fuzzyData.getSecond()));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java,24,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java,89,if (this.stopRowKey != null) builder.setStopRowKey(HBaseZeroCopyByteString.wrap(this.stopRowKey));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/MultipleColumnPrefixFilter.java,21,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/MultipleColumnPrefixFilter.java,117,if (element != null) builder.addSortedPrefixes(HBaseZeroCopyByteString.wrap(element));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/PrefixFilter.java,23,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/PrefixFilter.java,94,if (this.prefix != null) builder.setPrefix(HBaseZeroCopyByteString.wrap(this.prefix));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,25,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,310,builder.setColumnFamily(HBaseZeroCopyByteString.wrap(this.columnFamily));
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java,313,builder.setColumnQualifier(HBaseZeroCopyByteString.wrap(this.columnQualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/MasterCoprocessorRpcChannel.java,23,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionCoprocessorRpcChannel.java,23,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,827,attributeBuilder.setValue(HBaseZeroCopyByteString.wrap(attribute.getValue()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,833,scanBuilder.setStartRow(HBaseZeroCopyByteString.wrap(startRow));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,837,scanBuilder.setStopRow(HBaseZeroCopyByteString.wrap(stopRow));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,846,columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family.getKey()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,851,columnBuilder.addQualifier(HBaseZeroCopyByteString.wrap(qualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,959,builder.setRow(HBaseZeroCopyByteString.wrap(get.getRow()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,978,attributeBuilder.setValue(HBaseZeroCopyByteString.wrap(attribute.getValue()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,987,columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family.getKey()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,991,columnBuilder.addQualifier(HBaseZeroCopyByteString.wrap(qualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1020,builder.setRow(HBaseZeroCopyByteString.wrap(increment.getRow()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1037,columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family.getKey()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1043,valueBuilder.setQualifier(HBaseZeroCopyByteString.wrap(
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1045,valueBuilder.setValue(HBaseZeroCopyByteString.wrap(
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1048,valueBuilder.setTags(HBaseZeroCopyByteString.wrap(kv.getTagsArray(),
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1061,attributeBuilder.setValue(HBaseZeroCopyByteString.wrap(attribute.getValue()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1102,columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family.getKey()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1105,valueBuilder.setQualifier(HBaseZeroCopyByteString.wrap(
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1107,valueBuilder.setValue(HBaseZeroCopyByteString.wrap(
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1171,builder.setRow(HBaseZeroCopyByteString.wrap(mutation.getRow()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1180,attributeBuilder.setValue(HBaseZeroCopyByteString.wrap(attribute.getValue()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1311,builder.setSerializedComparator(HBaseZeroCopyByteString.wrap(comparator.toByteArray()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1373,builder.setSerializedFilter(HBaseZeroCopyByteString.wrap(filter.toByteArray()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1862,builder.setFamily(HBaseZeroCopyByteString.wrap(tablePerm.getFamily()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1865,builder.setQualifier(HBaseZeroCopyByteString.wrap(tablePerm.getQualifier()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2233,builder.setIdentifier(HBaseZeroCopyByteString.wrap(token.getIdentifier()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2234,builder.setPassword(HBaseZeroCopyByteString.wrap(token.getPassword()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2331,kvbuilder.setRow(HBaseZeroCopyByteString.wrap(kv.getRowArray(), kv.getRowOffset(),
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2333,kvbuilder.setFamily(HBaseZeroCopyByteString.wrap(kv.getFamilyArray(),
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2335,kvbuilder.setQualifier(HBaseZeroCopyByteString.wrap(kv.getQualifierArray(),
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2339,kvbuilder.setValue(HBaseZeroCopyByteString.wrap(kv.getValueArray(), kv.getValueOffset(),
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,2498,.setQualifier(HBaseZeroCopyByteString.wrap(tableName.getQualifier())).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,23,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,137,columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,140,getBuilder.setRow(HBaseZeroCopyByteString.wrap(row));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,185,mutateBuilder.setRow(HBaseZeroCopyByteString.wrap(row));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,189,columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,191,valueBuilder.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(amount)));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,192,valueBuilder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,495,familyPathBuilder.setFamily(HBaseZeroCopyByteString.wrap(familyPath.getFirst()));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,663,builder.addFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,809,builder.setSplitPoint(HBaseZeroCopyByteString.wrap(splitPoint));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,849,builder.setFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,908,regionBuilder.setValue(HBaseZeroCopyByteString.wrap(value));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,929,builder.setRow(HBaseZeroCopyByteString.wrap(row));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,930,builder.setFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,931,builder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,963,builder.setColumnName(HBaseZeroCopyByteString.wrap(columnName));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,1103,builder.addSplitKeys(HBaseZeroCopyByteString.wrap(splitKey));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,1256,HBaseZeroCopyByteString.wrap(regionName)).build();
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,1311,permissionBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,1314,permissionBuilder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,1407,permissionBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,1410,permissionBuilder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/EncryptionUtil.java,29,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/EncryptionUtil.java,86,builder.setIv(HBaseZeroCopyByteString.wrap(iv));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/EncryptionUtil.java,90,builder.setHash(HBaseZeroCopyByteString.wrap(Encryption.hash128(keyBytes)));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/EncryptionUtil.java,94,builder.setData(HBaseZeroCopyByteString.wrap(out.toByteArray()));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,23,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,89,permissionBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,92,permissionBuilder.setQualifier(HBaseZeroCopyByteString.wrap(qual));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,153,permissionBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlClient.java,156,permissionBuilder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityClient.java,25,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityClient.java,89,newBuilder.setLabel(HBaseZeroCopyByteString.wrap(Bytes.toBytes(label)));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityClient.java,140,getAuthReqBuilder.setUser(HBaseZeroCopyByteString.wrap(Bytes.toBytes(user)));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityClient.java,182,setAuthReqBuilder.setUser(HBaseZeroCopyByteString.wrap(Bytes.toBytes(user)));
hbase-client/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityClient.java,185,setAuthReqBuilder.addAuth(HBaseZeroCopyByteString.wrap(Bytes.toBytes(auth)));
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,38,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java,1952,storeSequenceIdBuilder.setFamilyName(HBaseZeroCopyByteString.wrap(columnFamilyName));
hbase-server/src/main/java/org/apache/hadoop/hbase/codec/MessageCodec.java,24,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/codec/MessageCodec.java,47,builder.setRow(HBaseZeroCopyByteString.wrap(cell.getRowArray(), cell.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/codec/MessageCodec.java,49,builder.setFamily(HBaseZeroCopyByteString.wrap(cell.getFamilyArray(), cell.getFamilyOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/codec/MessageCodec.java,51,builder.setQualifier(HBaseZeroCopyByteString.wrap(cell.getQualifierArray(),
hbase-server/src/main/java/org/apache/hadoop/hbase/codec/MessageCodec.java,55,builder.setValue(HBaseZeroCopyByteString.wrap(cell.getValueArray(), cell.getValueOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java,27,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java,196,builder.setSplitkey(HBaseZeroCopyByteString.wrap(getSplitKey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java,29,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/FixedFileTrailer.java,208,builder.setEncryptionKey(HBaseZeroCopyByteString.wrap(encryptionKey));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,43,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,742,bbpBuilder.setFirst(HBaseZeroCopyByteString.wrap(e.getKey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java,743,bbpBuilder.setSecond(HBaseZeroCopyByteString.wrap(e.getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1237,return Bytes.toInt(dest, destOffset + size + BlockType.MAGIC_LENGTH) +
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFileBlock.java,1238,hdrSize;
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java,31,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java,94,HBaseZeroCopyByteString.wrap(key.getEncodedRegionName()));
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java,95,keyBuilder.setTableName(HBaseZeroCopyByteString.wrap(key.getTablename().getName()));
hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java,113,scopeBuilder.setFamily(HBaseZeroCopyByteString.wrap(scope.getKey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,53,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,197,import org.apache.hadoop.hbase.regionserver.snapshot.RegionServerSnapshotManager;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1333,regionSpecifier.setValue(HBaseZeroCopyByteString.wrap(name));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3997,builder.addRegionToFlush(HBaseZeroCopyByteString.wrap(region));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogKey.java,34,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogKey.java,446,builder.setEncodedRegionName(HBaseZeroCopyByteString.wrap(this.encodedRegionName));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogKey.java,447,builder.setTableName(HBaseZeroCopyByteString.wrap(this.tablename.getName()));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogWriter.java,27,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/SecureProtobufLogWriter.java,60,builder.setEncryptionKey(HBaseZeroCopyByteString.wrap(EncryptionUtil.wrapKey(conf,
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellModel.java,31,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellModel.java,187,builder.setColumn(HBaseZeroCopyByteString.wrap(getColumn()));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellModel.java,188,builder.setData(HBaseZeroCopyByteString.wrap(getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java,32,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java,117,rowBuilder.setKey(HBaseZeroCopyByteString.wrap(row.getKey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java,120,cellBuilder.setColumn(HBaseZeroCopyByteString.wrap(cell.getColumn()));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java,121,cellBuilder.setData(HBaseZeroCopyByteString.wrap(cell.getValue()));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java,762,builder.setStartRow(HBaseZeroCopyByteString.wrap(startRow));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java,765,builder.setEndRow(HBaseZeroCopyByteString.wrap(endRow));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java,768,builder.addColumns(HBaseZeroCopyByteString.wrap(column));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/StorageClusterStatusModel.java,32,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/StorageClusterStatusModel.java,724,regionBuilder.setName(HBaseZeroCopyByteString.wrap(region.name));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/TableInfoModel.java,31,import com.google.protobuf.HBaseZeroCopyByteString;
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/TableInfoModel.java,137,regionBuilder.setStartKey(HBaseZeroCopyByteString.wrap(aRegion.getStartKey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/TableInfoModel.java,138,regionBuilder.setEndKey(HBaseZeroCopyByteString.wrap(aRegion.getEndKey()));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,1242,response.addAuth(HBaseZeroCopyByteString.wrap(Bytes.toBytes(label)));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,59,visLabBuilder.setLabel(HBaseZeroCopyByteString.wrap(Bytes.toBytes(entry.getKey())));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityUtils.java,75,userAuthsBuilder.setUser(HBaseZeroCopyByteString.wrap(Bytes.toBytes(entry.getKey())));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,358,while (!futures.isEmpty()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,360,LOG.warn("Removing cancelled elements from taskPool");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java,361,futures.remove(taskPool.take());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1749,private int keepAliveZookeeperUserCount;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1770,keepAliveZookeeperUserCount++;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1781,--keepAliveZookeeperUserCount;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1782,if (keepAliveZookeeperUserCount <= 0 ){
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java,1862,keepAliveZookeeperUserCount = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3034,int rows = 1;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/BaseRowProcessor.java,41,public void postProcess(HRegion region, WALEdit walEdit) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,105,import org.apache.hadoop.hbase.filter.Filter;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4777,processor.postProcess(this, walEdit);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4791,List<KeyValue> mutations = new ArrayList<KeyValue>();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4815,for (KeyValue kv : mutations) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4816,kv.setMvccVersion(writeEntry.getWriteNumber());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4817,byte[] family = kv.getFamily();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4818,checkFamily(family);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4819,addedSize += stores.get(family).add(kv);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4849,for (KeyValue kv : mutations) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4850,stores.get(kv.getFamily()).rollback(kv);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4867,processor.postProcess(this, walEdit);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4883,final List<KeyValue> mutations,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MultiRowMutationProcessor.java,70,List<KeyValue> mutationKvs,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MultiRowMutationProcessor.java,74,for (Mutation m : mutations) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MultiRowMutationProcessor.java,85,throw new DoNotRetryIOException(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MultiRowMutationProcessor.java,89,for (List<Cell> cells: m.getFamilyCellMap().values()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MultiRowMutationProcessor.java,93,mutationKvs.add(kv);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MultiRowMutationProcessor.java,94,if (writeToWAL) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MultiRowMutationProcessor.java,95,walEdit.add(kv);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MultiRowMutationProcessor.java,125,public void postProcess(HRegion region, WALEdit walEdit) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RowProcessor.java,26,import org.apache.hadoop.hbase.KeyValue;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RowProcessor.java,86,List<KeyValue> mutations,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RowProcessor.java,103,void postProcess(HRegion region, WALEdit walEdit) throws IOException;
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/WALProtos.java,5226,new java.lang.String[] { "TableName", "EncodedRegionName", "FamilyName", "CompactionInput", "CompactionOutput", "StoreHomeDir", });
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4262,HLogSplitter.MutationReplay[] mArray = new HLogSplitter.MutationReplay[mutations.size()];
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4267,int i = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4268,for (HLogSplitter.MutationReplay m : mutations) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4274,mArray[i++] = m;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4280,return region.batchReplay(mArray);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,1440,skippedKVs.add(kv);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,1441,continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,1446,locateRegionAndRefreshLastFlushedSequenceId(hconn, table, kv.getRow(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,1476,Long maxStoreSeqId = maxStoreSequenceIds.get(kv.getFamily());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogUtil.java,266,WALEdit e = WALEdit.createCompaction(c);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java,257,public static WALEdit createCompaction(final CompactionDescriptor c) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java,259,KeyValue kv = new KeyValue(METAROW, METAFAMILY, COMPACTION, System.currentTimeMillis(), pbbytes);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java,268,public static CompactionDescriptor getCompaction(KeyValue kv) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEdit.java,269,if (kv.matchingRow(METAROW) && kv.matchingColumn(METAFAMILY, COMPACTION)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/WALEditsReplaySink.java,233,if (kv.matchingFamily(WALEdit.METAFAMILY)) continue;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,926,movedRegionsCleaner.stop("Region Server stopping");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,992,this.rpcClient.stop();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,993,this.leases.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1010,this.zooKeeper.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1857,Threads.shutdown(this.compactionChecker.getThread());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1858,Threads.shutdown(this.periodicFlusher.getThread());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1859,this.cacheFlusher.join();
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/HFileBlockDefaultEncodingContext.java,209,Encryption.incrementIv(iv);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,298,result = rowEndKeyComparator.compare(left.getEndKey(), right.getEndKey());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/CatalogJanitor.java,300,return -result; // Flip the result so parent comes first.
hbase-server/src/main/java/org/apache/hadoop/hbase/migration/NamespaceUpgrade.java,505,return -left.compareTo(right);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSTableDescriptors.java,381,return -left.compareTo(right);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/StripeCompactionPolicy.java,269,return stripePolicy.applyCompactionPolicy(sfs, isOffpeak, false, minFilesLocal, maxFilesLocal);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,605,List<String> superUsers = getSystemAndSuperUsers();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,606,for (String superUser : superUsers) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,1028,List<String> superUsers = getSystemAndSuperUsers();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,1030,return superUsers.contains(activeUser.getShortName());
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/CacheConfig.java,409,LruBlockCache lruCache = new LruBlockCache(lruCacheSize, blockSize);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java,461,byte[] bytes = getAttribute(AccessControlConstants.OP_ATTRIBUTE_ACL_STRATEGY);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java,462,if (bytes != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java,463,return Bytes.equals(bytes, AccessControlConstants.OP_ATTRIBUTE_ACL_STRATEGY_CELL_FIRST);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java,474,if (cellFirstStrategy) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java,475,setAttribute(AccessControlConstants.OP_ATTRIBUTE_ACL_STRATEGY,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Mutation.java,476,AccessControlConstants.OP_ATTRIBUTE_ACL_STRATEGY_CELL_FIRST);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Query.java,111,byte[] bytes = getAttribute(AccessControlConstants.OP_ATTRIBUTE_ACL_STRATEGY);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Query.java,112,if (bytes != null) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Query.java,113,return Bytes.equals(bytes, AccessControlConstants.OP_ATTRIBUTE_ACL_STRATEGY_CELL_FIRST);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Query.java,124,if (cellFirstStrategy) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Query.java,125,setAttribute(AccessControlConstants.OP_ATTRIBUTE_ACL_STRATEGY,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Query.java,126,AccessControlConstants.OP_ATTRIBUTE_ACL_STRATEGY_CELL_FIRST);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,237,if (LOG.isDebugEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,238,LOG.debug("RegionServer " + sn +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,241,existingValue + ") for region " +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,242,Bytes.toString(entry.getKey()) + " Ignoring.");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,671,this.completeSequenceId = nextSeqid;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1497,if(this.completeSequenceId + this.flushPerChanges < this.sequenceId.get()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1111,valueBuilder.setTags(ByteString.copyFrom(CellUtil.getTagArray(kv)));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,688,byte[] tags = CellUtil.getTagArray(cell);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,689,Iterator<Tag> tagsIterator = CellUtil.tagsIterator(tags, 0, tags.length);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,80,import org.apache.hadoop.hbase.regionserver.StoreFile;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,605,byte[] tagBytes = CellUtil.getTagArray(cell);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,606,Iterator<Tag> tagIterator = CellUtil.tagsIterator(tagBytes, 0, tagBytes.length);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1306,byte[] tagBytes = CellUtil.getTagArray(oldCell);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1307,Iterator<Tag> tagIterator = CellUtil.tagsIterator(tagBytes, 0, tagBytes.length);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/ColumnDescriptor.java,197,this.timeToLive = -1;
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/generated/ColumnDescriptor.java,273,this.timeToLive = -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1119,public void preCompactSelection(final ObserverContext<RegionCoprocessorEnvironment> e,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1120,final Store store, final List<StoreFile> candidates) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1121,requirePermission("compact", getTableName(e.getEnvironment()), null, null, Action.ADMIN);
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,1059,return ServerName.valueOf(hostAndPort,
hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java,1060,Bytes.toLong(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength()));
hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java,834,while (currentNumberOfTask == tasksDone.get()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java,835,try {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java,836,synchronized (this.tasksDone) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java,840,throw new InterruptedIOException("#" + id + ", interrupted." +
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,29,import java.io.InterruptedIOException;
hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/bucket/BucketCache.java,327,cacheWaitSignals[queueNum].wait(DEFAULT_CACHE_WAIT_TIME);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,444,while (!onlineServers.isEmpty()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,461,onlineServers.wait(100);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/LogRoller.java,78,rollLog.wait(this.threadWakeFrequency);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/handler/OpenRegionHandler.java,269,signaller.wait(period);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,2135,this.writeRequestsCount.increment();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,4195,requestCount.add(mutations.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/client/TableSnapshotScanner.java,181,result = currentRegionScanner.next();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/TableSnapshotScanner.java,182,if (result != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/client/TableSnapshotScanner.java,183,return result;
hbase-server/src/main/java/org/apache/hadoop/hbase/client/TableSnapshotScanner.java,185,currentRegionScanner.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/client/TableSnapshotScanner.java,186,currentRegionScanner = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,4769,processor.preProcess(this, walEdit);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableMapReduceUtil.java,355,HBaseConfiguration.addHbaseResources(job.getConfiguration());
hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java,528,res = createCaller(callable).callWithoutRetries(callable);
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java,284,transportFactory = new TFramedTransport.Factory();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,128,private static TTransportFactory getTTransportFactory(boolean framed) {
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,131,return new TFramedTransport.Factory();
hbase-thrift/src/main/java/org/apache/hadoop/hbase/thrift2/ThriftServer.java,277,TTransportFactory transportFactory = getTTransportFactory(framed);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureUtil.java,187,return path.startsWith(this.acquiredZnode) && !path.equals(acquiredZnode);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ZKProcedureUtil.java,201,return path.startsWith(this.reachedZnode) && !path.equals(reachedZnode);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1876,this.writeRequestsCount.increment();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1973,this.writeRequestsCount.increment();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/AsyncProcess.java,642,if (manageError(action.getOriginalIndex(), action.getAction(), true, t, location)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/lock/ZKInterProcessLockBase.java,249,return suffix.startsWith(WRITE_LOCK_CHILD_NODE_PREFIX);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1315,return addConfig(resp, "fs.default.name");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,266,status = TaskMonitor.get().createStatus(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,286,status.markComplete("Was nothing to split in log file");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,357,LOG.info("Finishing writing output logs and closing down.");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,358,if (outputSinkStarted) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,359,progress_failed = outputSink.finishWritingAndClose() == null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,361,String msg = "Processed " + editsCount + " edits across "
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,362,+ outputSink.getNumberOfRecoveredRegions() + " regions; log file=" + logPath
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,363,+ " is corrupted = " + isCorrupted + " progress failed = " + progress_failed;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,364,LOG.info(msg);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogSplitter.java,365,status.markComplete(msg);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,46,import org.apache.hadoop.hbase.catalog.MetaReader;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,138,if (!MetaReader.tableExists(master.getCatalogTracker(), ACL_TABLE_NAME)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlLists.java,139,master.createTable(ACL_TABLEDESC, null);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,707,HTableDescriptor desc, HRegionInfo[] regions) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,708,if (!AccessControlLists.isAclTable(desc)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,709,String owner = desc.getOwnerString();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,711,if (owner == null) owner = getActiveUser().getShortName();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,712,UserPermission userperm = new UserPermission(Bytes.toBytes(owner), desc.getTableName(), null,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,713,Action.values());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,714,AccessControlLists.addUserPermission(c.getEnvironment().getConfiguration(), userperm);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,720,HTableDescriptor desc, HRegionInfo[] regions) throws IOException {}
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,943,AccessControlLists.init(ctx.getEnvironment().getMasterServices());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java,102,return newCounter(Interns.info(name, desc), iVal);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java,124,return newCounter(Interns.info(name, desc), iVal);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java,146,return newGauge(Interns.info(name, desc), iVal);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java,167,return newGauge(Interns.info(name, desc), iVal);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java,345,return tag(Interns.info(name, description), value, override);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java,425,MutableGaugeLong newGauge = new MutableGaugeLong(Interns.info(gaugeName, ""),
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java,457,new MutableCounterLong(Interns.info(counterName, ""), potentialStartingValue);
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/DynamicMetricsRegistry.java,478,new MutableHistogram(Interns.info(histoName, ""));
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/MiniZooKeeperCluster.java,155,recreateDir(dir);
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/MiniZooKeeperCluster.java,205,private void recreateDir(File dir) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/MiniZooKeeperCluster.java,206,if (dir.exists()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/MiniZooKeeperCluster.java,207,if(!FileUtil.fullyDelete(dir)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/MiniZooKeeperCluster.java,208,throw new IOException("Could not delete zk base directory: " + dir);
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/MiniZooKeeperCluster.java,212,dir.mkdirs();
hbase-prefix-tree/src/main/java/org/apache/hadoop/hbase/codec/prefixtree/decode/PrefixTreeArrayScanner.java,423,return CellComparator.compareStatic(this, key);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,469,cur.getRowLength(), key.getBuffer(), key.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1725,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1726,if (this.rsHost != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1727,this.rsHost.preStop(msg);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1729,this.stopped = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1730,LOG.info("STOPPED: " + msg);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1732,sleeper.skipSleepCycle();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1734,LOG.warn("The region server did not stop", exp);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,117,int handlerCount = conf.getInt("hbase.hstore.flusher.count", 1);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/FastDiffDeltaEncoder.java,392,return ByteBuffer.wrap(block.array(), pos, keyLength).slice();
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/PrefixKeyDeltaEncoder.java,157,return ByteBuffer.wrap(block.array(), pos, keyLength).slice();
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,766,saslRpcClient = new HBaseSaslRpcClient(authMethod, token, serverPrincipal, fallbackAllowed);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,32,import javax.security.sasl.Sasl;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,49,public static enum QualityOfProtection {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,50,AUTHENTICATION("auth"),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,51,INTEGRITY("auth-int"),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,52,PRIVACY("auth-conf");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,54,public final String saslQop;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,56,private QualityOfProtection(String saslQop) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,57,this.saslQop = saslQop;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,60,public String getSaslQop() {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,61,return saslQop;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,66,QualityOfProtection saslQOP = QualityOfProtection.AUTHENTICATION;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,67,String rpcProtection = conf.get("hbase.rpc.protection",
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,68,QualityOfProtection.AUTHENTICATION.name().toLowerCase());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,70,.equals(rpcProtection)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,71,saslQOP = QualityOfProtection.INTEGRITY;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,73,rpcProtection)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,74,saslQOP = QualityOfProtection.PRIVACY;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,77,SaslUtil.SASL_PROPS.put(Sasl.QOP, saslQOP.getSaslQop());
hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBaseSaslRpcServer.java,78,SaslUtil.SASL_PROPS.put(Sasl.SERVER_AUTH, "true");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/KeyValueSortReducer.java,54,if (index > 0 && index % 100 == 0) context.setStatus("Wrote " + index);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,48,import org.apache.hadoop.hbase.HConstants;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,126,private long lastNodeCreateTime = Long.MAX_VALUE;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,373,LOG.warn("returning success without actually splitting and " +
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,709,lastNodeCreateTime = EnvironmentEdgeManager.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,724,new GetDataAsyncCallback(), retry_count);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,732,new GetDataAsyncCallback(), Long.valueOf(-1) /* retry count */);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,978,lastNodeCreateTime = EnvironmentEdgeManager.currentTimeMillis();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,1423,((EnvironmentEdgeManager.currentTimeMillis() - lastNodeCreateTime) >
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,1535,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,1536,getDataSetWatchSuccess(path, null, Integer.MIN_VALUE);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/SplitLogManager.java,1538,LOG.warn("Deserialization problem", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java,1148,int idx = (int)this.lastWrittenTxid % asyncSyncers.length;
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,249,LOG.error("Propagating foreign exception to subprocedure " + sub.getName(), ee);
hbase-server/src/main/java/org/apache/hadoop/hbase/procedure/ProcedureMember.java,250,sub.monitor.receive(ee);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/MetricsSource.java,144,public void shipBatch(long batchSize) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,680,this.metrics.shipBatch(this.currentNbOperations);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,676,System.err.println("  -no-checksum-verify     Do not verify checksum.");
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,32,import org.apache.hadoop.hbase.HRegionInfo;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,33,import org.apache.hadoop.hbase.io.Reference;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,34,import org.apache.hadoop.hbase.regionserver.HRegion;
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSVisitor.java,36,import org.apache.hadoop.hbase.util.FSUtils;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,714,long storeSeqIdForReplay = store.getMaxSequenceId(false);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,716,storeSeqIdForReplay);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,718,long storeSeqIdForAssignment = store.getMaxSequenceId(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,719,if (maxSeqId == -1 || storeSeqIdForAssignment > maxSeqId) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,720,maxSeqId = storeSeqIdForAssignment;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1431,public boolean flushcache() throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1434,LOG.debug("Skipping flush on " + this + " because closing");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1435,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1443,LOG.debug("Skipping flush on " + this + " because closed");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1444,status.abort("Skipped: closed");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1445,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1464,status.abort("Not flushing since "
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1466,: "writes not enabled"));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1467,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1471,boolean result = internalFlushcache(status);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1479,return result;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1568,protected boolean internalFlushcache(
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1579,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1614,status.setStatus("Flush will not be started for ["
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1615,+ this.getRegionInfo().getEncodedName() + "] - because the WAL is closing.");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1616,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1731,return compactionRequested;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3542,store.bulkLoadHFile(finalPath, assignSeqId ? this.sequenceId.incrementAndGet() : -1);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3749,boolean result = region.flushcache();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,424,long getMaxSequenceId(boolean includeBulkFiles) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,425,return StoreFile.getMaxSequenceIdInList(this.getStorefiles(), includeBulkFiles);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,456,boolean shouldCompact = region.flushcache();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,304,public static long getMaxSequenceIdInList(Collection<StoreFile> sfs,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,305,boolean includeBulkLoadedFiles) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,308,if (includeBulkLoadedFiles || !sf.isBulkLoadResult()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,309,max = Math.max(max, sf.getMaxSequenceId());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3743,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,467,private void requireCoveringPermission(String request, RegionCoprocessorEnvironment e,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,469,boolean allVersions, Action...actions) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,481,results[i] = permissionGranted(request, user, actions[i], e, familyMap);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,507,if (allVersions) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,556,AuthResult authResult = AuthResult.deny(request, "Insufficient permissions",
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,581,AuthResult authResult = AuthResult.deny(request, "Insufficient permissions",
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,592,logResult(AuthResult.allow(request, "Permission granted", user, action,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1129,requireCoveringPermission("getClosestRowBefore", c.getEnvironment(), row,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1130,makeFamilyMap(family, null), HConstants.LATEST_TIMESTAMP, false, Permission.Action.READ);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1156,requireCoveringPermission("put", c.getEnvironment(), put.getRow(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1157,put.getFamilyCellMap(), put.getTimeStamp(), false, Permission.Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1189,requireCoveringPermission("delete", c.getEnvironment(), delete.getRow(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1190,delete.getFamilyCellMap(), delete.getTimeStamp(), true, Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1209,requireCoveringPermission("checkAndPut", c.getEnvironment(), row,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1210,makeFamilyMap(family, qualifier), HConstants.LATEST_TIMESTAMP, false,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1211,Action.READ, Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1236,requireCoveringPermission("checkAndDelete", c.getEnvironment(), row,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1237,makeFamilyMap(family, qualifier), HConstants.LATEST_TIMESTAMP, false,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1238,Action.READ, Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1249,requireCoveringPermission("incrementColumnValue", c.getEnvironment(), row,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1250,makeFamilyMap(family, qualifier), HConstants.LATEST_TIMESTAMP, false,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1251,Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1259,requireCoveringPermission("append", c.getEnvironment(), append.getRow(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1260,append.getFamilyCellMap(), append.getTimeStamp(), false,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1261,Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1279,requireCoveringPermission("increment", c.getEnvironment(), increment.getRow(),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1280,increment.getFamilyCellMap(), increment.getTimeRange().getMax(), false,
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,1281,Action.WRITE);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,93,private static final String FULL_RWX_PERMISSIONS = "777";
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,296,.invoke(backingFs, path, FsPermission.getDefault(), true,
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,369,return FsPermission.getDefault();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,378,return FsPermission.getDefault();
hbase-server/src/main/java/org/apache/hadoop/hbase/util/FSUtils.java,381,return FsPermission.getDefault();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,494,StoreFile storeFile = createStoreFileAndReader(storeFileInfo.getPath());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1083,sfs = new ArrayList<StoreFile>();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1107,List<StoreFile> sfs = new ArrayList<StoreFile>();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1136,List<Path> inputPaths = new ArrayList<Path>();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1217,List<String> compactionOutputs = compaction.getCompactionOutputList();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1219,List<StoreFile> outputStoreFiles = new ArrayList<StoreFile>(compactionOutputs.size());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1220,for (String compactionOutput : compactionOutputs) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1222,boolean found = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1223,Path outputPath = new Path(fs.getStoreDir(family.getNameAsString()), compactionOutput);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1224,outputPath = outputPath.makeQualified(fs.getFileSystem());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1225,for (StoreFile sf : this.getStorefiles()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1226,if (sf.getPath().makeQualified(sf.getPath().getFileSystem(conf)).equals(outputPath)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1227,found = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1228,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1231,if (!found) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1232,if (getFileSystem().exists(outputPath)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1233,outputStoreFiles.add(createStoreFileAndReader(outputPath));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1240,Path inputPath = new Path(fs.getStoreDir(family.getNameAsString()), compactionInput);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1241,inputPath = inputPath.makeQualified(fs.getFileSystem());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1248,if (inputPaths.contains(sf.getPath().makeQualified(fs.getFileSystem()))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,1253,this.replaceStoreFiles(inputStoreFiles, outputStoreFiles);
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,54,private List<TaskAndWeakRefPair> tasks =
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,55,Lists.newArrayList();
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,77,if (tasks.size() > MAX_TASKS) {
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,78,purgeExpiredTasks();
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,92,if (tasks.size() > MAX_TASKS) {
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,93,purgeExpiredTasks();
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,99,int size = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,118,size++;
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,122,if (size > MAX_TASKS) {
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,123,LOG.warn("Too many actions in action monitor! Purging some.");
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,124,tasks = tasks.subList(size - MAX_TASKS, size);
hbase-server/src/main/java/org/apache/hadoop/hbase/monitoring/TaskMonitor.java,136,for (TaskAndWeakRefPair pair : tasks) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java,185,if (methodName.equals("scan")) { // scanner methods...
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/RowCounter.java,128,String [] fields = columnName.split(":");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/RowCounter.java,129,if(fields.length == 1) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/RowCounter.java,130,scan.addFamily(Bytes.toBytes(fields[0]));
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/RowCounter.java,132,byte[] qualifier = Bytes.toBytes(fields[1]);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/RowCounter.java,133,qualifiers.add(qualifier);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/RowCounter.java,134,scan.addColumn(Bytes.toBytes(fields[0]), qualifier);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,37,import org.apache.hadoop.hbase.util.Bytes;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,200,&& Bytes.compareTo(cur.getBuffer(), cur.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,433,|| Bytes.compareTo(cur.getBuffer(), cur.getRowOffset(),
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java,468,|| Bytes.compareTo(cur.getBuffer(), cur.getRowOffset(),
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Delete.java,183,this.deleteFamily(family, HConstants.LATEST_TIMESTAMP);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Delete.java,240,this.deleteColumns(family, qualifier, HConstants.LATEST_TIMESTAMP);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Delete.java,277,this.deleteColumn(family, qualifier, HConstants.LATEST_TIMESTAMP);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessControlFilter.java,57,boolean cellFirstStrategy) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,28,import com.google.protobuf.Message;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,29,import com.google.protobuf.RpcCallback;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,30,import com.google.protobuf.RpcController;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,31,import com.google.protobuf.Service;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,40,import org.apache.hadoop.hbase.HConstants;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,41,import org.apache.hadoop.hbase.TableName;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,61,import org.apache.hadoop.hbase.client.Durability;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,62,import org.apache.hadoop.hbase.coprocessor.*;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,66,import org.apache.hadoop.hbase.filter.ByteArrayComparable;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,78,import org.apache.hadoop.hbase.regionserver.Store;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,87,import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,97,import static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.AccessControlService;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,640,new AccessControlFilter(authManager, activeUser, tableName, cellFirstStrategy),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,642,: new AccessControlFilter(authManager, activeUser, tableName, cellFirstStrategy);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1706,&& t instanceof RegionAlreadyInTransitionException) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1708,LOG.debug("update " + state + " the timestamp.");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1709,state.updateTimestampToNow();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1710,if (maxWaitTime < 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1712,+ this.server.getConfiguration().getLong(ALREADY_IN_TRANSITION_WAITTIME,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1713,DEFAULT_ALREADY_IN_TRANSITION_WAITTIME);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1715,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1720,Thread.sleep(100);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/AssignmentManager.java,1727,if (!tomActivated) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.java,205,return StringUtils.humanReadableInt(sf.getReader().length());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.java,223,sz += sf.getReader().length();
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,69,Configuration conf = HBaseConfiguration.create();
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,70,String hostport = new ZooKeeperMainServer().parse(conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,71,String[] newArgs = args;
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,72,if (hostport != null && hostport.length() > 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,73,newArgs = new String[args.length + 2];
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,74,System.arraycopy(args, 0, newArgs, 2, args.length);
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,75,newArgs[0] = "-server";
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,76,newArgs[1] = hostport;
hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/ZooKeeperMainServer.java,78,ZooKeeperMain.main(newArgs);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java,338,if (retainDeletesInOutput
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java,340,|| kv.getMvccVersion() > maxReadPointToTrackVersions) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FilterWrapper.java,34,import org.apache.zookeeper.KeeperException.UnimplementedException;
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FilterWrapper.java,163,if (!kvs.isEmpty() && this.filter.filterRow()) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FilterWrapper.java,164,kvs.clear();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3602,private final Filter filter;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3886,filter.filterRowCells(results);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3889,if (isEmptyRow || filterRow()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,975,return new VisibilityLabelFilter(new BitSet(0));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityController.java,995,visibilityLabelFilter = new VisibilityLabelFilter(bs);
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelFilter.java,39,private BitSet authLabels;
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/VisibilityLabelFilter.java,41,public VisibilityLabelFilter(BitSet authLabels) {
hbase-client/src/main/java/org/apache/hadoop/hbase/filter/NullComparator.java,59,throw new UnsupportedOperationException();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,530,for (Cell cell: list) {
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,531,get.addColumn(col, CellUtil.cloneQualifier(cell));
hbase-server/src/main/java/org/apache/hadoop/hbase/security/visibility/DefaultScanLabelGenerator.java,61,String userName = user.getName();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,620,HRegionLocation firstMetaServer = getFirstMetaServerForTable(tableName);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,674,if(tries == numRetries - 1) {           // no more tries left
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2653,throw new RegionOpeningException("Region " + regionNameStr + " is opening");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2655,throw new NotServingRegionException("Region " + regionNameStr + " is not online");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3048,seqid = replayRecoveredEdits(edits, maxSeqIdInStores, reporter);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,3209,currentEditSeqId = key.getLogSeqNum();
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,506,get.setMaxResultsPerColumnFamily(1); // Hold down memory use on wide rows
hbase-server/src/main/java/org/apache/hadoop/hbase/security/access/AccessController.java,548,more = scanner.next(cells);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,600,Configuration conf = getConf();
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,602,FileSystem inputFs = FileSystem.get(conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,482,private static Path[] createInputFiles(final Configuration conf,
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,485,Path inputFolderPath = getInputFolderPath(conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,538,for (Path path: createInputFiles(conf, snapshotFiles, mappers)) {
hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java,204,c = (0xff & a.getTypeByte()) - (0xff & b.getTypeByte());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java,115,if (topScanner == null ||
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/KeyValueHeap.java,116,this.comparator.compare(kvNext, topScanner.peek()) >= 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,737,this.errorCode = INIT_ERROR_EXIT_CODE;
hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java,744,this.errorCode = INIT_ERROR_EXIT_CODE;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java,187,FileStatus status;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java,189,status = fs.getFileStatus(snapshotDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java,197,if (status.getModificationTime() <= lastModifiedTime) return;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java,205,this.lastModifiedTime = status.getModificationTime();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,40,import org.apache.hadoop.hbase.TableName;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,48,import org.apache.hadoop.hbase.NamespaceDescriptor;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,64,import org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,65,import org.apache.hadoop.hbase.snapshot.HBaseSnapshotException;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,67,import org.apache.hadoop.hbase.snapshot.RestoreSnapshotException;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,68,import org.apache.hadoop.hbase.snapshot.SnapshotCreationException;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,69,import org.apache.hadoop.hbase.snapshot.UnknownSnapshotException;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,1373,RequestConverter.buildCloseRegionRequest(encodedRegionName, false);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java,1397,ProtobufUtil.closeRegion(admin, hri.getRegionName(), false);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1573,final byte[] regionName, final boolean transitionInZK) throws IOException {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1575,RequestConverter.buildCloseRegionRequest(regionName, transitionInZK);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1598,RequestConverter.buildCloseRegionRequest(
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1616,final HRegionInfo region) throws IOException {
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,1618,RequestConverter.buildOpenRegionRequest(region, -1, null);
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,26,import org.apache.hadoop.hbase.HConstants;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,27,import org.apache.hadoop.hbase.TableName;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,718,public static OpenRegionRequest buildOpenRegionRequest(
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,751,public static CloseRegionRequest buildCloseRegionRequest(
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,761,public static CloseRegionRequest buildCloseRegionRequest(
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java,784,buildCloseRegionRequest(final String encodedRegionName,
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java,21039,new java.lang.String[] { "OpenInfo", });
hbase-protocol/src/main/java/org/apache/hadoop/hbase/protobuf/generated/AdminProtos.java,21057,new java.lang.String[] { "Region", "VersionOfClosingNode", "TransitionInZK", "DestinationServer", });
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,631,RequestConverter.buildOpenRegionRequest(region, versionOfOfflineNode, favoredNodes);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java,693,return ProtobufUtil.closeRegion(admin, region.getRegionName(),
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsckRepair.java,152,ProtobufUtil.closeRegion(rs, region.getRegionName(), false);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/BaseLoadBalancer.java,393,if (!(cs.getMinLoad() > ceiling || cs.getMaxLoad() < floor)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/ClusterLoadState.java,78,int getMinLoad() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/ClusterLoadState.java,82,int getMaxLoad() {
hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java,89,c = (0xff & a.getTypeByte()) - (0xff & b.getTypeByte());
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ShutdownHook.java,201,if (!fsShutdownHooks.containsKey(hdfsClientFinalizer) &&
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ShutdownHook.java,202,!ShutdownHookManager.deleteShutdownHook(hdfsClientFinalizer)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ShutdownHook.java,203,throw new RuntimeException("Failed suppression of fs shutdown hook: " +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ShutdownHook.java,204,hdfsClientFinalizer);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,288,private MasterAddressTracker masterAddressManager;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,577,this.masterAddressManager = new MasterAddressTracker(getZooKeeperWatcher(), this);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,578,this.masterAddressManager.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1151,public MasterAddressTracker getMasterAddressManager() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1152,return this.masterAddressManager;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,426,private MasterAddressTracker masterAddressManager;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,723,this.masterAddressManager = new MasterAddressTracker(this.zooKeeper, this);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,724,this.masterAddressManager.start();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,725,blockAndCheckIfStopped(this.masterAddressManager);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1552,public MasterAddressTracker getMasterAddressManager() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1553,return this.masterAddressManager;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1921,sn = this.masterAddressManager.getMasterAddress(refresh);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1033,boolean wasFlushing;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1038,wasFlushing = writestate.flushing;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1045,if (!abort && !wasFlushing && worthPreFlushing()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1048,internalFlushcache(status);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1064,internalFlushcache(status);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1603,long flushsize = this.memstoreSize.get();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1683,this.addAndGetGlobalMemstoreSize(-flushsize);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1721,StringUtils.humanReadableInt(flushsize) + "/" + flushsize +
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,1729,this.recentFlushes.add(new Pair<Long,Long>(time/1000, flushsize));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,804,LOG.warn("Failed flushing store file, retring num=" + i, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java,986,ClassSize.OBJECT + (10 * ClassSize.REFERENCE) + Bytes.SIZEOF_LONG);
hbase-server/src/main/java/org/apache/hadoop/hbase/executor/EventHandler.java,131,LOG.error("Caught throwable while processing event " + eventType, t);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSStatusServlet.java,56,tmpl.render(resp.getWriter(), hrs);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2757,long scannerId = -1;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2758,while (true) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2759,scannerId = Math.abs(rand.nextLong() << 24) ^ startcode;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2760,String scannerName = String.valueOf(scannerId);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2761,RegionScannerHolder existing =
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2762,scanners.putIfAbsent(scannerName, new RegionScannerHolder(s, r));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2763,if (existing == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2764,this.leases.createLease(scannerName, this.scannerLeaseTimeoutPeriod,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2765,new ScannerListener(scannerName));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2766,break;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,546,int idx = 0;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,548,while (idx < regionLocations.length && regionLocations[idx] == thisServer) {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,549,idx++;
hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java,2762,if (length == 0) return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ExplicitColumnTracker.java,81,int maxVersions, long oldestUnexpiredTS) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ExplicitColumnTracker.java,139,return ScanQueryMatcher.MatchCode.SEEK_NEXT_COL;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java,188,this.columns = new ExplicitColumnTracker(columns,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/ScanQueryMatcher.java,189,scanInfo.getMinVersions(), maxVersions, oldestUnexpiredTS);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,52,import org.apache.hadoop.hbase.util.Threads;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionFileSystem.java,405,if (!srcFs.getUri().equals(desFs.getUri())) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.java,226,scan.setIsolationLevel(IsolationLevel.READ_UNCOMMITTED); // region is immutable, this should be fine,
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,733,double min = cluster.numRegions / cluster.numServers;
hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RpcClient.java,923,if (t instanceof IOException) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/HTable.java,326,this.connection.locateRegion(tableName, HConstants.EMPTY_START_ROW);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,32,import org.apache.hadoop.conf.Configuration;
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,68,public RpcRetryingCaller(Configuration conf) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,69,this.pause = conf.getLong(HConstants.HBASE_CLIENT_PAUSE,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,70,HConstants.DEFAULT_HBASE_CLIENT_PAUSE);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,71,this.retries =
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,72,conf.getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,73,HConstants.DEFAULT_HBASE_CLIENT_RETRIES_NUMBER);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,74,this.callTimeout = conf.getInt(
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,75,HConstants.HBASE_CLIENT_OPERATION_TIMEOUT,
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCaller.java,76,HConstants.DEFAULT_HBASE_CLIENT_OPERATION_TIMEOUT);
hbase-client/src/main/java/org/apache/hadoop/hbase/client/RpcRetryingCallerFactory.java,37,return new RpcRetryingCaller<T>(conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,3208,scanners.remove(scannerName);
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,3793,out.println("   -sidelineCorruptHfiles  Quarantine corrupted HFiles.  implies -checkCorruptHfiles");
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,533,Path path = new Path(getConf().get(HConstants.HBASE_DIR) + "/"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,534,+ Bytes.toString(regionInfo.getTable().getName()) + "/"
hbase-server/src/main/java/org/apache/hadoop/hbase/util/HBaseFsck.java,535,+ regionInfo.getEncodedName() + "/");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,638,getReader().timeRangeTracker.minimumTimestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFile.java,1508,return timeRangeTracker == null ? Long.MAX_VALUE : timeRangeTracker.maximumTimestamp;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,137,public void write(final DataOutput out) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,142,public void readFields(final DataInput in) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,148,public String toString() {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,87,public enum Counter { MISSING_FILES, COPY_FAILED, BYTES_EXPECTED, BYTES_COPIED };
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,107,public void setup(Context context) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,123,throw new RuntimeException("Could not get the input FileSystem with root=" + inputRoot, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,129,throw new RuntimeException("Could not get the output FileSystem with root="+ outputRoot, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,171,FSDataInputStream in = openSourceFile(inputPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,172,if (in == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,173,context.getCounter(Counter.MISSING_FILES).increment(1);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,177,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,179,FileStatus inputStat = getFileStatus(inputFs, inputPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,183,if (outputFs.exists(outputPath)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,184,FileStatus outputStat = outputFs.getFileStatus(outputPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,185,if (sameFile(inputStat, outputStat)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,186,LOG.info("Skip copy " + inputPath + " to " + outputPath + ", same file.");
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,229,LOG.error("Unable to set the permission for file=" + path, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,233,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,234,String user = (filesUser != null) ? filesUser : refStat.getOwner();
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,235,String group = (filesGroup != null) ? filesGroup : refStat.getGroup();
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,236,if (!(user.equals(stat.getOwner()) && group.equals(stat.getGroup()))) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,237,outputFs.setOwner(path, user, group);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,240,LOG.error("Unable to set the owner/group for file=" + path, e);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,241,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,255,byte[] buffer = new byte[BUFFER_SIZE];
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,269,totalBytesWritten/(float)inputFileSize) +
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,278,totalBytesWritten/(float)inputFileSize) +
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,297,private FSDataInputStream openSourceFile(final Path path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,309,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,313,private FileStatus getFileStatus(final FileSystem fs, final Path path) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,317,return link.getFileStatus(fs);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,321,return new HLogLink(inputRoot, serverName, logName).getFileStatus(fs);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,323,return fs.getFileStatus(path);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,325,LOG.warn("Unable to get the status for file=" + path);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,326,return null;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,551,public int run(String[] args) throws Exception {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,558,int mappers = getConf().getInt("mapreduce.job.maps", 1);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,618,System.err.println("A snapshot with the same name '" + snapshotName + "' may be in-progress");
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,619,System.err.println("Please check " + snapshotTmpDir + ". If the snapshot has completed, ");
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,621,return 1;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,633,System.err.println("Failed to copy the snapshot directory: from=" + snapshotDir +
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,635,e.printStackTrace(System.err);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,636,return 1;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,647,filesUser, filesGroup, filesMode, mappers)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,648,throw new ExportSnapshotException("Snapshot export failed!");
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,654,System.err.println("Snapshot export failed!");
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,655,System.err.println("Unable to rename snapshot directory from=" +
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,656,snapshotTmpDir + " to=" + outputSnapshotDir);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,657,return 1;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,662,System.err.println("Snapshot export failed!");
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,663,e.printStackTrace(System.err);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,701,System.exit(innerMain(HBaseConfiguration.create(), args));
hbase-client/src/main/java/org/apache/hadoop/hbase/snapshot/ClientSnapshotDescriptionUtils.java,42,TableName.isLegalTableQualifierName(Bytes.toBytes(snapshot.getName()));
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,148,public static byte [] isLegalTableQualifierName(final byte[] qualifierName){
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,149,isLegalTableQualifierName(qualifierName, 0, qualifierName.length);
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,164,int end){
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,166,throw new IllegalArgumentException("Table qualifier must not be empty");
hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java,185,Bytes.toString(qualifierName, start, end));
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/BaseLoadBalancer.java,22,import java.util.Collection;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/BaseLoadBalancer.java,32,import java.util.NavigableMap;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/BaseLoadBalancer.java,143,regionsPerServer[serverIndex] = new int[entry.getValue().size()];
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/BaseLoadBalancer.java,184,(serversToIndex.get(loc.get(i)) == null ? -1 : serversToIndex.get(loc.get(i)));
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java,552,return idx;
hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java,200,public static final boolean DEFAULT_COMPRESS_TAGS = false;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TagCompressionContext.java,44,public TagCompressionContext(Class<? extends Dictionary> dictType) throws SecurityException,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TagCompressionContext.java,45,NoSuchMethodException, InstantiationException, IllegalAccessException,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TagCompressionContext.java,46,InvocationTargetException {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/TagCompressionContext.java,49,tagDict.init(Short.MAX_VALUE);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,55,if (decodingCtx.getHFileContext().isCompressTags()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,56,try {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,57,TagCompressionContext tagCompressionContext = new TagCompressionContext(LRUDictionary.class);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,58,decodingCtx.setTagCompressionContext(tagCompressionContext);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,60,throw new IOException("Failed to initialize TagCompressionContext", e);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,163,tagCompressionContext = new TagCompressionContext(LRUDictionary.class);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,270,current.ensureSpaceForTags();
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,271,try {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,272,tagCompressionContext.uncompressTags(currentBuffer, current.tagsBuffer, 0,
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,273,current.tagsLength);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,275,throw new RuntimeException("Exception while uncompressing tags", e);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,471,if (encodingCtx.getHFileContext().isCompressTags()) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,472,try {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,473,TagCompressionContext tagCompressionContext = new TagCompressionContext(LRUDictionary.class);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,474,encodingCtx.setTagCompressionContext(tagCompressionContext);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java,476,throw new IOException("Failed to initialize TagCompressionContext", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,894,if(family.shouldCompressTags()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java,896,+ "', see HBASE-10443.");
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/CompressionContext.java,67,tagCompressionContext = new TagCompressionContext(dictType);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,1686,&& this.periodicFlusher.isAlive()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/io/FileLink.java,290,in.seek(pos);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,99,private void includeTimestamp(final long timestamp) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,118,public boolean includesTimeRange(final TimeRange tr) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,126,public long getMinimumTimestamp() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java,133,public long getMaximumTimestamp() {
hbase-client/src/main/java/org/apache/hadoop/hbase/catalog/MetaReader.java,170,return new HTable(catalogTracker.getConnection().getConfiguration(), tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java,171,hris = MetaReader.getServerUserRegions(this.server.getCatalogTracker(),
hbase-server/src/main/java/org/apache/hadoop/hbase/master/handler/ServerShutdownHandler.java,172,this.serverName);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,84,import org.apache.hadoop.security.token.Token;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,109,private boolean hasForwardedToken;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,110,private Token<?> userToken;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,258,if (userProvider.isHadoopSecurityEnabled()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,259,userToken = userProvider.getCurrent().getToken("HDFS_DELEGATION_TOKEN",
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,260,fs.getCanonicalServiceName());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,261,if (userToken == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,262,hasForwardedToken = false;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,263,userToken = fs.getDelegationToken("renewer");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,265,hasForwardedToken = true;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,266,LOG.info("Use the existing token: " + userToken);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,301,if (userToken != null && !hasForwardedToken) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,302,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,305,LOG.warn("Failed to cancel HDFS delegation token.", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,573,success = secureClient.bulkLoadHFiles(famPaths, userToken, bulkToken,
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,574,getLocation().getRegionInfo().getStartKey());
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,516,private boolean runCopyJob(final Path inputRoot, final Path outputRoot,
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,543,return job.waitForCompletion(true);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,646,if (!runCopyJob(inputRoot, outputRoot, files, verifyChecksum,
hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterWrapper.java,86,int getRegionServers();
hbase-hadoop-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterWrapper.java,93,int getDeadRegionServers();
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,21,import org.apache.commons.logging.Log;
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,22,import org.apache.commons.logging.LogFactory;
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,27,import org.apache.hadoop.metrics2.lib.MetricMutableGaugeLong;
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,28,import org.apache.hadoop.metrics2.lib.MetricMutableHistogram;
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,29,import org.apache.hadoop.metrics2.lib.MetricMutableStat;
hbase-hadoop1-compat/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterSourceImpl.java,39,private static final Log LOG = LogFactory.getLog(MetricsMasterSourceImpl.class.getName());
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterWrapperImpl.java,21,import org.apache.hadoop.hbase.master.HMaster;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterWrapperImpl.java,22,import org.apache.hadoop.hbase.master.MetricsMasterWrapper;
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterWrapperImpl.java,71,public int getRegionServers() {
hbase-server/src/main/java/org/apache/hadoop/hbase/master/MetricsMasterWrapperImpl.java,80,public int getDeadRegionServers() {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,209,metrics.clear();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,214,while (this.peerClusterId == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,216,if (this.peerClusterId == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,362,if (this.conn != null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,363,try {
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,364,this.conn.close();
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,366,LOG.debug("Attempt to close connection failed", e);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,369,LOG.debug("Source exiting " + this.peerId);
hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/ReplicationSource.java,370,metrics.clear();
hbase-server/src/main/java/org/apache/hadoop/hbase/migration/NamespaceUpgrade.java,456,private void updateAcls(HRegion region) throws IOException {
hbase-server/src/main/java/org/apache/hadoop/hbase/migration/NamespaceUpgrade.java,461,if (r == null || r.size() == 0) return;
hbase-server/src/main/java/org/apache/hadoop/hbase/migration/NamespaceUpgrade.java,463,Put p = new Put(AccessControlLists.ACL_GLOBAL_NAME);
hbase-server/src/main/java/org/apache/hadoop/hbase/migration/NamespaceUpgrade.java,464,for (Cell c : r.rawCells()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/migration/NamespaceUpgrade.java,465,p.addImmutable(CellUtil.cloneFamily(c), CellUtil.cloneQualifier(c), CellUtil.cloneValue(c));
hbase-server/src/main/java/org/apache/hadoop/hbase/migration/NamespaceUpgrade.java,467,region.put(p);
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1340,this.serverManager.regionServerReport(ProtobufUtil.toServerName(request.getServer()), new ServerLoad(sl));
hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java,1343,this.metricsMaster.incrementRequests(sl.getTotalNumberOfRequests());
hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/ipc/MetricsHBaseServerSourceImpl.java,113,metricsRegistry.snapshot(metricsCollector.addRecord(metricsRegistry.info()), all);
hbase-common/src/main/java/org/apache/hadoop/hbase/io/util/LRUDictionary.java,90,for (int i = 0; i < initialSize; i++) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/util/LRUDictionary.java,91,indexToNode[i] = new Node();
hbase-common/src/main/java/org/apache/hadoop/hbase/io/util/LRUDictionary.java,180,for (Node n : indexToNode) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/util/LRUDictionary.java,181,n.container = null;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/util/LRUDictionary.java,184,for (int i = 0; i < initSize; i++) {
hbase-common/src/main/java/org/apache/hadoop/hbase/io/util/LRUDictionary.java,185,indexToNode[i].next = null;
hbase-common/src/main/java/org/apache/hadoop/hbase/io/util/LRUDictionary.java,186,indexToNode[i].prev = null;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,611,System.err.println("The snapshot '" + snapshotName +
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,613,return 1;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,617,if (outputFs.exists(snapshotTmpDir)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,631,FileUtil.copy(inputFs, snapshotDir, outputFs, snapshotTmpDir, false, false, conf);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,683,System.err.println("  hbase " + getClass() + " \\");
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,684,System.err.println("    -snapshot MySnapshot -copy-to hdfs:///srv2:8082/hbase \\");
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/AuthenticationTokenSecretManager.java,133,return createPassword(WritableUtils.toByteArray(identifier),
hbase-server/src/main/java/org/apache/hadoop/hbase/security/token/AuthenticationTokenSecretManager.java,150,return createPassword(WritableUtils.toByteArray(identifier),
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java,374,return new Pair<Integer, Integer>(startPos, endPos);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,140,if (copyFile(context, inputPath, outputPath)) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,141,LOG.info("copy completed for input=" + inputPath + " output=" + outputPath);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,174,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,180,if (inputStat == null) return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,187,return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,198,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,204,return preserveAttributes(outputPath, inputStat);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,247,private boolean copyData(final Context context,
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,250,final long inputFileSize) {
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,283,LOG.error("number of bytes copied not matching copied=" + totalBytesWritten +
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,285,context.getCounter(Counter.COPY_FAILED).increment(1);
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,286,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,289,return true;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,293,return false;
hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/ExportSnapshot.java,620,System.err.println("consider removing " + snapshotTmpDir + " before retrying export");
hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/FavoredNodesPlan.java,29,import org.jboss.netty.util.internal.ConcurrentHashMap;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,44,private long flushSize;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,52,this.flushSize = desc.getMemStoreFlushSize();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,54,if (this.flushSize <= 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,55,this.flushSize = conf.getLong(HConstants.HREGION_MEMSTORE_FLUSH_SIZE,
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,93,long getSizeToCheck(final int tableRegionsCount) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,94,return tableRegionsCount == 0? getDesiredMaxFileSize():
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.java,96,this.flushSize * (tableRegionsCount * (long)tableRegionsCount));
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2777,protected long nextLong() {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2778,long n = rand.nextLong();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2779,if (n == 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2780,return nextLong();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2782,if (n < 0) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2783,n = -n;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,2785,return n;
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java,839,return this.memstoreSize.getAndAdd(memStoreSize);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java,365,flushHandlers[i] = new FlushHandler();
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,876,if (oldRequestCount == this.requestCount.get()) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java,880,oldRequestCount = this.requestCount.get();
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Get.java,159,public Get setTimeStamp(long timestamp) {
hbase-client/src/main/java/org/apache/hadoop/hbase/client/Scan.java,300,public Scan setTimeStamp(long timestamp) {
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RegionMergeRequest.java,134,LOG.warn("Could not release the table lock", ex);
hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/SplitRequest.java,135,LOG.warn("Could not release the table lock", ex);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,103,private Configuration cfg;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,116,this.cfg = conf;
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,207,int nrThreads = cfg.getInt("hbase.loadincremental.threads.max",
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,208,Runtime.getRuntime().availableProcessors());
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,255,FileSystem fs = FileSystem.get(cfg);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,281,int maxRetries = cfg.getInt("hbase.bulkload.retries.number", 0);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,303,userToken.cancel(cfg);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,582,FileSystem fs = FileSystem.get(cfg);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,814,String dirPath   = args[0];
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,817,boolean tableExists   = this.doesTableExist(tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,821,HTable table = new HTable(this.cfg, tableName);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java,828,int ret = ToolRunner.run(new LoadIncrementalHFiles(HBaseConfiguration.create()), args);
hbase-server/src/main/java/org/apache/hadoop/hbase/migration/UpgradeTo96.java,87,printUsage();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MultiTableInputFormatBase.java,146,String regionLocation =
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MultiTableInputFormatBase.java,147,table.getRegionLocation(keys.getFirst()[i], false).getHostname();
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MultiTableInputFormatBase.java,162,InputSplit split =
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/MultiTableInputFormatBase.java,164,scan, splitStart, splitStop, regionLocation);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java,149,if (table == null) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java,150,throw new IOException("No table was provided.");
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java,164,InputSplit split = new TableSplit(table.getName(),
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java,166,.getHostnamePort().split(Addressing.HOSTNAME_PORT_SEPARATOR)[0]);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java,204,InputSplit split = new TableSplit(table.getName(),
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java,205,splitStart, splitStop, regionLocation);
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java,111,final String location) {
hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableSplit.java,224,return 0;
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,686,append.add(CellUtil.createCell(row, family, qualifier, append.getTimeStamp(),
hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java,764,increment.add(CellUtil.createCell(row, family, qualifier, increment.getTimeStamp(),
