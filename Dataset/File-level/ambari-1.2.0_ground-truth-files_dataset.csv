File,Bug,SRC
ambari-metrics/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/Precision.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline;

/**
 * Is used to determine metrics aggregate table.
 *
 * @see org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.TimelineWebServices#getTimelineMetric
 */
public enum Precision {
  SECONDS,
  MINUTES,
  HOURS,
  DAYS;

  public static class PrecisionFormatException extends IllegalArgumentException {
    public PrecisionFormatException(String message, Throwable cause) {
      super(message, cause);
    }
  }

  public static Precision getPrecision(String precision) throws PrecisionFormatException {
    if (precision == null ) {
      return null;
    }
    try {
      return Precision.valueOf(precision.toUpperCase());
    } catch (IllegalArgumentException e) {
      throw new PrecisionFormatException("precision should be seconds, " +
        "minutes, hours or days", e);
    }
  }
}
"
ambari-metrics/ambari-metrics-timelineservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/metrics/timeline/aggregators/TimelineMetricClusterAggregatorMinute.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.aggregators;


import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.metrics2.sink.timeline.TimelineMetric;
import org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.PhoenixHBaseAccessor;
import org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.query.Condition;
import org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.query.DefaultCondition;
import org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.query.PhoenixTransactSQL;
import java.io.IOException;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import static org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.TimelineMetricConfiguration.SERVER_SIDE_TIMESIFT_ADJUSTMENT;
import static org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.query.PhoenixTransactSQL.GET_METRIC_SQL;
import static org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.query.PhoenixTransactSQL.METRICS_RECORD_TABLE_NAME;
import static org.apache.hadoop.yarn.server.applicationhistoryservice.metrics.timeline.query.PhoenixTransactSQL.NATIVE_TIME_RANGE_DELTA;

/**
 * Aggregates a metric across all hosts in the cluster. Reads metrics from
 * the precision table and saves into the aggregate.
 */
public class TimelineMetricClusterAggregatorMinute extends AbstractTimelineAggregator {
  private static final Log LOG = LogFactory.getLog(TimelineMetricClusterAggregatorMinute.class);
  public Long timeSliceIntervalMillis;
  private TimelineMetricReadHelper timelineMetricReadHelper = new TimelineMetricReadHelper(true);
  // Aggregator to perform app-level aggregates for host metrics
  private final TimelineMetricAppAggregator appAggregator;
  // 1 minute client side buffering adjustment
  private final Long serverTimeShiftAdjustment;

  public TimelineMetricClusterAggregatorMinute(PhoenixHBaseAccessor hBaseAccessor,
                                               Configuration metricsConf,
                                               String checkpointLocation,
                                               Long sleepIntervalMillis,
                                               Integer checkpointCutOffMultiplier,
                                               String aggregatorDisabledParam,
                                               String tableName,
                                               String outputTableName,
                                               Long nativeTimeRangeDelay,
                                               Long timeSliceInterval) {
    super(hBaseAccessor, metricsConf, checkpointLocation, sleepIntervalMillis,
      checkpointCutOffMultiplier, aggregatorDisabledParam, tableName,
      outputTableName, nativeTimeRangeDelay);

    appAggregator = new TimelineMetricAppAggregator(metricsConf);
    this.timeSliceIntervalMillis = timeSliceInterval;
    this.serverTimeShiftAdjustment = Long.parseLong(metricsConf.get(SERVER_SIDE_TIMESIFT_ADJUSTMENT, "90000"));
  }

  @Override
  protected void aggregate(ResultSet rs, long startTime, long endTime) throws SQLException, IOException {
    // Account for time shift due to client side buffering by shifting the
    // timestamps with the difference between server time and series start time
    List<Long[]> timeSlices = getTimeSlices(startTime - serverTimeShiftAdjustment, endTime);
    // Initialize app aggregates for host metrics
    appAggregator.init();
    Map<TimelineClusterMetric, MetricClusterAggregate> aggregateClusterMetrics =
      aggregateMetricsFromResultSet(rs, timeSlices);

    LOG.info("Saving " + aggregateClusterMetrics.size() + " metric aggregates.");
    hBaseAccessor.saveClusterAggregateRecords(aggregateClusterMetrics);
    appAggregator.cleanup();
  }

  @Override
  protected Condition prepareMetricQueryCondition(long startTime, long endTime) {
    Condition condition = new DefaultCondition(null, null, null, null, startTime,
      endTime, null, null, true);
    condition.setNoLimit();
    condition.setFetchSize(resultsetFetchSize);
    condition.setStatement(String.format(GET_METRIC_SQL,
      PhoenixTransactSQL.getNaiveTimeRangeHint(startTime, NATIVE_TIME_RANGE_DELTA),
      METRICS_RECORD_TABLE_NAME));
    // Retaining order of the row-key avoids client side merge sort.
    condition.addOrderByColumn("METRIC_NAME");
    condition.addOrderByColumn("HOSTNAME");
    condition.addOrderByColumn("SERVER_TIME");
    condition.addOrderByColumn("APP_ID");
    return condition;
  }

  /**
   * Return time slices to normalize the timeseries data.
   */
  private List<Long[]> getTimeSlices(long startTime, long endTime) {
    List<Long[]> timeSlices = new ArrayList<Long[]>();
    long sliceStartTime = startTime;
    while (sliceStartTime < endTime) {
      timeSlices.add(new Long[] { sliceStartTime, sliceStartTime + timeSliceIntervalMillis });
      sliceStartTime += timeSliceIntervalMillis;
    }
    return timeSlices;
  }

  private Map<TimelineClusterMetric, MetricClusterAggregate> aggregateMetricsFromResultSet(ResultSet rs, List<Long[]> timeSlices)
      throws SQLException, IOException {
    Map<TimelineClusterMetric, MetricClusterAggregate> aggregateClusterMetrics =
      new HashMap<TimelineClusterMetric, MetricClusterAggregate>();

    TimelineMetric metric = null;
    if (rs.next()) {
      metric = timelineMetricReadHelper.getTimelineMetricFromResultSet(rs);

      // Call slice after all rows for a host are read
      while (rs.next()) {
        TimelineMetric nextMetric = timelineMetricReadHelper.getTimelineMetricFromResultSet(rs);
        // If rows belong to same host combine them before slicing. This
        // avoids issues across rows that belong to same hosts but get
        // counted as coming from different ones.
        if (metric.equalsExceptTime(nextMetric)) {
          metric.addMetricValues(nextMetric.getMetricValues());
        } else {
          // Process the current metric
          processAggregateClusterMetrics(aggregateClusterMetrics, metric, timeSlices);
          metric = nextMetric;
        }
      }
    }
    // Process last metric
    if (metric != null) {
      processAggregateClusterMetrics(aggregateClusterMetrics, metric, timeSlices);
    }

    // Add app level aggregates to save
    aggregateClusterMetrics.putAll(appAggregator.getAggregateClusterMetrics());
    return aggregateClusterMetrics;
  }

  /**
   * Slice metric values into interval specified by :
   * timeline.metrics.cluster.aggregator.minute.timeslice.interval
   * Normalize value by averaging them within the interval
   */
  private void processAggregateClusterMetrics(Map<TimelineClusterMetric, MetricClusterAggregate> aggregateClusterMetrics,
                                              TimelineMetric metric, List<Long[]> timeSlices) {
    // Create time slices
    Map<TimelineClusterMetric, Double> clusterMetrics = sliceFromTimelineMetric(metric, timeSlices);

    if (clusterMetrics != null && !clusterMetrics.isEmpty()) {
      for (Map.Entry<TimelineClusterMetric, Double> clusterMetricEntry :
        clusterMetrics.entrySet()) {

        TimelineClusterMetric clusterMetric = clusterMetricEntry.getKey();
        Double avgValue = clusterMetricEntry.getValue();

        MetricClusterAggregate aggregate = aggregateClusterMetrics.get(clusterMetric);

        if (aggregate == null) {
          aggregate = new MetricClusterAggregate(avgValue, 1, null, avgValue, avgValue);
          aggregateClusterMetrics.put(clusterMetric, aggregate);
        } else {
          aggregate.updateSum(avgValue);
          aggregate.updateNumberOfHosts(1);
          aggregate.updateMax(avgValue);
          aggregate.updateMin(avgValue);
        }
        // Update app level aggregates
        appAggregator.processTimelineClusterMetric(clusterMetric, metric.getHostName(), avgValue);
      }
    }
  }

  private Map<TimelineClusterMetric, Double> sliceFromTimelineMetric(
      TimelineMetric timelineMetric, List<Long[]> timeSlices) {

    if (timelineMetric.getMetricValues().isEmpty()) {
      return null;
    }

    Map<TimelineClusterMetric, Double> timelineClusterMetricMap =
      new HashMap<TimelineClusterMetric, Double>();

    Long timeShift = timelineMetric.getTimestamp() - timelineMetric.getStartTime();
    if (timeShift < 0) {
      LOG.debug("Invalid time shift found, possible discrepancy in clocks. " +
        "timeShift = " + timeShift);
      timeShift = 0l;
    }

    for (Map.Entry<Long, Double> metric : timelineMetric.getMetricValues().entrySet()) {
      // TODO: investigate null values - pre filter
      if (metric.getValue() == null) {
        continue;
      }

      Long timestamp = getSliceTimeForMetric(timeSlices, Long.parseLong(metric.getKey().toString()));
      if (timestamp != -1) {
        // Metric is within desired time range
        TimelineClusterMetric clusterMetric = new TimelineClusterMetric(
          timelineMetric.getMetricName(),
          timelineMetric.getAppId(),
          timelineMetric.getInstanceId(),
          timestamp,
          timelineMetric.getType());

        // do a sum / count here to get average for all points in a slice
        int count = 1;
        Double sum;
        if (!timelineClusterMetricMap.containsKey(clusterMetric)) {
          sum = metric.getValue();
        } else {
          count++;
          Double oldValue = timelineClusterMetricMap.get(clusterMetric);
          sum = oldValue + metric.getValue();
        }
        timelineClusterMetricMap.put(clusterMetric, (sum / count));
      } else {
        if (timelineMetric.getMetricName().equals("tserver.general.entries")) {
          LOG.info("--- Fallen off: serverTs = " + timelineMetric.getTimestamp() +
            ", timeShift: " + timeShift +
            ", timestamp: " + Long.parseLong(metric.getKey().toString()) +
            ", host = " + timelineMetric.getHostName());
        }
      }
    }

    return timelineClusterMetricMap;
  }

  /**
   * Return beginning of the time slice into which the metric fits.
   */
  private Long getSliceTimeForMetric(List<Long[]> timeSlices, Long timestamp) {
    for (Long[] timeSlice : timeSlices) {
      if (timestamp >= timeSlice[0] && timestamp < timeSlice[1]) {
        return timeSlice[0];
      }
    }
    return -1l;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/db/DBConnector.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.eventdb.db;

import java.io.IOException;
import java.util.List;

import org.apache.ambari.eventdb.model.DataTable;
import org.apache.ambari.eventdb.model.Jobs.JobDBEntry;
import org.apache.ambari.eventdb.model.TaskAttempt;
import org.apache.ambari.eventdb.model.WorkflowContext;
import org.apache.ambari.eventdb.model.Workflows;
import org.apache.ambari.eventdb.model.Workflows.WorkflowDBEntry.WorkflowFields;

public interface DBConnector {
  public void submitJob(JobDBEntry j, WorkflowContext context) throws IOException;
  
  public void updateJob(JobDBEntry j) throws IOException;
  
  public Workflows fetchWorkflows() throws IOException;
  
  public Workflows fetchWorkflows(WorkflowFields field, boolean sortAscending, int offset, int limit) throws IOException;
  
  public DataTable fetchWorkflows(int offset, int limit, String searchTerm, int echo, WorkflowFields field, boolean sortAscending, String searchWorkflowId,
      String searchWorkflowName, String searchWorkflowType, String searchUserName, int minJobs, int maxJobs, long minInputBytes, long maxInputBytes,
      long minOutputBytes, long maxOutputBytes, long minDuration, long maxDuration, long minStartTime, long maxStartTime) throws IOException;
  
  public List<JobDBEntry> fetchJobDetails(String workflowID) throws IOException;
  
  public long[] fetchJobStartStopTimes(String jobID) throws IOException;
  
  public List<TaskAttempt> fetchTaskAttempts(String jobID, String taskType) throws IOException;
  
  public void close();
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/db/PostgresConnector.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.eventdb.db;

import java.io.IOException;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.ArrayList;
import java.util.EnumMap;
import java.util.List;
import java.util.Map;

import org.apache.ambari.eventdb.model.DataTable;
import org.apache.ambari.eventdb.model.DataTable.AvgData;
import org.apache.ambari.eventdb.model.DataTable.Summary;
import org.apache.ambari.eventdb.model.DataTable.Summary.SummaryFields;
import org.apache.ambari.eventdb.model.DataTable.Times;
import org.apache.ambari.eventdb.model.Jobs.JobDBEntry;
import org.apache.ambari.eventdb.model.Jobs.JobDBEntry.JobFields;
import org.apache.ambari.eventdb.model.TaskAttempt;
import org.apache.ambari.eventdb.model.TaskAttempt.TaskAttemptFields;
import org.apache.ambari.eventdb.model.WorkflowContext;
import org.apache.ambari.eventdb.model.Workflows;
import org.apache.ambari.eventdb.model.Workflows.WorkflowDBEntry;
import org.apache.ambari.eventdb.model.Workflows.WorkflowDBEntry.WorkflowFields;
import org.apache.commons.lang.NotImplementedException;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.codehaus.jackson.JsonParseException;
import org.codehaus.jackson.map.JsonMappingException;
import org.codehaus.jackson.map.ObjectMapper;

public class PostgresConnector implements DBConnector {
  private static Log LOG = LogFactory.getLog(PostgresConnector.class);
  private static final String WORKFLOW_TABLE_NAME = "workflow";
  private static final String JOB_TABLE_NAME = "job";
  private static final String TASK_ATTEMPT_TABLE_NAME = "taskattempt";
  public static final String SORT_ASC = "ASC";
  public static final String SORT_DESC = "DESC";
  
  private static final ObjectMapper jsonMapper = new ObjectMapper();
  
  private Connection db;
  
  public static enum Statements {
    SJ_INSERT_JOB_PS(""),
    SJ_CHECK_WORKFLOW_PS(""),
    SJ_INSERT_WORKFLOW_PS(""),
    UJ_UPDATE_JOB_PS(""),
    UJ_UPDATE_WORKFLOW_PS(""),
    FW_PS("SELECT " + WorkflowDBEntry.WORKFLOW_FIELDS + " FROM " + WORKFLOW_TABLE_NAME),
    FW_COUNT_PS("SELECT count(*) as " + SummaryFields.numRows + " FROM " + WORKFLOW_TABLE_NAME),
    FW_SUMMARY_PS("SELECT count(*) as " + SummaryFields.numRows + ", "
        + getAvg(WorkflowFields.NUMJOBSTOTAL, SummaryFields.avgJobs, SummaryFields.minJobs, SummaryFields.maxJobs) + ", "
        + getAvg(WorkflowFields.INPUTBYTES, SummaryFields.avgInput, SummaryFields.minInput, SummaryFields.maxInput) + ", "
        + getAvg(WorkflowFields.OUTPUTBYTES, SummaryFields.avgOutput, SummaryFields.minOutput, SummaryFields.maxOutput) + ", "
        + getAvg(WorkflowFields.DURATION, SummaryFields.avgDuration, SummaryFields.minDuration, SummaryFields.maxDuration) + ", min("
        + WorkflowFields.STARTTIME + ") as " + SummaryFields.youngest + ", max(" + WorkflowFields.STARTTIME + ") as " + SummaryFields.oldest + " FROM "
        + WORKFLOW_TABLE_NAME),
    FJD_PS("SELECT " + JobDBEntry.JOB_FIELDS + " FROM " + JOB_TABLE_NAME + " WHERE " + JobFields.WORKFLOWID.toString() + " = ?"),
    FJSS_PS("SELECT " + JobFields.SUBMITTIME + ", " + JobFields.FINISHTIME + " FROM " + JOB_TABLE_NAME + " WHERE " + JobFields.JOBID + " = ?"),
    FTA_PS("SELECT " + TaskAttempt.TASK_ATTEMPT_FIELDS + " FROM " + TASK_ATTEMPT_TABLE_NAME + " WHERE " + TaskAttemptFields.JOBID + " = ? AND "
        + TaskAttemptFields.TASKTYPE + " = ? ORDER BY " + TaskAttemptFields.STARTTIME);
    
    private String statementString;
    
    Statements(String statementString) {
      this.statementString = statementString;
    }
    
    public String getStatementString() {
      return statementString;
    }
    
    private static String getAvg(WorkflowFields field, SummaryFields avg, SummaryFields min, SummaryFields max) {
      return "avg(" + field + ") as " + avg + ", min(" + field + ") as " + min + ", max(" + field + ") as " + max;
    }
  }
  
  private Map<Statements,PreparedStatement> preparedStatements = new EnumMap<Statements,PreparedStatement>(Statements.class);
  
  public PostgresConnector(String hostname, String dbname, String username, String password) throws IOException {
    String url = "jdbc:postgresql://" + hostname + "/" + dbname;
    try {
      Class.forName("org.postgresql.Driver");
      db = DriverManager.getConnection(url, username, password);
    } catch (ClassNotFoundException e) {
      db = null;
      throw new IOException(e);
    } catch (SQLException e) {
      db = null;
      throw new IOException(e);
    }
  }
  
  @Override
  public void submitJob(JobDBEntry j, WorkflowContext context) throws IOException {
    // PreparedStatement insertJobPS = getPS(Statements.SJ_INSERT_JOB_PS);
    // PreparedStatement checkWorkflowPS = getPS(Statements.SJ_CHECK_WORKFLOW_PS);
    // PreparedStatement insertWorkflowPS = getPS(Statements.SJ_INSERT_WORKFLOW_PS);
    throw new NotImplementedException();
  }
  
  @Override
  public void updateJob(JobDBEntry j) throws IOException {
    // PreparedStatement updateJobPS = getPS(Statements.UJ_UPDATE_JOB_PS);
    // PreparedStatement updateWorkflowPS = getPS(Statements.UJ_UPDATE_WORKFLOW_PS);
    throw new NotImplementedException();
  }
  
  @Override
  public Workflows fetchWorkflows() throws IOException {
    Workflows workflows = new Workflows();
    workflows.setWorkflows(fetchWorkflows(getPS(Statements.FW_PS)));
    workflows.setSummary(fetchSummary(getPS(Statements.FW_SUMMARY_PS)));
    return workflows;
  }
  
  @Override
  public Workflows fetchWorkflows(WorkflowFields field, boolean sortAscending, int offset, int limit) throws IOException {
    if (offset < 0)
      offset = 0;
    Workflows workflows = new Workflows();
    workflows.setWorkflows(fetchWorkflows(getQualifiedPS(Statements.FW_PS, "", field, sortAscending, offset, limit)));
    workflows.setSummary(fetchSummary(getPS(Statements.FW_SUMMARY_PS)));
    return workflows;
  }
  
  private List<WorkflowDBEntry> fetchWorkflows(PreparedStatement ps) throws IOException {
    List<WorkflowDBEntry> workflows = new ArrayList<WorkflowDBEntry>();
    ResultSet rs = null;
    try {
      rs = ps.executeQuery();
      while (rs.next()) {
        workflows.add(getWorkflowDBEntry(rs));
      }
    } catch (SQLException e) {
      throw new IOException(e);
    } finally {
      try {
        if (rs != null)
          rs.close();
      } catch (SQLException e) {
        LOG.error("Exception while closing ResultSet", e);
      }
    }
    return workflows;
  }
  
  private Summary fetchSummary(PreparedStatement ps) throws IOException {
    Summary summary = new Summary();
    ResultSet rs = null;
    try {
      rs = ps.executeQuery();
      if (rs.next()) {
        summary.setNumRows(SummaryFields.numRows.getInt(rs));
        summary.setJobs(getAvgData(rs, SummaryFields.avgJobs, SummaryFields.minJobs, SummaryFields.maxJobs));
        summary.setInput(getAvgData(rs, SummaryFields.avgInput, SummaryFields.minInput, SummaryFields.maxInput));
        summary.setOutput(getAvgData(rs, SummaryFields.avgOutput, SummaryFields.minOutput, SummaryFields.maxOutput));
        summary.setDuration(getAvgData(rs, SummaryFields.avgDuration, SummaryFields.minDuration, SummaryFields.maxDuration));
        Times times = new Times();
        times.setYoungest(SummaryFields.youngest.getLong(rs));
        times.setOldest(SummaryFields.oldest.getLong(rs));
        summary.setTimes(times);
      }
    } catch (SQLException e) {
      throw new IOException(e);
    } finally {
      try {
        if (rs != null)
          rs.close();
      } catch (SQLException e) {
        LOG.error("Exception while closing ResultSet", e);
      }
    }
    return summary;
  }
  
  private static WorkflowDBEntry getWorkflowDBEntry(ResultSet rs) throws SQLException, JsonParseException, JsonMappingException, IOException {
    WorkflowDBEntry w = new WorkflowDBEntry();
    w.setWorkflowId(WorkflowFields.WORKFLOWID.getString(rs));
    w.setWorkflowName(WorkflowFields.WORKFLOWNAME.getString(rs));
    w.setUserName(WorkflowFields.USERNAME.getString(rs));
    w.setStartTime(WorkflowFields.STARTTIME.getLong(rs));
    w.setElapsedTime(WorkflowFields.DURATION.getLong(rs));
    w.setNumJobsTotal(WorkflowFields.NUMJOBSTOTAL.getInt(rs));
    w.setInputBytes(WorkflowFields.INPUTBYTES.getLong(rs));
    w.setOutputBytes(WorkflowFields.OUTPUTBYTES.getLong(rs));
    w.setNumJobsCompleted(WorkflowFields.NUMJOBSCOMPLETED.getInt(rs));
    w.setWorkflowContext(jsonMapper.readValue(WorkflowFields.WORKFLOWCONTEXT.getString(rs), WorkflowContext.class));
    return w;
  }
  
  private static AvgData getAvgData(ResultSet rs, SummaryFields avg, SummaryFields min, SummaryFields max) throws SQLException {
    AvgData avgData = new AvgData();
    avgData.setAvg(avg.getDouble(rs));
    avgData.setMin(min.getLong(rs));
    avgData.setMax(max.getLong(rs));
    return avgData;
  }
  
  @Override
  public DataTable fetchWorkflows(int offset, int limit, String searchTerm, int echo, WorkflowFields col, boolean sortAscending, String searchWorkflowId,
      String searchWorkflowName, String searchWorkflowType, String searchUserName, int minJobs, int maxJobs, long minInputBytes, long maxInputBytes,
      long minOutputBytes, long maxOutputBytes, long minDuration, long maxDuration, long minStartTime, long maxStartTime) throws IOException {
    int total = 0;
    PreparedStatement ps = getPS(Statements.FW_COUNT_PS);
    ResultSet rs = null;
    try {
      rs = ps.executeQuery();
      if (rs.next())
        total = SummaryFields.numRows.getInt(rs);
    } catch (SQLException e) {
      throw new IOException(e);
    } finally {
      try {
        if (rs != null)
          rs.close();
      } catch (SQLException e) {
        LOG.error("Exception while closing ResultSet", e);
      }
    }
    
    String searchClause = buildSearchClause(searchTerm, searchWorkflowId, searchWorkflowName, searchWorkflowType, searchUserName, minJobs, maxJobs,
        minInputBytes, maxInputBytes, minOutputBytes, maxOutputBytes, minDuration, maxDuration, minStartTime, maxStartTime);
    List<WorkflowDBEntry> workflows = fetchWorkflows(getQualifiedPS(Statements.FW_PS, searchClause, col, sortAscending, offset, limit));
    Summary summary = fetchSummary(getQualifiedPS(Statements.FW_SUMMARY_PS, searchClause));
    DataTable table = new DataTable();
    table.setiTotalRecords(total);
    table.setiTotalDisplayRecords(summary.getNumRows());
    table.setAaData(workflows);
    table.setsEcho(echo);
    table.setSummary(summary);
    return table;
  }
  
  @Override
  public List<JobDBEntry> fetchJobDetails(String workflowId) throws IOException {
    PreparedStatement ps = getPS(Statements.FJD_PS);
    List<JobDBEntry> jobs = new ArrayList<JobDBEntry>();
    ResultSet rs = null;
    try {
      ps.setString(1, workflowId);
      rs = ps.executeQuery();
      while (rs.next()) {
        JobDBEntry j = new JobDBEntry();
        j.setConfPath(JobFields.CONFPATH.getString(rs));
        j.setSubmitTime(JobFields.SUBMITTIME.getLong(rs));
        long finishTime = JobFields.FINISHTIME.getLong(rs);
        if (finishTime > j.getSubmitTime())
          j.setElapsedTime(finishTime - j.getSubmitTime());
        else
          j.setElapsedTime(0);
        j.setInputBytes(JobFields.INPUTBYTES.getLong(rs));
        j.setJobId(JobFields.JOBID.getString(rs));
        j.setJobName(JobFields.JOBNAME.getString(rs));
        j.setMaps(JobFields.MAPS.getInt(rs));
        j.setOutputBytes(JobFields.OUTPUTBYTES.getLong(rs));
        j.setReduces(JobFields.REDUCES.getInt(rs));
        j.setStatus(JobFields.STATUS.getString(rs));
        j.setUserName(JobFields.USERNAME.getString(rs));
        j.setWorkflowEntityName(JobFields.WORKFLOWENTITYNAME.getString(rs));
        j.setWorkflowId(JobFields.WORKFLOWID.getString(rs));
        jobs.add(j);
      }
      rs.close();
    } catch (SQLException e) {
      throw new IOException(e);
    } finally {
      if (rs != null)
        try {
          rs.close();
        } catch (SQLException e) {
          LOG.error("Exception while closing ResultSet", e);
        }
      
    }
    return jobs;
  }
  
  @Override
  public long[] fetchJobStartStopTimes(String jobID) throws IOException {
    PreparedStatement ps = getPS(Statements.FJSS_PS);
    long[] times = new long[2];
    ResultSet rs = null;
    try {
      ps.setString(1, jobID);
      rs = ps.executeQuery();
      if (!rs.next())
        return null;
      times[0] = JobFields.SUBMITTIME.getLong(rs);
      times[1] = JobFields.FINISHTIME.getLong(rs);
      rs.close();
    } catch (SQLException e) {
      throw new IOException(e);
    } finally {
      if (rs != null)
        try {
          rs.close();
        } catch (SQLException e) {
          LOG.error("Exception while closing ResultSet", e);
        }
    }
    if (times[1] == 0)
      times[1] = System.currentTimeMillis();
    if (times[1] < times[0])
      times[1] = times[0];
    return times;
  }
  
  @Override
  public List<TaskAttempt> fetchTaskAttempts(String jobID, String taskType) throws IOException {
    PreparedStatement ps = getPS(Statements.FTA_PS);
    List<TaskAttempt> taskAttempts = new ArrayList<TaskAttempt>();
    ResultSet rs = null;
    try {
      ps.setString(1, jobID);
      ps.setString(2, taskType);
      rs = ps.executeQuery();
      while (rs.next()) {
        TaskAttempt t = new TaskAttempt();
        t.setFinishTime(TaskAttemptFields.FINISHTIME.getLong(rs));
        t.setInputBytes(TaskAttemptFields.INPUTBYTES.getLong(rs));
        t.setLocality(TaskAttemptFields.LOCALITY.getString(rs));
        t.setMapFinishTime(TaskAttemptFields.MAPFINISHTIME.getLong(rs));
        t.setOutputBytes(TaskAttemptFields.OUTPUTBYTES.getLong(rs));
        t.setShuffleFinishTime(TaskAttemptFields.SHUFFLEFINISHTIME.getLong(rs));
        t.setSortFinishTime(TaskAttemptFields.SORTFINISHTIME.getLong(rs));
        t.setStartTime(TaskAttemptFields.STARTTIME.getLong(rs));
        t.setStatus(TaskAttemptFields.STATUS.getString(rs));
        t.setTaskAttemptId(TaskAttemptFields.TASKATTEMPTID.getString(rs));
        t.setTaskType(TaskAttemptFields.TASKTYPE.getString(rs));
        taskAttempts.add(t);
      }
      rs.close();
    } catch (SQLException e) {
      throw new IOException(e);
    } finally {
      if (rs != null)
        try {
          rs.close();
        } catch (SQLException e) {
          LOG.error("Exception while closing ResultSet", e);
        }
    }
    return taskAttempts;
  }
  
  private PreparedStatement getPS(Statements statement) throws IOException {
    if (db == null)
      throw new IOException("postgres db not initialized");
    
    synchronized (preparedStatements) {
      if (!preparedStatements.containsKey(statement)) {
        try {
          preparedStatements.put(statement, db.prepareStatement(statement.getStatementString()));
        } catch (SQLException e) {
          throw new IOException(e);
        }
      }
    }
    
    return preparedStatements.get(statement);
  }
  
  private PreparedStatement getQualifiedPS(Statements statement, String searchClause) throws IOException {
    if (db == null)
      throw new IOException("postgres db not initialized");
    try {
      // LOG.debug("preparing " + statement.getStatementString() + searchClause);
      return db.prepareStatement(statement.getStatementString() + searchClause);
    } catch (SQLException e) {
      throw new IOException(e);
    }
  }
  
  private PreparedStatement getQualifiedPS(Statements statement, String searchClause, WorkflowFields field, boolean sortAscending, int offset, int limit)
      throws IOException {
    if (db == null)
      throw new IOException("postgres db not initialized");
    String limitClause = " ORDER BY " + field.toString() + " " + (sortAscending ? SORT_ASC : SORT_DESC) + " OFFSET " + offset
        + (limit >= 0 ? " LIMIT " + limit : "");
    return getQualifiedPS(statement, searchClause + limitClause);
  }
  
  private static void addRangeSearch(StringBuilder sb, WorkflowFields field, int min, int max) {
    if (min >= 0)
      append(sb, greaterThan(field, Integer.toString(min)));
    if (max >= 0)
      append(sb, lessThan(field, Integer.toString(max)));
  }
  
  private static void addRangeSearch(StringBuilder sb, WorkflowFields field, long min, long max) {
    if (min >= 0)
      append(sb, greaterThan(field, Long.toString(min)));
    if (max >= 0)
      append(sb, lessThan(field, Long.toString(max)));
  }
  
  private static void append(StringBuilder sb, String s) {
    if (sb.length() > WHERE.length())
      sb.append(" and ");
    sb.append(s);
  }
  
  private static String like(WorkflowFields field, String s) {
    return field.toString() + " like '%" + s + "%'";
  }
  
  private static String startsWith(WorkflowFields field, String s) {
    return field.toString() + " like '" + s + "%'";
  }
  
  private static String equals(WorkflowFields field, String s) {
    return field.toString() + " = '" + s + "'";
  }
  
  private static String lessThan(WorkflowFields field, String s) {
    return field.toString() + " <= " + s;
  }
  
  private static String greaterThan(WorkflowFields field, String s) {
    return field.toString() + " >= " + s;
  }
  
  private static final String WHERE = " where";
  
  private static String buildSearchClause(String searchTerm, String searchWorkflowId, String searchWorkflowName, String searchWorkflowType,
      String searchUserName, int minJobs, int maxJobs, long minInputBytes, long maxInputBytes, long minOutputBytes, long maxOutputBytes, long minDuration,
      long maxDuration, long minStartTime, long maxStartTime) {
    StringBuilder sb = new StringBuilder();
    sb.append(WHERE);
    if (searchTerm != null && searchTerm.length() > 0) {
      sb.append(" (");
      sb.append(like(WorkflowFields.WORKFLOWID, searchTerm));
      sb.append(" or ");
      sb.append(like(WorkflowFields.WORKFLOWNAME, searchTerm));
      sb.append(" or ");
      sb.append(like(WorkflowFields.USERNAME, searchTerm));
      sb.append(")");
    }
    if (searchWorkflowId != null)
      append(sb, like(WorkflowFields.WORKFLOWID, searchWorkflowId));
    if (searchWorkflowName != null)
      append(sb, like(WorkflowFields.WORKFLOWNAME, searchWorkflowName));
    if (searchWorkflowType != null)
      append(sb, startsWith(WorkflowFields.WORKFLOWID, searchWorkflowType));
    if (searchUserName != null)
      append(sb, equals(WorkflowFields.USERNAME, searchUserName));
    addRangeSearch(sb, WorkflowFields.NUMJOBSTOTAL, minJobs, maxJobs);
    addRangeSearch(sb, WorkflowFields.INPUTBYTES, minInputBytes, maxInputBytes);
    addRangeSearch(sb, WorkflowFields.OUTPUTBYTES, minOutputBytes, maxOutputBytes);
    addRangeSearch(sb, WorkflowFields.DURATION, minDuration, maxDuration);
    addRangeSearch(sb, WorkflowFields.STARTTIME, minStartTime, maxStartTime);
    
    if (sb.length() == WHERE.length())
      return "";
    else
      return sb.toString();
  }
  
  @Override
  public void close() {
    if (db != null) {
      try {
        db.close();
      } catch (SQLException e) {
        LOG.error("Exception while closing connector", e);
      }
      db = null;
    }
  }
  
  @Override
  protected void finalize() throws Throwable {
    close();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/model/DataTable.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.eventdb.model;

import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.List;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;

import org.apache.ambari.eventdb.model.Workflows.WorkflowDBEntry;

@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class DataTable {
  int sEcho;
  int iTotalRecords;
  int iTotalDisplayRecords;
  List<WorkflowDBEntry> aaData;
  Summary summary;
  
  @XmlRootElement
  @XmlAccessorType(XmlAccessType.FIELD)
  public static class Summary {
    public static enum SummaryFields {
      numRows,
      avgJobs,
      minJobs,
      maxJobs,
      avgInput,
      minInput,
      maxInput,
      avgOutput,
      minOutput,
      maxOutput,
      avgDuration,
      minDuration,
      maxDuration,
      youngest,
      oldest;
      
      public int getInt(ResultSet rs) throws SQLException {
        return rs.getInt(this.toString());
      }
      
      public long getLong(ResultSet rs) throws SQLException {
        return rs.getLong(this.toString());
      }
      
      public double getDouble(ResultSet rs) throws SQLException {
        return rs.getDouble(this.toString());
      }
    }
    
    int numRows;
    AvgData jobs;
    AvgData input;
    AvgData output;
    AvgData duration;
    Times times;
    
    public int getNumRows() {
      return numRows;
    }
    
    public void setNumRows(int numRows) {
      this.numRows = numRows;
    }
    
    public AvgData getJobs() {
      return jobs;
    }
    
    public void setJobs(AvgData jobs) {
      this.jobs = jobs;
    }
    
    public AvgData getInput() {
      return input;
    }
    
    public void setInput(AvgData input) {
      this.input = input;
    }
    
    public AvgData getOutput() {
      return output;
    }
    
    public void setOutput(AvgData output) {
      this.output = output;
    }
    
    public AvgData getDuration() {
      return duration;
    }
    
    public void setDuration(AvgData duration) {
      this.duration = duration;
    }
    
    public Times getTimes() {
      return times;
    }
    
    public void setTimes(Times times) {
      this.times = times;
    }
  }
  
  @XmlRootElement
  @XmlAccessorType(XmlAccessType.FIELD)
  public static class AvgData {
    double avg;
    long min;
    long max;
    
    public double getAvg() {
      return avg;
    }
    
    public void setAvg(double avg) {
      this.avg = avg;
    }
    
    public long getMin() {
      return min;
    }
    
    public void setMin(long min) {
      this.min = min;
    }
    
    public long getMax() {
      return max;
    }
    
    public void setMax(long max) {
      this.max = max;
    }
  }
  
  @XmlRootElement
  @XmlAccessorType(XmlAccessType.FIELD)
  public static class Times {
    long oldest;
    long youngest;
    
    public long getOldest() {
      return oldest;
    }
    
    public void setOldest(long oldest) {
      this.oldest = oldest;
    }
    
    public long getYoungest() {
      return youngest;
    }
    
    public void setYoungest(long youngest) {
      this.youngest = youngest;
    }
  }
  
  public DataTable() {}
  
  public int getsEcho() {
    return sEcho;
  }
  
  public void setsEcho(int sEcho) {
    this.sEcho = sEcho;
  }
  
  public int getiTotalRecords() {
    return iTotalRecords;
  }
  
  public void setiTotalRecords(int iTotalRecords) {
    this.iTotalRecords = iTotalRecords;
  }
  
  public int getiTotalDisplayRecords() {
    return iTotalDisplayRecords;
  }
  
  public void setiTotalDisplayRecords(int iTotalDisplayRecords) {
    this.iTotalDisplayRecords = iTotalDisplayRecords;
  }
  
  public List<WorkflowDBEntry> getAaData() {
    return aaData;
  }
  
  public void setAaData(List<WorkflowDBEntry> aaData) {
    this.aaData = aaData;
  }
  
  public Summary getSummary() {
    return summary;
  }
  
  public void setSummary(Summary summary) {
    this.summary = summary;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/model/Jobs.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.eventdb.model;

import org.apache.commons.lang.StringUtils;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlTransient;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.List;

@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class Jobs {
  List<JobDBEntry> jobs;
  
  public static class JobDBEntry {
    public static enum JobFields {
      JOBID,
      JOBNAME,
      STATUS,
      USERNAME,
      SUBMITTIME,
      FINISHTIME,
      MAPS,
      REDUCES,
      INPUTBYTES,
      OUTPUTBYTES,
      CONFPATH,
      WORKFLOWID,
      WORKFLOWENTITYNAME;
      
      public String getString(ResultSet rs) throws SQLException {
        return rs.getString(this.toString());
      }
      
      public int getInt(ResultSet rs) throws SQLException {
        return rs.getInt(this.toString());
      }
      
      public long getLong(ResultSet rs) throws SQLException {
        return rs.getLong(this.toString());
      }
      
      public static String join() {
        String[] tmp = new String[JobFields.values().length];
        for (int i = 0; i < tmp.length; i++)
          tmp[i] = JobFields.values()[i].toString();
        return StringUtils.join(tmp, ",");
      }
    }
    
    @XmlTransient
    public static final String JOB_FIELDS = JobFields.join();
    
    private String jobId;
    private String jobName;
    private String status;
    private String userName;
    private long submitTime;
    private long elapsedTime;
    private int maps;
    private int reduces;
    private long inputBytes;
    private long outputBytes;
    private String confPath;
    private String workflowId;
    private String workflowEntityName;
    
    public JobDBEntry() {
      /* Required by JAXB. */
    }
    
    public String getJobId() {
      return jobId;
    }
    
    public String getJobName() {
      return jobName;
    }
    
    public String getStatus() {
      return status;
    }
    
    public String getUserName() {
      return userName;
    }
    
    public long getSubmitTime() {
      return submitTime;
    }
    
    public long getElapsedTime() {
      return elapsedTime;
    }
    
    public int getMaps() {
      return maps;
    }
    
    public int getReduces() {
      return reduces;
    }
    
    public long getInputBytes() {
      return inputBytes;
    }
    
    public long getOutputBytes() {
      return outputBytes;
    }
    
    public String getConfPath() {
      return confPath;
    }
    
    public String getWorkflowId() {
      return workflowId;
    }
    
    public String getWorkflowEntityName() {
      return workflowEntityName;
    }
    
    public void setJobId(String jobId) {
      this.jobId = jobId;
    }
    
    public void setJobName(String jobName) {
      this.jobName = jobName;
    }
    
    public void setStatus(String status) {
      this.status = status;
    }
    
    public void setUserName(String userName) {
      this.userName = userName;
    }
    
    public void setSubmitTime(long submitTime) {
      this.submitTime = submitTime;
    }
    
    public void setElapsedTime(long elapsedTime) {
      this.elapsedTime = elapsedTime;
    }
    
    public void setMaps(int maps) {
      this.maps = maps;
    }
    
    public void setReduces(int reduces) {
      this.reduces = reduces;
    }
    
    public void setInputBytes(long inputBytes) {
      this.inputBytes = inputBytes;
    }
    
    public void setOutputBytes(long outputBytes) {
      this.outputBytes = outputBytes;
    }
    
    public void setConfPath(String confPath) {
      this.confPath = confPath;
    }
    
    public void setWorkflowId(String workflowId) {
      this.workflowId = workflowId;
    }
    
    public void setWorkflowEntityName(String workflowEntityName) {
      this.workflowEntityName = workflowEntityName;
    }
  }
  
  public Jobs() {}
  
  public List<JobDBEntry> getJobs() {
    return jobs;
  }
  
  public void setJobs(List<JobDBEntry> jobs) {
    this.jobs = jobs;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/model/TaskAttempt.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.eventdb.model;

import java.sql.ResultSet;
import java.sql.SQLException;

import org.apache.commons.lang.StringUtils;

/**
 * 
 */
public class TaskAttempt {
  public static enum TaskAttemptFields {
    JOBID,
    TASKATTEMPTID,
    TASKTYPE,
    STARTTIME,
    FINISHTIME,
    MAPFINISHTIME,
    SHUFFLEFINISHTIME,
    SORTFINISHTIME,
    INPUTBYTES,
    OUTPUTBYTES,
    STATUS,
    LOCALITY;
    
    public String getString(ResultSet rs) throws SQLException {
      return rs.getString(this.toString());
    }
    
    public int getInt(ResultSet rs) throws SQLException {
      return rs.getInt(this.toString());
    }
    
    public long getLong(ResultSet rs) throws SQLException {
      return rs.getLong(this.toString());
    }
    
    public static String join() {
      String[] tmp = new String[TaskAttemptFields.values().length];
      for (int i = 0; i < tmp.length; i++)
        tmp[i] = TaskAttemptFields.values()[i].toString();
      return StringUtils.join(tmp, ",");
    }
  }
  
  public static final String TASK_ATTEMPT_FIELDS = TaskAttemptFields.join();
  
  private String taskAttemptId;
  private String taskType;
  private long startTime;
  private long finishTime;
  private long mapFinishTime;
  private long shuffleFinishTime;
  private long sortFinishTime;
  private long inputBytes;
  private long outputBytes;
  private String status;
  private String locality;
  
  public TaskAttempt() {}
  
  public String getTaskAttemptId() {
    return taskAttemptId;
  }
  
  public void setTaskAttemptId(String taskAttemptId) {
    this.taskAttemptId = taskAttemptId;
  }
  
  public String getTaskType() {
    return taskType;
  }
  
  public void setTaskType(String taskType) {
    this.taskType = taskType;
  }
  
  public long getStartTime() {
    return startTime;
  }
  
  public void setStartTime(long startTime) {
    this.startTime = startTime;
  }
  
  public long getFinishTime() {
    return finishTime;
  }
  
  public void setFinishTime(long finishTime) {
    this.finishTime = finishTime;
  }
  
  public long getMapFinishTime() {
    return mapFinishTime;
  }
  
  public void setMapFinishTime(long mapFinishTime) {
    this.mapFinishTime = mapFinishTime;
  }
  
  public long getShuffleFinishTime() {
    return shuffleFinishTime;
  }
  
  public void setShuffleFinishTime(long shuffleFinishTime) {
    this.shuffleFinishTime = shuffleFinishTime;
  }
  
  public long getSortFinishTime() {
    return sortFinishTime;
  }
  
  public void setSortFinishTime(long sortFinishTime) {
    this.sortFinishTime = sortFinishTime;
  }
  
  public long getInputBytes() {
    return inputBytes;
  }

  public long getOutputBytes() {
    return outputBytes;
  }

  public void setInputBytes(long inputBytes) {
    this.inputBytes = inputBytes;
  }

  public void setOutputBytes(long outputBytes) {
    this.outputBytes = outputBytes;
  }

  public String getStatus() {
    return status;
  }
  
  public void setStatus(String status) {
    this.status = status;
  }
  
  public String getLocality() {
    return locality;
  }
  
  public void setLocality(String locality) {
    this.locality = locality;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/model/TaskData.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.eventdb.model;

import java.util.List;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;

@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class TaskData {
  private List<Point> map;
  private List<Point> shuffle;
  private List<Point> reduce;
  
  public static class Point {
    private long x;
    private int y;
    
    public Point() {}
    
    public Point(long x, int y) {
      this.x = x;
      this.y = y;
    }
    
    public long getX() {
      return x;
    }
    
    public int getY() {
      return y;
    }
    
    public void setX(long x) {
      this.x = x;
    }
    
    public void setY(int y) {
      this.y = y;
    }
  }
  
  public TaskData() {}
  
  public List<Point> getMapData() {
    return map;
  }
  
  public void setMapData(List<Point> mapData) {
    this.map = mapData;
  }
  
  public List<Point> getShuffleData() {
    return shuffle;
  }
  
  public void setShuffleData(List<Point> shuffleData) {
    this.shuffle = shuffleData;
  }
  
  public List<Point> getReduceData() {
    return reduce;
  }
  
  public void setReduceData(List<Point> reduceData) {
    this.reduce = reduceData;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/model/TaskLocalityData.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.eventdb.model;

import java.util.List;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;

@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class TaskLocalityData {
  private List<DataPoint> mapNodeLocal;
  private List<DataPoint> mapRackLocal;
  private List<DataPoint> mapOffSwitch;
  private List<DataPoint> reduceOffSwitch;
  private long submitTime;
  private long finishTime;
  
  public static class DataPoint {
    private long x;
    private long y;
    private long r;
    private long io;
    private String label;
    private String status;
    
    public DataPoint() {}
    
    public DataPoint(long x) {
      this(x, 0, 0, 0, null, null);
    }
    
    public DataPoint(long x, long y, long r, long io, String taskAttemptId, String status) {
      this.x = x;
      this.y = y;
      this.r = r;
      this.io = io;
      this.label = taskAttemptId;
      this.status = status;
    }
    
    public long getX() {
      return x;
    }
    
    public long getY() {
      return y;
    }
    
    public long getR() {
      return r;
    }
    
    public long getIO() {
      return io;
    }
    
    public String getLabel() {
      return label;
    }
    
    public String getStatus() {
      return status;
    }
    
    public void setX(long x) {
      this.x = x;
    }
    
    public void setY(long y) {
      this.y = y;
    }
    
    public void setR(long r) {
      this.r = r;
    }
    
    public void setIO(long io) {
      this.io = io;
    }
    
    public void setLabel(String label) {
      this.label = label;
    }
    
    public void setStatus(String status) {
      this.status = status;
    }
  }
  
  public TaskLocalityData() {}
  
  public List<DataPoint> getMapNodeLocal() {
    return mapNodeLocal;
  }
  
  public void setMapNodeLocal(List<DataPoint> mapNodeLocal) {
    this.mapNodeLocal = mapNodeLocal;
  }
  
  public List<DataPoint> getMapRackLocal() {
    return mapRackLocal;
  }
  
  public void setMapRackLocal(List<DataPoint> mapRackLocal) {
    this.mapRackLocal = mapRackLocal;
  }
  
  public List<DataPoint> getMapOffSwitch() {
    return mapOffSwitch;
  }
  
  public void setMapOffSwitch(List<DataPoint> mapOffSwitch) {
    this.mapOffSwitch = mapOffSwitch;
  }
  
  public List<DataPoint> getReduceOffSwitch() {
    return reduceOffSwitch;
  }
  
  public void setReduceOffSwitch(List<DataPoint> reduceOffSwitch) {
    this.reduceOffSwitch = reduceOffSwitch;
  }
  
  public long getSubmitTime() {
    return submitTime;
  }
  
  public void setSubmitTime(long submitTime) {
    this.submitTime = submitTime;
  }
  
  public long getFinishTime() {
    return finishTime;
  }
  
  public void setFinishTime(long finishTime) {
    this.finishTime = finishTime;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/model/WorkflowContext.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.eventdb.model;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;


@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class WorkflowContext {
  
  private String workflowId;
  private String workflowName;
  private String workflowEntityName;
  
  private WorkflowDag workflowDag;
  
  private WorkflowContext parentWorkflowContext;
  
  public WorkflowContext() {
    /* Required by JAXB. */
  }
  
  /* Getters. */
  public String getWorkflowId() {
    return this.workflowId;
  }
  
  public String getWorkflowName() {
    return this.workflowName;
  }
  
  public String getWorkflowEntityName() {
    return this.workflowEntityName;
  }
  
  public WorkflowDag getWorkflowDag() {
    return this.workflowDag;
  }
  
  public WorkflowContext getParentWorkflowContext() {
    return this.parentWorkflowContext;
  }
  
  /* Setters. */
  public void setWorkflowId(String wfId) {
    this.workflowId = wfId;
  }
  
  public void setWorkflowName(String wfName) {
    this.workflowName = wfName;
  }
  
  public void setWorkflowEntityName(String wfEntityName) {
    this.workflowEntityName = wfEntityName;
  }
  
  public void setWorkflowDag(WorkflowDag wfDag) {
    this.workflowDag = wfDag;
  }
  
  public void setParentWorkflowContext(WorkflowContext pWfContext) {
    this.parentWorkflowContext = pWfContext;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/model/WorkflowDag.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.eventdb.model;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;

@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class WorkflowDag {
  
  public static class WorkflowDagEntry {
    
    private String source;
    private List<String> targets = new ArrayList<String>();
    
    public WorkflowDagEntry() {
      /* Required by JAXB. */
    }
    
    /* Getters. */
    public String getSource() {
      return this.source;
    }
    
    public List<String> getTargets() {
      return this.targets;
    }
    
    /* Setters. */
    public void setSource(String source) {
      this.source = source;
    }
    
    public void setTargets(List<String> targets) {
      this.targets = targets;
    }
    
    public void addTarget(String target) {
      this.targets.add(target);
    }
  }
  
  List<WorkflowDagEntry> entries = new ArrayList<WorkflowDagEntry>();
  
  public WorkflowDag() {
    /* Required by JAXB. */
  }
  
  /* Getters. */
  public List<WorkflowDagEntry> getEntries() {
    return this.entries;
  }
  
  /* Setters. */
  public void setEntries(List<WorkflowDagEntry> entries) {
    this.entries = entries;
  }
  
  public void addEntry(WorkflowDag.WorkflowDagEntry entry) {
    this.entries.add(entry);
  }
  
  public int size() {
    Set<String> nodes = new HashSet<String>();
    for (WorkflowDagEntry entry : entries) {
      nodes.add(entry.getSource());
      nodes.addAll(entry.getTargets());
    }
    return nodes.size();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/model/Workflows.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.eventdb.model;

import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.List;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlTransient;

import org.apache.ambari.eventdb.model.DataTable.Summary;
import org.apache.commons.lang.StringUtils;

@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class Workflows {
  List<WorkflowDBEntry> workflows;
  Summary summary;
  
  public static class WorkflowDBEntry {
    public static enum WorkflowFields {
      WORKFLOWID,
      WORKFLOWNAME,
      USERNAME,
      STARTTIME,
      LASTUPDATETIME,
      DURATION,
      NUMJOBSTOTAL,
      NUMJOBSCOMPLETED,
      INPUTBYTES,
      OUTPUTBYTES,
      PARENTWORKFLOWID,
      WORKFLOWCONTEXT;
      
      public String getString(ResultSet rs) throws SQLException {
        return rs.getString(this.toString());
      }
      
      public int getInt(ResultSet rs) throws SQLException {
        return rs.getInt(this.toString());
      }
      
      public long getLong(ResultSet rs) throws SQLException {
        return rs.getLong(this.toString());
      }
      
      public static String join() {
        String[] tmp = new String[WorkflowFields.values().length];
        for (int i = 0; i < tmp.length; i++)
          tmp[i] = WorkflowFields.values()[i].toString();
        return StringUtils.join(tmp, ",");
      }
    }
    
    @XmlTransient
    public static final String WORKFLOW_FIELDS = WorkflowFields.join();
    
    private String workflowId;
    private String workflowName;
    private String userName;
    private long startTime;
    private long elapsedTime;
    private long inputBytes;
    private long outputBytes;
    private int numJobsTotal;
    private int numJobsCompleted;
    private String parentWorkflowId;
    private WorkflowContext workflowContext;
    
    public WorkflowDBEntry() {
      /* Required by JAXB. */
    }
    
    public String getWorkflowId() {
      return workflowId;
    }
    
    public String getWorkflowName() {
      return workflowName;
    }
    
    public String getUserName() {
      return userName;
    }
    
    public long getStartTime() {
      return startTime;
    }
    
    public long getElapsedTime() {
      return elapsedTime;
    }
    
    public int getNumJobsTotal() {
      return numJobsTotal;
    }
    
    public int getNumJobsCompleted() {
      return numJobsCompleted;
    }
    
    public String getParentWorkflowId() {
      return parentWorkflowId;
    }
    
    public WorkflowContext getWorkflowContext() {
      return workflowContext;
    }
    
    public void setWorkflowId(String workflowId) {
      this.workflowId = workflowId;
    }
    
    public void setWorkflowName(String workflowName) {
      this.workflowName = workflowName;
    }
    
    public void setUserName(String userName) {
      this.userName = userName;
    }
    
    public void setStartTime(long startTime) {
      this.startTime = startTime;
    }
    
    public void setElapsedTime(long elapsedTime) {
      this.elapsedTime = elapsedTime;
    }
    
    public void setNumJobsTotal(int numJobsTotal) {
      this.numJobsTotal = numJobsTotal;
    }
    
    public void setNumJobsCompleted(int numJobsCompleted) {
      this.numJobsCompleted = numJobsCompleted;
    }
    
    public void setParentWorkflowId(String parentWorkflowId) {
      this.parentWorkflowId = parentWorkflowId;
    }
    
    public void setWorkflowContext(WorkflowContext workflowContext) {
      this.workflowContext = workflowContext;
    }
    
    public long getInputBytes() {
      return inputBytes;
    }
    
    public void setInputBytes(long inputBytes) {
      this.inputBytes = inputBytes;
    }
    
    public long getOutputBytes() {
      return outputBytes;
    }
    
    public void setOutputBytes(long outputBytes) {
      this.outputBytes = outputBytes;
    }
  }
  
  public Workflows() {}
  
  public List<WorkflowDBEntry> getWorkflows() {
    return workflows;
  }
  
  public void setWorkflows(List<WorkflowDBEntry> workflows) {
    this.workflows = workflows;
  }
  
  public Summary getSummary() {
    return summary;
  }
  
  public void setSummary(Summary summary) {
    this.summary = summary;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/webservice/JAXBContextResolver.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.eventdb.webservice;

import javax.ws.rs.core.MediaType;
import javax.ws.rs.ext.Provider;

import org.codehaus.jackson.jaxrs.JacksonJaxbJsonProvider;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.map.annotate.JsonSerialize.Inclusion;

@Provider
public class JAXBContextResolver extends JacksonJaxbJsonProvider {
  public JAXBContextResolver() {
    super();
  }
  
  @Override
  public ObjectMapper locateMapper(Class<?> type, MediaType mediaType) {
    ObjectMapper mapper = super.locateMapper(type, mediaType);
    mapper.setSerializationInclusion(Inclusion.NON_NULL);
    return mapper;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/eventdb/webservice/WorkflowJsonService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.eventdb.webservice;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.Set;
import java.util.TreeSet;

import javax.servlet.ServletContext;
import javax.ws.rs.DefaultValue;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.QueryParam;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.MediaType;

import org.apache.ambari.eventdb.db.PostgresConnector;
import org.apache.ambari.eventdb.model.DataTable;
import org.apache.ambari.eventdb.model.Jobs;
import org.apache.ambari.eventdb.model.Jobs.JobDBEntry;
import org.apache.ambari.eventdb.model.TaskAttempt;
import org.apache.ambari.eventdb.model.TaskData;
import org.apache.ambari.eventdb.model.TaskData.Point;
import org.apache.ambari.eventdb.model.TaskLocalityData;
import org.apache.ambari.eventdb.model.TaskLocalityData.DataPoint;
import org.apache.ambari.eventdb.model.Workflows;
import org.apache.ambari.eventdb.model.Workflows.WorkflowDBEntry;
import org.apache.ambari.eventdb.model.Workflows.WorkflowDBEntry.WorkflowFields;

@Path("/jobhistory")
public class WorkflowJsonService {
  private static final String PREFIX = "eventdb.";
  private static final String HOSTNAME = PREFIX + "db.hostname";
  private static final String DBNAME = PREFIX + "db.name";
  private static final String USERNAME = PREFIX + "db.user";
  private static final String PASSWORD = PREFIX + "db.password";
  
  private static final String DEFAULT_HOSTNAME = "localhost";
  private static final String DEFAULT_DBNAME = "ambarirca";
  private static final String DEFAULT_USERNAME = "mapred";
  private static final String DEFAULT_PASSWORD = "mapred";
  
  private static final Workflows EMPTY_WORKFLOWS = new Workflows();
  private static final List<JobDBEntry> EMPTY_JOBS = Collections.emptyList();
  {
    List<WorkflowDBEntry> emptyWorkflows = Collections.emptyList();
    EMPTY_WORKFLOWS.setWorkflows(emptyWorkflows);
  }
  
  PostgresConnector getConnector() throws IOException {
    return new PostgresConnector(DEFAULT_HOSTNAME, DEFAULT_DBNAME, DEFAULT_USERNAME, DEFAULT_PASSWORD);
  }
  
  @Context
  ServletContext servletContext;
  
  @GET
  @Produces(MediaType.APPLICATION_JSON)
  @Path("/workflow")
  public Workflows getWorkflows(@QueryParam("orderBy") String field, @DefaultValue(PostgresConnector.SORT_ASC) @QueryParam("sortDir") String sortDir,
      @DefaultValue("0") @QueryParam("offset") int offset, @DefaultValue("-1") @QueryParam("limit") int limit) {
    Workflows workflows = EMPTY_WORKFLOWS;
    PostgresConnector conn = null;
    try {
      conn = getConnector();
      if (field == null)
        workflows = conn.fetchWorkflows();
      else {
        field = field.toUpperCase();
        if ("ELAPSEDTIME".equals(field))
          field = "DURATION";
        workflows = conn.fetchWorkflows(WorkflowFields.valueOf(field), sortDir.toUpperCase().equals(PostgresConnector.SORT_ASC), offset, limit);
      }
    } catch (IOException e) {
      e.printStackTrace();
      workflows = EMPTY_WORKFLOWS;
    } finally {
      if (conn != null) {
        conn.close();
      }
    }
    return workflows;
  }
  
  @GET
  @Produces(MediaType.APPLICATION_JSON)
  @Path("/datatable")
  public DataTable getWorkflowDataTable(@DefaultValue("0") @QueryParam("iDisplayStart") int start,
      @DefaultValue("10") @QueryParam("iDisplayLength") int amount, @QueryParam("sSearch") String searchTerm, @DefaultValue("0") @QueryParam("sEcho") int echo,
      @DefaultValue("0") @QueryParam("iSortCol_0") int col, @DefaultValue(PostgresConnector.SORT_ASC) @QueryParam("sSortDir_0") String sdir,
      @QueryParam("sSearch_0") String workflowId, @QueryParam("sSearch_1") String workflowName, @QueryParam("sSearch_2") String workflowType,
      @QueryParam("sSearch_3") String userName, @DefaultValue("-1") @QueryParam("minJobs") int minJobs, @DefaultValue("-1") @QueryParam("maxJobs") int maxJobs,
      @DefaultValue("-1") @QueryParam("minInputBytes") long minInputBytes, @DefaultValue("-1") @QueryParam("maxInputBytes") long maxInputBytes,
      @DefaultValue("-1") @QueryParam("minOutputBytes") long minOutputBytes, @DefaultValue("-1") @QueryParam("maxOutputBytes") long maxOutputBytes,
      @DefaultValue("-1") @QueryParam("minDuration") long minDuration, @DefaultValue("-1") @QueryParam("maxDuration") long maxDuration,
      @DefaultValue("-1") @QueryParam("minStartTime") long minStartTime, @DefaultValue("-1") @QueryParam("maxStartTime") long maxStartTime) {
    
    if (start < 0)
      start = 0;
    if (amount < 10 || amount > 100)
      amount = 10;
    
    boolean sortAscending = true;
    if (!sdir.toUpperCase().equals(PostgresConnector.SORT_ASC))
      sortAscending = false;
    
    WorkflowFields field = null;
    switch (col) {
      case 0: // workflowId
        field = WorkflowFields.WORKFLOWID;
        break;
      case 1: // workflowName
        field = WorkflowFields.WORKFLOWNAME;
        break;
      case 2: // workflowType
        field = WorkflowFields.WORKFLOWID;
        break;
      case 3: // userName
        field = WorkflowFields.USERNAME;
        break;
      case 4: // numJobsTotal
        field = WorkflowFields.NUMJOBSTOTAL;
        break;
      case 5: // inputBytes
        field = WorkflowFields.INPUTBYTES;
        break;
      case 6: // outputBytes
        field = WorkflowFields.OUTPUTBYTES;
        break;
      case 7: // duration
        field = WorkflowFields.DURATION;
        break;
      case 8: // startTime
        field = WorkflowFields.STARTTIME;
        break;
      default:
        field = WorkflowFields.WORKFLOWID;
    }
    
    DataTable table = null;
    PostgresConnector conn = null;
    try {
      conn = getConnector();
      table = conn.fetchWorkflows(start, amount, searchTerm, echo, field, sortAscending, workflowId, workflowName, workflowType, userName, minJobs, maxJobs,
          minInputBytes, maxInputBytes, minOutputBytes, maxOutputBytes, minDuration, maxDuration, minStartTime, maxStartTime);
    } catch (IOException e) {
      e.printStackTrace();
    } finally {
      if (conn != null) {
        conn.close();
      }
    }
    return table;
  }
  
  @GET
  @Produces(MediaType.APPLICATION_JSON)
  @Path("/job")
  public Jobs getJobs(@QueryParam("workflowId") String workflowId) {
    Jobs jobs = new Jobs();
    PostgresConnector conn = null;
    try {
      conn = getConnector();
      jobs.setJobs(conn.fetchJobDetails(workflowId));
    } catch (IOException e) {
      e.printStackTrace();
      jobs.setJobs(EMPTY_JOBS);
    } finally {
      if (conn != null) {
        conn.close();
      }
    }
    return jobs;
  }
  
  @GET
  @Produces(MediaType.APPLICATION_JSON)
  @Path("/task")
  public TaskData getTaskDetails(@QueryParam("jobId") String jobId, @QueryParam("width") int steps) {
    TaskData points = new TaskData();
    PostgresConnector conn = null;
    try {
      conn = getConnector();
      long[] times = conn.fetchJobStartStopTimes(jobId);
      if (times != null) {
        double submitTimeSecs = times[0] / 1000.0;
        double finishTimeSecs = times[1] / 1000.0;
        double step = (finishTimeSecs - submitTimeSecs) / steps;
        if (step < 1)
          step = 1;
        getMapDetails(conn, points, jobId, submitTimeSecs, finishTimeSecs, step);
        getReduceDetails(conn, points, jobId, submitTimeSecs, finishTimeSecs, step);
      }
    } catch (IOException e) {
      e.printStackTrace();
    } finally {
      if (conn != null) {
        conn.close();
      }
    }
    return points;
  }
  
  @GET
  @Produces(MediaType.APPLICATION_JSON)
  @Path("/tasklocality")
  public TaskLocalityData getTaskLocalityDetails(@QueryParam("jobId") String jobId, @DefaultValue("4") @QueryParam("minr") int minr,
      @DefaultValue("24") @QueryParam("maxr") int maxr) {
    if (maxr < minr)
      maxr = minr;
    TaskLocalityData data = new TaskLocalityData();
    PostgresConnector conn = null;
    try {
      conn = getConnector();
      long[] times = conn.fetchJobStartStopTimes(jobId);
      if (times != null) {
        getTaskAttemptsByLocality(conn, jobId, times[0], times[1], data, minr, maxr);
      }
    } catch (IOException e) {
      e.printStackTrace();
    } finally {
      if (conn != null) {
        conn.close();
      }
    }
    return data;
  }
  
  private static void getMapDetails(PostgresConnector conn, TaskData points, String jobId, double submitTimeSecs, double finishTimeSecs, double step)
      throws IOException {
    List<TaskAttempt> taskAttempts = conn.fetchTaskAttempts(jobId, "MAP");
    List<Point> mapPoints = new ArrayList<Point>();
    for (double time = submitTimeSecs; time < finishTimeSecs; time += step) {
      int numTasks = 0;
      for (TaskAttempt taskAttempt : taskAttempts)
        if ((taskAttempt.getStartTime() / 1000.0) <= (time + step) && (taskAttempt.getFinishTime() / 1000.0) >= time)
          numTasks++;
      mapPoints.add(new Point(Math.round(time), numTasks));
    }
    points.setMapData(mapPoints);
  }
  
  private static void getReduceDetails(PostgresConnector conn, TaskData points, String jobId, double submitTimeSecs, double finishTimeSecs, double step)
      throws IOException {
    List<TaskAttempt> taskAttempts = conn.fetchTaskAttempts(jobId, "REDUCE");
    List<Point> shufflePoints = new ArrayList<Point>();
    List<Point> reducePoints = new ArrayList<Point>();
    for (double time = submitTimeSecs; time < finishTimeSecs; time += step) {
      int numShuffleTasks = 0;
      int numReduceTasks = 0;
      for (TaskAttempt taskAttempt : taskAttempts) {
        if ((taskAttempt.getStartTime() / 1000.0) <= (time + step) && (taskAttempt.getShuffleFinishTime() / 1000.0) >= time) {
          numShuffleTasks++;
        } else if ((taskAttempt.getShuffleFinishTime() / 1000.0) < (time + step) && (taskAttempt.getFinishTime() / 1000.0) >= time) {
          numReduceTasks++;
        }
      }
      shufflePoints.add(new Point(Math.round(time), numShuffleTasks));
      reducePoints.add(new Point(Math.round(time), numReduceTasks));
    }
    points.setShuffleData(shufflePoints);
    points.setReduceData(reducePoints);
  }
  
  private static void getTaskAttemptsByLocality(PostgresConnector conn, String jobId, long submitTime, long finishTime, TaskLocalityData data, int minr,
      int maxr) throws IOException {
    long submitTimeX = transformX(submitTime);
    long finishTimeX = transformX(finishTime);
    List<TaskAttempt> mapAttempts = conn.fetchTaskAttempts(jobId, "MAP");
    List<TaskAttempt> reduceAttempts = conn.fetchTaskAttempts(jobId, "REDUCE");
    Set<Long> xPoints = getXPoints(mapAttempts, reduceAttempts, submitTimeX, finishTimeX);
    Long[] xList = xPoints.toArray(new Long[xPoints.size()]);
    MinMax io = new MinMax();
    data.setMapNodeLocal(processLocalityData(mapAttempts, "NODE_LOCAL", xList, io));
    data.setMapRackLocal(processLocalityData(mapAttempts, "RACK_LOCAL", xList, io));
    data.setMapOffSwitch(processLocalityData(mapAttempts, "OFF_SWITCH", xList, io));
    data.setReduceOffSwitch(processLocalityData(reduceAttempts, "OFF_SWITCH", xList, io));
    setRValues(data.getMapNodeLocal(), minr, maxr, io.max);
    setRValues(data.getMapRackLocal(), minr, maxr, io.max);
    setRValues(data.getMapOffSwitch(), minr, maxr, io.max);
    setRValues(data.getReduceOffSwitch(), minr, maxr, io.max);
    data.setSubmitTime(submitTimeX);
    data.setFinishTime(finishTimeX);
  }
  
  private static class MinMax {
    private long min = Long.MAX_VALUE;
    private long max = 0;
  }
  
  private static long transformX(long time) {
    return Math.round(time / 1000.0);
  }
  
  private static long untransformX(long x) {
    return x * 1000;
  }
  
  private static long transformY(long time) {
    return time;
  }
  
  private static Set<Long> getXPoints(List<TaskAttempt> mapAttempts, List<TaskAttempt> reduceAttempts, long submitTimeX, long finishTimeX) {
    TreeSet<Long> xPoints = new TreeSet<Long>();
    TreeSet<TaskAttempt> sortedAttempts = new TreeSet<TaskAttempt>(new Comparator<TaskAttempt>() {
      @Override
      public int compare(TaskAttempt t1, TaskAttempt t2) {
        if (t1.getStartTime() < t2.getStartTime())
          return -1;
        else if (t1.getStartTime() > t2.getStartTime())
          return 1;
        return t1.getTaskAttemptId().compareTo(t2.getTaskAttemptId());
      }
    });
    sortedAttempts.addAll(mapAttempts);
    sortedAttempts.addAll(reduceAttempts);
    getXPoints(sortedAttempts, xPoints);
    xPoints.add(submitTimeX);
    xPoints.add(finishTimeX);
    return xPoints;
  }
  
  private static void getXPoints(Iterable<TaskAttempt> taskAttempts, Set<Long> xPoints) {
    for (TaskAttempt taskAttempt : taskAttempts) {
      long x = transformX(taskAttempt.getStartTime());
      while (xPoints.contains(x))
        x += 1;
      xPoints.add(x);
      taskAttempt.setStartTime(untransformX(x));
    }
  }
  
  private static int addDataPoint(List<DataPoint> data, DataPoint point, int index, Long[] xPoints) {
    while (index < xPoints.length) {
      if (point.getX() == xPoints[index]) {
        index++;
        break;
      } else if (point.getX() > xPoints[index]) {
        data.add(new DataPoint(xPoints[index++]));
      }
    }
    data.add(point);
    return index;
  }
  
  private static List<DataPoint> processLocalityData(List<TaskAttempt> taskAttempts, String locality, Long[] xPoints, MinMax io) {
    List<DataPoint> data = new ArrayList<DataPoint>();
    int i = 0;
    for (TaskAttempt taskAttempt : taskAttempts) {
      if (locality.equals(taskAttempt.getLocality())) {
        DataPoint point = new DataPoint();
        point.setX(transformX(taskAttempt.getStartTime()));
        point.setY(transformY(taskAttempt.getFinishTime() - taskAttempt.getStartTime()));
        point.setIO(taskAttempt.getInputBytes() + taskAttempt.getOutputBytes());
        point.setLabel(taskAttempt.getTaskAttemptId());
        point.setStatus(taskAttempt.getStatus());
        i = addDataPoint(data, point, i, xPoints);
        io.max = Math.max(io.max, point.getIO());
        io.min = Math.min(io.min, point.getIO());
      }
    }
    while (i < xPoints.length)
      data.add(new DataPoint(xPoints[i++]));
    return data;
  }
  
  private static void setRValues(List<DataPoint> data, int minr, int maxr, long maxIO) {
    for (DataPoint point : data) {
      if (point.getY() == 0) {
        continue;
      }
      if (maxIO == 0 || maxr == minr) {
        point.setR(minr);
        continue;
      }
      point.setR(Math.round(Math.sqrt(point.getIO() * 1.0 / maxIO) * (maxr - minr) + minr));
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/AmbariException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

import java.io.IOException;

@SuppressWarnings("serial")
public class AmbariException extends IOException {

  public AmbariException(String message) {
    super(message);
  }

  public AmbariException(String message, Throwable cause) {
    super(message, cause);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/ClusterNotFoundException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

@SuppressWarnings("serial")
public class ClusterNotFoundException extends ObjectNotFoundException {

  public ClusterNotFoundException(String clusterName) {
    super("Cluster not found, clusterName=" + clusterName);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/DuplicateResourceException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

/**
 * Thrown when an attempt is made to create an already existing resource.
 */
public class DuplicateResourceException extends AmbariException {

  /**
   * Constructor.
   *
   * @param message  message
   */
  public DuplicateResourceException(String message) {
    super(message);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/HostNotFoundException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

@SuppressWarnings("serial")
public class HostNotFoundException extends ObjectNotFoundException {

  public HostNotFoundException(String hostname) {
    super("Host not found, hostname=" + hostname);
  }

  public HostNotFoundException(String clusterName, String hostname) {
    super("Host not found, cluster=" + clusterName + ", hostname=" + hostname);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/ObjectNotFoundException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

@SuppressWarnings("serial")
public class ObjectNotFoundException extends AmbariException {

  public ObjectNotFoundException(String message) {
    super(message);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/ParentObjectNotFoundException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

/**
 * Indicates that a parent of a resource doesn't exist.
 */
public class ParentObjectNotFoundException extends AmbariException {

  /**
   * Constructor.
   *
   * @param msg    message
   * @param cause  the root cause
   */
  public ParentObjectNotFoundException(String msg, ObjectNotFoundException cause) {
    super(msg + ".  " + cause.getMessage(), cause);
  }

  /**
   * Constructor.
   *
   * @param message message
   */
  public ParentObjectNotFoundException(String message) {
    super(message);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/Role.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

//This enumerates all the roles that the server can handle.
//Each component or a job maps to a particular role.
public enum Role {
  ZOOKEEPER_SERVER,
  ZOOKEEPER_CLIENT,
  NAMENODE,
  NAMENODE_SERVICE_CHECK,
  DATANODE,
  HDFS_SERVICE_CHECK,
  SECONDARY_NAMENODE,
  HDFS_CLIENT,
  HBASE_MASTER,
  HBASE_REGIONSERVER,
  HBASE_CLIENT,
  JOBTRACKER,
  TASKTRACKER,
  MAPREDUCE_CLIENT,
  JAVA_JCE,
  KERBEROS_SERVER,
  KERBEROS_CLIENT,
  KERBEROS_ADMIN_CLIENT,
  HADOOP_CLIENT,
  JOBTRACKER_SERVICE_CHECK,
  MAPREDUCE_SERVICE_CHECK,
  ZOOKEEPER_SERVICE_CHECK,
  ZOOKEEPER_QUORUM_SERVICE_CHECK,
  HBASE_SERVICE_CHECK,
  MYSQL_SERVER,
  HIVE_SERVER,
  HIVE_METASTORE,
  HIVE_CLIENT,
  HIVE_SERVICE_CHECK,
  HCAT,
  HCAT_SERVICE_CHECK,
  OOZIE_CLIENT,
  OOZIE_SERVER,
  OOZIE_SERVICE_CHECK,
  PIG,
  PIG_SERVICE_CHECK,
  SQOOP,
  SQOOP_SERVICE_CHECK,
  WEBHCAT_SERVER,
  WEBHCAT_SERVICE_CHECK,
  DASHBOARD,
  DASHBOARD_SERVICE_CHECK,
  NAGIOS_SERVER,
  GANGLIA_SERVER,
  GANGLIA_MONITOR,
  GMOND_SERVICE_CHECK,
  GMETAD_SERVICE_CHECK,
  MONTOR_WEBSERVER,
  DECOMMISSION_DATANODE
}
"
ambari-server/src/main/java/org/apache/ambari/server/RoleCommand.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server;

public enum RoleCommand {
  INSTALL,
  UNINSTALL,
  START,
  STOP,
  EXECUTE,
  ABORT
}
"
ambari-server/src/main/java/org/apache/ambari/server/ServiceComponentHostNotFoundException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

@SuppressWarnings("serial")
public class ServiceComponentHostNotFoundException
    extends ObjectNotFoundException {

  public ServiceComponentHostNotFoundException(String clusterName,
      String serviceName, String serviceComponentName, String hostName) {
    super("ServiceComponentHost not found"
        + ", clusterName=" + clusterName
        + ", serviceName=" + serviceName
        + ", serviceComponentName=" + serviceComponentName
        + ", hostName=" + hostName);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/ServiceComponentNotFoundException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

@SuppressWarnings("serial")
public class ServiceComponentNotFoundException
    extends ObjectNotFoundException {

  public ServiceComponentNotFoundException (String clusterName,
      String serviceName, String serviceComponentName) {
    super("ServiceComponent not found"
        + ", clusterName=" + clusterName
        + ", serviceName=" + serviceName
        + ", serviceComponentName=" + serviceComponentName);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/ServiceNotFoundException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

@SuppressWarnings("serial")
public class ServiceNotFoundException extends ObjectNotFoundException {

  public ServiceNotFoundException(String clusterName, String serviceName) {
    super("Service not found"
        + ", clusterName=" + clusterName
        + ", serviceName=" + serviceName);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/StackNotFoundException.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server;

@SuppressWarnings("serial")
public class StackNotFoundException extends ObjectNotFoundException {

  public StackNotFoundException (String stackName,
      String stackVersion) {
    super("Stack Information not found"
        + ", stackName=" + stackName
        + ", stackVersion=" + stackVersion);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionDBAccessor.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import java.util.Collection;
import java.util.List;
import java.util.Set;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.agent.CommandReport;

public interface ActionDBAccessor {

  public Stage getAction(String actionId);

  public List<Stage> getAllStages(long requestId);

  public void abortOperation(long requestId);

  public void timeoutHostRole(String host, long requestId, long stageId, Role role);

  /**
   * Returns all the pending stages, including queued and not-queued.
   * A stage is considered in progress if it is in progress for any host.
   */
  public List<Stage> getStagesInProgress();

  public void persistActions(List<Stage> stages);

  public void updateHostRoleState(String hostname, long requestId,
      long stageId, String role, CommandReport report);

  public void abortHostRole(String host, long requestId, long stageId,
      Role role);

  /**
   * Return the last persisted Request ID as seen when the DBAccessor object
   * was initialized.
   * Value should remain unchanged through the lifetime of the object instance.
   * @return Request Id seen at init time
   */
  public long getLastPersistedRequestIdWhenInitialized();

  /**
   * Updates scheduled stage.
   * @param s
   * @param hostname
   * @param roleStr
   */
  public void hostRoleScheduled(Stage s, String hostname, String roleStr);

  public List<HostRoleCommand> getRequestTasks(long requestId);

  public List<HostRoleCommand> getAllTasksByRequestIds(Collection<Long> requestIds);

  public List<HostRoleCommand> getTasksByRequestAndTaskIds(Collection<Long> requestIds, Collection<Long> taskIds);

  public Collection<HostRoleCommand> getTasks(Collection<Long> taskIds);

  public List<Stage> getStagesByHostRoleStatus(Set<HostRoleStatus> statuses);

  public List<Long> getRequests();

  public HostRoleCommand getTask(long taskId);

  public List<Long> getRequestsByStatus(RequestStatus status);
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionDBAccessorImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import java.util.*;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.Role;
import org.apache.ambari.server.agent.CommandReport;
import org.apache.ambari.server.orm.dao.ClusterDAO;
import org.apache.ambari.server.orm.dao.ExecutionCommandDAO;
import org.apache.ambari.server.orm.dao.HostDAO;
import org.apache.ambari.server.orm.dao.HostRoleCommandDAO;
import org.apache.ambari.server.orm.dao.RoleSuccessCriteriaDAO;
import org.apache.ambari.server.orm.dao.StageDAO;
import org.apache.ambari.server.orm.entities.ClusterEntity;
import org.apache.ambari.server.orm.entities.ExecutionCommandEntity;
import org.apache.ambari.server.orm.entities.HostEntity;
import org.apache.ambari.server.orm.entities.HostRoleCommandEntity;
import org.apache.ambari.server.orm.entities.RoleSuccessCriteriaEntity;
import org.apache.ambari.server.orm.entities.StageEntity;
import org.apache.ambari.server.state.Cluster;
import org.apache.ambari.server.state.Clusters;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.Singleton;
import com.google.inject.persist.Transactional;

@Singleton
public class ActionDBAccessorImpl implements ActionDBAccessor {
  private static final Logger LOG = LoggerFactory.getLogger(ActionDBAccessorImpl.class);

  @Inject
  private ClusterDAO clusterDAO;
  @Inject
  private HostDAO hostDAO;
  @Inject
  private StageDAO stageDAO;
  @Inject
  private HostRoleCommandDAO hostRoleCommandDAO;
  @Inject
  private ExecutionCommandDAO executionCommandDAO;
  @Inject
  private RoleSuccessCriteriaDAO roleSuccessCriteriaDAO;
  @Inject
  private StageFactory stageFactory;
  @Inject
  private HostRoleCommandFactory hostRoleCommandFactory;
  @Inject
  private Clusters clusters;

  private final long requestId;

  @Inject
  public ActionDBAccessorImpl(Injector injector) {
    injector.injectMembers(this);
    requestId = stageDAO.getLastRequestId();


  }

  /* (non-Javadoc)
   * @see org.apache.ambari.server.actionmanager.ActionDBAccessor#getAction(java.lang.String)
   */
  @Override
  public Stage getAction(String actionId) {
    return stageFactory.createExisting(actionId);
  }

  /* (non-Javadoc)
   * @see org.apache.ambari.server.actionmanager.ActionDBAccessor#getAllStages(java.lang.String)
   */
  @Override
  public List<Stage> getAllStages(long requestId) {
    List<Stage> stages = new ArrayList<Stage>();
    for (StageEntity stageEntity : stageDAO.findByRequestId(requestId)) {
      stages.add(stageFactory.createExisting(stageEntity));
    }
    return stages;
  }

  /* (non-Javadoc)
   * @see org.apache.ambari.server.actionmanager.ActionDBAccessor#abortOperation(long)
   */
  @Override
  public void abortOperation(long requestId) {
    Collection<HostRoleStatus> sourceStatuses =
        Arrays.asList(HostRoleStatus.QUEUED, HostRoleStatus.IN_PROGRESS,
            HostRoleStatus.PENDING);
    int result = hostRoleCommandDAO.updateStatusByRequestId(requestId,
        HostRoleStatus.ABORTED, sourceStatuses);
    LOG.info("Aborted {} commands " + result);
  }

  /* (non-Javadoc)
   * @see org.apache.ambari.server.actionmanager.ActionDBAccessor#timeoutHostRole(long, long, org.apache.ambari.server.Role)
   */
  @Override
  @Transactional
  public void timeoutHostRole(String host, long requestId, long stageId,
      Role role) {
    List<HostRoleCommandEntity> commands =
        hostRoleCommandDAO.findByHostRole(host, requestId, stageId, role);
    for (HostRoleCommandEntity command : commands) {
      command.setStatus(HostRoleStatus.TIMEDOUT);
      hostRoleCommandDAO.merge(command);
    }
  }

  /* (non-Javadoc)
   * @see org.apache.ambari.server.actionmanager.ActionDBAccessor#getPendingStages()
   */
  @Override
  public List<Stage> getStagesInProgress() {
    List<Stage> stages = new ArrayList<Stage>();
    List<HostRoleStatus> statuses =
        Arrays.asList(HostRoleStatus.QUEUED, HostRoleStatus.IN_PROGRESS,
            HostRoleStatus.PENDING);
    for (StageEntity stageEntity : stageDAO.findByCommandStatuses(statuses)) {
      stages.add(stageFactory.createExisting(stageEntity));
    }
    return stages;
  }

  /* (non-Javadoc)
   * @see org.apache.ambari.server.actionmanager.ActionDBAccessor#persistActions(java.util.List)
   */
  @Override
  @Transactional
  public void persistActions(List<Stage> stages) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding stages to DB, stageCount=" + stages.size());
    }
    for (Stage stage : stages) {
      StageEntity stageEntity = stage.constructNewPersistenceEntity();
      Cluster cluster;
      try {
        cluster = clusters.getCluster(stage.getClusterName());
      } catch (AmbariException e) {
        throw new RuntimeException(e);
      }
      ClusterEntity clusterEntity = clusterDAO.findById(cluster.getClusterId());

      stageEntity.setCluster(clusterEntity);
      clusterEntity.getStages().add(stageEntity);

      for (HostRoleCommand hostRoleCommand : stage.getOrderedHostRoleCommands()) {
        HostRoleCommandEntity hostRoleCommandEntity = hostRoleCommand.constructNewPersistenceEntity();
        stageEntity.getHostRoleCommands().add(hostRoleCommandEntity);
        hostRoleCommandEntity.setStage(stageEntity);

        HostEntity hostEntity = hostDAO.findByName(hostRoleCommandEntity.getHostName());
        if (hostEntity == null) {
          LOG.error("Host {} doesn't exists in database" + hostRoleCommandEntity.getHostName());
          throw new RuntimeException("Host '"+hostRoleCommandEntity.getHostName()+"' doesn't exists in database");
        }
        hostEntity.getHostRoleCommandEntities().add(hostRoleCommandEntity);
        hostRoleCommandEntity.setHost(hostEntity);
        hostRoleCommandDAO.create(hostRoleCommandEntity);

        assert hostRoleCommandEntity.getTaskId() != null;

        hostRoleCommand.setTaskId(hostRoleCommandEntity.getTaskId());
        ExecutionCommandEntity executionCommandEntity = hostRoleCommand.constructExecutionCommandEntity();
        executionCommandEntity.setHostRoleCommand(hostRoleCommandEntity);
        hostRoleCommandEntity.setExecutionCommand(executionCommandEntity);

        executionCommandDAO.create(hostRoleCommandEntity.getExecutionCommand());
        hostRoleCommandDAO.merge(hostRoleCommandEntity);
        hostDAO.merge(hostEntity);
      }

      for (RoleSuccessCriteriaEntity roleSuccessCriteriaEntity : stageEntity.getRoleSuccessCriterias()) {
        roleSuccessCriteriaDAO.create(roleSuccessCriteriaEntity);
      }

      stageDAO.create(stageEntity);
      clusterDAO.merge(clusterEntity);
    }
  }

  @Override
  @Transactional
  public void updateHostRoleState(String hostname, long requestId,
      long stageId, String role, CommandReport report) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Update HostRoleState: "
          + "HostName " + hostname + " requestId " + requestId + " stageId "
          + stageId + " role " + role + " report " + report);
    }
    List<HostRoleCommandEntity> commands = hostRoleCommandDAO.findByHostRole(
        hostname, requestId, stageId, Role.valueOf(role));
    for (HostRoleCommandEntity command : commands) {
      command.setStatus(HostRoleStatus.valueOf(report.getStatus()));
      command.setStdOut(report.getStdOut().getBytes());
      command.setStdError(report.getStdErr().getBytes());
      command.setExitcode(report.getExitCode());
      hostRoleCommandDAO.merge(command);
    }
  }

  @Override
  public void abortHostRole(String host, long requestId, long stageId, Role role) {
    CommandReport report = new CommandReport();
    report.setExitCode(999);
    report.setStdErr("Host Role in invalid state");
    report.setStdOut("");
    report.setStatus("ABORTED");
    updateHostRoleState(host, requestId, stageId, role.toString(), report);
  }

  @Override
  public long getLastPersistedRequestIdWhenInitialized() {
    return requestId;
  }

  @Override
  @Transactional
  public void hostRoleScheduled(Stage s, String hostname, String roleStr) {
    HostRoleCommand hostRoleCommand = s.getHostRoleCommand(hostname, roleStr);
    HostRoleCommandEntity entity = hostRoleCommandDAO.findByPK(hostRoleCommand.getTaskId());
    if (entity != null) {
      entity.setStartTime(hostRoleCommand.getStartTime());
      entity.setLastAttemptTime(hostRoleCommand.getLastAttemptTime());
      entity.setStatus(hostRoleCommand.getStatus());
      entity.setAttemptCount(hostRoleCommand.getAttemptCount());
      hostRoleCommandDAO.merge(entity);
    } else {
      throw new RuntimeException("HostRoleCommand is not persisted, cannot update:\n" + hostRoleCommand);
    }

  }

  @Override
  public List<HostRoleCommand> getRequestTasks(long requestId) {
    List<HostRoleCommand> tasks = new ArrayList<HostRoleCommand>();
    for (HostRoleCommandEntity hostRoleCommandEntity : hostRoleCommandDAO.findByRequest(requestId)) {
      tasks.add(hostRoleCommandFactory.createExisting(hostRoleCommandEntity));
    }
    return tasks;
  }

  @Override
  public List<HostRoleCommand> getAllTasksByRequestIds(Collection<Long> requestIds) {
    if (requestIds.isEmpty()) {
      return Collections.emptyList();
    }
    List<HostRoleCommand> tasks = new ArrayList<HostRoleCommand>();
    for (HostRoleCommandEntity hostRoleCommandEntity : hostRoleCommandDAO.findByRequestIds(requestIds)) {
      tasks.add(hostRoleCommandFactory.createExisting(hostRoleCommandEntity));
    }
    return tasks;
  }

  @Override
  public List<HostRoleCommand> getTasksByRequestAndTaskIds(Collection<Long> requestIds, Collection<Long> taskIds) {
    if (!requestIds.isEmpty() && !taskIds.isEmpty()) {
      List<HostRoleCommand> tasks = new ArrayList<HostRoleCommand>();
      for (HostRoleCommandEntity hostRoleCommandEntity : hostRoleCommandDAO.findByRequestAndTaskIds(requestIds, taskIds)) {
        tasks.add(hostRoleCommandFactory.createExisting(hostRoleCommandEntity));
      }
      return tasks;
    }else if (requestIds.isEmpty()) {
      return getTasks(taskIds);
    }else if (taskIds.isEmpty()) {
      return getAllTasksByRequestIds(requestIds);
    } else {
      return Collections.emptyList();
    }
  }

  @Override
  public List<HostRoleCommand> getTasks(Collection<Long> taskIds) {
    if (taskIds.isEmpty()) {
      return Collections.emptyList();
    }
    List<HostRoleCommand> commands = new ArrayList<HostRoleCommand>();
    for (HostRoleCommandEntity commandEntity : hostRoleCommandDAO.findByPKs(taskIds)) {
      commands.add(hostRoleCommandFactory.createExisting(commandEntity));
    }
    return commands;
  }

  @Override
  public List<Stage> getStagesByHostRoleStatus(Set<HostRoleStatus> statuses) {
    List<Stage> stages = new ArrayList<Stage>();
    for (StageEntity stageEntity : stageDAO.findByCommandStatuses(statuses)) {
      stages.add(stageFactory.createExisting(stageEntity));
    }
    return stages;
  }

  @Override
  public List<Long> getRequests() {
    return hostRoleCommandDAO.getRequests();
  }

  public HostRoleCommand getTask(long taskId) {
    HostRoleCommandEntity commandEntity = hostRoleCommandDAO.findByPK((int)taskId);
    if (commandEntity == null) {
      return null;
    }
    return hostRoleCommandFactory.createExisting(commandEntity);
  }

  @Override
  public List<Long> getRequestsByStatus(RequestStatus status) {
    boolean match = true;
    Set<HostRoleStatus> statuses = new HashSet<HostRoleStatus>();
    if (status == RequestStatus.IN_PROGRESS) {
      statuses.addAll( Arrays.asList(HostRoleStatus.PENDING,
          HostRoleStatus.IN_PROGRESS, HostRoleStatus.QUEUED));
    } else if (status == RequestStatus.COMPLETED) {
      match = false;
      statuses.addAll( Arrays.asList(HostRoleStatus.PENDING,
          HostRoleStatus.IN_PROGRESS, HostRoleStatus.QUEUED,
          HostRoleStatus.ABORTED, HostRoleStatus.FAILED,
          HostRoleStatus.FAILED, HostRoleStatus.TIMEDOUT));
    } else if (status == RequestStatus.FAILED) {
      statuses.addAll( Arrays.asList(HostRoleStatus.ABORTED,
          HostRoleStatus.FAILED, HostRoleStatus.FAILED,
          HostRoleStatus.TIMEDOUT));
    }
    return hostRoleCommandDAO.getRequestsByTaskStatus(statuses, match);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionDBInMemoryImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import java.util.*;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.agent.CommandReport;
import org.apache.ambari.server.agent.ExecutionCommand;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Singleton;

@Singleton
public class ActionDBInMemoryImpl implements ActionDBAccessor {

  // for a persisted DB, this will be initialized in the ctor
  // with the highest persisted requestId value in the DB
  private final long lastRequestId = 0;
  private static Logger LOG = LoggerFactory.getLogger(ActionDBInMemoryImpl.class);
  List<Stage> stageList = new ArrayList<Stage>();

  @Override
  public synchronized Stage getAction(String actionId) {
    for (Stage s: stageList) {
      if (s.getActionId().equals(actionId)) {
        return s;
      }
    }
    return null;
  }
  @Override
  public synchronized List<Stage> getAllStages(long requestId) {
    List<Stage> l = new ArrayList<Stage>();
    for (Stage s: stageList) {
      if (s.getRequestId() == requestId) {
        l.add(s);
      }
    }
    return l;
  }

  @Override
  public synchronized void abortOperation(long requestId) {
    for (Stage s : stageList) {
      if (s.getRequestId() == requestId) {
        for (String host : s.getHostRoleCommands().keySet()) {
          Map<String, HostRoleCommand> roleCommands = s.getHostRoleCommands().get(host);
          for (String role : roleCommands.keySet()) {
            HostRoleCommand cmd = roleCommands.get(role);
            HostRoleStatus status = s.getHostRoleStatus(host, cmd.getRole()
                .toString());
            if (status.equals(HostRoleStatus.IN_PROGRESS)
                || status.equals(HostRoleStatus.QUEUED)
                || status.equals(HostRoleStatus.PENDING)) {
              s.setHostRoleStatus(host, cmd.getRole().toString(),
                  HostRoleStatus.ABORTED);
            }
          }
        }
      }
    }
  }

  @Override
  public synchronized void timeoutHostRole(String host, long requestId,
      long stageId, Role role) {
    for (Stage s : stageList) {
      s.setHostRoleStatus(host, role.toString(), HostRoleStatus.TIMEDOUT);
    }
  }

  @Override
  public synchronized List<Stage> getStagesInProgress() {
    List<Stage> l = new ArrayList<Stage>();
    for (Stage s: stageList) {
      if (s.isStageInProgress()) {
        l.add(s);
      }
    }
    return l;
  }

  @Override
  public synchronized void persistActions(List<Stage> stages) {
    for (Stage s: stages) {
      stageList.add(s);
    }
  }
  @Override
  public synchronized void updateHostRoleState(String hostname, long requestId,
      long stageId, String role, CommandReport report) {
    LOG.info("DEBUG stages to iterate: "+stageList.size());
    for (Stage s : stageList) {
      if (s.getRequestId() == requestId && s.getStageId() == stageId) {
        s.setHostRoleStatus(hostname, role,
            HostRoleStatus.valueOf(report.getStatus()));
        s.setExitCode(hostname, role, report.getExitCode());
        s.setStderr(hostname, role, report.getStdErr());
        s.setStdout(hostname, role, report.getStdOut());
      }
    }
  }

  @Override
  public void abortHostRole(String host, long requestId, long stageId, Role role) {
    CommandReport report = new CommandReport();
    report.setExitCode(999);
    report.setStdErr("Host Role in invalid state");
    report.setStdOut("");
    report.setStatus("ABORTED");
    updateHostRoleState(host, requestId, stageId, role.toString(), report);
  }

  @Override
  public synchronized long getLastPersistedRequestIdWhenInitialized() {
    return lastRequestId;
  }

  @Override
  public void hostRoleScheduled(Stage s, String hostname, String roleStr) {
    //Nothing needed for in-memory implementation
  }

  @Override
  public List<HostRoleCommand> getRequestTasks(long requestId) {
    return null;
  }

  @Override
  public List<HostRoleCommand> getAllTasksByRequestIds(Collection<Long> requestIds) {
    //TODO not implemented
    return null;
  }

  @Override
  public List<HostRoleCommand> getTasksByRequestAndTaskIds(Collection<Long> requestIds, Collection<Long> taskIds) {
    //TODO not implemented
    return null;
  }

  @Override
  public Collection<HostRoleCommand> getTasks(Collection<Long> taskIds) {
    return null;
  }

  @Override
  public List<Stage> getStagesByHostRoleStatus(Set<HostRoleStatus> statuses) {
    List<Stage> l = new ArrayList<Stage>();
    for (Stage s: stageList) {
      if (s.doesStageHaveHostRoleStatus(statuses)) {
        l.add(s);
      }
    }
    return l;
  }
  @Override
  public synchronized List<Long> getRequests() {
    Set<Long> requestIds = new HashSet<Long>();
    for (Stage s: stageList) {
      requestIds.add(s.getRequestId());
    }
    List<Long> ids = new ArrayList<Long>();
    ids.addAll(requestIds);
    return ids;
  }

  public HostRoleCommand getTask(long taskId) {
    for (Stage s : stageList) {
      for (String host : s.getHostRoleCommands().keySet()) {
        Map<String, HostRoleCommand> map = s.getHostRoleCommands().get(host);
        for (HostRoleCommand hostRoleCommand : map.values()) {
          if (hostRoleCommand.getTaskId() == taskId) {
            return hostRoleCommand;
          }
        }
      }
    }
    return null;
  }
  @Override
  public List<Long> getRequestsByStatus(RequestStatus status) {
    // TODO
    throw new RuntimeException("Functionality not implemented");
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionManager.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import java.util.Collection;
import java.util.List;
import java.util.Set;
import java.util.concurrent.atomic.AtomicLong;

import org.apache.ambari.server.agent.ActionQueue;
import org.apache.ambari.server.agent.CommandReport;
import org.apache.ambari.server.controller.HostsMap;
import org.apache.ambari.server.state.Clusters;
import org.apache.ambari.server.utils.StageUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Inject;
import com.google.inject.Singleton;
import com.google.inject.name.Named;


/**
 * This class acts as the interface for action manager with other components.
 */
@Singleton
public class ActionManager {
  private final ActionScheduler scheduler;
  private final ActionDBAccessor db;
  private final ActionQueue actionQueue;
  private final HostsMap hostsMap;
  private static Logger LOG = LoggerFactory.getLogger(ActionManager.class);
  private final AtomicLong requestCounter;

  @Inject
  public ActionManager(@Named("schedulerSleeptime") long schedulerSleepTime,
      @Named("actionTimeout") long actionTimeout,
      ActionQueue aq, Clusters fsm, ActionDBAccessor db, HostsMap hostsMap) {
    this.actionQueue = aq;
    this.db = db;
    this.hostsMap = hostsMap;
    scheduler = new ActionScheduler(schedulerSleepTime, actionTimeout, db,
        actionQueue, fsm, 2, hostsMap);
    requestCounter = new AtomicLong(
        db.getLastPersistedRequestIdWhenInitialized());
  }

  public void start() {
    LOG.info("Starting scheduler thread");
    scheduler.start();
  }

  public void shutdown() {
    scheduler.stop();
  }

  public void sendActions(List<Stage> stages) {
    
    for (Stage s: stages) {
      LOG.info("Persisting stage into db: " + s.toString());
    }
    db.persistActions(stages);
  }

  public List<Stage> getRequestStatus(long requestId) {
    return db.getAllStages(requestId);
  }

  public Stage getAction(long requestId, long stageId) {
    return db.getAction(StageUtils.getActionId(requestId, stageId));
  }

  public void processTaskResponse(String hostname, List<CommandReport> reports) {
    if (reports == null) {
      return;
    }
    //persist the action response into the db.
    for (CommandReport report : reports) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Processing command report : " + report.toString());
      }
      String actionId = report.getActionId();
      long [] requestStageIds = StageUtils.getRequestStage(actionId);
      long requestId = requestStageIds[0];
      long stageId = requestStageIds[1];
      HostRoleCommand command = db.getTask(report.getTaskId());
      if (command == null) {
        LOG.warn("The task " + report.getTaskId()
            + " is invalid");
        continue;
      }
      if (!command.getStatus().equals(HostRoleStatus.IN_PROGRESS)
          && !command.getStatus().equals(HostRoleStatus.QUEUED)) {
        LOG.warn("The task " + command.getTaskId()
            + " is not in progress, ignoring update");
        continue;
      }
      db.updateHostRoleState(hostname, requestId, stageId, report.getRole(),
          report);
    }
  }

  public void handleLostHost(String host) {
    //Do nothing, the task will timeout anyway.
    //The actions can be failed faster as an optimization
    //if action timeout happens to be much larger than
    //heartbeat timeout.
  }

  public long getNextRequestId() {
    return requestCounter.incrementAndGet();
  }

  public List<HostRoleCommand> getRequestTasks(long requestId) {
    return db.getRequestTasks(requestId);
  }

  public List<HostRoleCommand> getAllTasksByRequestIds(Collection<Long> requestIds) {
    return db.getAllTasksByRequestIds(requestIds);
  }

  public List<HostRoleCommand> getTasksByRequestAndTaskIds(Collection<Long> requestIds, Collection<Long> taskIds) {
    return db.getTasksByRequestAndTaskIds(requestIds, taskIds);
  }

  public Collection<HostRoleCommand> getTasks(Collection<Long> taskIds) {
    return db.getTasks(taskIds);
  }

  public List<Stage> getRequestsByHostRoleStatus(Set<HostRoleStatus> statuses) {
    return db.getStagesByHostRoleStatus(statuses);
  }

  /**
   * Returns last 20 requests
   * @return
   */
  public List<Long> getRequests() {
    return db.getRequests();
  }

  /**
   * Returns last 20 requests
   * @return
   */
  public List<Long> getRequestsByStatus(RequestStatus status) {
    return db.getRequestsByStatus(status);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ActionScheduler.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.TreeMap;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.Role;
import org.apache.ambari.server.ServiceComponentNotFoundException;
import org.apache.ambari.server.agent.ActionQueue;
import org.apache.ambari.server.agent.ExecutionCommand;
import org.apache.ambari.server.controller.HostsMap;
import org.apache.ambari.server.state.Cluster;
import org.apache.ambari.server.state.Clusters;
import org.apache.ambari.server.state.Service;
import org.apache.ambari.server.state.ServiceComponent;
import org.apache.ambari.server.state.ServiceComponentHost;
import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostOpFailedEvent;
import org.apache.ambari.server.utils.StageUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

//This class encapsulates the action scheduler thread.
//Action schedule frequently looks at action database and determines if
//there is an action that can be scheduled.
class ActionScheduler implements Runnable {

  private static Logger LOG = LoggerFactory.getLogger(ActionScheduler.class);
  private final long actionTimeout;
  private final long sleepTime;
  private volatile boolean shouldRun = true;
  private Thread schedulerThread = null;
  private final ActionDBAccessor db;
  private final short maxAttempts;
  private final ActionQueue actionQueue;
  private final Clusters fsmObject;
  private boolean taskTimeoutAdjustment = true;
  private final HostsMap hostsMap;

  public ActionScheduler(long sleepTimeMilliSec, long actionTimeoutMilliSec,
      ActionDBAccessor db, ActionQueue actionQueue, Clusters fsmObject,
      int maxAttempts, HostsMap hostsMap) {
    this.sleepTime = sleepTimeMilliSec;
    this.hostsMap = hostsMap;
    this.actionTimeout = actionTimeoutMilliSec;
    this.db = db;
    this.actionQueue = actionQueue;
    this.fsmObject = fsmObject;
    this.maxAttempts = (short) maxAttempts;
  }

  public void start() {
    schedulerThread = new Thread(this);
    schedulerThread.start();
  }

  public void stop() {
    shouldRun = false;
    schedulerThread.interrupt();
  }

  @Override
  public void run() {
    while (shouldRun) {
      try {
        Thread.sleep(sleepTime);
        doWork();
      } catch (InterruptedException ex) {
        LOG.warn("Scheduler thread is interrupted going to stop", ex);
        shouldRun = false;
      } catch (Exception ex) {
        LOG.warn("Exception received", ex);
      } catch (Throwable t) {
        LOG.warn("ERROR", t);
      }
    }
  }

  private void doWork() throws AmbariException {
    List<Stage> stages = db.getStagesInProgress();
    if (LOG.isDebugEnabled()) {
      LOG.debug("Scheduler wakes up");
    }
    if (stages == null || stages.isEmpty()) {
      //Nothing to do
      if (LOG.isDebugEnabled()) {
        LOG.debug("No stage in progress..nothing to do");
      }
      return;
    }

    for (Stage s : stages) {
      List<ExecutionCommand> commandsToSchedule = new ArrayList<ExecutionCommand>();
      Map<String, RoleStats> roleStats = processInProgressStage(s, commandsToSchedule);
      //Check if stage is failed
      boolean failed = false;
      for (String role : roleStats.keySet()) {
        RoleStats stats = roleStats.get(role);
        if (LOG.isDebugEnabled()) {
          LOG.debug("Stats for role:"+role+", stats="+stats);
        }
        if (stats.isRoleFailed()) {
          failed = true;
          break;
        }
      }
      if (failed) {
        LOG.warn("Operation completely failed, borting request id:"
            + s.getRequestId());
        db.abortOperation(s.getRequestId());
        return;
      }

      //Schedule what we have so far
      for (ExecutionCommand cmd : commandsToSchedule) {
        try {
          scheduleHostRole(s, cmd);
        } catch (InvalidStateTransitionException e) {
          LOG.warn("Could not schedule host role "+cmd.toString(), e);
          db.abortHostRole(cmd.getHostname(), s.getRequestId(), s.getStageId(),
              cmd.getRole());
        }
      }

      //Check if ready to go to next stage
      boolean goToNextStage = true;
      for (String role: roleStats.keySet()) {
        RoleStats stats = roleStats.get(role);
        if (!stats.isSuccessFactorMet()) {
          goToNextStage = false;
          break;
        }
      }
      if (!goToNextStage) {
        return;
      }
    }
  }

  /**
   * @param commandsToSchedule
   * @return Stats for the roles in the stage. It is used to determine whether stage
   * has succeeded or failed.
   */
  private Map<String, RoleStats> processInProgressStage(Stage s,
      List<ExecutionCommand> commandsToSchedule) {
    // Map to track role status
    Map<String, RoleStats> roleStats = initRoleStats(s);
    long now = System.currentTimeMillis();
    long taskTimeout = actionTimeout;
    if (taskTimeoutAdjustment) {
      taskTimeout = actionTimeout + s.getTaskTimeout();
    }
    for (String host : s.getHosts()) {
      List<ExecutionCommandWrapper> commandWrappers = s.getExecutionCommands(host);
      for(ExecutionCommandWrapper wrapper : commandWrappers) {
        ExecutionCommand c = wrapper.getExecutionCommand();
        String roleStr = c.getRole().toString();
        HostRoleStatus status = s.getHostRoleStatus(host, roleStr);
        if (timeOutActionNeeded(status, s, host, roleStr, now, taskTimeout)) {
          LOG.info("Host:" + host + ", role:" + roleStr + ", actionId:"
              + s.getActionId() + " timed out");
          if (s.getAttemptCount(host, roleStr) >= maxAttempts) {
            LOG.warn("Host:" + host + ", role:" + roleStr + ", actionId:"
                + s.getActionId() + " expired");
            db.timeoutHostRole(host, s.getRequestId(), s.getStageId(),
                c.getRole());
            //Reinitialize status
            status = s.getHostRoleStatus(host, roleStr);
            ServiceComponentHostOpFailedEvent timeoutEvent =
                new ServiceComponentHostOpFailedEvent(roleStr,
                    host, now);
            try {
              Cluster cluster = fsmObject.getCluster(s.getClusterName());
              Service svc = cluster.getService(c.getServiceName());
              ServiceComponent svcComp = svc.getServiceComponent(
                  roleStr);
              ServiceComponentHost svcCompHost =
                  svcComp.getServiceComponentHost(host);
              svcCompHost.handleEvent(timeoutEvent);
            } catch (ServiceComponentNotFoundException scnex) {
              LOG.info("Not a service component, assuming its an action", scnex);
            } catch (InvalidStateTransitionException e) {
              LOG.info("Transition failed for host: " + host + ", role: "
                  + roleStr, e);
            } catch (AmbariException ex) {
              LOG.warn("Invalid live state", ex);
            }
          } else {
            commandsToSchedule.add(c);
          }
        } else if (status.equals(HostRoleStatus.PENDING)) {
          //Need to schedule first time
          commandsToSchedule.add(c);
        }
        this.updateRoleStats(status, roleStats.get(roleStr));
      }
    }
    return roleStats;
  }

  private Map<String, RoleStats> initRoleStats(Stage s) {
    Map<Role, Integer> hostCountsForRoles = new HashMap<Role, Integer>();
    Map<String, RoleStats> roleStats = new TreeMap<String, RoleStats>();

    for (String host : s.getHostRoleCommands().keySet()) {
      Map<String, HostRoleCommand> roleCommandMap = s.getHostRoleCommands().get(host);
      for (String role : roleCommandMap.keySet()) {
        HostRoleCommand c = roleCommandMap.get(role);
        if (hostCountsForRoles.get(c.getRole()) == null) {
          hostCountsForRoles.put(c.getRole(), 0);
        }
        int val = hostCountsForRoles.get(c.getRole());
        hostCountsForRoles.put(c.getRole(), val + 1);
      }
    }

    for (Role r : hostCountsForRoles.keySet()) {
      RoleStats stats = new RoleStats(hostCountsForRoles.get(r),
          s.getSuccessFactor(r));
      roleStats.put(r.toString(), stats);
    }
    return roleStats;
  }

  private boolean timeOutActionNeeded(HostRoleStatus status, Stage stage,
      String host, String role, long currentTime, long taskTimeout) {
    if (( !status.equals(HostRoleStatus.QUEUED) ) &&
        ( ! status.equals(HostRoleStatus.IN_PROGRESS) )) {
      return false;
    }
    if (currentTime > stage.getLastAttemptTime(host, role)+taskTimeout) {
      return true;
    }
    return false;
  }

  private void scheduleHostRole(Stage s, ExecutionCommand cmd)
      throws InvalidStateTransitionException, AmbariException {
    long now = System.currentTimeMillis();
    String roleStr = cmd.getRole().toString();
    String hostname = cmd.getHostname();
    if (s.getStartTime(hostname, roleStr) < 0) {
      try {
        Cluster c = fsmObject.getCluster(s.getClusterName());
        Service svc = c.getService(cmd.getServiceName());
        ServiceComponent svcComp = svc.getServiceComponent(roleStr);
        ServiceComponentHost svcCompHost =
            svcComp.getServiceComponentHost(hostname);
        svcCompHost.handleEvent(s.getFsmEvent(hostname, roleStr).getEvent());
      } catch (ServiceComponentNotFoundException scnex) {
        LOG.info("Not a service component, assuming its an action", scnex);
      } catch (InvalidStateTransitionException e) {
        LOG.info(
            "Transition failed for host: " + hostname + ", role: "
                + roleStr, e);
        throw e;
      } catch (AmbariException e) {
        LOG.warn("Exception in fsm: " + hostname + ", role: " + roleStr,
            e);
        throw e;
      }
      s.setStartTime(hostname,roleStr, now);
      s.setHostRoleStatus(hostname, roleStr, HostRoleStatus.QUEUED);
    }
    s.setLastAttemptTime(hostname, roleStr, now);
    s.incrementAttemptCount(hostname, roleStr);
    LOG.info("Scheduling command: "+cmd.toString()+" for host: "+hostname);
    /** change the hostname in the command for the host itself **/
    cmd.setHostname(hostsMap.getHostMap(hostname));
    actionQueue.enqueue(hostname, cmd);
    db.hostRoleScheduled(s, hostname, roleStr);
  }

  private void updateRoleStats(HostRoleStatus status, RoleStats rs) {
    switch (status) {
    case COMPLETED:
      rs.numSucceeded++;
      break;
    case FAILED:
      rs.numFailed++;
      break;
    case QUEUED:
      rs.numQueued++;
      break;
    case PENDING:
      rs.numPending++;
      break;
    case TIMEDOUT:
      rs.numTimedOut++;
      break;
    case ABORTED:
      rs.numAborted++;
      break;
    case IN_PROGRESS:
      rs.numInProgress++;
      break;
    default:
      LOG.error("Unknown status " + status.name());
    }
  }
  
  
  public void setTaskTimeoutAdjustment(boolean val) {
    this.taskTimeoutAdjustment = val;
  }

  static class RoleStats {
    int numInProgress;
    int numQueued = 0;
    int numSucceeded = 0;
    int numFailed = 0;
    int numTimedOut = 0;
    int numPending = 0;
    int numAborted = 0;
    final int totalHosts;
    final float successFactor;

    RoleStats(int total, float successFactor) {
      this.totalHosts = total;
      this.successFactor = successFactor;
    }

    /**
     * Role successful means the role is successful enough to
     */
    boolean isSuccessFactorMet() {
      int minSuccessNeeded = (int) Math.ceil(successFactor * totalHosts);
      if (minSuccessNeeded <= numSucceeded) {
        return true;
      } else {
        return false;
      }
    }

    private boolean isRoleInProgress() {
      return (numPending+numQueued+numInProgress > 0);
    }

    /**
     * Role failure means role is no longer in progress and success factor is
     * not met.
     */
    boolean isRoleFailed() {
      if (isRoleInProgress() || isSuccessFactorMet()) {
        return false;
      } else {
        return true;
      }
    }

    public String toString() {
      StringBuilder builder = new StringBuilder();
      builder.append("numQueued="+numQueued);
      builder.append(", numInProgress="+numInProgress);
      builder.append(", numSucceeded="+numSucceeded);
      builder.append(", numFailed="+numFailed);
      builder.append(", numTimedOut="+numTimedOut);
      builder.append(", numPending="+numPending);
      builder.append(", numAborted="+numAborted);
      builder.append(", totalHosts="+totalHosts);
      builder.append(", successFactor="+successFactor);
      return builder.toString();
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ExecutionCommandWrapper.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import org.apache.ambari.server.agent.ExecutionCommand;
import org.apache.ambari.server.utils.StageUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import javax.xml.bind.JAXBException;
import java.io.IOException;

public class ExecutionCommandWrapper {
  private static Log LOG = LogFactory.getLog(ExecutionCommandWrapper.class);
  String jsonExecutionCommand = null;
  ExecutionCommand executionCommand = null;

  public ExecutionCommandWrapper(String jsonExecutionCommand) {
    this.jsonExecutionCommand = jsonExecutionCommand;
  }

  public ExecutionCommandWrapper(ExecutionCommand executionCommand) {
    this.executionCommand = executionCommand;
  }

  public ExecutionCommand getExecutionCommand() {
    if (executionCommand != null) {
      return executionCommand;
    } else if (jsonExecutionCommand != null) {
      try {
        executionCommand = StageUtils.stringToExecutionCommand(jsonExecutionCommand);
        return executionCommand;
      } catch (IOException e) {
        throw new RuntimeException(e);
      }
    } else {
      throw new RuntimeException(
          "Invalid ExecutionCommandWrapper, both object and string"
              + " representations are null");
    }
  }

  public String getJson() {
    if (jsonExecutionCommand != null) {
      return jsonExecutionCommand;
    } else if (executionCommand != null) {
      try {
        jsonExecutionCommand = StageUtils.jaxbToString(executionCommand);
        return jsonExecutionCommand;
      } catch (JAXBException e) {
        throw new RuntimeException(e);
      } catch (IOException e) {
        throw new RuntimeException(e);
      }
    } else {
      throw new RuntimeException(
          "Invalid ExecutionCommandWrapper, both object and string"
              + " representations are null");
    }
  }

  @Override
  public boolean equals(Object o) {
    if (this == o)
      return true;
    if (o == null || getClass() != o.getClass())
      return false;

    ExecutionCommandWrapper wrapper = (ExecutionCommandWrapper) o;
    
    if (executionCommand != null && wrapper.executionCommand != null) {
      return executionCommand.equals(wrapper.executionCommand);
    } else {
      return getJson().equals(wrapper.getJson());
    }
  }

  @Override
  public int hashCode() {
    if (executionCommand != null) {
      return executionCommand.hashCode();
    } else if (jsonExecutionCommand != null) {
      return jsonExecutionCommand.hashCode();
    }
    throw new RuntimeException("Invalid Wrapper object");
  }

  void invalidateJson() {
    if (executionCommand == null) {
      throw new RuntimeException("Invalid Wrapper object");
    }
    jsonExecutionCommand = null;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/HostAction.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import java.util.ArrayList;
import java.util.List;

import org.apache.ambari.server.agent.ExecutionCommand;
import org.apache.ambari.server.utils.StageUtils;

/**
 * Encapsulates entire task for a host for a stage or action. This class
 * contains all the information to generate an
 * {@link org.apache.ambari.server.agent.ExecutionCommand} that will be
 * scheduled for a host.
 */
public class HostAction {
  private final String host;
  private List<HostRoleCommand> roles;
  private long startTime = -1;
  private long lastAttemptTime = -1;
  private short attemptCount = 0;

  /**
   * This object will be serialized and sent to the agent.
   */
  private ExecutionCommand commandToHost;

  public String getManifest() {
    //generate manifest
    return null;
  }

  public HostAction(String host) {
    this.host = host;
    roles = new ArrayList<HostRoleCommand>();
    commandToHost = new ExecutionCommand();
    commandToHost.setHostname(host);
  }

  public HostAction(HostAction ha) {
    this.host = ha.host;
    this.roles = ha.roles;
    this.startTime = ha.startTime;
    this.lastAttemptTime = ha.lastAttemptTime;
    this.attemptCount = ha.attemptCount;
    this.commandToHost = ha.commandToHost;
  }

  public void addHostRoleCommand(HostRoleCommand cmd) {
    roles.add(cmd);
  }

  public List<HostRoleCommand> getRoleCommands() {
    return roles;
  }

  public long getStartTime() {
    return startTime;
  }

  public long getLastAttemptTime() {
    return this.lastAttemptTime;
  }

  public void setLastAttemptTime(long t) {
    this.lastAttemptTime = t;
  }

  public void incrementAttemptCount() {
    this.attemptCount ++;
  }

  public short getAttemptCount() {
    return this.attemptCount;
  }

  public ExecutionCommand getCommandToHost() {
    return this.commandToHost;
  }

  public synchronized void setCommandId(long requestId, long stageId) {
    commandToHost.setCommandId(StageUtils.getActionId(requestId, stageId));
  }

  public void setStartTime(long startTime) {
    this.startTime = startTime;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/HostRoleCommand.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.RoleCommand;
import org.apache.ambari.server.orm.entities.ExecutionCommandEntity;
import org.apache.ambari.server.orm.entities.HostRoleCommandEntity;
import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Injector;
import com.google.inject.assistedinject.Assisted;
import com.google.inject.assistedinject.AssistedInject;

/**
 * This class encapsulates the information for an task on a host for a
 * particular role which action manager needs. It doesn't capture actual
 * command and parameters, but just the stuff enough for action manager to
 * track the request.
 * For the actual command refer {@link HostAction#commandToHost}
 */
public class HostRoleCommand {
  private static final Logger log = LoggerFactory.getLogger(HostRoleCommand.class);

  private long taskId = -1;
  private long stageId = -1;
  private long requestId = -1;
  private String hostName;
  private final Role role;
  private HostRoleStatus status = HostRoleStatus.PENDING;
  private String stdout = "";
  private String stderr = "";
  private int exitCode = 999; //Default is unknown
  private final ServiceComponentHostEventWrapper event;
  private long startTime = -1;
  private long lastAttemptTime = -1;
  private short attemptCount = 0;
  private RoleCommand roleCommand;

  private ExecutionCommandWrapper executionCommandWrapper;

  public HostRoleCommand(String host, Role role,
      ServiceComponentHostEvent event, RoleCommand command) {
    this.hostName = host;
    this.role = role;
    this.event = new ServiceComponentHostEventWrapper(event);
    this.roleCommand = command;
  }

  @AssistedInject
  public HostRoleCommand(@Assisted HostRoleCommandEntity hostRoleCommandEntity, Injector injector) {
    taskId = hostRoleCommandEntity.getTaskId();
    stageId = hostRoleCommandEntity.getStage().getStageId();
    requestId = hostRoleCommandEntity.getStage().getRequestId();
    this.hostName = hostRoleCommandEntity.getHostName();
    role = hostRoleCommandEntity.getRole();
    status = hostRoleCommandEntity.getStatus();
    stdout = new String(hostRoleCommandEntity.getStdOut());
    stderr = new String(hostRoleCommandEntity.getStdError());
    exitCode = hostRoleCommandEntity.getExitcode();
    startTime = hostRoleCommandEntity.getStartTime();
    lastAttemptTime = hostRoleCommandEntity.getLastAttemptTime();
    attemptCount = hostRoleCommandEntity.getAttemptCount();
    roleCommand = hostRoleCommandEntity.getRoleCommand();
    event = new ServiceComponentHostEventWrapper(hostRoleCommandEntity.getEvent());
    executionCommandWrapper = new ExecutionCommandWrapper(new String(
        hostRoleCommandEntity
            .getExecutionCommand().getCommand()
    ));
  }

  HostRoleCommandEntity constructNewPersistenceEntity() {
    HostRoleCommandEntity hostRoleCommandEntity = new HostRoleCommandEntity();
    hostRoleCommandEntity.setHostName(hostName);
    hostRoleCommandEntity.setRole(role);
    hostRoleCommandEntity.setStatus(status);
    hostRoleCommandEntity.setStdError(stderr.getBytes());
    hostRoleCommandEntity.setExitcode(exitCode);
    hostRoleCommandEntity.setStdOut(stdout.getBytes());
    hostRoleCommandEntity.setStartTime(startTime);
    hostRoleCommandEntity.setLastAttemptTime(lastAttemptTime);
    hostRoleCommandEntity.setAttemptCount(attemptCount);
    hostRoleCommandEntity.setRoleCommand(roleCommand);

    hostRoleCommandEntity.setEvent(event.getEventJson());
    ExecutionCommandEntity executionCommandEntity = new ExecutionCommandEntity();
    executionCommandEntity.setCommand(executionCommandWrapper.getJson().getBytes());
    executionCommandEntity.setHostRoleCommand(hostRoleCommandEntity);
    hostRoleCommandEntity.setExecutionCommand(executionCommandEntity);

    return hostRoleCommandEntity;
  }

  ExecutionCommandEntity constructExecutionCommandEntity() {
    ExecutionCommandEntity executionCommandEntity = new ExecutionCommandEntity();
    executionCommandEntity.setCommand(executionCommandWrapper.getJson().getBytes());
    return executionCommandEntity;
  }


  public long getTaskId() {
    return taskId;
  }

  public void setTaskId(long taskId) {
    if (this.taskId != -1) {
      throw new RuntimeException("Attempt to set taskId again, not allowed");
    }
    this.taskId = taskId;
    executionCommandWrapper.getExecutionCommand().setTaskId(taskId);
    //Need to invalidate json because taskId is updated.
    executionCommandWrapper.invalidateJson();
  }

  public String getHostName() {
    return hostName;
  }

  public Role getRole() {
    return role;
  }

  public HostRoleStatus getStatus() {
    return status;
  }

  public ServiceComponentHostEventWrapper getEvent() {
    return event;
  }

  public void setStatus(HostRoleStatus status) {
    this.status = status;
  }

  public String getStdout() {
    return stdout;
  }

  public void setStdout(String stdout) {
    this.stdout = stdout;
  }

  public String getStderr() {
    return stderr;
  }

  public void setStderr(String stderr) {
    this.stderr = stderr;
  }

  public int getExitCode() {
    return exitCode;
  }

  public void setExitCode(int exitCode) {
    this.exitCode = exitCode;
  }

  public long getStartTime() {
    return startTime;
  }

  public void setStartTime(long startTime) {
    this.startTime = startTime;
  }

  public long getLastAttemptTime() {
    return lastAttemptTime;
  }

  public void setLastAttemptTime(long lastAttemptTime) {
    this.lastAttemptTime = lastAttemptTime;
  }

  public short getAttemptCount() {
    return attemptCount;
  }

  public void incrementAttemptCount() {
    this.attemptCount++;
  }

  public ExecutionCommandWrapper getExecutionCommandWrapper() {
    return executionCommandWrapper;
  }

  public void setExecutionCommandWrapper(ExecutionCommandWrapper executionCommandWrapper) {
    this.executionCommandWrapper = executionCommandWrapper;
  }

  public RoleCommand getRoleCommand() {
    return roleCommand;
  }

  public void setRoleCommand(RoleCommand roleCommand) {
    this.roleCommand = roleCommand;
  }

  public long getStageId() {
    return stageId;
  }

  public long getRequestId() {
    return requestId;
  }

  @Override
  public int hashCode() {
    return (hostName.toString() + role.toString() + roleCommand.toString())
        .hashCode();
  }

  @Override
  public boolean equals(Object other) {
    if (!(other instanceof HostRoleCommand)) {
      return false;
    }
    HostRoleCommand o = (HostRoleCommand) other;
    return (this.role.equals(o.role) && this.hostName.equals(o.hostName) && this.roleCommand
        .equals(o.roleCommand));
  }

  @Override
  public String toString() {
    StringBuilder builder = new StringBuilder();
    builder.append("HostRoleCommand State:\n");
    builder.append("  TaskId: ").append(taskId).append("\n");
    builder.append("  Role: ").append(role).append("\n");
    builder.append("  Status: ").append(status).append("\n");
    builder.append("  Event: ").append(event).append("\n");
    builder.append("  stdout: ").append(stdout).append("\n");
    builder.append("  stderr: ").append(stderr).append("\n");
    builder.append("  exitcode: ").append(exitCode).append("\n");
    builder.append("  Start time: ").append(startTime).append("\n");
    builder.append("  Last attempt time: ").append(lastAttemptTime).append("\n");
    builder.append("  attempt count: ").append(attemptCount).append("\n");
    return builder.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/HostRoleCommandFactory.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.actionmanager;

import org.apache.ambari.server.orm.entities.HostRoleCommandEntity;

public interface HostRoleCommandFactory {
  HostRoleCommand createExisting(HostRoleCommandEntity hostRoleCommandEntity);
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/HostRoleStatus.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

public enum HostRoleStatus {
  PENDING, //Not queued for a host
  QUEUED, //Queued for a host
  IN_PROGRESS, //Host reported it is working
  COMPLETED, //Host reported success
  FAILED, //Failed
  TIMEDOUT, //Host did not respond in time
  ABORTED //Operation was abandoned
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/RequestStatus.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.actionmanager;

public enum RequestStatus {
  /// At least, one task is pending/queued or in progress
  IN_PROGRESS,
  /// All tasks are completed
  COMPLETED, 
  /// At least, one task is failed/timed out or aborted
  FAILED
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/ServiceComponentHostEventWrapper.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import java.io.IOException;

import javax.xml.bind.JAXBException;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.utils.StageUtils;

public class ServiceComponentHostEventWrapper {

  private ServiceComponentHostEvent event = null;
  private String eventJson = null;

  public ServiceComponentHostEventWrapper(ServiceComponentHostEvent event) {
    this.event  = event;
  }
  
  public ServiceComponentHostEventWrapper(String eventJson) {
    this.eventJson = eventJson;
  }

  public ServiceComponentHostEvent getEvent() {
    if (event != null) {
      return event;
    } else if (eventJson != null) {
      try {
        event = StageUtils.fromJson(eventJson, ServiceComponentHostEvent.class);
        return event;
      } catch (IOException e) {
        throw new RuntimeException("Illegal Json for event", e);
      }
    }
    return null;
  }
  
  public String getEventJson() { 
    if (eventJson != null) {
      return eventJson;
    } else if (event != null) {
      try {
        eventJson = StageUtils.jaxbToString(event);
        return eventJson;
      } catch (JAXBException e) {
        throw new RuntimeException("Couldn't get json", e);
      } catch (IOException e) {
        throw new RuntimeException("Couldn't get json", e);
      }
    } else {
      return null;
    }
  }
  
  public String toString() {
    if (event != null) {
      return event.toString();
    } else if (eventJson != null) {
      return eventJson;
    }
    return "null";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/Stage.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.actionmanager;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.TreeMap;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.RoleCommand;
import org.apache.ambari.server.agent.ExecutionCommand;
import org.apache.ambari.server.orm.dao.HostDAO;
import org.apache.ambari.server.orm.dao.HostRoleCommandDAO;
import org.apache.ambari.server.orm.dao.StageDAO;
import org.apache.ambari.server.orm.entities.HostEntity;
import org.apache.ambari.server.orm.entities.HostRoleCommandEntity;
import org.apache.ambari.server.orm.entities.RoleSuccessCriteriaEntity;
import org.apache.ambari.server.orm.entities.StageEntity;
import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.utils.StageUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import com.google.inject.Injector;
import com.google.inject.assistedinject.Assisted;
import com.google.inject.assistedinject.AssistedInject;

//This class encapsulates the stage. The stage encapsulates all the information
//required to persist an action.
public class Stage {
  private static Logger LOG = LoggerFactory.getLogger(Stage.class);
  private final long requestId;
  private final String clusterName;
  private long stageId = -1;
  private final String logDir;
  private int taskTimeout = -1;
  private int perTaskTimeFactor = 60000;

  //Map of roles to successFactors for this stage. Default is 1 i.e. 100%
  private Map<Role, Float> successFactors = new HashMap<Role, Float>();

  //Map of host to host-roles
  Map<String, Map<String, HostRoleCommand>> hostRoleCommands =
      new TreeMap<String, Map<String, HostRoleCommand>>();
  private Map<String, List<ExecutionCommandWrapper>> commandsToSend =
      new TreeMap<String, List<ExecutionCommandWrapper>>();

  @AssistedInject
  public Stage(@Assisted long requestId, @Assisted("logDir") String logDir, @Assisted("clusterName") String clusterName) {
    this.requestId = requestId;
    this.logDir = logDir;
    this.clusterName = clusterName;
  }

  /**
   * Creates Stage existing in database
   * @param actionId "requestId-stageId" string
   */
  @AssistedInject
  public Stage(@Assisted String actionId, Injector injector) {
    this(injector.getInstance(StageDAO.class).findByActionId(actionId), injector);
  }

  @AssistedInject
  public Stage(@Assisted StageEntity stageEntity, Injector injector) {
    HostRoleCommandDAO hostRoleCommandDAO = injector.getInstance(HostRoleCommandDAO.class);
    HostDAO hostDAO = injector.getInstance(HostDAO.class);
    HostRoleCommandFactory hostRoleCommandFactory = injector.getInstance(HostRoleCommandFactory.class);

    requestId = stageEntity.getRequestId();
    stageId = stageEntity.getStageId();
    logDir = stageEntity.getLogInfo();
    clusterName = stageEntity.getCluster().getClusterName();

    for (HostEntity hostEntity : hostDAO.findByStage(stageEntity)) {
      List<HostRoleCommandEntity> commands = hostRoleCommandDAO.findSortedCommandsByStageAndHost(stageEntity, hostEntity);
      commandsToSend.put(hostEntity.getHostName(), new ArrayList<ExecutionCommandWrapper>());
      hostRoleCommands.put(hostEntity.getHostName(), new TreeMap<String, HostRoleCommand>());
      for (HostRoleCommandEntity command : commands) {
        HostRoleCommand hostRoleCommand = hostRoleCommandFactory.createExisting(command);
        hostRoleCommands.get(hostEntity.getHostName()).put(hostRoleCommand.getRole().toString(), hostRoleCommand);
        commandsToSend.get(hostEntity.getHostName()).add(hostRoleCommand.getExecutionCommandWrapper());
      }
    }

    for (RoleSuccessCriteriaEntity successCriteriaEntity : stageEntity.getRoleSuccessCriterias()) {
      successFactors.put(successCriteriaEntity.getRole(), successCriteriaEntity.getSuccessFactor().floatValue());
    }
  }

  /**
   * Creates object to be persisted in database
   * @return StageEntity
   */
  public synchronized StageEntity constructNewPersistenceEntity() {
    StageEntity stageEntity = new StageEntity();
    stageEntity.setRequestId(requestId);
    stageEntity.setStageId(getStageId());
    stageEntity.setLogInfo(logDir);
    stageEntity.setHostRoleCommands(new ArrayList<HostRoleCommandEntity>());
    stageEntity.setRoleSuccessCriterias(new ArrayList<RoleSuccessCriteriaEntity>());

    for (Role role : successFactors.keySet()) {
      RoleSuccessCriteriaEntity roleSuccessCriteriaEntity = new RoleSuccessCriteriaEntity();
      roleSuccessCriteriaEntity.setRole(role);
      roleSuccessCriteriaEntity.setStage(stageEntity);
      roleSuccessCriteriaEntity.setSuccessFactor(successFactors.get(role).doubleValue());
      stageEntity.getRoleSuccessCriterias().add(roleSuccessCriteriaEntity);
    }
    return stageEntity;
  }

  public List<HostRoleCommand> getOrderedHostRoleCommands() {
    List<HostRoleCommand> commands = new ArrayList<HostRoleCommand>();
    //TODO trick for proper storing order, check it
    for (String hostName : hostRoleCommands.keySet()) {
      for (ExecutionCommandWrapper executionCommandWrapper : commandsToSend.get(hostName)) {
        for (HostRoleCommand hostRoleCommand : hostRoleCommands.get(hostName).values()) {
          if (hostRoleCommand.getExecutionCommandWrapper() == executionCommandWrapper) {
            commands.add(hostRoleCommand);
          }
        }
      }
    }
    return commands;
  }

  public synchronized void setStageId(long stageId) {
    if (this.stageId != -1) {
      throw new RuntimeException("Attempt to set stageId again! Not allowed.");
    }
    this.stageId = stageId;
    for (String host: this.commandsToSend.keySet()) {
      for (ExecutionCommandWrapper wrapper : this.commandsToSend.get(host)) {
        ExecutionCommand cmd = wrapper.getExecutionCommand();
        cmd.setCommandId(StageUtils.getActionId(requestId, stageId));
      }
    }
  }

  public synchronized long getStageId() {
    return stageId;
  }

  public String getActionId() {
    return StageUtils.getActionId(requestId, getStageId());
  }

  /**
   * A new host role command is created for execution.
   * Creates both ExecutionCommand and HostRoleCommand objects and
   * adds them to the Stage. This should be called only once for a host-role
   * for a given stage.
   */
  public synchronized void addHostRoleExecutionCommand(String host, Role role,  RoleCommand command,
      ServiceComponentHostEvent event, String clusterName, String serviceName) {
    HostRoleCommand hrc = new HostRoleCommand(host, role, event, command);
    ExecutionCommand cmd = new ExecutionCommand();
    ExecutionCommandWrapper wrapper = new ExecutionCommandWrapper(cmd);
    hrc.setExecutionCommandWrapper(wrapper);
    cmd.setHostname(host);
    cmd.setClusterName(clusterName);
    cmd.setServiceName(serviceName);
    cmd.setCommandId(this.getActionId());
    cmd.setRole(role);
    cmd.setRoleCommand(command);
    Map<String, HostRoleCommand> hrcMap = this.hostRoleCommands.get(host);
    if (hrcMap == null) {
      hrcMap = new TreeMap<String, HostRoleCommand>();
      this.hostRoleCommands.put(host, hrcMap);
    }
    if (hrcMap.get(role.toString()) != null) {
      throw new RuntimeException(
          "Setting the host role command second time for same stage: stage="
              + this.getActionId() + ", host=" + host + ", role=" + role);
    }
    hrcMap.put(role.toString(), hrc);
    List<ExecutionCommandWrapper> execCmdList = this.commandsToSend.get(host);
    if (execCmdList == null) {
      execCmdList = new ArrayList<ExecutionCommandWrapper>();
      this.commandsToSend.put(host, execCmdList);
    }

    if (execCmdList.contains(wrapper)) {
      //todo: proper exception
      throw new RuntimeException(
          "Setting the execution command second time for same stage: stage="
              + this.getActionId() + ", host=" + host + ", role=" + role);
    }
    execCmdList.add(wrapper);
  }

  /**
   *
   * @return list of hosts
   */
  public synchronized List<String> getHosts() { // TODO: Check whether method should be synchronized
    List<String> hlist = new ArrayList<String>();
    for (String h : this.hostRoleCommands.keySet()) {
      hlist.add(h);
    }
    return hlist;
  }

  synchronized float getSuccessFactor(Role r) {
    Float f = successFactors.get(r);
    if (f == null) {
      if (r.equals(Role.DATANODE) || r.equals(Role.TASKTRACKER) || r.equals(Role.GANGLIA_MONITOR) ||
          r.equals(Role.HBASE_REGIONSERVER)) {
        return (float) 0.5;
      } else {
        return 1;
      }
    } else {
      return f;
    }
  }

  public synchronized void setSuccessFactors(Map<Role, Float> suc) {
    successFactors = suc;
  }

  public synchronized Map<Role, Float> getSuccessFactors() {
    return successFactors;
  }

  public long getRequestId() {
    return requestId;
  }

  public String getClusterName() {
    return clusterName;
  }

  public long getLastAttemptTime(String host, String role) {
    return this.hostRoleCommands.get(host).get(role).getLastAttemptTime();
  }

  public short getAttemptCount(String host, String role) {
    return this.hostRoleCommands.get(host).get(role).getAttemptCount();
  }

  public void incrementAttemptCount(String hostname, String role) {
    this.hostRoleCommands.get(hostname).get(role).incrementAttemptCount();
  }

  public void setLastAttemptTime(String host, String role, long t) {
    this.hostRoleCommands.get(host).get(role).setLastAttemptTime(t);
  }

  public ExecutionCommandWrapper getExecutionCommandWrapper(String hostname,
      String role) {
    HostRoleCommand hrc = hostRoleCommands.get(hostname).get(role);
    if (hrc != null) {
      return hrc.getExecutionCommandWrapper();
    } else {
      return null;
    }
  }

  public List<ExecutionCommandWrapper> getExecutionCommands(String hostname) {
    return commandsToSend.get(hostname);
  }

  public long getStartTime(String hostname, String role) {
    return this.hostRoleCommands.get(hostname).get(role).getStartTime();
  }

  public void setStartTime(String hostname, String role, long startTime) {
    this.hostRoleCommands.get(hostname).get(role).setStartTime(startTime);
  }

  public HostRoleStatus getHostRoleStatus(String hostname, String role) {
    return this.hostRoleCommands.get(hostname).get(role).getStatus();
  }

  public void setHostRoleStatus(String host, String role,
      HostRoleStatus status) {
    this.hostRoleCommands.get(host).get(role).setStatus(status);
  }

  public ServiceComponentHostEventWrapper getFsmEvent(String hostname, String roleStr) {
    return this.hostRoleCommands.get(hostname).get(roleStr).getEvent();
  }


  public void setExitCode(String hostname, String role, int exitCode) {
    this.hostRoleCommands.get(hostname).get(role).setExitCode(exitCode);
  }

  public int getExitCode(String hostname, String role) {
    return this.hostRoleCommands.get(hostname).get(role).getExitCode();
  }

  public void setStderr(String hostname, String role, String stdErr) {
    this.hostRoleCommands.get(hostname).get(role).setStderr(stdErr);
  }

  public void setStdout(String hostname, String role, String stdOut) {
    this.hostRoleCommands.get(hostname).get(role).setStdout(stdOut);
  }

  public synchronized boolean isStageInProgress() {
    for(String host: hostRoleCommands.keySet()) {
      for (String role : hostRoleCommands.get(host).keySet()) {
        HostRoleCommand hrc = hostRoleCommands.get(host).get(role);
        if (hrc == null) {
          return false;
        }
        if (hrc.getStatus().equals(HostRoleStatus.PENDING) ||
            hrc.getStatus().equals(HostRoleStatus.QUEUED) ||
            hrc.getStatus().equals(HostRoleStatus.IN_PROGRESS)) {
          return true;
        }
      }
    }
    return false;
  }

  public synchronized boolean doesStageHaveHostRoleStatus(
      Set<HostRoleStatus> statuses) {
    for(String host: hostRoleCommands.keySet()) {
      for (String role : hostRoleCommands.get(host).keySet()) {
        HostRoleCommand hrc = hostRoleCommands.get(host).get(role);
        if (hrc == null) {
          return false;
        }
        for (HostRoleStatus status : statuses)
        if (hrc.getStatus().equals(status)) {
          return true;
        }
      }
    }
    return false;
  }

  public Map<String, List<ExecutionCommandWrapper>> getExecutionCommands() {
    return this.commandsToSend;
  }

  public String getLogDir() {
    return this.logDir;
  }

  public Map<String, Map<String, HostRoleCommand>> getHostRoleCommands() {
    return hostRoleCommands;
  }

  /**
   * This method should be used only in stage planner. To add
   * a new execution command use
   * {@link #addHostRoleExecutionCommand(String, Role, RoleCommand,
   * ServiceComponentHostEvent, String, String)}
   */
  public synchronized void addExecutionCommandWrapper(Stage origStage,
      String hostname, Role r) {
    String role = r.toString();
    if (commandsToSend.get(hostname) == null) {
      commandsToSend.put(hostname, new ArrayList<ExecutionCommandWrapper>());
    }
    commandsToSend.get(hostname).add(
        origStage.getExecutionCommandWrapper(hostname, role));
    if (hostRoleCommands.get(hostname) == null) {
      hostRoleCommands.put(hostname, new TreeMap<String, HostRoleCommand>());
    }
    // TODO add reference to ExecutionCommand into HostRoleCommand
    hostRoleCommands.get(hostname).put(role,
        origStage.getHostRoleCommand(hostname, role));
  }

  HostRoleCommand getHostRoleCommand(String hostname, String role) {
    return hostRoleCommands.get(hostname).get(role);
  }
  
  public synchronized int getTaskTimeout() {
    if (taskTimeout == -1) {
      int maxTasks = 0;
      for (String host: commandsToSend.keySet()) {
        if (commandsToSend.get(host).size() > maxTasks) {
          maxTasks = commandsToSend.get(host).size();
        }
      }
      taskTimeout = maxTasks * perTaskTimeFactor;
    }  
    return taskTimeout;
  }

  @Override //Object
  public synchronized String toString() {
    StringBuilder builder = new StringBuilder();
    builder.append("STAGE DESCRIPTION BEGIN\n");
    builder.append("requestId="+requestId+"\n");
    builder.append("stageId="+stageId+"\n");
    builder.append("clusterName="+clusterName+"\n");
    builder.append("logDir=" + logDir+"\n");
    builder.append("Success Factors:\n");
    for (Role r : successFactors.keySet()) {
      builder.append("  role: "+r+", factor: "+successFactors.get(r)+"\n");
    }
    for (HostRoleCommand hostRoleCommand : getOrderedHostRoleCommands()) {
      builder.append("HOST: ").append(hostRoleCommand.getHostName()).append(" :\n");
      builder.append(hostRoleCommand.getExecutionCommandWrapper().getJson());
      builder.append("\n");
      builder.append(hostRoleCommand.toString());
      builder.append("\n");
    }
    builder.append("STAGE DESCRIPTION END\n");
    return builder.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/actionmanager/StageFactory.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.actionmanager;

import com.google.inject.assistedinject.Assisted;
import org.apache.ambari.server.orm.entities.StageEntity;

public interface StageFactory {

  Stage createNew(long requestId, @Assisted("logDir") String logDir, @Assisted("clusterName") String clusterName);

  Stage createExisting(String actionId);

  Stage createExisting(StageEntity stageEntity);
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/ActionQueue.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Queue;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Singleton;

@Singleton
public class ActionQueue {

  private static Logger LOG = LoggerFactory.getLogger(ActionQueue.class);

  Map<String, Queue<AgentCommand>> hostQueues;

  public ActionQueue() {
    hostQueues = new HashMap<String, Queue<AgentCommand>>();
  }

  private synchronized Queue<AgentCommand> getQueue(String hostname) {
    return hostQueues.get(hostname);
  }

  private synchronized void addQueue(String hostname, Queue<AgentCommand> q) {
    hostQueues.put(hostname, q);
  }

  public void enqueue(String hostname, AgentCommand cmd) {
    Queue<AgentCommand> q;
    synchronized (this) {
      q = getQueue(hostname);
      if (q == null) {
        addQueue(hostname, new LinkedList<AgentCommand>());
        q = getQueue(hostname);
      }
    }
    synchronized (q) {
      if (q.contains(cmd)) {
        LOG.warn("cmd already exists in the queue, not adding again");
        return;
      }
      q.add(cmd);
    }
  }

  public AgentCommand dequeue(String hostname) {
    Queue<AgentCommand> q = getQueue(hostname);
    if (q == null) {
      return null;
    }
    synchronized (q) {
      if (q.isEmpty()) {
        return null;
      } else {
        return q.remove();
      }
    }
  }
  
  public int size(String hostname) {
    Queue<AgentCommand> q = getQueue(hostname);
    if (q == null) {
      return 0;
    }
    synchronized(q) {
      return q.size();
    }
  }

  public List<AgentCommand> dequeueAll(String hostname) {
    Queue<AgentCommand> q = getQueue(hostname);
    if (q == null) {
      return null;
    }
    List<AgentCommand> l = new ArrayList<AgentCommand>();
    synchronized (q) {
      while (true) {
        try {
          AgentCommand cmd = q.remove();
          if (cmd != null) {
            l.add(cmd);
          }
        } catch (NoSuchElementException ex) {
          return l;
        }
      }
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/AgentCommand.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;

public abstract class AgentCommand {

  private AgentCommandType commandType;

  public AgentCommand() {
    this.commandType = AgentCommandType.STATUS_COMMAND;
  }

  public AgentCommand(AgentCommandType type) {
    this.commandType = type;
  }

  public enum AgentCommandType {
    EXECUTION_COMMAND,
    STATUS_COMMAND,
    REGISTRATION_COMMAND
  }

  public AgentCommandType getCommandType() {
    return commandType;
  }
  
  public void setCommandType(AgentCommandType commandType) {
    this.commandType = commandType;
  }

  @Override
  public String toString() {
    return "AgentCommand{" +
            "commandType=" + commandType +
            '}';
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/CommandReport.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;

import org.codehaus.jackson.annotate.JsonProperty;


public class CommandReport {

  String role;
  String actionId;
  String stdout;
  String stderr;
  String status;
  int exitCode;
  private String clusterName;
  private String serviceName;
  private long taskId;
  
  @JsonProperty("taskId")
  public long getTaskId() {
    return taskId;
  }
  
  @JsonProperty("taskId")
  public void setTaskId(long taskId) {
    this.taskId = taskId;
  }
  
  @JsonProperty("clusterName")
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }
  
  @JsonProperty("clusterName") 
  public String getClusterName() {
    return this.clusterName;
  }

  @JsonProperty("actionId")
  public String getActionId() {
    return this.actionId;
  }
  
  @JsonProperty("actionId")
  public void setActionId(String actionId) {
    this.actionId = actionId;
  }
  
  @JsonProperty("stderr")
  public String getStdErr() {
    return this.stderr;
  }
  
  @JsonProperty("stderr")
  public void setStdErr(String stderr) {
    this.stderr = stderr;
  }
  
  @JsonProperty("exitcode")
  public int getExitCode() {
    return this.exitCode;
  }
  
  @JsonProperty("exitcode")
  public void setExitCode(int exitCode) {
    this.exitCode = exitCode;
  }
  
  @JsonProperty("stdout")
  public String getStdOut() {
    return this.stdout;
  }
  
  @JsonProperty("stdout")
  public void setStdOut(String stdout) {
    this.stdout = stdout;
  }

  @JsonProperty("role")
  public String getRole() {
    return role;
  }
  
  @JsonProperty("role")
  public void setRole(String role) {
    this.role = role;
  }
  
  @JsonProperty("status")
  public String getStatus() {
    return status;
  }
  
  @JsonProperty("status")
  public void setStatus(String status) {
    this.status = status;
  }
  
  @JsonProperty("serviceName")
  public String getServiceName() {
    return serviceName;
  }
  
  @JsonProperty("serviceName")
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  @Override
  public String toString() {
    return "CommandReport{" +
            "role='" + role + '\'' +
            ", actionId='" + actionId + '\'' +
            ", status='" + status + '\'' +
            ", exitCode=" + exitCode +
            ", clusterName='" + clusterName + '\'' +
            ", serviceName='" + serviceName + '\'' +
            ", taskId=" + taskId +
            '}';
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/ComponentStatus.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;



public class ComponentStatus {
  String componentName;
  String msg;
  String status;
  String serviceName;
  String clusterName;

  public String getComponentName() {
    return this.componentName;
  }

  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  public String getMessage() {
    return this.msg;
  }

  public void setMessage(String msg) {
    this.msg = msg;
  }

  public String getStatus() {
    return this.status;
  }

  public void setStatus(String status) {
    this.status = status;
  }

  public String getMsg() {
    return msg;
  }

  public void setMsg(String msg) {
    this.msg = msg;
  }

  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  public String getClusterName() {
    return clusterName;
  }

  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  @Override
  public String toString() {
    return "ComponentStatus{" +
            "componentName='" + componentName + '\'' +
            ", msg='" + msg + '\'' +
            ", status='" + status + '\'' +
            ", serviceName='" + serviceName + '\'' +
            ", clusterName='" + clusterName + '\'' +
            '}';
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/DiskInfo.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.agent;

import org.codehaus.jackson.annotate.JsonProperty;


/**
 * Information about a mounted disk on a given node
 */

public class DiskInfo {
  String available;
  String mountpoint;
  String device;
  String used;
  String percent;
  String size;
  String type;

  /**
   * DiskInfo object that tracks information about a disk.
   * @param mountpoint
   * @param available
   * @param used
   * @param percent
   * @param size
   */
  public DiskInfo(String device, String mountpoint, String available,
      String used, String percent, String size, String type) {
    this.device = device;
    this.mountpoint = mountpoint;
    this.available = available;
    this.used = used;
    this.percent = percent;
    this.size = size;
    this.type = type;
  }

  /**
   * Needed for Serialization
   */
  public DiskInfo() {}

  @JsonProperty("available")
  public void setAvailable(String available) {
    this.available = available;
  }
  
  @JsonProperty("available")
  public String getAvailable() {
    return this.available;
  }

  @JsonProperty("mountpoint")
  public String getMountPoint() {
    return this.mountpoint;
  }
  
  @JsonProperty("mountpoint")
  public void setMountPoint(String mountpoint) {
    this.mountpoint = mountpoint;
  }

  @JsonProperty("type")
  public String getType() {
    return this.type;
  }

  @JsonProperty("type")
  public void setType(String type) {
    this.type = type;
  }
  
  @JsonProperty("used")
  public String getUsed() {
    return this.used;
  }

  @JsonProperty("used")
  public void setUsed(String used) {
    this.used = used;
  }
  
  @JsonProperty("percent")
  public String getPercent() {
    return this.percent;
  }
  
  @JsonProperty("percent")
  public void setPercent(String percent) {
    this.percent = percent;
  }
  
  @JsonProperty("size")
  public String getSize() {
    return this.size;
  }
  
  @JsonProperty("size")
  public void setSize(String size) {
    this.size = size;
  }
  
  @Override
  public String toString() {
    return "available=" + this.available + ",mountpoint=" + this.mountpoint
         + ",used=" + this.used + ",percent=" + this.percent + ",size=" +
        this.size + ",device=" + this.device +
        ",type=" + this.type;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/ExecutionCommand.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;

import java.util.HashMap;
import java.util.List;
import java.util.Map;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.RoleCommand;
import org.apache.ambari.server.utils.StageUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.codehaus.jackson.annotate.JsonProperty;


/**
 * Execution commands are scheduled by action manager, and these are
 * persisted in the database for recovery.
 */
public class ExecutionCommand extends AgentCommand {
  
  private static Log LOG = LogFactory.getLog(ExecutionCommand.class);
  
  public ExecutionCommand() {
    super(AgentCommandType.EXECUTION_COMMAND);
  }
  private String clusterName;
  private long taskId;
  private String commandId;
  private String hostname;
  private Role role;
  private Map<String, String> hostLevelParams = new HashMap<String, String>();
  private Map<String, String> roleParams = null;
  private RoleCommand roleCommand;
  private Map<String, List<String>> clusterHostInfo = 
      new HashMap<String, List<String>>();
  private Map<String, Map<String, String>> configurations;
  private String serviceName;
  
  @JsonProperty("commandId")
  public String getCommandId() {
    return this.commandId;
  }
  
  @JsonProperty("commandId")
  public void setCommandId(String commandId) {
    this.commandId = commandId;
  }
  
  @Override
  public boolean equals(Object other) {
    if (!(other instanceof ExecutionCommand)) {
      return false;
    }
    ExecutionCommand o = (ExecutionCommand) other;
    return (this.commandId.equals(o.commandId) &&
            this.hostname.equals(o.hostname) &&
            this.role.equals(o.role) &&
            this.roleCommand.equals(o.roleCommand));
  }
  
  @Override
  public String toString() {
    try {
      return StageUtils.jaxbToString(this);
    } catch (Exception ex) {
      LOG.warn("Exception in json conversion", ex);
      return "Exception in json conversion"; 
    }
  }

  @Override
  public int hashCode() {
    return (hostname + commandId + role).hashCode();
  }

  @JsonProperty("taskId")
  public long getTaskId() {
    return taskId;
  }

  @JsonProperty("taskId")
  public void setTaskId(long taskId) {
    this.taskId = taskId;
  }

  @JsonProperty("role")
  public Role getRole() {
    return role;
  }

  @JsonProperty("role")
  public void setRole(Role role) {
    this.role = role;
  }

  @JsonProperty("roleParams")
  public Map<String, String> getRoleParams() {
    return roleParams;
  }

  @JsonProperty("roleParams")
  public void setRoleParams(Map<String, String> roleParams) {
    this.roleParams = roleParams;
  }

  @JsonProperty("roleCommand")
  public RoleCommand getRoleCommand() {
    return roleCommand;
  }

  @JsonProperty("roleCommand")
  public void setRoleCommand(RoleCommand cmd) {
    this.roleCommand = cmd;
  }
  
  @JsonProperty("clusterName")
  public String getClusterName() {
    return clusterName;
  }
  
  @JsonProperty("clusterName")
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  @JsonProperty("hostname")
  public String getHostname() {
    return hostname;
  }

  @JsonProperty("hostname")
  public void setHostname(String hostname) {
    this.hostname = hostname;
  }

  @JsonProperty("hostLevelParams")
  public Map<String, String> getHostLevelParams() {
    return hostLevelParams;
  }

  @JsonProperty("hostLevelParams")
  public void setHostLevelParams(Map<String, String> params) {
    this.hostLevelParams = params;
  }

  @JsonProperty("clusterHostInfo")
  public Map<String, List<String>> getClusterHostInfo() {
    return clusterHostInfo;
  }

  @JsonProperty("clusterHostInfo")
  public void setClusterHostInfo(Map<String, List<String>> clusterHostInfo) {
    this.clusterHostInfo = clusterHostInfo;
  }
  
  @JsonProperty("configurations")
  public Map<String, Map<String, String>> getConfigurations() {
    return configurations;
  }

  @JsonProperty("configurations")
  public void setConfigurations(Map<String, Map<String, String>> configurations) {
    this.configurations = configurations;
  }

  @JsonProperty("serviceName")
  public String getServiceName() {
    return serviceName;
  }

  @JsonProperty("serviceName")
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/HeartBeat.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.agent;

import java.util.ArrayList;
import java.util.List;

import org.codehaus.jackson.annotate.JsonProperty;

/**
 *
 *
 * Data model for Ambari Agent to send heartbeat to Ambari Server.
 *
 */

public class HeartBeat {
  private long responseId = -1;
  private long timestamp;
  private String hostname;
  List<CommandReport> reports = new ArrayList<CommandReport>();
  List<ComponentStatus> componentStatus = new ArrayList<ComponentStatus>();
  HostStatus nodeStatus;

  public long getResponseId() {
    return responseId;
  }

  public void setResponseId(long responseId) {
    this.responseId=responseId;
  }

  public long getTimestamp() {
    return timestamp;
  }

  public String getHostname() {
    return hostname;
  }

  public void setTimestamp(long timestamp) {
    this.timestamp = timestamp;
  }

  public void setHostname(String hostname) {
    this.hostname = hostname;
  }
  
  @JsonProperty("reports")
  public List<CommandReport> getReports() {
    return this.reports;
  }
  
  @JsonProperty("reports")
  public void setReports(List<CommandReport> reports) {
    this.reports = reports;
  }
  
  public HostStatus getNodeStatus() {
    return nodeStatus;
  }

  public void setNodeStatus(HostStatus nodeStatus) {
    this.nodeStatus = nodeStatus;
  }

  @JsonProperty("componentStatus")
  public List<ComponentStatus> getComponentStatus() {
    return componentStatus;
  }

  @JsonProperty("componentStatus")
  public void setComponentStatus(List<ComponentStatus> componentStatus) {
    this.componentStatus = componentStatus;
  }

  @Override
  public String toString() {
    return "HeartBeat{" +
            "responseId=" + responseId +
            ", timestamp=" + timestamp +
            ", hostname='" + hostname + '\'' +
            ", reports=" + reports +
            ", componentStatus=" + componentStatus +
            ", nodeStatus=" + nodeStatus +
            '}';
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/HeartBeatHandler.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;

import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.Singleton;
import org.apache.ambari.server.*;
import org.apache.ambari.server.actionmanager.ActionManager;
import org.apache.ambari.server.api.services.AmbariMetaInfo;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.ambari.server.metadata.ActionMetadata;
import org.apache.ambari.server.state.*;
import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;
import org.apache.ambari.server.state.host.HostHealthyHeartbeatEvent;
import org.apache.ambari.server.state.host.HostRegistrationRequestEvent;
import org.apache.ambari.server.state.host.HostStatusUpdatesReceivedEvent;
import org.apache.ambari.server.state.host.HostUnhealthyHeartbeatEvent;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostOpFailedEvent;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostOpInProgressEvent;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostOpSucceededEvent;
import org.apache.ambari.server.utils.StageUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;


/**
 * This class handles the heartbeats coming from the agent, passes on the information
 * to other modules and processes the queue to send heartbeat response.
 */
@Singleton
public class HeartBeatHandler {
  private static Log LOG = LogFactory.getLog(HeartBeatHandler.class);
  private final Clusters clusterFsm;
  private final ActionQueue actionQueue;
  private final ActionManager actionManager;
  private HeartbeatMonitor heartbeatMonitor;

  @Inject
  Injector injector;
  @Inject
  Configuration config;
  @Inject
  AmbariMetaInfo ambariMetaInfo;
  @Inject
  ActionMetadata actionMetadata;

  private Map<String, Long> hostResponseIds = new HashMap<String, Long>();
  private Map<String, HeartBeatResponse> hostResponses = new HashMap<String, HeartBeatResponse>();

  @Inject
  public HeartBeatHandler(Clusters fsm, ActionQueue aq, ActionManager am,
      Injector injector) {
    this.clusterFsm = fsm;
    this.actionQueue = aq;
    this.actionManager = am;
    this.heartbeatMonitor = new HeartbeatMonitor(fsm, aq, am, 60000);
    injector.injectMembers(this);
  }

  public void start() {
    heartbeatMonitor.start();
  }

  void setHeartbeatMonitor(HeartbeatMonitor heartbeatMonitor) {
    this.heartbeatMonitor = heartbeatMonitor;
  }

  public HeartBeatResponse handleHeartBeat(HeartBeat heartbeat)
      throws AmbariException {
    String hostname = heartbeat.getHostname();
    Long currentResponseId = hostResponseIds.get(hostname);
    HeartBeatResponse response;
    if (currentResponseId == null) {
      //Server restarted, or unknown host.
      LOG.error("CurrentResponseId unknown - send register command");
      response = new HeartBeatResponse();
      RegistrationCommand regCmd = new RegistrationCommand();
      response.setResponseId(0);
      response.setRegistrationCommand(regCmd);
      return response;
    }

    if (LOG.isDebugEnabled()) {
      LOG.debug("Received heartbeat from host"
          +  ", hostname=" + hostname
          + ", currentResponseId=" + currentResponseId
          + ", receivedResponseId=" + heartbeat.getResponseId());
    }

    if (heartbeat.getResponseId() == currentResponseId - 1) {
      LOG.warn("Old responseId received - response was lost - returning cached response");
      return hostResponses.get(hostname);
    }else if (heartbeat.getResponseId() != currentResponseId) {
      LOG.error("Error in responseId sequence - sending agent restart command");
      response = new HeartBeatResponse();
      response.setRestartAgent(true);
      response.setResponseId(currentResponseId);
      return response;
    }

    response = new HeartBeatResponse();
    response.setResponseId(++currentResponseId);

    Host hostObject = clusterFsm.getHost(hostname);

    if (hostObject.getState().equals(HostState.HEARTBEAT_LOST)) {
      // After loosing heartbeat agent should reregister
      LOG.warn("Host is in HEARTBEAT_LOST state - sending register command");
      response = new HeartBeatResponse();
      RegistrationCommand regCmd = new RegistrationCommand();
      response.setResponseId(0);
      response.setRegistrationCommand(regCmd);
      return response;
    }

    hostResponseIds.put(hostname, currentResponseId);
    hostResponses.put(hostname, response);

    long now = System.currentTimeMillis();

    // If the host is waiting for component status updates, notify it
    if (heartbeat.componentStatus.size() > 0
            && hostObject.getState().equals(HostState.WAITING_FOR_HOST_STATUS_UPDATES)) {
      try {
        LOG.debug("Got component status updates");
        hostObject.handleEvent(new HostStatusUpdatesReceivedEvent(hostname, now));
      } catch (InvalidStateTransitionException e) {
        LOG.warn("Failed to notify the host about component status updates", e);
      }
    }

    try {
      if (heartbeat.getNodeStatus().getStatus()
          .equals(HostStatus.Status.HEALTHY)) {
        hostObject.handleEvent(new HostHealthyHeartbeatEvent(hostname, now));
      } else {
        hostObject.handleEvent(new HostUnhealthyHeartbeatEvent(hostname, now,
            null));
      }
    } catch (InvalidStateTransitionException ex) {
      LOG.warn("Asking agent to reregister due to " + ex.getMessage(),  ex);
      hostObject.setState(HostState.INIT);
      RegistrationCommand regCmd = new RegistrationCommand();
      response.setRegistrationCommand(regCmd);
      return response;
    }

    //Examine heartbeat for command reports
    List<CommandReport> reports = heartbeat.getReports();
    for (CommandReport report : reports) {
      String clusterName = report.getClusterName();
      if ((clusterName == null) || "".equals(clusterName)) {
        clusterName = "cluster1";
      }
      Cluster cl = clusterFsm.getCluster(report.getClusterName());
      String service = report.getServiceName();
      if (service == null || "".equals(service)) {
        throw new AmbariException("Invalid command report, service: " + service);
      }
      if (actionMetadata.getActions(service.toLowerCase()).contains(report.getRole())) {
        LOG.info(report.getRole() + " is an action - skip component lookup");
      } else {
        try {
          Service svc = cl.getService(service);
          ServiceComponent svcComp = svc.getServiceComponent(report.getRole());
          ServiceComponentHost scHost = svcComp.getServiceComponentHost(hostname);
          if (report.getStatus().equals("COMPLETED")) {
            scHost.handleEvent(new ServiceComponentHostOpSucceededEvent(scHost
                .getServiceComponentName(), hostname, now));
          } else if (report.getStatus().equals("FAILED")) {
            scHost.handleEvent(new ServiceComponentHostOpFailedEvent(scHost
                .getServiceComponentName(), hostname, now));
          } else if (report.getStatus().equals("IN_PROGRESS")) {
            scHost.handleEvent(new ServiceComponentHostOpInProgressEvent(scHost
                .getServiceComponentName(), hostname, now));
          }
        } catch (ServiceComponentNotFoundException scnex) {
          LOG.info("Service component not found ", scnex);
        } catch (InvalidStateTransitionException ex) {
          LOG.warn("State machine exception", ex);
        }
      }
    }
    //Update state machines from reports
    actionManager.processTaskResponse(hostname, reports);

    // Examine heartbeart for component live status reports
    Set<Cluster> clusters = clusterFsm.getClustersForHost(hostname);
    for (Cluster cl : clusters) {
      for (ComponentStatus status : heartbeat.componentStatus) {
        if (status.getClusterName().equals(cl.getClusterName())) {
          try {
            Service svc = cl.getService(status.getServiceName());
            String componentName = status.getComponentName();
            if (svc.getServiceComponents().containsKey(componentName)) {
              ServiceComponent svcComp = svc.getServiceComponent(
                      componentName);
              ServiceComponentHost scHost = svcComp.getServiceComponentHost(
                      hostname);
              State prevState = scHost.getState();
              State liveState = State.valueOf(State.class, status.getStatus());
              if (prevState.equals(State.INSTALLED)
                  || prevState.equals(State.START_FAILED)
                  || prevState.equals(State.STARTED)
                  || prevState.equals(State.STOP_FAILED)) {
                scHost.setState(liveState);
                if (!prevState.equals(liveState)) {
                  LOG.info("State of service component " + componentName
                      + " of service " + status.getServiceName()
                      + " of cluster " + status.getClusterName()
                      + " has changed from " + prevState + " to " + liveState
                      + " at host " + hostname);
                }
              }
              // TODO need to get config version and stack version from live state
            } else {
              // TODO: What should be done otherwise?
            }
          }
          catch (ServiceNotFoundException e) {
            LOG.warn("Received a live status update for a non-initialized"
                + " service"
                + ", clusterName=" + status.getClusterName()
                + ", serviceName=" + status.getServiceName());
            // FIXME ignore invalid live update and continue for now?
            continue;
          }
          catch (ServiceComponentNotFoundException e) {
            LOG.warn("Received a live status update for a non-initialized"
                + " servicecomponent"
                + ", clusterName=" + status.getClusterName()
                + ", serviceName=" + status.getServiceName()
                + ", componentName=" + status.getComponentName());
            // FIXME ignore invalid live update and continue for now?
            continue;
          }
          catch (ServiceComponentHostNotFoundException e) {
            LOG.warn("Received a live status update for a non-initialized"
                + " service"
                + ", clusterName=" + status.getClusterName()
                + ", serviceName=" + status.getServiceName()
                + ", componentName=" + status.getComponentName()
                + ", hostname=" + hostname);
            // FIXME ignore invalid live update and continue for now?
            continue;
          }
        }
      }
    }

    // Send commands if node is active
    if (hostObject.getState().equals(HostState.HEALTHY)) {
      List<AgentCommand> cmds = actionQueue.dequeueAll(heartbeat.getHostname());
      if (cmds != null && !cmds.isEmpty()) {
        for (AgentCommand ac : cmds) {
          try {
            if (LOG.isDebugEnabled()) {
              LOG.debug("Sending command string = " + StageUtils.jaxbToString(ac));
            }
          } catch (Exception e) {
            throw new AmbariException("Could not get jaxb string for command", e);
          }
          switch (ac.getCommandType()) {
            case EXECUTION_COMMAND: {
              response.addExecutionCommand((ExecutionCommand) ac);
              break;
            }
            case STATUS_COMMAND: {
              response.addStatusCommand((StatusCommand) ac);
              break;
            }
              default:
                  LOG.error("There is no action for agent command ="+ ac.getCommandType().name() );
          }
        }
      }
    }
    return response;
  }

  public String getOsType(String os, String osRelease) {
    String osType = "";
    if (os != null) {
      osType = os;
    }
    if (osRelease != null) {
      String[] release = osRelease.split("\\.");
      if (release.length > 0) {
        osType += release[0];
      }
    }
    return osType.toLowerCase();
  }

  public RegistrationResponse handleRegistration(Register register)
    throws InvalidStateTransitionException, AmbariException {
    String hostname = register.getHostname();
    long now = System.currentTimeMillis();

    String agentOsType = getOsType(register.getHardwareProfile().getOS(),
        register.getHardwareProfile().getOSRelease());
    if (!ambariMetaInfo.areOsTypesCompatible(
        config.getServerOsType().toLowerCase(), agentOsType)) {
      LOG.warn("Received registration request from host with non matching"
          + " os type"
          + ", hostname=" + hostname
          + ", serverOsType=" + config.getServerOsType()
          + ", agentOstype=" + agentOsType);
      throw new AmbariException("Cannot register host as it does not match"
          + " server's os type"
          + ", hostname=" + hostname
          + ", serverOsType=" + config.getServerOsType()
          + ", agentOstype=" + agentOsType);
    }

    Host hostObject;
    try {
      hostObject = clusterFsm.getHost(hostname);
    } catch (HostNotFoundException ex) {
      clusterFsm.addHost(hostname);
      hostObject = clusterFsm.getHost(hostname);
    }
    // Resetting host state
    hostObject.setState(HostState.INIT);

    // Get status of service components
    List<StatusCommand> cmds = heartbeatMonitor.generateStatusCommands(hostname);

    hostObject.handleEvent(new HostRegistrationRequestEvent(hostname,
        null != register.getPublicHostname() ? register.getPublicHostname() : hostname,
        new AgentVersion("v1"), now, register.getHardwareProfile()));
    RegistrationResponse response = new RegistrationResponse();
    if (cmds.isEmpty()) {
      //No status commands needed let the fsm know that status step is done
      hostObject.handleEvent(new HostStatusUpdatesReceivedEvent(hostname,
          now));
    }
    response.setStatusCommands(cmds);

    response.setResponseStatus(RegistrationStatus.OK);

    Long requestId = 0L;
    hostResponseIds.put(hostname, requestId);
    response.setResponseId(requestId);
    return response;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/HeartbeatMonitor.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;

import java.util.ArrayList;
import java.util.List;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.actionmanager.ActionManager;
import org.apache.ambari.server.state.*;
import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;
import org.apache.ambari.server.state.host.HostHeartbeatLostEvent;
import org.apache.ambari.server.state.host.HostStatusUpdatesReceivedEvent;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

/**
 * Monitors the node state and heartbeats.
 */
public class HeartbeatMonitor implements Runnable {
  private static Log LOG = LogFactory.getLog(HeartbeatMonitor.class);
  private Clusters fsm;
  private ActionQueue actionQueue;
  private ActionManager actionManager;
  private final int threadWakeupInterval; //1 minute
  private volatile boolean shouldRun = true;
  private Thread monitorThread = null;

  public HeartbeatMonitor(Clusters fsm, ActionQueue aq, ActionManager am,
      int threadWakeupInterval) {
    this.fsm = fsm;
    this.actionQueue = aq;
    this.actionManager = am;
    this.threadWakeupInterval = threadWakeupInterval;
  }

  public void shutdown() {
    shouldRun = false;
  }

  public void start() {
    monitorThread = new Thread(this);
    monitorThread.start();
  }

  void join(long millis) throws InterruptedException {
    monitorThread.join(millis);
  }

  public boolean isAlive() {
    return monitorThread.isAlive();
  }

  @Override
  public void run() {
    while (shouldRun) {
      try {
        Thread.sleep(threadWakeupInterval);
        doWork();
      } catch (InterruptedException ex) {
        LOG.warn("Scheduler thread is interrupted going to stop", ex);
        shouldRun = false;
      } catch (Exception ex) {
        LOG.warn("Exception received", ex);
      } catch (Throwable t) {
        LOG.warn("ERROR", t);
      }
    }
  }

  //Go through all the nodes, check for last heartbeat or any waiting state
  //If heartbeat is lost, update node fsm state, purge the action queue
  //notify action manager for node failure.
  private void doWork() throws InvalidStateTransitionException, AmbariException {
    List<Host> allHosts = fsm.getHosts();
    long now = System.currentTimeMillis();
    for (Host hostObj : allHosts) {
      String host = hostObj.getHostName();
      HostState hostState = hostObj.getState();
      String hostname = hostObj.getHostName();

      long lastHeartbeat = 0;
      try {
        lastHeartbeat = fsm.getHost(host).getLastHeartbeatTime();
      } catch (AmbariException e) {
        LOG.warn("Exception in getting host object; Is it fatal?", e);
      }
      if (lastHeartbeat + 5*threadWakeupInterval < now) {
        LOG.warn("Hearbeat lost from host "+host);
        //Heartbeat is expired
        hostObj.handleEvent(new HostHeartbeatLostEvent(host));
        //Purge action queue
        actionQueue.dequeueAll(host);
        //notify action manager
        actionManager.handleLostHost(host);
      }
      if (hostState == HostState.WAITING_FOR_HOST_STATUS_UPDATES) {
        long timeSpentInState = hostObj.getTimeInState();
        if (timeSpentInState + 5*threadWakeupInterval < now) {
          //Go back to init, the agent will be asked to register again in the next heartbeat
          LOG.warn("timeSpentInState + 5*threadWakeupInterval < now, Go back to init");
          hostObj.setState(HostState.INIT);
        }
      }

      // Get status of service components
      List<StatusCommand> cmds = generateStatusCommands(hostname);
      if (cmds.isEmpty()) {
        // Nothing to do
      } else {
        for (StatusCommand command : cmds) {
          actionQueue.enqueue(hostname, command);
        }
      }
    }
  }

  /**
   * @param hostname
   * @return  list of commands to get status of service components on a concrete host
   */
  public List<StatusCommand> generateStatusCommands(String hostname) throws AmbariException {
    List<StatusCommand> cmds = new ArrayList<StatusCommand>();
    for (Cluster cl : fsm.getClustersForHost(hostname)) {
      List<ServiceComponentHost> roleList = cl
              .getServiceComponentHosts(hostname);
      for (ServiceComponentHost sch : roleList) {
        String serviceName = sch.getServiceName();
        if (LOG.isDebugEnabled()) {
          LOG.debug("Live status will include status of service " + serviceName +
                " of cluster " + cl.getClusterName());
        }
        StatusCommand statusCmd = new StatusCommand();
        statusCmd.setClusterName(cl.getClusterName());
        statusCmd.setServiceName(serviceName);
        statusCmd.setComponentName(sch.getServiceComponentName());
        cmds.add(statusCmd);
      }
    }
    return cmds;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/HeartBeatResponse.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.agent;

import java.util.ArrayList;
import java.util.List;

import org.codehaus.jackson.annotate.JsonProperty;

/**
 *
 * Controller to Agent response data model.
 *
 */
public class HeartBeatResponse {

  private long responseId;
 
  List<ExecutionCommand> executionCommands = new ArrayList<ExecutionCommand>();
  List<StatusCommand> statusCommands = new ArrayList<StatusCommand>();

  RegistrationCommand registrationCommand;

  boolean restartAgent = false;

  @JsonProperty("responseId")
  public long getResponseId() {
    return responseId;
  }

  @JsonProperty("responseId")
  public void setResponseId(long responseId) {
    this.responseId=responseId;
  }

  @JsonProperty("executionCommands")
  public List<ExecutionCommand> getExecutionCommands() {
    return executionCommands;
  }

  @JsonProperty("executionCommands")
  public void setExecutionCommands(List<ExecutionCommand> executionCommands) {
    this.executionCommands = executionCommands;
  }

  @JsonProperty("statusCommands")
  public List<StatusCommand> getStatusCommands() {
    return statusCommands;
  }

  @JsonProperty("statusCommands")
  public void setStatusCommands(List<StatusCommand> statusCommands) {
    this.statusCommands = statusCommands;
  }

  @JsonProperty("registrationCommand")
  public RegistrationCommand getRegistrationCommand() {
    return registrationCommand;
  }

  @JsonProperty("registrationCommand")
  public void setRegistrationCommand(RegistrationCommand registrationCommand) {
    this.registrationCommand = registrationCommand;
  }

  @JsonProperty("restartAgent")
  public boolean isRestartAgent() {
    return restartAgent;
  }

  @JsonProperty("restartAgent")
  public void setRestartAgent(boolean restartAgent) {
    this.restartAgent = restartAgent;
  }

  public void addExecutionCommand(ExecutionCommand execCmd) {
    executionCommands.add(execCmd);
  }

  public void addStatusCommand(StatusCommand statCmd) {
    statusCommands.add(statCmd);
  }

  @Override
  public String toString() {
    return "HeartBeatResponse{" +
            "responseId=" + responseId +
            ", executionCommands=" + executionCommands +
            ", statusCommands=" + statusCommands +
            ", registrationCommand=" + registrationCommand +
            ", restartAgent=" + restartAgent +
            '}';
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/HostInfo.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.agent;

import java.util.ArrayList;
import java.util.List;

import org.codehaus.jackson.annotate.JsonProperty;

/**
 *
 * Data model for Ambari Agent to send hardware profile to Ambari Server.
 *
 */
public class HostInfo {
  private String architecture;
  private String domain;
  private String fqdn;
  private String hardwareisa;
  private String hardwaremodel;
  private String hostname;
  private String id;
  private String interfaces;
  private String ipaddress;
  private String kernel;
  private String kernelmajversion;
  private String kernelrelease;
  private String kernelversion;
  private String macaddress;
  private long memoryfree;
  private long memorysize;
  private List<DiskInfo> mounts = new ArrayList<DiskInfo>();
  private long memorytotal;
  private String netmask;
  private String operatingsystem;
  private String operatingsystemrelease;
  private String osfamily;
  private int physicalprocessorcount;
  private int processorcount;
  private boolean selinux;
  private String swapfree;
  private String swapsize;
  private String timezone;
  private String uptime;
  private long uptime_days;
  private long uptime_hours;


  @JsonProperty("architecture")
  public String getArchitecture() {
    return this.architecture;
  }

  @JsonProperty("architecture")
  public void setArchitecture(String architecture) {
    this.architecture = architecture;
  }

  @JsonProperty("domain")
  public String getDomain() {
    return this.domain;
  }

  @JsonProperty("domain")
  public void setDomain(String domain) {
    this.domain = domain;
  }

  @JsonProperty("fqdn")
  public String getFQDN() {
    return this.fqdn;
  }

  @JsonProperty("fqdn")
  public void setFQDN(String fqdn) {
    this.fqdn = fqdn;
  }

  @JsonProperty("hardwareisa")
  public String getHardwareIsa() {
    return hardwareisa;
  }

  @JsonProperty("hardwareisa")
  public void setHardwareIsa(String hardwareisa) {
    this.hardwareisa = hardwareisa;
  }

  @JsonProperty("hardwaremodel")
  public String getHardwareModel() {
    return this.hardwaremodel;
  }

  @JsonProperty("hardwaremodel")
  public void setHardwareModel(String hardwaremodel) {
    this.hardwaremodel = hardwaremodel;
  }

  @JsonProperty("hostname")
  public String getHostName() {
    return this.hostname;
  }

  @JsonProperty("hostname")
  public void setHostName(String hostname) {
    this.hostname = hostname;
  }

  @JsonProperty("id")
  public String getAgentUserId() {
    return id;
  }

  @JsonProperty("id")
  public void setAgentUserId(String id) {
    this.id = id;
  }

  @JsonProperty("interfaces")
  public String getInterfaces() {
    return this.interfaces;
  }

  @JsonProperty("interfaces")
  public void setInterfaces(String interfaces) {
    this.interfaces = interfaces;
  }

  @JsonProperty("ipaddress")
  public String getIPAddress() {
    return this.ipaddress;
  }

  @JsonProperty("ipaddress")
  public void setIPAddress(String ipaddress) {
    this.ipaddress = ipaddress;
  }

  @JsonProperty("kernel")
  public String getKernel() {
    return this.kernel;
  }

  @JsonProperty("kernel")
  public void setKernel(String kernel) {
    this.kernel = kernel;
  }

  @JsonProperty("kernelmajversion")
  public String getKernelMajVersion() {
    return this.kernelmajversion;
  }

  @JsonProperty("kernelmajversion")
  public void setKernelMajVersion(String kernelmajversion) {
    this.kernelmajversion = kernelmajversion;
  }

  @JsonProperty("kernelrelease")
  public String getKernelRelease() {
    return this.kernelrelease;
  }

  @JsonProperty("kernelrelease")
  public void setKernelRelease(String kernelrelease) {
    this.kernelrelease = kernelrelease;
  }

  @JsonProperty("kernelversion")
  public String getKernelVersion() {
    return this.kernelversion;
  }

  @JsonProperty("kernelversion")
  public void setKernelVersion(String kernelversion) {
    this.kernelversion = kernelversion;
  }

  @JsonProperty("macaddress")
  public String getMacAddress() {
    return this.macaddress;
  }

  @JsonProperty("macaddress")
  public void setMacAddress(String macaddress) {
    this.macaddress = macaddress;
  }

  @JsonProperty("memoryfree")
  public long getFreeMemory() {
    return this.memoryfree;
  }

  @JsonProperty("memoryfree")
  public void setFreeMemory(long memoryfree) {
    this.memoryfree = memoryfree;
  }

  @JsonProperty("memorysize")
  public long getMemorySize() {
    return this.memorysize;
  }

  @JsonProperty("memorysize")
  public void setMemorySize(long memorysize) {
    this.memorysize = memorysize;
  }

  @JsonProperty("mounts")
  public List<DiskInfo> getMounts() {
    return this.mounts;
  }

  @JsonProperty("mounts")
  public void setMounts(List<DiskInfo> mounts) {
    this.mounts = mounts;
  }

  @JsonProperty("memorytotal")
  public long getMemoryTotal() {
    return this.memorytotal;
  }

  @JsonProperty("memorytotal")
  public void setMemoryTotal(long memorytotal) {
    this.memorytotal = memorytotal;
  }

  @JsonProperty("netmask")
  public String getNetMask() {
    return this.netmask;
  }

  @JsonProperty("netmask")
  public void setNetMask(String netmask) {
    this.netmask = netmask;
  }

  @JsonProperty("operatingsystem")
  public String getOS() {
    return this.operatingsystem;
  }

  @JsonProperty("operatingsystem")
  public void setOS(String operatingsystem) {
    this.operatingsystem = operatingsystem;
  }

  @JsonProperty("operatingsystemrelease")
  public String getOSRelease() {
    return this.operatingsystemrelease;
  }

  @JsonProperty("operatingsystemrelease")
  public void setOSRelease(String operatingsystemrelease) {
    this.operatingsystemrelease = operatingsystemrelease;
  }

  @JsonProperty("osfamily")
  public String getOSFamily() {
    return this.osfamily;
  }

  @JsonProperty("osfamily")
  public void setOSFamily(String osfamily) {
    this.osfamily = osfamily;
  }

  @JsonProperty("physicalprocessorcount")
  public int getPhysicalProcessorCount() {
    return this.physicalprocessorcount;
  }

  @JsonProperty("physicalprocessorcount")
  public void setPhysicalProcessorCount(int physicalprocessorcount) {
    this.physicalprocessorcount = physicalprocessorcount;
  }

  @JsonProperty("processorcount")
  public int getProcessorCount() {
    return this.processorcount;
  }

  @JsonProperty("processorcount")
  public void setProcessorCount(int processorcount) {
    this.processorcount = processorcount;
  }

  @JsonProperty("selinux")
  public boolean getSeLinux() {
    return selinux;
  }

  @JsonProperty("selinux")
  public void setSeLinux(boolean selinux) {
    this.selinux = selinux;
  }

  @JsonProperty("swapfree")
  public String getSwapFree() {
    return this.swapfree;
  }

  @JsonProperty("swapfree")
  public void setSwapFree(String swapfree) {
    this.swapfree = swapfree;
  }

  @JsonProperty("swapsize")
  public String getSwapSize() {
    return swapsize;
  }

  @JsonProperty("swapsize")
  public void setSwapSize(String swapsize) {
    this.swapsize = swapsize;
  }

  @JsonProperty("timezone")
  public String getTimeZone() {
    return this.timezone;
  }

  @JsonProperty("timezone")
  public void setTimeZone(String timezone) {
    this.timezone = timezone;
  }

  @JsonProperty("uptime")
  public String getUptime() {
    return this.uptime;
  }

  @JsonProperty("uptime")
  public void setUpTime(String uptime) {
    this.uptime = uptime;
  }

  @JsonProperty("uptime_hours")
  public long getUptimeHours() {
    return this.uptime_hours;
  }

  @JsonProperty("uptime_hours")
  public void setUpTimeHours(long uptime_hours) {
    this.uptime_hours = uptime_hours;
  }

  @JsonProperty("uptime_days")
  public long getUpTimeDays() {
    return this.uptime_days;
  }

  @JsonProperty("uptime_days")
  public void setUpTimeDays(long uptime_days) {
    this.uptime_days = uptime_days;
  }

  private String getDiskString() {
    if (mounts == null) {
      return null;
    }
    StringBuilder ret = new StringBuilder();
    for (DiskInfo diskInfo : mounts) {
      ret.append("(").append(diskInfo.toString()).append(")");
    }
    return ret.toString();
  }

  public String toString() {
    return "[" +
        "hostname=" + this.hostname + "," +
        "fqdn=" + this.fqdn + "," +
        "domain=" + this.domain + "," +
        "architecture=" + this.architecture + "," +
        "processorcount=" + this.processorcount + "," +
        "physicalprocessorcount=" + this.physicalprocessorcount + "," +
        "osname=" + this.operatingsystem + "," +
        "osversion=" + this.operatingsystemrelease + "," +
        "osfamily=" + this.osfamily + "," +
        "memory=" + this.memorytotal + "," +
        "uptime_hours=" + this.uptime_hours + "," +
        "mounts=" + getDiskString() + "]\n";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/HostStatus.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;


/**
 * Status of the host as described by the agent.
 *
 */
public class HostStatus {
  public HostStatus(Status status, String cause) {
    super();
    this.status = status;
    this.cause = cause;
  }
  public HostStatus() {
    super();
  }
  
  public enum Status {
    HEALTHY,
    UNHEALTHY
  }
  Status status;
  String cause;
  public Status getStatus() {
    return status;
  }
  public void setStatus(Status status) {
    this.status = status;
  }
  public String getCause() {
    return cause;
  }
  public void setCause(String cause) {
    this.cause = cause;
  }

  @Override
  public String toString() {
    return "HostStatus{" +
            "status=" + status +
            ", cause='" + cause + '\'' +
            '}';
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/Register.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.agent;

import org.codehaus.jackson.annotate.JsonProperty;

/**
 *
 * Data model for Ambari Agent to send heartbeat to Ambari Controller.
 *
 */
public class Register {
  private int responseId = -1;
  private long timestamp;
  private String hostname;
  private HostInfo hardwareProfile;
  private String publicHostname;

  @JsonProperty("responseId")
  public int getResponseId() {
    return responseId;
  }

  @JsonProperty("responseId")
  public void setResponseId(int responseId) {
    this.responseId=responseId;
  }

  public long getTimestamp() {
    return timestamp;
  }

  public String getHostname() {
    return hostname;
  }
  
  public HostInfo getHardwareProfile() {
    return hardwareProfile;
  }

  public void setTimestamp(long timestamp) {
    this.timestamp = timestamp;
  }

  public void setHostname(String hostname) {
    this.hostname = hostname;
  }

  public void setHardwareProfile(HostInfo hardwareProfile) {
    this.hardwareProfile = hardwareProfile;
  }
  
  public String getPublicHostname() {
    return publicHostname;
  }
  
  public void setPublicHostname(String name) {
    publicHostname = name;
  }

  @Override
  public String toString() {
    String ret = "responseId=" + responseId + "\n" +
             "timestamp=" + timestamp + "\n" +
             "hostname="  + hostname + "\n";

    if (hardwareProfile != null)
      ret = ret + "hardwareprofile=" + this.hardwareProfile.toString();
    return ret;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/RegistrationCommand.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlType;

@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
@XmlType(name = "", propOrder = {})
public class RegistrationCommand extends AgentCommand {

  public RegistrationCommand() {
    super(AgentCommandType.REGISTRATION_COMMAND);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/RegistrationResponse.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.agent;

import java.util.List;

import org.codehaus.jackson.annotate.JsonProperty;

/**
 *
 * Controller to Agent response data model.
 *
 */
public class RegistrationResponse {
  @JsonProperty("response")
  private RegistrationStatus response;
  
  //Response id to start with, usually zero.
  @JsonProperty("responseId")
  private long responseId;
  
  @JsonProperty("statusCommands")
  private List<StatusCommand> statusCommands = null;

  public RegistrationStatus getResponseStatus() {
    return response;
  }

  public void setResponseStatus(RegistrationStatus response) {
    this.response = response;
  }

  public List<StatusCommand> getStatusCommands() {
    return statusCommands;
  }

  public void setStatusCommands(List<StatusCommand> statusCommands) {
    this.statusCommands = statusCommands;
  }

  public long getResponseId() {
    return responseId;
  }

  public void setResponseId(long responseId) {
    this.responseId = responseId;
  }

  @Override
  public String toString() {
    return "RegistrationResponse{" +
            "response=" + response +
            ", responseId=" + responseId +
            ", statusCommands=" + statusCommands +
            '}';
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/RegistrationStatus.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;


public enum RegistrationStatus {
  OK,
  FAILED
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/StatusCommand.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.agent;

import java.util.List;

import org.codehaus.jackson.annotate.JsonProperty;

/**
 * Command to report the status of a list of services in roles.
 */
public class StatusCommand extends AgentCommand {

  public StatusCommand() {
    super(AgentCommandType.STATUS_COMMAND);
  }

  private String clusterName;
  private String serviceName;
  private String componentName;

  @JsonProperty("clusterName")
  public String getClusterName() {
    return clusterName;
  }
  
  @JsonProperty("clusterName")
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  @JsonProperty("serviceName")
  public String getServiceName() {
    return serviceName;
  }

  @JsonProperty("serviceName")
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  @JsonProperty("componentName")
  public String getComponentName() {
    return componentName;
  }

  @JsonProperty("componentName")
  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/rest/AgentJackSonJsonProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.agent.rest;

import javax.ws.rs.ext.ContextResolver;
import javax.ws.rs.ext.Provider;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.codehaus.jackson.map.DeserializationConfig;
import org.codehaus.jackson.map.ObjectMapper;


@Provider
public class AgentJackSonJsonProvider implements ContextResolver<ObjectMapper> {
  private static Log LOG = LogFactory.getLog(AgentJackSonJsonProvider.class);
  @Override
  public ObjectMapper getContext(Class<?> type) {
    ObjectMapper result = new ObjectMapper();
    result.configure(DeserializationConfig.Feature.FAIL_ON_UNKNOWN_PROPERTIES, 
        false);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/agent/rest/AgentResource.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.agent.rest;

import javax.servlet.http.HttpServletRequest;
import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.WebApplicationException;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.MediaType;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.agent.HeartBeat;
import org.apache.ambari.server.agent.HeartBeatHandler;
import org.apache.ambari.server.agent.HeartBeatResponse;
import org.apache.ambari.server.agent.Register;
import org.apache.ambari.server.agent.RegistrationResponse;
import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;

/**
 * Agent Resource represents Ambari agent controller.
 * It provides API for Ambari agents to get the cluster configuration changes
 * as well as report the node attributes and state of services running the on
 * the cluster nodes
 */
@Path("/")
public class AgentResource {
  private static HeartBeatHandler hh;
  private static Log LOG = LogFactory.getLog(AgentResource.class);

  @Inject
  public static void init(HeartBeatHandler instance) {
    hh = instance;
    hh.start();
  }

  /**
   * Register information about the host (Internal API to be used for
   * Ambari Agent)
   * @response.representation.200.doc This API is invoked by Ambari agent running
   *  on a cluster to register with the server.
   * @response.representation.200.mediaType application/json
   * @response.representation.406.doc Error in register message format
   * @response.representation.408.doc Request Timed out
   * @param message Register message
   * @throws InvalidStateTransitionException
   * @throws AmbariException
   * @throws Exception
   */
  @Path("register/{hostName}")
  @POST
  @Consumes(MediaType.APPLICATION_JSON)
  @Produces({MediaType.APPLICATION_JSON})
  public RegistrationResponse register(Register message,
      @Context HttpServletRequest req)
      throws WebApplicationException, AmbariException, InvalidStateTransitionException {
    /* Call into the heartbeat handler */

    RegistrationResponse response = hh.handleRegistration(message);
    LOG.debug("Sending registration responce " + hh);
    return response;
  }

  /**
   * Update state of the node (Internal API to be used by Ambari agent).
   *
   * @response.representation.200.doc This API is invoked by Ambari agent running
   *  on a cluster to update the state of various services running on the node.
   * @response.representation.200.mediaType application/json
   * @response.representation.406.doc Error in heartbeat message format
   * @response.representation.408.doc Request Timed out
   * @param message Heartbeat message
   * @throws Exception
   */
  @Path("heartbeat/{hostName}")
  @POST
  @Consumes(MediaType.APPLICATION_JSON)
  @Produces({MediaType.APPLICATION_JSON})
  public HeartBeatResponse heartbeat(HeartBeat message)
      throws WebApplicationException {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Received Heartbeat message " + message);
    }
    HeartBeatResponse heartBeatResponse;
    try {
      heartBeatResponse = hh.handleHeartBeat(message);
      LOG.debug("Sending heartbeat responce " + hh);
    } catch (Exception e) {
      LOG.info("Error in HeartBeat", e);
      throw new WebApplicationException(500);
    }
    return heartBeatResponse;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/BaseManagementHandler.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.api.services.Result;
import org.apache.ambari.server.api.services.ResultImpl;
import org.apache.ambari.server.api.services.persistence.PersistenceManager;
import org.apache.ambari.server.api.services.persistence.PersistenceManagerImpl;
import org.apache.ambari.server.api.util.TreeNode;
import org.apache.ambari.server.controller.spi.ClusterController;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.ClusterControllerHelper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Map;
import java.util.Set;

/**
 * Base handler for operations that persist state to the back-end.
 */
public abstract class BaseManagementHandler implements RequestHandler {

  /**
   * Logger instance.
   */
  protected final static Logger LOG =
      LoggerFactory.getLogger(BaseManagementHandler.class);

  /**
   * PersistenceManager implementation.
   */
  PersistenceManager m_pm = new PersistenceManagerImpl(getClusterController());

  protected BaseManagementHandler() {
  }

  public Result handleRequest(Request request) {
    ResourceInstance resource = request.getResource();
    Predicate queryPredicate = request.getQueryPredicate();
    if (queryPredicate != null) {
      resource.getQuery().setUserPredicate(queryPredicate);
    }

    return handleRequest(resource, request.getHttpBodyProperties());
  }

  protected Result handleRequest(ResourceInstance resource, Set<Map<String, Object>> setProperties) {
    return persist(resource, setProperties);
  }

  protected Result createResult(RequestStatus requestStatus) {

    boolean            isSynchronous = requestStatus.getStatus() == RequestStatus.Status.Complete;
    Result             result        = new ResultImpl(isSynchronous);
    TreeNode<Resource> tree          = result.getResultTree();

    if (! isSynchronous) {
      tree.addChild(requestStatus.getRequestResource(), "request");
    }

    //todo: currently always empty
    Set<Resource> setResources = requestStatus.getAssociatedResources();
    if (! setResources.isEmpty()) {
      TreeNode<Resource> resourcesNode = tree.addChild(null, "resources");

      int count = 1;
      for (Resource resource : setResources) {
        //todo: provide a more meaningful node name
        resourcesNode.addChild(resource, resource.getType() + ":" + count++);
      }
    }

    return result;
  }

  //todo: controller should be injected
  protected ClusterController getClusterController() {
    return ClusterControllerHelper.getClusterController();
  }

  protected PersistenceManager getPersistenceManager() {
    return m_pm;
  }

  protected abstract Result persist(ResourceInstance r, Set<Map<String, Object>> properties);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/CreateHandler.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.api.services.*;
import org.apache.ambari.server.api.services.ResultStatus;
import org.apache.ambari.server.controller.spi.*;

import java.util.Map;
import java.util.Set;


/**
 * Responsible for create requests.
 */
public class CreateHandler extends BaseManagementHandler {

  @Override
  protected Result persist(ResourceInstance r, Set<Map<String, Object>> properties) {
    Result result;
    try {
      RequestStatus status = getPersistenceManager().create(r, properties);

      result = createResult(status);

      if (result.isSynchronous()) {
        result.setResultStatus(new ResultStatus(ResultStatus.STATUS.CREATED));
      } else {
        result.setResultStatus(new ResultStatus(ResultStatus.STATUS.ACCEPTED));
      }

    } catch (UnsupportedPropertyException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.BAD_REQUEST, e.getMessage()));
    } catch (NoSuchParentResourceException e) {
      //todo: is this the correct status code?
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.NOT_FOUND, e.getMessage()));
    } catch (SystemException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught a system exception while attempting to create a resource", e.getMessage());
      }
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.SERVER_ERROR, e.getMessage()));
    } catch (ResourceAlreadyExistsException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.CONFLICT, e.getMessage()));
    } catch(IllegalArgumentException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.BAD_REQUEST, e.getMessage()));
    } catch (RuntimeException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught a runtime exception while attempting to create a resource", e);
      }
      //result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.SERVER_ERROR, e.getMessage()));
      throw e;
    }

    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/DelegatingRequestHandler.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.api.services.Result;

/**
 * Request handler implementation that all requests are funneled through.
 * Provides common handler functionality and delegates to concrete handler.
 */
public class DelegatingRequestHandler implements RequestHandler {
  @Override
  public Result handleRequest(Request request) {
    Result result = getRequestHandlerFactory().getRequestHandler(request.getRequestType()).handleRequest(request);
    request.getResultPostProcessor().process(result);

    return result;
  }

  /**
   * Obtain a factory for the request specific concrete request handlers.
   *
   * @return A request handler factory
   */
  RequestHandlerFactory getRequestHandlerFactory() {
    return new RequestHandlerFactory();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/DeleteHandler.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.api.services.ResultStatus;
import org.apache.ambari.server.api.services.Result;
import org.apache.ambari.server.api.services.ResultImpl;
import org.apache.ambari.server.controller.spi.*;

import java.util.Map;
import java.util.Set;

/**
 * Responsible for delete requests.
 */
public class DeleteHandler extends BaseManagementHandler implements RequestHandler {

  @Override
  protected Result persist(ResourceInstance r, Set<Map<String, Object>> properties) {
    Result result;
      try {
        RequestStatus status = getPersistenceManager().delete(r, properties);
        result = createResult(status);

        if (result.isSynchronous()) {
          result.setResultStatus(new ResultStatus(ResultStatus.STATUS.OK));
        } else {
          result.setResultStatus(new ResultStatus(ResultStatus.STATUS.ACCEPTED));
        }
      } catch (SystemException e) {
        result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.SERVER_ERROR, e));
      } catch (NoSuchParentResourceException e) {
        result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.NOT_FOUND, e));
      } catch (NoSuchResourceException e) {
        if (r.isCollectionResource()) {
          //todo: The query didn't match any resource so no resources were updated.
          //todo: 200 may be ok but we need to return a collection
          //todo: of resources that were updated.
          result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.OK, e));
        } else {
          result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.NOT_FOUND, e));
        }
      } catch (UnsupportedPropertyException e) {
        result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.BAD_REQUEST, e));
      }

    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/QueryCreateHandler.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.api.resources.ResourceInstanceFactory;
import org.apache.ambari.server.api.resources.ResourceInstanceFactoryImpl;
import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.api.services.ResultStatus;
import org.apache.ambari.server.api.services.Result;
import org.apache.ambari.server.api.services.ResultImpl;
import org.apache.ambari.server.api.util.TreeNode;
import org.apache.ambari.server.controller.spi.*;

import java.util.*;

/**
 * Handler for creates that are applied to the results of a query.
 */
public class QueryCreateHandler extends BaseManagementHandler {

  private RequestHandler m_readHandler = new ReadHandler();

  @Override
  public Result handleRequest(Request request) {
    Result queryResult = getReadHandler().handleRequest(request);
    if (queryResult.getStatus().isErrorState() ||
        queryResult.getResultTree().getChildren().isEmpty()) {

      //return the query result if result has error state or contains no resources
      //todo: For case where no resources are returned, will return 200 ok.
      //todo: What is the appropriate status code?
      return queryResult;
    }

    ResourceInstance resource = request.getResource();
    Resource.Type createType = getCreateType(request.getHttpBody(), resource);
    Set<Map<String, Object>> setProperties = buildCreateSet(request, queryResult, createType);
    ResourceInstance createResource = getResourceFactory().createResource(
        createType, request.getResource().getIds());

    return super.handleRequest(createResource, setProperties);
  }

  private Set<Map<String, Object>> buildCreateSet(Request request, Result queryResult, Resource.Type createType) {
    Set<Map<String, Object>> setRequestProps = request.getHttpBodyProperties();
    Set<Map<String, Object>> setCreateProps = new HashSet<Map<String, Object>>(setRequestProps.size());

    ResourceInstance  resource            = request.getResource();
    Resource.Type     type                = resource.getResourceDefinition().getType();
    ClusterController controller          = getClusterController();
    String            resourceKeyProperty = controller.getSchema(type).getKeyPropertyId(type);
    String            createKeyProperty   = controller.getSchema(createType).getKeyPropertyId(type);

    TreeNode<Resource> tree = queryResult.getResultTree();
    Collection<TreeNode<Resource>> treeChildren = tree.getChildren();
    for (TreeNode<Resource> node : treeChildren) {
      Resource r = node.getObject();
      Object keyVal = r.getPropertyValue(resourceKeyProperty);

      for (Map<String, Object> mapProps : setRequestProps) {
        Map<String, Object> mapResourceProps = new HashMap<String, Object>(mapProps);
        mapResourceProps.put(createKeyProperty, keyVal);
        setCreateProps.add(mapResourceProps);
      }
    }
    return setCreateProps;
  }

  private Resource.Type getCreateType(String requestBody, ResourceInstance resource) {
    int startIdx = requestBody.indexOf("\"") + 1;
    int endIdx = requestBody.indexOf("\"", startIdx + 1);

    ResourceInstance res =  resource.getSubResources().get(requestBody.substring(startIdx, endIdx));
    return res == null ? null : res.getResourceDefinition().getType();
  }

  @Override
  protected Result persist(ResourceInstance r, Set<Map<String, Object>> properties) {
    Result result;
    try {
      RequestStatus status = getPersistenceManager().create(r, properties);

      result = createResult(status);

      if (result.isSynchronous()) {
        result.setResultStatus(new ResultStatus(ResultStatus.STATUS.CREATED));
      } else {
        result.setResultStatus(new ResultStatus(ResultStatus.STATUS.ACCEPTED));
      }

    } catch (UnsupportedPropertyException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.BAD_REQUEST, e));
    } catch (ResourceAlreadyExistsException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.CONFLICT, e));
    } catch (NoSuchParentResourceException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.NOT_FOUND, e));
    } catch (SystemException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.SERVER_ERROR, e));
    }

    return result;
  }

  protected ResourceInstanceFactory getResourceFactory() {
    return new ResourceInstanceFactoryImpl();
  }

  protected RequestHandler getReadHandler() {
    return m_readHandler;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/ReadHandler.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.api.services.ResultImpl;
import org.apache.ambari.server.api.services.ResultStatus;
import org.apache.ambari.server.api.services.Result;
import org.apache.ambari.server.api.query.Query;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Map;

/**
 * Responsible for read requests.
 */
public class ReadHandler implements RequestHandler {

  /**
   * Logger instance.
   */
  private final static Logger LOG =
      LoggerFactory.getLogger(ReadHandler.class);

  @Override
  public Result handleRequest(Request request) {
    Query query = request.getResource().getQuery();

    try {
      addFieldsToQuery(request, query);
    } catch (IllegalArgumentException e) {
      return new ResultImpl(new ResultStatus(ResultStatus.STATUS.BAD_REQUEST, e.getMessage()));
    }

    query.setUserPredicate(request.getQueryPredicate());
    Result result;
    try {
      result = query.execute();
      result.setResultStatus(new ResultStatus(ResultStatus.STATUS.OK));
    } catch (SystemException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.SERVER_ERROR, e));
    } catch (NoSuchParentResourceException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.NOT_FOUND, e.getMessage()));
    } catch (UnsupportedPropertyException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.BAD_REQUEST, e.getMessage()));
    } catch (NoSuchResourceException e) {
      if (request.getQueryPredicate() == null) {
        // no predicate specified, resource requested by id
        result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.NOT_FOUND, e.getMessage()));
      } else {
        // resource(s) requested using predicate
        result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.OK, e));
        result.getResultTree().setProperty("isCollection", "true");
      }
    } catch (IllegalArgumentException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.BAD_REQUEST,
          "Invalid Request: " + e.getMessage()));
    } catch (RuntimeException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught a runtime exception executing a query", e);
      }
      //result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.SERVER_ERROR, e));
      throw e;
    }
    return result;
  }

  private void addFieldsToQuery(Request request, Query query) throws IllegalArgumentException {
    //Partial response
    for (Map.Entry<String, TemporalInfo> entry : request.getFields().entrySet()) {
      // Iterate over map and add props/temporalInfo
      String propertyId = entry.getKey();
      query.addProperty(PropertyHelper.getPropertyCategory(propertyId),
          PropertyHelper.getPropertyName(propertyId), entry.getValue());
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/RequestHandler.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.api.services.Result;

/**
 * Responsible for handling of requests and returning a result.
 */
public interface RequestHandler {
  /**
   * Handle the given request and return a result.
   *
   * @param request the request to handle
   * @return the result of the request
   */
  public Result handleRequest(Request request);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/RequestHandlerFactory.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.api.services.Request;

/**
 * Factory for {@link RequestHandler}
 * Returns the appropriate request handler based on the request.
 */
public class RequestHandlerFactory {
  /**
   * Return an instance of the correct request handler based on the request type.
   *
   * @param requestType the request type.  Is one of {@link Request.Type}
   * @return a request handler for the request
   */
  public RequestHandler getRequestHandler(Request.Type requestType) {
    switch (requestType) {
      case GET:
        return new ReadHandler();
      case POST:
        return new CreateHandler();
      case PUT:
        return new UpdateHandler();
      case DELETE:
        return new DeleteHandler();
      case QUERY_POST:
        return new QueryCreateHandler();
      default:
        //todo:
        throw new UnsupportedOperationException("Unsupported Request Type: " + requestType);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/handlers/UpdateHandler.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.handlers;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.api.services.*;
import org.apache.ambari.server.controller.spi.*;

import java.util.Map;
import java.util.Set;


/**
 * Responsible for update requests.
 */
public class UpdateHandler extends BaseManagementHandler {

  @Override
  protected Result persist(ResourceInstance r, Set<Map<String, Object>> properties) {
    Result result;
    try {
      RequestStatus status = getPersistenceManager().update(r, properties);

      result = createResult(status);
      if (result.isSynchronous()) {
        result.setResultStatus(new ResultStatus(ResultStatus.STATUS.OK));
      } else {
        result.setResultStatus(new ResultStatus(ResultStatus.STATUS.ACCEPTED));
      }

    } catch (UnsupportedPropertyException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.BAD_REQUEST, e));
    } catch (NoSuchParentResourceException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.NOT_FOUND, e));
    } catch (NoSuchResourceException e) {
      if (r.isCollectionResource()) {
        //todo: what is the correct status code here.  The query didn't match any resource
        //todo: so no resource were updated.  200 may be ok but we would need to return a collection
        //todo: of resources that were updated.
        result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.OK, e));
      } else {
        result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.NOT_FOUND, e));
      }
    } catch (SystemException e) {
      result = new ResultImpl(new ResultStatus(ResultStatus.STATUS.SERVER_ERROR, e));
    }

    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/query/Query.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.query;

import org.apache.ambari.server.api.services.Result;
import org.apache.ambari.server.controller.spi.*;

import java.util.Map;
import java.util.Set;


/**
 * Responsible for querying the back end for read requests
 */
public interface Query {

  /**
   * Add a property to the query.
   * This is the select portion of the query.
   *
   * @param group         the group name that contains the property
   * @param property      the property name
   * @param temporalInfo  temporal information for the property
   */
  public void addProperty(String group, String property, TemporalInfo temporalInfo);

  /**
   * Add a property to the query.
   * This is the select portion of the query.
   *
   * @param property the property id which contains the group, property name
   *                 and whether the property is temporal
   */
  public void addProperty(String property);

  /**
   * Obtain the properties of the query.
   * These are the properties that make up the select portion of the query for which
   * values are to be retrieved.
   *
   * @return the query properties
   */
  public Map<String, Set<String>> getProperties();

  /**
   * Execute the query.
   *
   * @return the result of the query.
   *
   * @throws UnsupportedPropertyException if the query or query predicate contains invalid non-existent properties
   * @throws SystemException an internal error occurred
   * @throws NoSuchResourceException the query didn't match any resources
   * @throws NoSuchParentResourceException a specified parent resource doesn't exist
   */
  public Result execute()
      throws UnsupportedPropertyException, SystemException, NoSuchResourceException, NoSuchParentResourceException;

  /**
   * Return the predicate used to identify the associated resource.  This includes the primary key and
   * all parent id's;
   *
   * @return the predicate used to identify the associated resource
   */
  public Predicate getPredicate();

  /**
   * Set the user provided predicated on this query.
   * This predicate will be "AND'd" with the internal query to produce the final predicate.
   *
   * @param predicate  the user provided predicate
   */
  public void setUserPredicate(Predicate predicate);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/query/QueryImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.query;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.api.services.ResultImpl;
import org.apache.ambari.server.api.util.TreeNodeImpl;
import org.apache.ambari.server.controller.utilities.ClusterControllerHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.apache.ambari.server.controller.predicate.AndPredicate;
import org.apache.ambari.server.controller.predicate.BasePredicate;
import org.apache.ambari.server.controller.predicate.EqualsPredicate;
import org.apache.ambari.server.api.services.Result;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.api.util.TreeNode;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.*;

/**
 * Default read query.
 */
public class QueryImpl implements Query {

  /**
   * Resource instance.
   */
  private ResourceInstance m_resource;

  /**
   * Properties of the query which make up the select portion of the query.
   */
  private Map<String, Set<String>> m_mapQueryProperties = new HashMap<String, Set<String>>();

  /**
   * Map that associates each property set on the query to temporal data.
   */
  private Map<String, TemporalInfo> m_mapPropertyTemporalInfo = new HashMap<String, TemporalInfo>();

  /**
   * Map that associates categories with temporal data.
   */
  private Map<String, TemporalInfo> m_mapCategoryTemporalInfo = new HashMap<String, TemporalInfo>();

  /**
   * All properties that are available for the resource.
   */
  private Map<String, Set<String>> m_mapAllProperties;

  /**
   * Tree index of m_mapAllProperties.  Used to match sub-categories.
   */
  TreeNode<Set<String>> m_treeAllProperties = new TreeNodeImpl<Set<String>>(null, new HashSet<String>(), null);

  /**
   * Sub-resources of the resource which is being operated on.
   */
  private Map<String, ResourceInstance> m_mapSubResources = new HashMap<String, ResourceInstance>();

  /**
   * The user supplied predicate.
   */
  private Predicate m_userPredicate;

  /**
   * The logger.
   */
  private final static Logger LOG =
      LoggerFactory.getLogger(QueryImpl.class);

  /**
   * Constructor.
   *
   * @param resource the resource being operated on
   */
  public QueryImpl(ResourceInstance resource) {
    m_resource = resource;
    m_mapAllProperties = Collections.unmodifiableMap(getClusterController().
        getSchema(resource.getResourceDefinition().getType()).getCategoryProperties());
    buildAllPropertiesTree();
  }

  @Override
  //todo: consider requiring a path and a property.  For categories the property name '*' could be used.
  public void addProperty(String category, String property, TemporalInfo temporalInfo) {    
    if (category == null && property.equals("*")) {
      // wildcard
      addAllProperties(temporalInfo);
    } else if (m_mapAllProperties.containsKey(category) && m_mapAllProperties.get(category).contains(property)) {
      // local property
      Set<String> setProps = m_mapQueryProperties.get(category);
      if (setProps == null) {
        setProps = new HashSet<String>();
        m_mapQueryProperties.put(category, setProps);
      }
      setProps.add(property);
      if (temporalInfo != null) {
        m_mapPropertyTemporalInfo.put(PropertyHelper.getPropertyId(category, property), temporalInfo);
      }
    } else if (! addCategory(category, property, temporalInfo)){
      // not a local category/property
      boolean success = addPropertyToSubResource(category, property, temporalInfo);
      if (!success) {
        //TODO.  Remove when handled by back end
        String propString = category == null ? property : property == null ? category : category + '/' + property;
        throw new IllegalArgumentException("An invalid resource property was requested.  Resource: " +
            m_resource.getResourceDefinition().getType() + ", Property: " + propString);
      }
    }
  }

  @Override
  public void addProperty(String property) {
    addProperty(PropertyHelper.getPropertyCategory(property), PropertyHelper.getPropertyName(property), null);
  }

  @Override
  public Result execute()
      throws UnsupportedPropertyException, SystemException, NoSuchResourceException, NoSuchParentResourceException {

    Result result = createResult();
    Resource.Type resourceType = m_resource.getResourceDefinition().getType();
    if (m_resource.getIds().get(resourceType) == null) {
      addCollectionProperties(resourceType);
      result.getResultTree().setProperty("isCollection", "true");
    }

    if (m_mapQueryProperties.isEmpty() && m_mapSubResources.isEmpty()) {
      //Add sub resource properties for default case where no fields are specified.
      m_mapSubResources.putAll(m_resource.getSubResources());
    }

    Predicate predicate = createPredicate(m_resource);
    Iterable<Resource> iterResource = getClusterController().getResources(
        resourceType, createRequest(), predicate);

    TreeNode<Resource> tree = result.getResultTree();
    int count = 1;
    for (Resource resource : iterResource) {
      // add a child node for the resource and provide a unique name.  The name is never used.
      //todo: provide a more meaningful node name
      TreeNode<Resource> node = tree.addChild(resource, resource.getType() + ":" + count++);
       for (Map.Entry<String, ResourceInstance> entry : m_mapSubResources.entrySet()) {
        String subResCategory = entry.getKey();
        ResourceInstance r = entry.getValue();

        setParentIdsOnSubResource(resource, r);

        TreeNode<Resource> childResult = r.getQuery().execute().getResultTree();
        childResult.setName(subResCategory);
        childResult.setProperty("isCollection", "false");
        node.addChild(childResult);
      }
    }
    return result;
  }

  @Override
  public Predicate getPredicate() {
    //todo: create predicate once
    return createPredicate(m_resource);
  }

  @Override
  public Map<String, Set<String>> getProperties() {
    return Collections.unmodifiableMap(m_mapQueryProperties);
  }

  @Override
  public void setUserPredicate(Predicate predicate) {
    m_userPredicate = predicate;
  }

  ClusterController getClusterController() {
    return ClusterControllerHelper.getClusterController();
  }

  private void addCollectionProperties(Resource.Type resourceType) {
    Schema schema = getClusterController().getSchema(resourceType);
    // add pk
    addProperty(schema.getKeyPropertyId(resourceType));

    for (Resource.Type type : m_resource.getIds().keySet()) {
      // add fk's
      String keyPropertyId = schema.getKeyPropertyId(type);
      //todo: property id can be null in some cases such as host_component queries which obtain
      //todo: component sub-resources.  Component will not have host fk.
      //todo: refactor so that null check is not required.
      if (keyPropertyId != null) {
        addProperty(keyPropertyId);
      }
    }
  }

  private void addAllProperties(TemporalInfo temporalInfo) {
    if (temporalInfo == null) {
      m_mapQueryProperties.putAll(m_mapAllProperties);
    } else {
      for (Map.Entry<String, Set<String>> entry : m_mapAllProperties.entrySet()) {
        String path = entry.getKey();
        Set<String> setProps = entry.getValue();
        m_mapQueryProperties.put(path, setProps);
        m_mapCategoryTemporalInfo.put(path, temporalInfo);
      }
    }

    for (Map.Entry<String, ResourceInstance> entry : m_resource.getSubResources().entrySet()) {
      String name = entry.getKey();
      if (! m_mapSubResources.containsKey(name)) {
        m_mapSubResources.put(name, entry.getValue());
      }
    }
  }

  private boolean addCategory(String category, String name, TemporalInfo temporalInfo) {
    if (category != null) {
      if (name != null && ! name.isEmpty()) {
        name = category + '/' + name;
      } else  {
        name = category;
      }
    }
    TreeNode<Set<String>> node = m_treeAllProperties.getChild(name);
    if (node == null) {
      return false;
    }

    addCategory(node, name, temporalInfo);
    return true;
  }

  private void addCategory(TreeNode<Set<String>> node, String category, TemporalInfo temporalInfo) {
    if (node != null) {
      Set<String> setProps = m_mapQueryProperties.get(category);
      if (setProps == null) {
        setProps = new HashSet<String>();
        m_mapQueryProperties.put(category, setProps);
      }
      setProps.addAll(node.getObject());
      m_mapCategoryTemporalInfo.put(category, temporalInfo);

      for (TreeNode<Set<String>> child : node.getChildren()) {
        addCategory(child, category + '/' + child.getName(), temporalInfo);
      }
    }
  }

  private boolean addPropertyToSubResource(String path, String property, TemporalInfo temporalInfo) {
    // cases:
    // - path is null, property is path (all sub-resource props will have a path)
    // - path is single token and prop in non null
    //      (path only will presented as above case with property only)
    // - path is multi level and prop is non null

    boolean resourceAdded = false;
    if (path == null) {
      path = property;
      property = null;
    }

    int i = path.indexOf("/");
    String p = i == -1 ? path : path.substring(0, i);

    ResourceInstance subResource = m_resource.getSubResources().get(p);
    if (subResource != null) {
      m_mapSubResources.put(p, subResource);
      //todo: handle case of trailing '/' (for example fields=subResource/)

      if (property != null || !path.equals(p)) {
        //only add if a sub property is set or if a sub category is specified
        subResource.getQuery().addProperty(i == -1 ? null : path.substring(i + 1), property, temporalInfo);
      }
      resourceAdded = true;
    }
    return resourceAdded;
  }

  private BasePredicate createInternalPredicate(ResourceInstance resource) {
    Resource.Type resourceType = resource.getResourceDefinition().getType();
    Map<Resource.Type, String> mapResourceIds = resource.getIds();
    Schema schema = getClusterController().getSchema(resourceType);

    Set<BasePredicate> setPredicates = new HashSet<BasePredicate>();
    for (Map.Entry<Resource.Type, String> entry : mapResourceIds.entrySet()) {
      if (entry.getValue() != null) {
        String keyPropertyId = schema.getKeyPropertyId(entry.getKey());
        if (keyPropertyId != null) {
          setPredicates.add(new EqualsPredicate<String>(keyPropertyId, entry.getValue()));
        }
      }
    }

    if (setPredicates.size() == 1) {
      return setPredicates.iterator().next();
    } else if (setPredicates.size() > 1) {
      return new AndPredicate(setPredicates.toArray(new BasePredicate[setPredicates.size()]));
    } else {
      return null;
    }
  }

  private Predicate createPredicate(ResourceInstance resource) {
    Predicate predicate = null;
    //todo: change reference type to Predicate when predicate hierarchy is fixed
    BasePredicate internalPredicate = createInternalPredicate(resource);
    if (internalPredicate == null) {
      if (m_userPredicate != null) {
        predicate = m_userPredicate;
      }
    } else {
      predicate = (m_userPredicate == null ? internalPredicate :
          new AndPredicate((BasePredicate) m_userPredicate, internalPredicate));
    }
    return predicate;
  }

  private void buildAllPropertiesTree() {
    // build index
    for (String category : m_mapAllProperties.keySet()) {
      TreeNode<Set<String>> node = m_treeAllProperties.getChild(category);
      if (node == null) {
        if (category == null) {
          node = m_treeAllProperties.addChild(new HashSet<String>(), null);
        } else {
          String[] tokens = category.split("/");
          node = m_treeAllProperties;
          for (String t : tokens) {
            TreeNode<Set<String>> child = node.getChild(t);
            if (child == null) {
              child = node.addChild(new HashSet<String>(), t);
            }
            node = child;
          }
        }
      }
      node.getObject().addAll(m_mapAllProperties.get(category));
    }
  }

  private Request createRequest() {
    Set<String> setProperties = new HashSet<String>();

    Map<String, TemporalInfo> mapTemporalInfo = new HashMap<String, TemporalInfo>();

    for (Map.Entry<String, Set<String>> entry : m_mapQueryProperties.entrySet()) {
      String group = entry.getKey();
      for (String property : entry.getValue()) {
        String propertyId = PropertyHelper.getPropertyId(group, property);

        TemporalInfo temporalInfo = m_mapCategoryTemporalInfo.get(group);
        if (temporalInfo == null) {
          temporalInfo = m_mapPropertyTemporalInfo.get(propertyId);
        }
        if (temporalInfo != null) {
          mapTemporalInfo.put(propertyId, temporalInfo);
        }
        setProperties.add(propertyId);
      }
    }

    return PropertyHelper.getReadRequest(setProperties, mapTemporalInfo);
  }

  private void setParentIdsOnSubResource(Resource resource, ResourceInstance r) {
    Map<Resource.Type, String> mapParentIds = m_resource.getIds();
    Map<Resource.Type, String> mapResourceIds = new HashMap<Resource.Type, String>(mapParentIds.size());
    for (Map.Entry<Resource.Type, String> resourceIdEntry : mapParentIds.entrySet()) {
      Resource.Type type = resourceIdEntry.getKey();
      String value = resourceIdEntry.getValue();

      if (value == null) {
        Object o = resource.getPropertyValue(getClusterController().getSchema(type).getKeyPropertyId(type));
        value = o == null ? null : o.toString();
      }
      if (value != null) {
        mapResourceIds.put(type, value);
      }
    }
    String resourceKeyProp = getClusterController().getSchema(resource.getType()).
        getKeyPropertyId(resource.getType());
    //todo: shouldn't use toString here
    mapResourceIds.put(resource.getType(), resource.getPropertyValue(resourceKeyProp).toString());
    r.setIds(mapResourceIds);
  }

  Result createResult() {
    return new ResultImpl(true);
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    QueryImpl that = (QueryImpl) o;

    return m_mapAllProperties.equals(that.m_mapAllProperties) &&
           m_mapCategoryTemporalInfo.equals(that.m_mapCategoryTemporalInfo) &&
           m_mapPropertyTemporalInfo.equals(that.m_mapPropertyTemporalInfo) &&
           m_mapQueryProperties.equals(that.m_mapQueryProperties) &&
           m_mapSubResources.equals(that.m_mapSubResources) &&
           m_resource.equals(that.m_resource) &&
           m_userPredicate == null ? that.m_userPredicate == null : m_userPredicate.equals(that.m_userPredicate);
  }

  @Override
  public int hashCode() {
    int result = m_resource.hashCode();
    result = 31 * result + m_mapQueryProperties.hashCode();
    result = 31 * result + m_mapPropertyTemporalInfo.hashCode();
    result = 31 * result + m_mapCategoryTemporalInfo.hashCode();
    result = 31 * result + m_mapAllProperties.hashCode();
    result = 31 * result + m_mapSubResources.hashCode();
    result = 31 * result + (m_userPredicate != null ? m_userPredicate.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ActionResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.api.resources;


import org.apache.ambari.server.controller.spi.Resource;


public class ActionResourceDefinition extends BaseResourceDefinition {


  public ActionResourceDefinition() {
    super(Resource.Type.Action);
  }
  
  @Override
  public String getPluralName() {
    return "actions";
  }

  @Override
  public String getSingularName() {
    return "action";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/BaseResourceDefinition.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;


import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.api.util.TreeNode;
import org.apache.ambari.server.controller.spi.ClusterController;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.Schema;
import org.apache.ambari.server.controller.utilities.ClusterControllerHelper;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Set;

/**
 * Base resource definition.  Contains behavior common to all resource types.
 */
public abstract class BaseResourceDefinition implements ResourceDefinition {

  /**
   * Resource type.  One of {@link Resource.Type}
   */
  private Resource.Type m_type;


  /**
   * Constructor.
   *
   * @param resourceType resource type
   */
  public BaseResourceDefinition(Resource.Type resourceType) {
    m_type = resourceType;
  }

  @Override
  public Resource.Type getType() {
    return m_type;
  }

  @Override
  public Set<SubResourceDefinition> getSubResourceDefinitions() {
    return Collections.emptySet();
  }

  @Override
  public List<PostProcessor> getPostProcessors() {
    List<PostProcessor> listProcessors = new ArrayList<PostProcessor>();
    listProcessors.add(new BaseHrefPostProcessor());

    return listProcessors;
  }

  ClusterController getClusterController() {
    return ClusterControllerHelper.getClusterController();
  }

  @Override
  public boolean equals(Object o) {
      boolean result =false;
      if(this == o) result = true;
      if(o instanceof BaseResourceDefinition){
          BaseResourceDefinition other = (BaseResourceDefinition) o;
          if(m_type == other.m_type )
              result = true;
      }
      return result;
  }

  @Override
  public int hashCode() {
    return m_type.hashCode();
  }

  class BaseHrefPostProcessor implements PostProcessor {
    @Override
    public void process(Request request, TreeNode<Resource> resultNode, String href) {
      Resource r = resultNode.getObject();
      TreeNode<Resource> parent = resultNode.getParent();

      if (parent.getName() != null) {
        Schema schema = getClusterController().getSchema(r.getType());
        Object id = r.getPropertyValue(schema.getKeyPropertyId(r.getType()));

        int i = href.indexOf("?");
        if (i != -1) {
          href = href.substring(0, i);
        }

        if (!href.endsWith("/")) {
          href = href + '/';
        }
        href = "true".equals(parent.getProperty("isCollection")) ?
            href + id : href + parent.getName() + '/' + id;
      }
      resultNode.setProperty("href", href);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ClusterResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;

import java.util.HashSet;
import java.util.Set;
import org.apache.ambari.server.controller.spi.Resource;

/**
 * Cluster resource definition.
 */
public class ClusterResourceDefinition extends BaseResourceDefinition {


  /**
   * Constructor.
   */
  public ClusterResourceDefinition() {
    super(Resource.Type.Cluster);
  }


  @Override
  public String getPluralName() {
    return "clusters";
  }

  @Override
  public String getSingularName() {
    return "cluster";
  }

  @Override
  public Set<SubResourceDefinition> getSubResourceDefinitions() {
    Set<SubResourceDefinition> setChildren = new HashSet<SubResourceDefinition>();
    setChildren.add(new SubResourceDefinition(Resource.Type.Service));
    setChildren.add(new SubResourceDefinition(Resource.Type.Host));
    setChildren.add(new SubResourceDefinition(Resource.Type.Configuration));
    setChildren.add(new SubResourceDefinition(Resource.Type.Request));

    return setChildren;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ComponentResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.controller.utilities.ClusterControllerHelper;
import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.Schema;
import org.apache.ambari.server.api.util.TreeNode;

import java.util.*;

/**
 * Component resource definition.
 */
public class ComponentResourceDefinition extends BaseResourceDefinition {

  /**
   * Constructor.
   */
  public ComponentResourceDefinition() {
    super(Resource.Type.Component);
  }

  @Override
  public String getPluralName() {
    return "components";
  }

  @Override
  public String getSingularName() {
    return "component";
  }


  @Override
  public Set<SubResourceDefinition> getSubResourceDefinitions() {
    return Collections.singleton(new SubResourceDefinition(
        Resource.Type.HostComponent, Collections.singleton(Resource.Type.Host), true));
  }

  @Override
  public List<PostProcessor> getPostProcessors() {
    List<PostProcessor> listProcessors = super.getPostProcessors();
    listProcessors.add(new ComponentHrefProcessor());

    return listProcessors;
  }

  /**
   * Base resource processor which generates href's.  This is called by the
   * {@link org.apache.ambari.server.api.services.ResultPostProcessor} during post processing of a result.
   */
  private class ComponentHrefProcessor extends BaseHrefPostProcessor {
    @Override
    public void process(Request request, TreeNode<Resource> resultNode, String href) {
      TreeNode<Resource> parent = resultNode.getParent();

      if (parent.getParent() != null && parent.getParent().getObject().getType() == Resource.Type.HostComponent) {
        Resource r = resultNode.getObject();
        Schema schema = ClusterControllerHelper.getClusterController().getSchema(r.getType());
        Object serviceId = r.getPropertyValue(schema.getKeyPropertyId(Resource.Type.Service));
        Object componentId = r.getPropertyValue(schema.getKeyPropertyId(r.getType()));

        href = href.substring(0, href.indexOf("/hosts/") + 1) +
            "services/" + serviceId + "/components/" + componentId;

        resultNode.setProperty("href", href);
      } else {
        super.process(request, resultNode, href);
      }
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ConfigurationResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;

import java.util.*;

import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.api.util.TreeNode;
import org.apache.ambari.server.controller.spi.Resource;

/**
 * Configuration resource definition.
 */
public class ConfigurationResourceDefinition extends BaseResourceDefinition {

  /**
   * Constructor.
   */
  public ConfigurationResourceDefinition() {
    super(Resource.Type.Configuration);
  }

  @Override
  public List<PostProcessor> getPostProcessors() {
    List<PostProcessor> listProcessors = super.getPostProcessors();
    listProcessors.add(new HrefProcessor());

    return listProcessors;
  }

  @Override
  public String getPluralName() {
    return "configurations";
  }

  @Override
  public String getSingularName() {
    return "configuration";
  }

  private class HrefProcessor extends BaseHrefPostProcessor {

    @Override
    public void process(Request request, TreeNode<Resource> resultNode, String href) {
      if (resultNode.getObject().getType() == Resource.Type.Configuration) {

        if (! href.endsWith("/")) {
          href += '/';
        }

        String clustersToken = "/clusters";
        int idx = href.indexOf(clustersToken) + clustersToken.length() + 1;
        idx = href.indexOf("/", idx) + 1;

        String type = (String) resultNode.getObject().getPropertyValue("type");
        String tag = (String) resultNode.getObject().getPropertyValue("tag");
        href = href.substring(0, idx) + "configurations?type=" + type + "&tag=" + tag;

        resultNode.setProperty("href", href);
      } else {
        super.process(request, resultNode, href);
      }

    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/DetachedHostResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.controller.spi.Resource;


/**
 * Resource definition for /hosts resources.
 */
public class DetachedHostResourceDefinition extends BaseResourceDefinition {

  public DetachedHostResourceDefinition() {
    super(Resource.Type.Host);
  }

  @Override
  public String getPluralName() {
    return "hosts";
  }

  @Override
  public String getSingularName() {
    return "host";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/HostComponentResourceDefinition.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.controller.utilities.ClusterControllerHelper;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.Schema;
import org.apache.ambari.server.api.util.TreeNode;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.*;

/**
 * Host_Component resource definition.
 */
public class HostComponentResourceDefinition extends BaseResourceDefinition {

  /**
   * Constructor.
   */
  public HostComponentResourceDefinition() {
    super(Resource.Type.HostComponent);
  }

  @Override
  public String getPluralName() {
    return "host_components";
  }

  @Override
  public String getSingularName() {
    return "host_component";
  }


  @Override
  public Set<SubResourceDefinition> getSubResourceDefinitions() {
    Set<SubResourceDefinition> setSubResources = new HashSet<SubResourceDefinition>();
    setSubResources.add(new SubResourceDefinition(Resource.Type.Component,
        Collections.singleton(Resource.Type.Service), false));

    return setSubResources;
  }

  @Override
  public List<PostProcessor> getPostProcessors() {
    List<PostProcessor> listProcessors = new ArrayList<PostProcessor>();
    listProcessors.add(new HostComponentHrefProcessor());
    listProcessors.add(new HostComponentHostProcessor());

    return listProcessors;
  }
  /**
   * Host_Component resource processor which is responsible for generating href's for host components.
   * This is called by the ResultPostProcessor during post processing of a result.
   */
  private class HostComponentHrefProcessor extends BaseHrefPostProcessor {
    @Override
    public void process(Request request, TreeNode<Resource> resultNode, String href) {
      if (! href.contains("/hosts/")) {
        Resource r = resultNode.getObject();
        Schema schema = ClusterControllerHelper.getClusterController().getSchema(r.getType());
        Object host = r.getPropertyValue(schema.getKeyPropertyId(Resource.Type.Host));
        Object hostComponent = r.getPropertyValue(schema.getKeyPropertyId(r.getType()));

        int idx = href.indexOf("clusters/") + "clusters/".length();
        idx = href.indexOf("/", idx) + 1;

        href = href.substring(0, idx) +
            "hosts/" + host + "/host_components/" + hostComponent;

        resultNode.setProperty("href", href);
      } else {
        super.process(request, resultNode, href);
      }
    }
  }

  /**
   * Host_Component resource processor which is responsible for generating a host section for host components.
   * This is called by the ResultPostProcessor during post processing of a result.
   */
  private class HostComponentHostProcessor implements PostProcessor {
    @Override
    public void process(Request request, TreeNode<Resource> resultNode, String href) {
      //todo: look at partial request fields to ensure that hosts should be returned
      if (request.getResource().getResourceDefinition().getType() == getType()) {
        // only add host if query host_resource was directly queried
        String nodeHref = resultNode.getProperty("href");
        resultNode.getObject().setProperty(PropertyHelper.getPropertyId("host", "href"),
            nodeHref.substring(0, nodeHref.indexOf("/host_components/")));
      }
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/HostResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;


import java.util.Collections;
import java.util.Set;

import org.apache.ambari.server.controller.spi.Resource;

/**
 * Host resource definition.
 */
public class HostResourceDefinition extends BaseResourceDefinition {

  /**
   * Constructor.
   */
  public HostResourceDefinition() {
    super(Resource.Type.Host);
  }

  @Override
  public String getPluralName() {
    return "hosts";
  }

  @Override
  public String getSingularName() {
    return "host";
  }

  @Override
  public Set<SubResourceDefinition> getSubResourceDefinitions() {
    return Collections.singleton(new SubResourceDefinition(Resource.Type.HostComponent));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/RequestResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;


import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.api.util.TreeNode;
import org.apache.ambari.server.controller.spi.Resource;

import java.util.Collections;
import java.util.List;
import java.util.Set;


/**
 * Request resource definition.
 */
public class RequestResourceDefinition extends BaseResourceDefinition {

  /**
   * Constructor.
   */
  public RequestResourceDefinition() {
    super(Resource.Type.Request);
  }

  @Override
  public String getPluralName() {
    return "requests";
  }

  @Override
  public String getSingularName() {
    return "request";
  }

  @Override
  public Set<SubResourceDefinition> getSubResourceDefinitions() {
      return Collections.singleton(new SubResourceDefinition(Resource.Type.Task));
  }

  @Override
  public List<PostProcessor> getPostProcessors() {
    return Collections.<PostProcessor>singletonList(new RequestHrefPostProcessor());
  }

  private class RequestHrefPostProcessor implements PostProcessor {
    @Override
    public void process(Request request, TreeNode<Resource> resultNode, String href) {
      StringBuilder sb = new StringBuilder();
      String[] toks = href.split("/");

      for (int i = 0; i < toks.length; ++i) {
        String s = toks[i];
        sb.append(s).append('/');
        if ("clusters".equals(s)) {
          sb.append(toks[i + 1]).append('/');
          break;
        }
      }

      Object requestId = resultNode.getObject().getPropertyValue(getClusterController().
          getSchema(Resource.Type.Request).getKeyPropertyId(Resource.Type.Request));

      sb.append("requests/").append(requestId);

      resultNode.setProperty("href", sb.toString());
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.api.services.Request;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.api.util.TreeNode;

import org.apache.ambari.server.api.services.ResultPostProcessor;

import java.util.List;
import java.util.Set;

/**
 * Resource Definition.
 * Provides information specific to a specific resource type.
 */
public interface ResourceDefinition {
  /**
   * Obtain the plural name of the resource.
   *
   * @return the plural name of the resource
   */
  public String getPluralName();

  /**
   * Obtain the singular name of the resource.
   *
   * @return the singular name of the resource
   */
  public String getSingularName();

  /**
   * Obtain the type of resource.  Is one of {@link Resource.Type}.
   *
   * @return the type of resource
   */
  public Resource.Type getType();

  /**
   * Obtain a set of all child resource types.
   *
   * @return set of sub-resource definitions
   */
  public Set<SubResourceDefinition> getSubResourceDefinitions();

  /**
   * Obtain any resource post processors.  A resource processor is used to provide resource specific processing of
   * results and is called by the {@link ResultPostProcessor} while post processing a result.
   *
   * @return list of resource specific result processors
   */
  public List<PostProcessor> getPostProcessors();

  /**
   * Resource specific result processor.
   * Used to provide resource specific processing of a result.
   */
  public interface PostProcessor {
    public void process(Request request, TreeNode<Resource> resultNode, String href);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ResourceInstance.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.api.query.Query;
import org.apache.ambari.server.controller.spi.Resource;

import java.util.Map;

/**
 * Resource instance which contains request specific state.
 */
public interface ResourceInstance {

  /**
   * Set the values of the parent foreign keys.
   *
   * @param mapIds  map of all parent foreign keys. Map from resource type to id value.
   */
  public void setIds(Map<Resource.Type, String> mapIds);

  /**
   * Obtain the primary and foreign key properties for the resource.
   *
   * @return map of primary and foreign key values keyed by resource type
   */
  public Map<Resource.Type, String> getIds();

  /**
   * Return the query associated with the resource.
   * Each resource has one query.
   *
   * @return the associated query
   */
  public Query getQuery();

  /**
   * Return the resource definition for this resource type.
   * All information in the definition is static and is specific to the resource type,
   * not the resource instance.
   *
   * @return  the associated resource definition
   */
  public ResourceDefinition getResourceDefinition();

  /**
   * Return all sub-resource instances.
   * This will include all children of this resource as well
   * as any other resources referred to via a foreign key property.
   *
   * @return all sub-resource instances
   */
  public Map<String, ResourceInstance> getSubResources();

  /**
   * Determine if resource is a collection resource.
   *
   * @return true if the resource is a collection resource; false otherwise
   */
  public boolean isCollectionResource();
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ResourceInstanceFactory.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.controller.spi.Resource;

import java.util.Map;

/**
 * Factory for creating resource instances.
 */
public interface ResourceInstanceFactory {
  /**
   * Create a resource instance.
   *
   * @param type    the type of resource to create
   * @param mapIds  the resource id's which identify the resource
   *
   * @return  a new resource instance of the specified type
   */
  public ResourceInstance createResource(Resource.Type type, Map<Resource.Type, String> mapIds);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ResourceInstanceFactoryImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.controller.spi.Resource;

import java.util.Map;

/**
 * Factory for creating resource instances.
 */
public class ResourceInstanceFactoryImpl implements ResourceInstanceFactory {

  @Override
  public ResourceInstance createResource(Resource.Type type, Map<Resource.Type, String> mapIds) {

    /**
     * The resource definition for the specified type.
     */
    ResourceDefinition resourceDefinition;

    //todo: consider ResourceDependencyManager : Map<Resource.Type, ResourceDefinition>
    switch (type) {
      case Cluster:
        resourceDefinition = new ClusterResourceDefinition();
        break;

      case Service:
        resourceDefinition = new ServiceResourceDefinition();
        break;

      case Host:
        resourceDefinition = mapIds.containsKey(Resource.Type.Cluster) ?
            new HostResourceDefinition() : new DetachedHostResourceDefinition();
        break;

      case Component:
        resourceDefinition = new  ComponentResourceDefinition();
        break;

      case HostComponent:
        resourceDefinition = new HostComponentResourceDefinition();
        break;

      case Action:
        resourceDefinition = new ActionResourceDefinition();
        break;

      case Configuration:
        resourceDefinition = new ConfigurationResourceDefinition();
        break;

      case Task:
        resourceDefinition = new TaskResourceDefinition();
        break;

      case User:
        resourceDefinition = new UserResourceDefinition();
        break;

      case Request:
        resourceDefinition = new RequestResourceDefinition();
        break;

      default:
        throw new IllegalArgumentException("Unsupported resource type: " + type);
    }

    return new ResourceInstanceImpl(mapIds, resourceDefinition, this);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ResourceInstanceImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.api.query.Query;
import org.apache.ambari.server.api.query.QueryImpl;
import org.apache.ambari.server.controller.spi.ClusterController;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.ClusterControllerHelper;

import java.util.HashMap;
import java.util.Map;
import java.util.Set;

/**
 * Resource instance which contains request specific state.
 */
public class ResourceInstanceImpl implements ResourceInstance {

  /**
   * Query associated with the resource definition.
   */
  private Query m_query;

  /**
   * Map of primary and foreign keys and values necessary to identify the resource.
   */
  private Map<Resource.Type, String> m_mapResourceIds = new HashMap<Resource.Type, String>();

  /**
   * Definition for the resource type.  The definition contains all information specific to the
   * resource type.
   */
  private ResourceDefinition m_resourceDefinition;

  /**
   * Sub-resource instances of this resource.
   * Map of resource resource name to resource instance.
   */
  private Map<String, ResourceInstance> m_mapSubResources;

  /**
   * Factory for creating resource instances.
   * Used to create sub-resource instances.
   */
  private ResourceInstanceFactory m_resourceFactory;

  /**
   * Cluster controller reference.
   */
  //todo: should be injected.
  private ClusterController m_controller = ClusterControllerHelper.getClusterController();


  public ResourceInstanceImpl(Map<Resource.Type, String> mapIds, ResourceDefinition resourceDefinition,
                              ResourceInstanceFactory resourceFactory) {

    m_resourceDefinition = resourceDefinition;
    m_query              = new QueryImpl(this);
    m_resourceFactory    = resourceFactory;

    setIds(mapIds);
  }

  @Override
  public void setIds(Map<Resource.Type, String> mapIds) {
    m_mapResourceIds.putAll(mapIds);
  }

  @Override
  public Map<Resource.Type, String> getIds() {
    return new HashMap<Resource.Type, String>((m_mapResourceIds));
  }

  @Override
  public Query getQuery() {
    return m_query;
  }

  @Override
  public ResourceDefinition getResourceDefinition() {
    return m_resourceDefinition;
  }


  @Override
  public Map<String, ResourceInstance> getSubResources() {
    if (m_mapSubResources == null) {
      m_mapSubResources = new HashMap<String, ResourceInstance>();
      Set<SubResourceDefinition> setSubResourceDefs = getResourceDefinition().getSubResourceDefinitions();

      for (SubResourceDefinition subResDef : setSubResourceDefs) {
        ResourceInstance resource = m_resourceFactory.createResource(subResDef.getType(), getIds());

        // ensure pk is returned
        resource.getQuery().addProperty(m_controller.getSchema(
            subResDef.getType()).getKeyPropertyId(subResDef.getType()));
        // add additionally required fk properties
        for (Resource.Type fkType : subResDef.getAdditionalForeignKeys()) {
          resource.getQuery().addProperty(m_controller.getSchema(subResDef.getType()).getKeyPropertyId(fkType));
        }

        String subResourceName = subResDef.isCollection() ? resource.getResourceDefinition().getPluralName() :
            resource.getResourceDefinition().getSingularName();

        m_mapSubResources.put(subResourceName, resource);
      }
    }
    return m_mapSubResources;
  }

  @Override
  public boolean isCollectionResource() {
    return getIds().get(getResourceDefinition().getType()) == null;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ResourceInstanceImpl that = (ResourceInstanceImpl) o;

    return m_mapResourceIds.equals(that.m_mapResourceIds) &&
           m_query.equals(that.m_query) &&
           m_resourceDefinition.equals(that.m_resourceDefinition) &&
           m_mapSubResources == null ? that.m_mapSubResources == null :
               m_mapSubResources.equals(that.m_mapSubResources);
  }

  @Override
  public int hashCode() {
    int result =m_query.hashCode();
    result = 31 * result + m_mapResourceIds.hashCode();
    result = 31 * result + m_resourceDefinition.hashCode();
    result = 31 * result + (m_mapSubResources != null ? m_mapSubResources.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/ServiceResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.controller.spi.Resource;

import java.util.*;

/**
 * Service resource definition.
 */
public class ServiceResourceDefinition extends BaseResourceDefinition {

  /**
   * Constructor.
   *
   */
  public ServiceResourceDefinition() {
    super(Resource.Type.Service);
  }

  @Override
  public String getPluralName() {
    return "services";
  }

  @Override
  public String getSingularName() {
    return "service";
  }

  @Override
  public Set<SubResourceDefinition> getSubResourceDefinitions() {
    return Collections.singleton(new SubResourceDefinition(Resource.Type.Component));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/SubResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.controller.spi.Resource;

import java.util.Collections;
import java.util.Set;

/**
 * Definition of a sub-resource.
 * Defines a resource instance that is added to another resource as a sub-resource.
 */
public class SubResourceDefinition {

  /**
   * Resource type.
   */
  private Resource.Type m_type;

  /**
   * Additional foreign key properties to include by default in the sub-resource.
   */
  private Set<Resource.Type> m_setForeignKeys;

  /**
   * Whether the sub-resource is a collection or a single instance.
   */
  private boolean m_isCollection = true;


  /**
   * Constructor.
   * Simple constructor which uses default state for everything except resource type.
   *
   * @param type  resource type
   */
  public SubResourceDefinition(Resource.Type type) {
    m_type = type;
  }

  /**
   * Constructor.
   * This constructor allows all state to be set.
   *
   * @param type            resource type
   * @param setForeignKeys  set of additional foreign keys to include in resource by default
   * @param isCollection    whether the sub-resource is a collection
   */
  public SubResourceDefinition(Resource.Type type, Set<Resource.Type> setForeignKeys, boolean isCollection) {
    m_type = type;
    m_setForeignKeys = setForeignKeys;
    m_isCollection = isCollection;
  }

  /**
   * Obtain the sub-resource type.
   *
   * @return  the sub-resource type
   */
  public Resource.Type getType() {
    return m_type;
  }

  /**
   * Get the set of additional foreign key properties that are included in the resource by default.
   *
   * @return  set of additional foreign key properties
   */
  public Set<Resource.Type> getAdditionalForeignKeys() {
    return m_setForeignKeys == null ? Collections.<Resource.Type>emptySet() : m_setForeignKeys;
  }

  /**
   * Whether the sub-resource is a collection.
   *
   * @return  true if a collection, false if an instance
   */
  public boolean isCollection() {
    return m_isCollection;
  }
}

"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/TaskResourceDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.resources;

import org.apache.ambari.server.controller.spi.Resource;


/**
 * Task resource definition.
 */
public class TaskResourceDefinition extends BaseResourceDefinition {

  /**
   * Constructor.
   */
  public TaskResourceDefinition() {
    super(Resource.Type.Task);
  }

  @Override
  public String getPluralName() {
    return "tasks";
  }

  @Override
  public String getSingularName() {
    return "task";
  }
}"
ambari-server/src/main/java/org/apache/ambari/server/api/resources/UserResourceDefinition.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.api.resources;

import java.util.Collections;
import java.util.Set;

import org.apache.ambari.server.controller.spi.Resource;

/**
 * User Resource Definition
 */
public class UserResourceDefinition extends BaseResourceDefinition {

  public UserResourceDefinition() {
    super(Resource.Type.User);
  }
  
  @Override
  public String getPluralName() {
    return "users";
  }

  @Override
  public String getSingularName() {
    return "user";
  }

  @Override
  public Set<SubResourceDefinition> getSubResourceDefinitions() {
    return Collections.emptySet();
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/rest/BootStrapResource.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.rest;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.ArrayList;
import java.util.List;

import javax.ws.rs.Consumes;
import javax.ws.rs.GET;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.WebApplicationException;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;

import org.apache.ambari.server.bootstrap.BSHostStatus;
import org.apache.ambari.server.bootstrap.BSResponse;
import org.apache.ambari.server.bootstrap.BootStrapImpl;
import org.apache.ambari.server.bootstrap.BootStrapStatus;
import org.apache.ambari.server.bootstrap.SshHostInfo;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;

@Path("/bootstrap")
public class BootStrapResource {

  private static BootStrapImpl bsImpl;
  private static Log LOG = LogFactory.getLog(BootStrapResource.class);

  @Inject
  public static void init(BootStrapImpl instance) {
    bsImpl = instance;
  }
  /**
   * Run bootstrap on a list of hosts.
   * @response.representation.200.doc
   *
   * @response.representation.200.mediaType application/json
   * @response.representation.406.doc Error in format
   * @response.representation.408.doc Request Timed out
   * @throws Exception
   */
  @POST
  @Consumes(MediaType.APPLICATION_JSON)
  @Produces({MediaType.APPLICATION_JSON, MediaType.APPLICATION_XML})
  public BSResponse bootStrap(SshHostInfo sshInfo, @Context UriInfo uriInfo) {
    
    normalizeHosts(sshInfo);

    BSResponse resp = bsImpl.runBootStrap(sshInfo);

    return resp;
  }

  /**
   * Current BootStrap Information thats running.
   * @response.representation.200.doc
   *
   * @response.representation.200.mediaType application/json
   * @response.representation.406.doc Error in format
   * @response.representation.408.doc Request Timed out
   * @throws Exception
   */
  @GET
  @Path("/{requestId}")
  @Produces({MediaType.APPLICATION_JSON, MediaType.APPLICATION_XML})
  public BootStrapStatus getBootStrapStatus(@PathParam("requestId")
    long requestId, @Context UriInfo info) {
    BootStrapStatus status = bsImpl.getStatus(requestId);
    if (status == null)
      throw new WebApplicationException(Response.Status.NO_CONTENT);
    return status;
  }


  /**
   * Gets a list of bootstrapped hosts.
   *
   * @param info  the host info, with no SSL key information
   */
  @GET
  @Path("/hosts")
  @Produces(MediaType.APPLICATION_JSON)
  public List<BSHostStatus> getBootStrapHosts(@Context UriInfo uriInfo) {
    List<BSHostStatus> allStatus = bsImpl.getHostInfo(null);

    if (0 == allStatus.size())
      throw new WebApplicationException(Response.Status.NO_CONTENT);

    return allStatus;
  }
  /**
   * Gets a list of bootstrapped hosts.
   *
   * @param info  the host info, with no SSL key information required
   */
  @POST
  @Path("/hosts")
  @Produces(MediaType.APPLICATION_JSON)
  public List<BSHostStatus> getBootStrapHosts(SshHostInfo info, @Context UriInfo uriInfo) {

    List<BSHostStatus> allStatus = bsImpl.getHostInfo(info.getHosts());

    if (0 == allStatus.size())
      throw new WebApplicationException(Response.Status.NO_CONTENT);

    return allStatus;
  }
  
  
  private void normalizeHosts(SshHostInfo info) {
    List<String> validHosts = new ArrayList<String>();
    List<String> newHosts = new ArrayList<String>();
    
    for (String host: info.getHosts()) {
      try {
        InetAddress addr = InetAddress.getByName(host);
        
        if (!validHosts.contains(addr.getHostAddress())) {
          validHosts.add(addr.getHostAddress());
          newHosts.add(host);
        } else {
          LOG.warn("Host " + host + " has already been targeted to be bootstrapped.");
        }
      } catch (UnknownHostException e) {
        LOG.warn("Host " + host + " cannot be determined.");
      }
    }
    
    info.setHosts(newHosts);
  }
  
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/rest/HealthCheck.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.rest;

import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

/**
 * A simple POJO to do a health check on the server to see if its running
 * or not
 */

@Path("/check")
public class HealthCheck {
  private static final String status = "RUNNING";
  // This method is called if TEXT_PLAIN is request

  @GET
  @Produces(MediaType.TEXT_PLAIN)
  public String plainTextCheck() {
    return status;
  }

  // This method is called if XML is request
  @GET
  @Produces(MediaType.TEXT_XML)
  public String xmlCheck() {
    return "<?xml version=\"1.0\"?>" + "<status> " + status + "</status>";
  }

  // This method is called if HTML is request
  @GET
  @Produces(MediaType.TEXT_HTML)
  public String  htmlCheck() {
    return "<html> " + "<title>" + "Status" + "</title>"
        + "<body><h1>" + status + "</body></h1>" + "</html> ";
  }
}

"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ActionService.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.api.services;

import javax.ws.rs.GET;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import java.util.HashMap;
import java.util.Map;

public class ActionService extends BaseService {
  /**
   * Parent cluster name.
   */
  private String m_clusterName;
  
  private String m_serviceName;

  /**
   * Constructor.
   *
   * @param clusterName cluster id
   * @param serviceName service
   */
  public ActionService(String clusterName, String serviceName) {
    m_clusterName = clusterName;
    m_serviceName = serviceName;
  }

  /**
   * Handles URL: /clusters/{clusterId}/services/{serviceName}/actions
   * Get all actions for a service in a cluster.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return service collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getActions(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET,
        createActionResource(m_clusterName, m_serviceName, null));
  }

  /**
   * Handles URL: /clusters/{clusterId}/services/{serviceName}/actions.  
   * The body should contain:
   * <pre>
   * {
   *     "actionName":"name_string",
   *     "parameters":
   *     {
   *         "key1":"value1",
   *         // ...
   *         "keyN":"valueN"
   *     }
   * }
   * </pre>
   * Get all services for a cluster.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return service collection resource representation
   */
  @POST
  @Produces("text/plain")
  public Response createActions(String body,@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, body, ui, Request.Type.POST,
        createActionResource(m_clusterName, m_serviceName, null));
  }
  
  /**
   * Handles: POST /clusters/{clusterId}/services/{serviceId}/{actionName}
   * Create a specific action.
   *
   * @param body        http body
   * @param headers     http headers
   * @param ui          uri info
   * @param actionName  action name
   *
   * @return information regarding the created action
   */
  @POST
  @Path("{actionName}")
  @Produces("text/plain")
  public Response createAction(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                               @PathParam("actionName") String actionName) {
    return handleRequest(headers, body, ui, Request.Type.POST,
        createActionResource(m_clusterName, m_serviceName, actionName));
  }

  /**
   * Create an action resource instance.
   *
   * @param clusterName cluster name
   * @param serviceName service name
   * @param actionName  action name
   *
   * @return an action resource instance
   */
  ResourceInstance createActionResource(String clusterName, String serviceName, String actionName) {
    Map<Resource.Type,String> mapIds = new HashMap<Resource.Type, String>();
    mapIds.put(Resource.Type.Cluster, clusterName);
    mapIds.put(Resource.Type.Service, serviceName);
    mapIds.put(Resource.Type.Action, actionName);

    return createResource(Resource.Type.Action, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/AmbariMetaInfo.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import com.google.inject.Inject;
import com.google.inject.Singleton;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.ambari.server.state.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.w3c.dom.*;
import org.xml.sax.SAXException;

import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;
import javax.xml.parsers.ParserConfigurationException;
import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * ServiceInfo responsible getting information about cluster.
 */
@Singleton
public class AmbariMetaInfo {

    private List<StackInfo> stacksResult = new ArrayList<StackInfo>();
    private File stackRoot;
    private final static Logger LOG = LoggerFactory
            .getLogger(AmbariMetaInfo.class);

    private static final String SERVICES_FOLDER_NAME = "services";
    private static final String SERVICE_METAINFO_FILE_NAME = "metainfo.xml";
    private static final String SERVICE_CONFIG_FOLDER_NAME = "configuration";
    private static final String SERVICE_CONFIG_FILE_NAME_POSTFIX = "-site.xml";

    private static final String REPOSITORY_FILE_NAME = "repoinfo.xml";
    private static final String REPOSITORY_FOLDER_NAME = "repos";
    private static final String REPOSITORY_XML_MAIN_BLOCK_NAME = "os";
    private static final String REPOSITORY_XML_ATTRIBUTE_OS_TYPE = "type";
    private static final String REPOSITORY_XML_REPO_BLOCK_NAME = "repo";
    private static final String REPOSITORY_XML_PROPERTY_BASEURL = "baseurl";
    private static final String REPOSITORY_XML_PROPERTY_REPOID = "repoid";
    private static final String REPOSITORY_XML_PROPERTY_REPONAME = "reponame";
    private static final String REPOSITORY_XML_PROPERTY_MIRRORSLIST = "mirrorslist";

    private static final String METAINFO_XML_MAIN_BLOCK_NAME = "metainfo";
    private static final String METAINFO_XML_PROPERTY_VERSION = "version";
    private static final String METAINFO_XML_PROPERTY_USER = "user";
    private static final String METAINFO_XML_PROPERTY_COMMENT = "comment";
    private static final String METAINFO_XML_PROPERTY_COMPONENT_MAIN = "component";
    private static final String METAINFO_XML_PROPERTY_COMPONENT_NAME = "name";
    private static final String METAINFO_XML_PROPERTY_COMPONENT_CATEGORY = "category";

    private static final String PROPERTY_XML_MAIN_BLOCK_NAME = "property";
    private static final String PROPERTY_XML_PROPERTY_NAME = "name";
    private static final String PROPERTY_XML_PROPERTY_VALUE = "value";
    private static final String PROPERTY_XML_PROPERTY_DESCRIPTION = "description";


    /**
     * Ambari Meta Info Object
     *
     * @param conf Configuration API to be used.
     * @throws Exception
     */
    @Inject
    public AmbariMetaInfo(Configuration conf) throws Exception {
        String stackPath = conf.getMetadataPath();
        this.stackRoot = new File(stackPath);
    }

    @Inject
    public AmbariMetaInfo(File stackRoot) throws Exception {
        this.stackRoot = stackRoot;
    }


    /**
     * Initialize the Ambari Meta Info
     *
     * @throws Exception throws exception if not able to parse the Meta data.
     */
    public void init() throws Exception {
        getConfigurationInformation(stackRoot);
    }


    /**
     * Get component category
     *
     * @param stackName
     * @param version
     * @param serviceName
     * @param componentName
     * @return component component Info
     */
    public ComponentInfo getComponentCategory(String stackName, String version,
                                              String serviceName, String componentName) {
        ComponentInfo component = null;
        List<ComponentInfo> components = getComponentsByService(stackName, version,
                serviceName);
        if (components != null)
            for (ComponentInfo cmp : components) {
                if (cmp.getName().equals(componentName)) {
                    component = cmp;
                    break;
                }
            }
        return component;
    }


    /**
     * Get components by service
     *
     * @param stackName
     * @param version
     * @param serviceName
     * @return
     */
    public List<ComponentInfo> getComponentsByService(String stackName,
                                                      String version, String serviceName) {
        List<ComponentInfo> componentsResult = null;
        ServiceInfo service = getServiceInfo(stackName, version, serviceName);
        if (service != null)
            componentsResult = service.getComponents();

        return componentsResult;
    }

    public Map<String, List<RepositoryInfo>> getRepository(String stackName,
                                                           String version) {
        Map<String, List<RepositoryInfo>> reposResult = null;
        StackInfo stack = getStackInfo(stackName, version);
        if (stack != null) {
            List<RepositoryInfo> repository = stack.getRepositories();
            reposResult = new HashMap<String, List<RepositoryInfo>>();
            for (RepositoryInfo repo : repository) {
                if (!reposResult.containsKey(repo.getOsType())) {
                    reposResult.put(repo.getOsType(),
                            new ArrayList<RepositoryInfo>());
                }
                reposResult.get(repo.getOsType()).add(repo);
            }
        }
        return reposResult;
    }

    /*
     * function for given a stack name and version, is it a supported stack
     */
    public boolean isSupportedStack(String stackName, String version) {
        boolean exist = false;
        StackInfo stack = getStackInfo(stackName, version);
        if (stack == null)
            exist = true;
        return exist;
    }

    /*
     * support isValidService(), isValidComponent for a given stack/version
     */
    public boolean isValidService(String stackName, String version,
                                  String serviceName) {
        ServiceInfo service = getServiceInfo(stackName, version, serviceName);
        return (service != null);
    }

    /*
     * support isValidService(), isValidComponent for a given stack/version
     */
    public boolean isValidServiceComponent(String stackName, String version,
                                           String serviceName, String componentName) {
        ServiceInfo service = getServiceInfo(stackName, version, serviceName);
        if (service == null) {
            return false;
        }
        for (ComponentInfo compInfo : service.getComponents()) {
            if (compInfo.getName().equals(componentName)) {
                return true;
            }
        }
        return false;
    }


    /**
     * Get the name of a service given the component name.
     *
     * @param stackName     the stack name
     * @param version       the stack version
     * @param componentName the component name
     * @return the service name
     */
    public String getComponentToService(String stackName, String version,
                                        String componentName) {
        if (LOG.isDebugEnabled()) {
            LOG.debug("Looking for service for component"
                    + ", stackName=" + stackName
                    + ", stackVersion=" + version
                    + ", componentName=" + componentName);
        }
        Map<String, ServiceInfo> services = getServices(stackName, version);
        String retService = null;
        if (services == null
                || services.isEmpty()) {
            return retService;
        }
        boolean found = false;
        for (Map.Entry<String, ServiceInfo> entry : services.entrySet()) {
            for (ComponentInfo compInfo : entry.getValue().getComponents()) {
                if (compInfo.getName().equals(componentName)) {
                    retService = entry.getKey();
                    found = true;
                    break;
                }
            }
            if (found)
                break;
        }
        return retService;
    }

    /**
     * Get the service configs supported for a service in a particular stack
     *
     * @param stackName   the stack name
     * @param version     the version of the stack
     * @param serviceName the name of the service in the stack
     * @return the config knobs supported for the service
     */
    public Map<String, Map<String, String>> getSupportedConfigs(String stackName,
                                                                String version, String serviceName) {
        Map<String, Map<String, String>> propertiesResult = new HashMap<String, Map<String, String>>();

        ServiceInfo service = getServiceInfo(stackName, version, serviceName);
        if (service != null)
            if (serviceName.equals(service.getName())) {
                List<PropertyInfo> properties = service.getProperties();
                if (properties != null)
                    for (PropertyInfo propertyInfo : properties) {
                        Map<String, String> fileProperties = propertiesResult
                                .get(propertyInfo.getFilename());
                        if (fileProperties == null) {
                            fileProperties = new HashMap<String, String>();
                            fileProperties.put(propertyInfo.getName(),
                                    propertyInfo.getValue());
                            propertiesResult.put(propertyInfo.getFilename(), fileProperties);

                        } else {
                            fileProperties.put(propertyInfo.getName(),
                                    propertyInfo.getValue());
                        }

                    }
            }

        return propertiesResult;
    }

    /**
     * Given a stack name and version return all the services with info
     *
     * @param stackName the stack name
     * @param version   the version of the stack
     * @return the information of abt varios services that are supported in the
     *         stack
     */
    public Map<String, ServiceInfo> getServices(String stackName, String version) {

        Map<String, ServiceInfo> servicesInfoResult = new HashMap<String, ServiceInfo>();

        List<ServiceInfo> services = null;
        StackInfo stack = getStackInfo(stackName, version);
        if (stack == null)
            return null;
        services = stack.getServices();
        if (services != null)
            for (ServiceInfo service : services) {
                servicesInfoResult.put(service.getName(), service);
            }
        return servicesInfoResult;
    }

    public ServiceInfo getServiceInfo(String stackName, String version,
                                      String serviceName) {
        ServiceInfo serviceInfoResult = null;
        List<ServiceInfo> services = null;
        StackInfo stack = getStackInfo(stackName, version);
        if (stack == null)
            return null;
        services = stack.getServices();
        if (services != null)
            for (ServiceInfo service : services) {
                if (serviceName.equals(service.getName())) {
                    serviceInfoResult = service;
                    break;
                }
            }
        return serviceInfoResult;
    }

    public List<ServiceInfo> getSupportedServices(String stackName, String version) {
        List<ServiceInfo> servicesResulr = null;
        StackInfo stack = getStackInfo(stackName, version);
        if (stack != null)
            servicesResulr = stack.getServices();
        return servicesResulr;
    }

    public List<StackInfo> getSupportedStacks() {
        return stacksResult;
    }

    public StackInfo getStackInfo(String stackName, String version) {
        StackInfo stackInfoResult = null;

        for (StackInfo stack : stacksResult) {
            if (stackName.equals(stack.getName())
                    && version.equals(stack.getVersion())) {
                stackInfoResult = stack;
                break;
            }
        }
        return stackInfoResult;
    }


    private void getConfigurationInformation(File stackRoot) throws Exception {

        if (LOG.isDebugEnabled()) {
            LOG.debug("Loading stack information"
                    + ", stackRoot=" + stackRoot.getAbsolutePath());
        }

        if (!stackRoot.isDirectory() && !stackRoot.exists())
            throw new IOException("" + Configuration.METADETA_DIR_PATH
                    + " should be a directory with stack"
                    + ", stackRoot=" + stackRoot.getAbsolutePath());
        File[] stacks = stackRoot.listFiles();
        for (File stackFolder : stacks) {
            if (stackFolder.isFile())
                continue;
            File[] concretStacks = stackFolder.listFiles();
            for (File stack : concretStacks) {
                if (stack.isFile())
                    continue;
                StackInfo stackInfo = new StackInfo();
                stackInfo.setName(stackFolder.getName());
                stackInfo.setVersion(stack.getName());

                if (LOG.isDebugEnabled()) {
                    LOG.debug("Adding new stack to known stacks"
                            + ", stackName=" + stackFolder.getName()
                            + ", stackVersion=" + stack.getName());
                }

                stacksResult.add(stackInfo);
                // get repository data for current stack of techs
                File repositoryFolder = new File(stack.getAbsolutePath()
                        + File.separator + REPOSITORY_FOLDER_NAME + File.separator
                        + REPOSITORY_FILE_NAME);

                if (repositoryFolder.exists()) {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug("Adding repositories to stack"
                                + ", stackName=" + stackFolder.getName()
                                + ", stackVersion=" + stack.getName()
                                + ", repoFolder=" + repositoryFolder.getPath());
                    }
                    List<RepositoryInfo> repositoryInfoList = getRepository(repositoryFolder);
                    stackInfo.getRepositories().addAll(repositoryInfoList);
                }

                // Get services for this stack
                File servicesRootFolder = new File(stack.getAbsolutePath()
                        + File.separator + SERVICES_FOLDER_NAME);
                File[] servicesFolders = servicesRootFolder.listFiles();

                if (servicesFolders != null) {
                    for (File serviceFolder : servicesFolders) {
                        // Get information about service
                        ServiceInfo serviceInfo = new ServiceInfo();
                        serviceInfo.setName(serviceFolder.getName());
                        stackInfo.getServices().add(serviceInfo);

                        if (LOG.isDebugEnabled()) {
                            LOG.debug("Adding new service to stack"
                                    + ", stackName=" + stackFolder.getName()
                                    + ", stackVersion=" + stack.getName()
                                    + ", serviceName=" + serviceInfo.getName());
                        }

                        // Get metainfo data from metainfo.xml
                        File metainfoFile = new File(serviceFolder.getAbsolutePath()
                                + File.separator + SERVICE_METAINFO_FILE_NAME);
                        if (metainfoFile.exists()) {
                            setMetaInfo(metainfoFile, serviceInfo);
                        }

                        // Get all properties from all "configs/*-site.xml" files
                        File serviceConfigFolder = new File(serviceFolder.getAbsolutePath()
                                + File.separator + SERVICE_CONFIG_FOLDER_NAME);
                        File[] configFiles = serviceConfigFolder.listFiles();
                        if (configFiles != null) {
                            for (File config : configFiles) {
                                if (config.getName().endsWith(SERVICE_CONFIG_FILE_NAME_POSTFIX)) {
                                    serviceInfo.getProperties().addAll(getProperties(config));
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    private List<RepositoryInfo> getRepository(File repositoryFile) throws ParserConfigurationException, IOException, SAXException {

        List<RepositoryInfo> repositorysInfo = new ArrayList<RepositoryInfo>();
//    try {

        DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();
        DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();
        Document doc = dBuilder.parse(repositoryFile);

        NodeList osNodes = doc
                .getElementsByTagName(REPOSITORY_XML_MAIN_BLOCK_NAME);

        for (int index = 0; index < osNodes.getLength(); index++) {
            Node osNode = osNodes.item(index);

            if (osNode.getNodeType() == Node.ELEMENT_NODE) {
                if (!osNode.getNodeName().equals(REPOSITORY_XML_MAIN_BLOCK_NAME)) {
                    continue;
                }
                NamedNodeMap attrs = osNode.getAttributes();
                Node osAttr = attrs.getNamedItem(REPOSITORY_XML_ATTRIBUTE_OS_TYPE);
                if (osAttr == null) {
                    continue;
                }
                String osType = osAttr.getNodeValue();

                NodeList repoNodes = osNode.getChildNodes();
                for (int j = 0; j < repoNodes.getLength(); j++) {
                    Node repoNode = repoNodes.item(j);
                    if (repoNode.getNodeType() != Node.ELEMENT_NODE
                            || !repoNode.getNodeName().equals(
                            REPOSITORY_XML_REPO_BLOCK_NAME)) {
                        continue;
                    }
                    Element property = (Element) repoNode;
                    String repoId = getTagValue(REPOSITORY_XML_PROPERTY_REPOID,
                            property);
                    String repoName = getTagValue(REPOSITORY_XML_PROPERTY_REPONAME,
                            property);
                    String baseUrl = getTagValue(
                            REPOSITORY_XML_PROPERTY_BASEURL, property);
                    String mirrorsList = getTagValue(
                            REPOSITORY_XML_PROPERTY_MIRRORSLIST, property);

                    String[] osTypes = osType.split(",");

                    for (String os : osTypes) {
                        RepositoryInfo repositoryInfo = new RepositoryInfo();
                        repositoryInfo.setOsType(os.trim());
                        repositoryInfo.setRepoId(repoId);
                        repositoryInfo.setRepoName(repoName);
                        repositoryInfo.setBaseUrl(baseUrl);
                        repositoryInfo.setMirrorsList(mirrorsList);

                        if (LOG.isDebugEnabled()) {
                            LOG.debug("Adding repo to stack"
                                    + ", repoInfo=" + repositoryInfo.toString());
                        }
                        repositorysInfo.add(repositoryInfo);
                    }
                }
            }
        }
//    } catch (Exception e) {
//      e.printStackTrace();
//    }

        return repositorysInfo;
    }

    private void setMetaInfo(File metainfoFile, ServiceInfo serviceInfo) {

        DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();

        Document doc = null;
        DocumentBuilder dBuilder = null;
        try {
            dBuilder = dbFactory.newDocumentBuilder();
            doc = dBuilder.parse(metainfoFile);
        } catch (SAXException e) {
            LOG.error("Error while parsing metainf.xml", e);
        } catch (IOException e) {
            LOG.error("Error while open metainf.xml", e);
        } catch (ParserConfigurationException e) {
            LOG.error("Error while parsing metainf.xml", e);
        }

        if(doc==null) return;

        doc.getDocumentElement().normalize();

        NodeList metaInfoNodes = doc
                .getElementsByTagName(METAINFO_XML_MAIN_BLOCK_NAME);

        if (metaInfoNodes.getLength() > 0) {
            Node metaInfoNode = metaInfoNodes.item(0);
            if (metaInfoNode.getNodeType() == Node.ELEMENT_NODE) {

                Element metaInfoElem = (Element) metaInfoNode;

                serviceInfo.setVersion(getTagValue(METAINFO_XML_PROPERTY_VERSION,
                        metaInfoElem));
                serviceInfo.setUser(getTagValue(METAINFO_XML_PROPERTY_USER,
                        metaInfoElem));
                serviceInfo.setComment(getTagValue(METAINFO_XML_PROPERTY_COMMENT,
                        metaInfoElem));
            }
        }

        NodeList componentInfoNodes = doc
                .getElementsByTagName(METAINFO_XML_PROPERTY_COMPONENT_MAIN);

        if (componentInfoNodes.getLength() > 0) {
            for (int index = 0; index < componentInfoNodes.getLength(); index++) {
                Node componentInfoNode = componentInfoNodes.item(index);
                if (componentInfoNode.getNodeType() == Node.ELEMENT_NODE) {
                    Element componentInfoElem = (Element) componentInfoNode;

                    ComponentInfo componentInfo = new ComponentInfo();
                    componentInfo.setName(getTagValue(
                            METAINFO_XML_PROPERTY_COMPONENT_NAME, componentInfoElem));
                    componentInfo.setCategory(getTagValue(
                            METAINFO_XML_PROPERTY_COMPONENT_CATEGORY, componentInfoElem));
                    serviceInfo.getComponents().add(componentInfo);

                }
            }
        }

    }

    private List<PropertyInfo> getProperties(File propertyFile) {

        List<PropertyInfo> resultPropertyList = new ArrayList<PropertyInfo>();
        try {
            DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();
            DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();
            Document doc = dBuilder.parse(propertyFile);
            doc.getDocumentElement().normalize();

            NodeList propertyNodes = doc
                    .getElementsByTagName(PROPERTY_XML_MAIN_BLOCK_NAME);

            for (int index = 0; index < propertyNodes.getLength(); index++) {

                Node node = propertyNodes.item(index);
                if (node.getNodeType() == Node.ELEMENT_NODE) {
                    Element property = (Element) node;
                    PropertyInfo propertyInfo = new PropertyInfo();
                    propertyInfo
                            .setName(getTagValue(PROPERTY_XML_PROPERTY_NAME, property));
                    propertyInfo.setValue(getTagValue(PROPERTY_XML_PROPERTY_VALUE,
                            property));

                    propertyInfo.setDescription(getTagValue(
                            PROPERTY_XML_PROPERTY_DESCRIPTION, property));
                    propertyInfo.setFilename(propertyFile.getName());

                    if (propertyInfo.getName() == null || propertyInfo.getValue() == null)
                        continue;

                    resultPropertyList.add(propertyInfo);
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
        return resultPropertyList;
    }

    private String getTagValue(String sTag, Element rawElement) {
        String result = null;

        if (rawElement.getElementsByTagName(sTag) != null && rawElement.getElementsByTagName(sTag).getLength() > 0) {
            if (rawElement.getElementsByTagName(sTag).item(0) != null) {
                NodeList element = rawElement.getElementsByTagName(sTag).item(0).getChildNodes();

                if (element != null && element.item(0)!=null) {
                    Node value = (Node) element.item(0);

                    result = value.getNodeValue();
                }
            }
        }

        return result;
    }

    public boolean areOsTypesCompatible(String type1, String type2) {
        if (type1 == null || type2 == null) {
            return false;
        }
        if (type1.equals(type2)) {
            return true;
        }
        if (type1.equals("redhat5") || type1.equals("centos5")) {
            if (type2.equals("centos5")
                    || type2.equals("redhat5")) {
                return true;
            }
        } else if (type1.equals("redhat6") || type1.equals("centos6")) {
            if (type2.equals("centos6")
                    || type2.equals("redhat6")) {
                return true;
            }
        }
        return false;
    }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/AmbariMetaService.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import java.io.IOException;
import java.util.List;

import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Response;
import javax.xml.bind.JAXBException;

import org.apache.ambari.server.state.ServiceInfo;
import org.apache.ambari.server.state.StackInfo;
import org.codehaus.jackson.JsonGenerationException;
import org.codehaus.jackson.map.JsonMappingException;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.map.SerializationConfig;
import org.codehaus.jackson.map.ser.FilterProvider;
import org.codehaus.jackson.map.ser.impl.SimpleBeanPropertyFilter;
import org.codehaus.jackson.map.ser.impl.SimpleFilterProvider;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Inject;

@Path("/stacks/")
public class AmbariMetaService {
  private static AmbariMetaInfo ambariMetainfo;
  private static Logger LOG = LoggerFactory.getLogger(AmbariMetaService.class);

  @Inject
  public static void init(AmbariMetaInfo instance) {
    ambariMetainfo = instance;
  }

  /**
   * Filter properties from the service info and others
   * @param object
   * @return
   * @throws IOException
   * @throws JsonMappingException
   * @throws JsonGenerationException
   */
  public String filterProperties(Object object, boolean ignoreConfigs) throws
  JsonGenerationException, JsonMappingException, IOException {
    ObjectMapper mapper = new ObjectMapper();
    mapper.configure(SerializationConfig.Feature.INDENT_OUTPUT, true);
    mapper.configure(SerializationConfig.Feature.USE_ANNOTATIONS, true);
    if (ignoreConfigs) {
    FilterProvider filters = new SimpleFilterProvider().addFilter(
          "propertiesfilter",
          SimpleBeanPropertyFilter.serializeAllExcept("properties"));
      mapper.setFilters(filters);
    } else {
      FilterProvider filters = new SimpleFilterProvider().addFilter(
          "propertiesfilter", SimpleBeanPropertyFilter.serializeAllExcept());
      mapper.setFilters(filters);
    }
    String json = mapper.writeValueAsString(object);
    return json;
  }

  @GET
  @Produces("text/plain")
  public Response getStacks() throws JsonGenerationException,
  JsonMappingException, JAXBException, IOException {
    List<StackInfo> stackInfos = ambariMetainfo.getSupportedStacks();
    String output = filterProperties(stackInfos, true);
    return Response.status(Response.Status.OK).entity(output).build();
  }

  @GET
  @Path("{stackName}/version/{versionNumber}")
  @Produces("text/plain")
  public Response getStack(@PathParam("stackName") String stackName,
      @PathParam("versionNumber") String versionNumber) throws
      JsonGenerationException, JsonMappingException, JAXBException, IOException  {
    StackInfo stackInfo = ambariMetainfo.getStackInfo(stackName, versionNumber);
    String output = filterProperties(stackInfo, true);
    return Response.status(Response.Status.OK).entity(output).build();
  }

  @GET
  @Path("{stackName}/version/{versionNumber}/services/{serviceName}")
  @Produces("text/plain")
  public Response getServiceInfo(@PathParam("stackName") String stackName,
      @PathParam("versionNumber") String versionNumber,
      @PathParam("serviceName") String serviceName) throws
      JsonGenerationException, JsonMappingException, JAXBException, IOException  {
    ServiceInfo serviceInfo = ambariMetainfo.getServiceInfo(stackName,
        versionNumber, serviceName);
    String output = filterProperties(serviceInfo, false);
    return Response.status(Response.Status.OK).entity(output).build();
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/BasePersistenceManager.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.controller.utilities.ClusterControllerHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.apache.ambari.server.controller.spi.ClusterController;
import org.apache.ambari.server.controller.spi.Request;

import java.util.Map;
import java.util.Set;

/**
 * Base PersistenceManager functionality.
 */
public abstract class BasePersistenceManager implements PersistenceManager {

  protected ClusterController getClusterController() {
    return ClusterControllerHelper.getClusterController();
  }

  protected Request createControllerRequest(Set<Map<String, Object>> setProperties) {
    return PropertyHelper.getCreateRequest(setProperties);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/BaseRequest.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.*;
import org.apache.ambari.server.api.services.parsers.JsonPropertyParser;
import org.apache.ambari.server.api.services.parsers.RequestBodyParser;
import org.apache.ambari.server.api.services.serializers.JsonSerializer;
import org.apache.ambari.server.api.services.serializers.ResultSerializer;
import org.apache.ambari.server.controller.internal.TemporalInfoImpl;
import org.apache.ambari.server.controller.predicate.*;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.TemporalInfo;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;
import java.io.UnsupportedEncodingException;
import java.net.URLDecoder;
import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

/**
 * Request implementation.
 */
public abstract class BaseRequest implements Request {

  /**
   * URI information
   */
  private UriInfo m_uriInfo;

  /**
   * Http headers
   */
  private HttpHeaders m_headers;

  /**
   * Http Body
   */
  private String m_body;


  /**
   * Predicate operators.
   */
  private Pattern m_pattern = Pattern.compile("!=|>=|<=|=|>|<");

  /**
   * Associated resource definition
   */
  private ResourceInstance m_resource;


  /**
   * Constructor.
   *
   * @param headers      http headers
   * @param body         http body
   * @param uriInfo      uri information
   * @param resource     associated resource definition
   */
  public BaseRequest(HttpHeaders headers, String body, UriInfo uriInfo, ResourceInstance resource) {

    m_headers  = headers;
    m_body     = body;
    m_uriInfo  = uriInfo;
    m_resource = resource;
  }

  @Override
  public ResourceInstance getResource() {
    return m_resource;
  }

  @Override
  public String getURI() {
    try {
      return URLDecoder.decode(m_uriInfo.getRequestUri().toASCIIString(), "UTF-8");
    } catch (UnsupportedEncodingException e) {
      throw new RuntimeException("Unable to decode URI: " + e, e);
    }
  }

  @Override
  public int getAPIVersion() {
    return 0;
  }

  @Override
  public Predicate getQueryPredicate() {
    //todo: parse during init
    //not using getQueryParameters because it assumes '=' operator
    String uri = getURI();
    int qsBegin = uri.indexOf("?");

    if (qsBegin == -1) return null;

    String[] tokens = uri.substring(qsBegin + 1).split("&");

    Set<BasePredicate> setPredicates = new HashSet<BasePredicate>();
    for (String outerToken : tokens) {
      if (outerToken.startsWith("_=")) {
        // NOTE: This is to enable UI to pass a _= parameter for unique query 
        // string even though the backend doesnt need it.
        continue;
      }
      
      if (outerToken != null &&  !outerToken.startsWith("fields")) {
        setPredicates.add(outerToken.contains("|") ?
            handleOrPredicate(outerToken) : createPredicate(outerToken));
      }
    }

    if (setPredicates.size() == 1) {
      return setPredicates.iterator().next();
    } else if (setPredicates.size() > 1) {
      return new AndPredicate(setPredicates.toArray(new BasePredicate[setPredicates.size()]));
    } else {
      return null;
    }
  }

  @Override
  public Map<String, TemporalInfo> getFields() {
    Map<String, TemporalInfo> mapProperties;
    String partialResponseFields = m_uriInfo.getQueryParameters().getFirst("fields");
    if (partialResponseFields == null) {
      mapProperties = Collections.emptyMap();
    } else {
      Set<String> setMatches = new HashSet<String>();
      // Pattern basically splits a string using ',' as the deliminator unless ',' is between '[' and ']'.
      // Actually, captures char sequences between ',' and all chars between '[' and ']' including ','.
      Pattern re = Pattern.compile("[^,\\[]*?\\[[^\\]]*?\\]|[^,]+");
      Matcher m = re.matcher(partialResponseFields);
      while (m.find()){
        for (int groupIdx = 0; groupIdx < m.groupCount() + 1; groupIdx++) {
          setMatches.add(m.group(groupIdx));
        }
      }

      mapProperties = new HashMap<String, TemporalInfo>(setMatches.size());
      for (String field : setMatches) {
        TemporalInfo temporalInfo = null;
        if (field.contains("[")) {
          String[] temporalData = field.substring(field.indexOf('[') + 1,
              field.indexOf(']')).split(",");
          field = field.substring(0, field.indexOf('['));
          long start = Long.parseLong(temporalData[0].trim());
          long end   = -1;
          long step  = -1;
          if (temporalData.length >= 2) {
            end = Long.parseLong(temporalData[1].trim());
            if (temporalData.length == 3) {
              step = Long.parseLong(temporalData[2].trim());
            }
          }
          temporalInfo = new TemporalInfoImpl(start, end, step);
        }
        mapProperties.put(field, temporalInfo);
      }
    }

    return mapProperties;
  }

  @Override
  public Map<String, List<String>> getHttpHeaders() {
    return m_headers.getRequestHeaders();
  }

  @Override
  public String getHttpBody() {
    return m_body;
  }

  @Override
  public Set<Map<String, Object>> getHttpBodyProperties() {
    return getHttpBodyParser().parse(getHttpBody());
  }

  @Override
  public ResultSerializer getResultSerializer() {
    return new JsonSerializer();
  }

  @Override
  public ResultPostProcessor getResultPostProcessor() {
    return new ResultPostProcessorImpl(this);
  }

  private BasePredicate createPredicate(String token) {

    Matcher m = m_pattern.matcher(token);
    m.find();

    String propertyId = token.substring(0, m.start());
    String     value      = token.substring(m.end());
    String     operator   = m.group();

    if (operator.equals("=")) {
      return new EqualsPredicate<String>(propertyId, value);
    } else if (operator.equals("!=")) {
      return new NotPredicate(new EqualsPredicate<String>(propertyId, value));
    } else if (operator.equals("<")) {
      return new LessPredicate<String>(propertyId, value);
    } else if (operator.equals(">"))  {
      return new GreaterPredicate<String>(propertyId, value);
    } else if (operator.equals("<=")) {
      return new LessEqualsPredicate<String>(propertyId, value);
    } else if (operator.equals(">=")) {
      return new GreaterEqualsPredicate<String>(propertyId, value);
    } else {
      throw new RuntimeException("Unknown operator provided in predicate: " + operator);
    }
  }

  private BasePredicate handleOrPredicate(String predicate) {
    Set<BasePredicate> setPredicates = new HashSet<BasePredicate>();
    String[] tokens = predicate.split("\\|");
    for (String tok : tokens) {
      setPredicates.add(createPredicate(tok));
    }

    return new OrPredicate(setPredicates.toArray(new BasePredicate[setPredicates.size()]));
  }

  protected RequestBodyParser getHttpBodyParser() {
    return new JsonPropertyParser();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/BaseService.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.handlers.RequestHandler;
import org.apache.ambari.server.api.handlers.RequestHandlerFactory;
import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.api.resources.ResourceInstanceFactory;
import org.apache.ambari.server.api.resources.ResourceInstanceFactoryImpl;
import org.apache.ambari.server.api.services.serializers.ResultSerializer;
import org.apache.ambari.server.controller.spi.Resource;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;
import java.util.Map;

/**
 * Provides common functionality to all services.
 */
public abstract class BaseService {

  /**
   * Factory for creating resource instances.
   */
  private ResourceInstanceFactory m_resourceFactory = new ResourceInstanceFactoryImpl();

  /**
   * Factory for creating request handlers.
   */
  private RequestHandlerFactory m_handlerFactory = new RequestHandlerFactory();

  /**
   * All requests are funneled through this method so that common logic can be executed.
   * This consists of creating a {@link Request} instance, invoking the correct {@link RequestHandler} and
   * applying the proper {@link ResultSerializer} to the result.
   *
   * @param headers      http headers
   * @param body         http body
   * @param uriInfo      uri information
   * @param requestType  http request type
   * @param resource     resource instance that is being acted on
   *
   * @return the response of the operation in serialized form
   */
  protected Response handleRequest(HttpHeaders headers, String body, UriInfo uriInfo, Request.Type requestType,
                                   ResourceInstance resource) {

    Request request = getRequestFactory().createRequest(
        headers, body, uriInfo, requestType, resource);

    Result result = getRequestHandler(request.getRequestType()).handleRequest(request);
    if (! result.getStatus().isErrorState()) {
      request.getResultPostProcessor().process(result);
    }

    return Response.status(result.getStatus().getStatusCode()).entity(
        request.getResultSerializer().serialize(result)).build();
  }

  /**
   * Obtain the factory from which to create Request instances.
   *
   * @return the Request factory
   */
  RequestFactory getRequestFactory() {
    return new RequestFactory();
  }

  /**
   * Obtain the appropriate RequestHandler for the request.
   *
   * @param requestType  the request type
   *
   * @return the request handler to invoke
   */
  RequestHandler getRequestHandler(Request.Type requestType) {
    return m_handlerFactory.getRequestHandler(requestType);
  }

  /**
   * Create a resource instance.
   *
   * @param type    the resource type
   * @param mapIds  all primary and foreign key properties and values
   *
   * @return a newly created resource instance
   */
  ResourceInstance createResource(Resource.Type type, Map<Resource.Type, String> mapIds) {
    return m_resourceFactory.createResource(type, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ClusterService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import javax.ws.rs.*;
import javax.ws.rs.core.*;
import java.util.Collections;


/**
 * Service responsible for cluster resource requests.
 */
@Path("/clusters/")
public class ClusterService extends BaseService {

  /**
   * Handles: GET /clusters/{clusterID}
   * Get a specific cluster.
   *
   * @param headers     http headers
   * @param ui          uri info
   * @param clusterName cluster id
   * @return cluster instance representation
   */
  @GET
  @Path("{clusterName}")
  @Produces("text/plain")
  public Response getCluster(@Context HttpHeaders headers, @Context UriInfo ui,
                             @PathParam("clusterName") String clusterName) {

    return handleRequest(headers, null, ui, Request.Type.GET, createClusterResource(clusterName));
  }

  /**
   * Handles: GET  /clusters
   * Get all clusters.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return cluster collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getClusters(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET, createClusterResource(null));
  }

  /**
   * Handles: POST /clusters/{clusterID}
   * Create a specific cluster.
   *
   * @param headers     http headers
   * @param ui          uri info
   * @param clusterName cluster id
   * @return information regarding the created cluster
   */
   @POST
   @Path("{clusterName}")
   @Produces("text/plain")
   public Response createCluster(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                 @PathParam("clusterName") String clusterName) {

    return handleRequest(headers, body, ui, Request.Type.POST, createClusterResource(clusterName));
  }

  /**
   * Handles: PUT /clusters/{clusterID}
   * Update a specific cluster.
   *
   * @param headers     http headers
   * @param ui          uri info
   * @param clusterName cluster id
   * @return information regarding the updated cluster
   */
  @PUT
  @Path("{clusterName}")
  @Produces("text/plain")
  public Response updateCluster(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                @PathParam("clusterName") String clusterName) {

    return handleRequest(headers, body, ui, Request.Type.PUT, createClusterResource(clusterName));
  }

  /**
   * Handles: DELETE /clusters/{clusterID}
   * Delete a specific cluster.
   *
   * @param headers     http headers
   * @param ui          uri info
   * @param clusterName cluster id
   * @return information regarding the deleted cluster
   */
  @DELETE
  @Path("{clusterName}")
  @Produces("text/plain")
  public Response deleteCluster(@Context HttpHeaders headers, @Context UriInfo ui,
                                @PathParam("clusterName") String clusterName) {

    return handleRequest(headers, null, ui, Request.Type.DELETE, createClusterResource(clusterName));
  }

  /**
   * Get the hosts sub-resource
   *
   * @param clusterName cluster id
   * @return the hosts service
   */
  @Path("{clusterName}/hosts")
  public HostService getHostHandler(@PathParam("clusterName") String clusterName) {
    return new HostService(clusterName);
  }

  /**
   * Get the services sub-resource
   *
   * @param clusterName cluster id
   * @return the services service
   */
  @Path("{clusterName}/services")
  public ServiceService getServiceHandler(@PathParam("clusterName") String clusterName) {
    return new ServiceService(clusterName);
  }
  
  /**
   * Gets the configurations sub-resource.
   *
   * @param clusterName  the cluster name
   * @return the configuration service
   */
  @Path("{clusterName}/configurations")
  public ConfigurationService getConfigurationHandler(@PathParam("clusterName") String clusterName) {
    return new ConfigurationService(clusterName);
  }

  /**
   * Gets the requests sub-resource.
   */
  @Path("{clusterName}/requests")
  public RequestService getRequestHandler(@PathParam("clusterName") String clusterName) {
    return new RequestService(clusterName);
  }

  /**
   * Get the host component resource without specifying the parent host component.
   * Allows accessing host component resources across hosts.
   *
   * @param clusterName the cluster name
   * @return  the host component service with no parent set
   */
  @Path("{clusterName}/host_components")
  public HostComponentService getHostComponentHandler(@PathParam("clusterName") String clusterName) {
    return new HostComponentService(clusterName, null);
  }

  /**
   * Create a cluster resource instance.
   *
   * @param clusterName cluster name
   *
   * @return a cluster resource instance
   */
  ResourceInstance createClusterResource(String clusterName) {
    return createResource(Resource.Type.Cluster,
        Collections.singletonMap(Resource.Type.Cluster, clusterName));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ComponentService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import javax.ws.rs.*;
import javax.ws.rs.core.*;
import java.util.HashMap;
import java.util.Map;

/**
 * Service responsible for components resource requests.
 */
public class ComponentService extends BaseService {
  /**
   * Parent cluster id.
   */
  private String m_clusterName;

  /**
   * Parent service id.
   */
  private String m_serviceName;

  /**
   * Constructor.
   *
   * @param clusterName cluster id
   * @param serviceName service id
   */
  public ComponentService(String clusterName, String serviceName) {
    m_clusterName = clusterName;
    m_serviceName = serviceName;
  }

  /**
   * Handles GET: /clusters/{clusterID}/services/{serviceID}/components/{componentID}
   * Get a specific component.
   *
   * @param headers       http headers
   * @param ui            uri info
   * @param componentName component id
   * @return a component resource representation
   */
  @GET
  @Path("{componentName}")
  @Produces("text/plain")
  public Response getComponent(@Context HttpHeaders headers, @Context UriInfo ui,
                               @PathParam("componentName") String componentName) {

    return handleRequest(headers, null, ui, Request.Type.GET,
        createComponentResource(m_clusterName, m_serviceName, componentName));
  }

  /**
   * Handles GET: /clusters/{clusterID}/services/{serviceID}/components
   * Get all components for a service.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return component collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getComponents(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET,
        createComponentResource(m_clusterName, m_serviceName, null));
  }

  /**
   * Handles: POST /clusters/{clusterID}/services/{serviceID}/components
   * Create components by specifying an array of components in the http body.
   * This is used to create multiple components in a single request.
   *
   * @param body          http body
   * @param headers       http headers
   * @param ui            uri info
   *
   * @return status code only, 201 if successful
   */
  @POST
  @Produces("text/plain")
  public Response createComponents(String body, @Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.POST,
        createComponentResource(m_clusterName, m_serviceName, null));
  }

  /**
   * Handles: POST /clusters/{clusterID}/services/{serviceID}/components/{componentID}
   * Create a specific component.
   *
   * @param body          http body
   * @param headers       http headers
   * @param ui            uri info
   * @param componentName component id
   *
   * @return information regarding the created component
   */
  @POST
  @Path("{componentName}")
  @Produces("text/plain")
  public Response createComponent(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                @PathParam("componentName") String componentName) {

    return handleRequest(headers, body, ui, Request.Type.POST,
        createComponentResource(m_clusterName, m_serviceName, componentName));
  }

  /**
   * Handles: PUT /clusters/{clusterID}/services/{serviceID}/components/{componentID}
   * Update a specific component.
   *
   * @param body          http body
   * @param headers       http headers
   * @param ui            uri info
   * @param componentName component id
   *
   * @return information regarding the updated component
   */
  @PUT
  @Path("{componentName}")
  @Produces("text/plain")
  public Response updateComponent(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                @PathParam("componentName") String componentName) {

    return handleRequest(headers, body, ui, Request.Type.PUT, createComponentResource(
        m_clusterName, m_serviceName, componentName));
  }

  /**
   * Handles: PUT /clusters/{clusterID}/services/{serviceID}/components
   * Update multiple components.
   *
   * @param body          http body
   * @param headers       http headers
   * @param ui            uri info
   *
   * @return information regarding the updated component
   */
  @PUT
  @Produces("text/plain")
  public Response updateComponents(String body, @Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.PUT, createComponentResource(
        m_clusterName, m_serviceName, null));
  }

  /**
   * Handles: DELETE /clusters/{clusterID}/services/{serviceID}/components/{componentID}
   * Delete a specific component.
   *
   * @param headers     http headers
   * @param ui          uri info
   * @param componentName cluster id
   * @return information regarding the deleted cluster
   */
  @DELETE
  @Path("{componentName}")
  @Produces("text/plain")
  public Response deleteComponent(@Context HttpHeaders headers, @Context UriInfo ui,
                                @PathParam("componentName") String componentName) {

    return handleRequest(headers, null, ui, Request.Type.DELETE, createComponentResource(
        m_clusterName, m_serviceName, componentName));
  }

  /**
   * Create a component resource instance.
   *
   *
   * @param clusterName   cluster name
   * @param serviceName   service name
   * @param componentName component name
   *
   * @return a component resource instance
   */
  ResourceInstance createComponentResource(String clusterName, String serviceName, String componentName) {
    Map<Resource.Type,String> mapIds = new HashMap<Resource.Type, String>();
    mapIds.put(Resource.Type.Cluster, clusterName);
    mapIds.put(Resource.Type.Service, serviceName);
    mapIds.put(Resource.Type.Component, componentName);

    return createResource(Resource.Type.Component, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ConfigurationService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import javax.ws.rs.GET;
import javax.ws.rs.POST;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import java.util.HashMap;
import java.util.Map;

/**
 * Service responsible for services resource requests.
 */
public class ConfigurationService extends BaseService {
  /**
   * Parent cluster name.
   */
  private String m_clusterName;

  /**
   * Constructor.
   *
   * @param clusterName cluster id
   */
  public ConfigurationService(String clusterName) {
    m_clusterName = clusterName;
  }

  /**
   * Handles URL: /clusters/{clusterId}/configurations
   * Get all services for a cluster.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return service collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getConfigurations(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET, createConfigurationResource(m_clusterName));
  }

  /**
   * Handles URL: /clusters/{clusterId}/configurations
   * The body should contain:
   * <pre>
   * {
   *     "type":"type_string",
   *     "tag":"version_tag",
   *     "properties":
   *     {
   *         "key1":"value1",
   *         // ...
   *         "keyN":"valueN"
   *     }
   * }
   * </pre>
   *
   * To create multiple configurations is a request, provide an array of configuration properties.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return status code only, 201 if successful
   */
  @POST
  @Produces("text/plain")
  public Response createConfigurations(String body,@Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.POST, createConfigurationResource(m_clusterName));
  }

  /**
   * Create a service resource instance.
   *
   * @param clusterName cluster name
   *
   * @return a service resource instance
   */
  ResourceInstance createConfigurationResource(String clusterName) {
    Map<Resource.Type,String> mapIds = new HashMap<Resource.Type, String>();
    mapIds.put(Resource.Type.Cluster, clusterName);
    mapIds.put(Resource.Type.Configuration, null);

    return createResource(Resource.Type.Configuration, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/CreatePersistenceManager.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.*;

import java.util.HashMap;
import java.util.Map;
import java.util.Set;

/**
 * Responsible for persisting the creation of a resource in the back end.
 */
public class CreatePersistenceManager extends BasePersistenceManager {
  @Override
  public RequestStatus persist(ResourceInstance resource, Set<Map<String, Object>> setProperties) {
    ClusterController controller = getClusterController();
    Map<Resource.Type, String> mapResourceIds = resource.getIds();
    Resource.Type type = resource.getResourceDefinition().getType();
    Schema schema = controller.getSchema(type);

    if (setProperties.size() == 0) {
      setProperties.add(new HashMap<String, Object>());
    }

    for (Map<String, Object> mapProperties : setProperties) {
      for (Map.Entry<Resource.Type, String> entry : mapResourceIds.entrySet()) {
        String property = schema.getKeyPropertyId(entry.getKey());
        if (! mapProperties.containsKey(property)) {
          mapProperties.put(property, entry.getValue());
        }
      }
    }

    try {
      return controller.createResources(type, createControllerRequest(setProperties));
    } catch (AmbariException e) {
      //todo: handle exception
      throw new RuntimeException("Create of resource failed: " + e, e);
    } catch (UnsupportedPropertyException e) {
      //todo: handle exception
      throw new RuntimeException("Create of resource failed: " + e, e);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/DeletePersistenceManager.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.UnsupportedPropertyException;

import java.util.Map;
import java.util.Set;


/**
 * Responsible for persisting the deletion of a resource in the back end.
 */
public class DeletePersistenceManager extends BasePersistenceManager {
  @Override
  public RequestStatus persist(ResourceInstance resource, Set<Map<String, Object>> setProperties) {
    try {
      //todo: need to account for multiple resources and user predicate
      return getClusterController().deleteResources(resource.getResourceDefinition().getType(),
          resource.getQuery().getPredicate());
    } catch (AmbariException e) {
      //todo: handle exception
      throw new RuntimeException("Delete of resource failed: " + e, e);
    } catch (UnsupportedPropertyException e) {
      //todo: handle exception
      throw new RuntimeException("Delete of resource failed: " + e, e);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/DeleteRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;

/**
 * A DELETE request.
 */
public class DeleteRequest extends BaseRequest {
  /**
   * Constructor.
   *
   * @param headers     http headers
   * @param body        http body
   * @param uriInfo     uri information
   * @param resource    associated resource definition
   */
  public DeleteRequest(HttpHeaders headers, String body, UriInfo uriInfo, ResourceInstance resource) {
    super(headers, body, uriInfo, resource);
  }

  @Override
  public Type getRequestType() {
    return Type.DELETE;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/GetRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;

/**
 * A GET request.
 */
public class GetRequest extends BaseRequest {
  /**
   * Constructor.
   *
   * @param headers     http headers
   * @param body        http body
   * @param uriInfo     uri information
   * @param resource    associated resource definition
   */
  public GetRequest(HttpHeaders headers, String body, UriInfo uriInfo, ResourceInstance resource) {
    super(headers, body, uriInfo, resource);
  }

  @Override
  public Type getRequestType() {
    return Type.GET;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/HostComponentService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import javax.ws.rs.*;
import javax.ws.rs.core.*;
import java.util.HashMap;
import java.util.Map;

/**
 * Service responsible for host_components resource requests.
 */
public class HostComponentService extends BaseService {
  /**
   * Parent cluster id.
   */
  private String m_clusterName;

  /**
   * Parent host id.
   */
  private String m_hostName;

  /**
   * Constructor.
   *
   * @param clusterName cluster id
   * @param hostName    host id
   */
  public HostComponentService(String clusterName, String hostName) {
    m_clusterName = clusterName;
    m_hostName = hostName;
  }

  /**
   * Handles GET /clusters/{clusterID}/hosts/{hostID}/host_components/{hostComponentID}
   * Get a specific host_component.
   *
   * @param headers           http headers
   * @param ui                uri info
   * @param hostComponentName host_component id
   * @return host_component resource representation
   */
  @GET
  @Path("{hostComponentName}")
  @Produces("text/plain")
  public Response getHostComponent(@Context HttpHeaders headers, @Context UriInfo ui,
                                   @PathParam("hostComponentName") String hostComponentName) {

    //todo: needs to be refactored when properly handling exceptions
    if (m_hostName == null) {
      // don't allow case where host is not in url but a host_component instance resource is requested
      String s = "Invalid request. Must provide host information when requesting a host_resource instance resource.";
      return Response.status(400).entity(s).build();
    }

    return handleRequest(headers, null, ui, Request.Type.GET,
        createHostComponentResource(m_clusterName, m_hostName, hostComponentName));
  }

  /**
   * Handles GET /clusters/{clusterID}/hosts/{hostID}/host_components/
   * Get all host components for a host.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return host_component collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getHostComponents(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET,
        createHostComponentResource(m_clusterName, m_hostName, null));
  }

  /**
   * Handles POST /clusters/{clusterID}/hosts/{hostID}/host_components
   * Create host components by specifying an array of host components in the http body.
   * This is used to create multiple host components in a single request.
   *
   * @param body              http body
   * @param headers           http headers
   * @param ui                uri info
   *
   * @return status code only, 201 if successful
   */
  @POST
  @Produces("text/plain")
  public Response createHostComponents(String body, @Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.POST,
        createHostComponentResource(m_clusterName, m_hostName, null));
  }

  /**
   * Handles POST /clusters/{clusterID}/hosts/{hostID}/host_components/{hostComponentID}
   * Create a specific host_component.
   *
   * @param body              http body
   * @param headers           http headers
   * @param ui                uri info
   * @param hostComponentName host_component id
   *
   * @return host_component resource representation
   */
  @POST
  @Path("{hostComponentName}")
  @Produces("text/plain")
  public Response createHostComponent(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                   @PathParam("hostComponentName") String hostComponentName) {

    return handleRequest(headers, body, ui, Request.Type.POST,
        createHostComponentResource(m_clusterName, m_hostName, hostComponentName));
  }

  /**
   * Handles PUT /clusters/{clusterID}/hosts/{hostID}/host_components/{hostComponentID}
   * Updates a specific host_component.
   *
   * @param body              http body
   * @param headers           http headers
   * @param ui                uri info
   * @param hostComponentName host_component id
   *
   * @return information regarding updated host_component
   */
  @PUT
  @Path("{hostComponentName}")
  @Produces("text/plain")
  public Response updateHostComponent(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                      @PathParam("hostComponentName") String hostComponentName) {

    return handleRequest(headers, body, ui, Request.Type.PUT,
        createHostComponentResource(m_clusterName, m_hostName, hostComponentName));
  }

  /**
   * Handles PUT /clusters/{clusterID}/hosts/{hostID}/host_components
   * Updates multiple host_component resources.
   *
   * @param body              http body
   * @param headers           http headers
   * @param ui                uri info
   *
   * @return information regarding updated host_component resources
   */
  @PUT
  @Produces("text/plain")
  public Response updateHostComponents(String body, @Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.PUT,
        createHostComponentResource(m_clusterName, m_hostName, null));
  }

  /**
   * Handles DELETE /clusters/{clusterID}/hosts/{hostID}/host_components/{hostComponentID}
   * Delete a specific host_component.
   *
   * @param headers           http headers
   * @param ui                uri info
   * @param hostComponentName host_component id
   *
   * @return host_component resource representation
   */
  @DELETE
  @Path("{hostComponentName}")
  @Produces("text/plain")
  public Response deleteHostComponent(@Context HttpHeaders headers, @Context UriInfo ui,
                                   @PathParam("hostComponentName") String hostComponentName) {

    return handleRequest(headers, null, ui, Request.Type.DELETE,
        createHostComponentResource(m_clusterName, m_hostName, hostComponentName));
  }

  /**
   * Create a host_component resource instance.
   *
   * @param clusterName       cluster name
   * @param hostName          host name
   * @param hostComponentName host_component name
   *
   * @return a host resource instance
   */
  ResourceInstance createHostComponentResource(String clusterName, String hostName, String hostComponentName) {
    Map<Resource.Type,String> mapIds = new HashMap<Resource.Type, String>();
    mapIds.put(Resource.Type.Cluster, clusterName);
    mapIds.put(Resource.Type.Host, hostName);
    mapIds.put(Resource.Type.HostComponent, hostComponentName);

    return createResource(Resource.Type.HostComponent, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/HostService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import javax.ws.rs.DELETE;
import javax.ws.rs.GET;
import javax.ws.rs.POST;
import javax.ws.rs.PUT;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import java.util.HashMap;
import java.util.Map;

/**
 * Service responsible for hosts resource requests.
 */
@Path("/hosts/")
public class HostService extends BaseService {

  /**
   * Parent cluster id.
   */
  private String m_clusterName;

  /**
   * Constructor.
   */
  public HostService() {
  }

  /**
   * Constructor.
   *
   * @param clusterName cluster id
   */
  public HostService(String clusterName) {
    m_clusterName = clusterName;
  }

  /**
   * Handles GET /clusters/{clusterID}/hosts/{hostID} and /hosts/{hostID}
   * Get a specific host.
   *
   * @param headers  http headers
   * @param ui       uri info
   * @param hostName host id
   * @return host resource representation
   */
  @GET
  @Path("{hostName}")
  @Produces("text/plain")
  public Response getHost(@Context HttpHeaders headers, @Context UriInfo ui,
                          @PathParam("hostName") String hostName) {

    return handleRequest(headers, null, ui, Request.Type.GET,
        createHostResource(m_clusterName, hostName, ui));
  }

  /**
   * Handles GET /clusters/{clusterID}/hosts and /hosts
   * Get all hosts for a cluster.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return host collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getHosts(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET,
        createHostResource(m_clusterName, null, ui));
  }

  /**
   * Handles POST /clusters/{clusterID}/hosts
   * Create hosts by specifying an array of hosts in the http body.
   * This is used to create multiple hosts in a single request.
   *
   * @param body     http body
   * @param headers  http headers
   * @param ui       uri info
   *
   * @return status code only, 201 if successful
   */
  @POST
  @Produces("text/plain")
  public Response createHosts(String body, @Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.POST,
        createHostResource(m_clusterName, null, ui));
  }

  /**
   * Handles POST /clusters/{clusterID}/hosts/{hostID}
   * Create a specific host.
   *
   * @param body     http body
   * @param headers  http headers
   * @param ui       uri info
   * @param hostName host id
   *
   * @return host resource representation
   */
  @POST
  @Path("{hostName}")
  @Produces("text/plain")
  public Response createHost(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                          @PathParam("hostName") String hostName) {

    return handleRequest(headers, body, ui, Request.Type.POST,
        createHostResource(m_clusterName, hostName, ui));
  }

  /**
   * Handles PUT /clusters/{clusterID}/hosts/{hostID}
   * Updates a specific host.
   *
   * @param body     http body
   * @param headers  http headers
   * @param ui       uri info
   * @param hostName host id
   *
   * @return information regarding updated host
   */
  @PUT
  @Path("{hostName}")
  @Produces("text/plain")
  public Response updateHost(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                          @PathParam("hostName") String hostName) {

    return handleRequest(headers, body, ui, Request.Type.PUT,
        createHostResource(m_clusterName, hostName, ui));
  }

  /**
   * Handles PUT /clusters/{clusterID}/hosts
   * Updates multiple hosts.
   *
   * @param body     http body
   * @param headers  http headers
   * @param ui       uri info
   *
   * @return information regarding updated host
   */
  @PUT
  @Produces("text/plain")
  public Response updateHosts(String body, @Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.PUT,
        createHostResource(m_clusterName, null, ui));
  }

  /**
   * Handles DELETE /clusters/{clusterID}/hosts/{hostID}
   * Deletes a specific host.
   *
   * @param headers  http headers
   * @param ui       uri info
   * @param hostName host id
   *
   * @return host resource representation
   */
  @DELETE
  @Path("{hostName}")
  @Produces("text/plain")
  public Response deleteHost(@Context HttpHeaders headers, @Context UriInfo ui,
                             @PathParam("hostName") String hostName) {

    return handleRequest(headers, null, ui, Request.Type.DELETE,
        createHostResource(m_clusterName, hostName, ui));
  }

  /**
   * Get the host_components sub-resource.
   *
   * @param hostName host id
   * @return the host_components service
   */
  @Path("{hostName}/host_components")
  public HostComponentService getHostComponentHandler(@PathParam("hostName") String hostName) {
    return new HostComponentService(m_clusterName, hostName);
  }

  /**
   * Create a service resource instance.
   *
   *
   *
   * @param clusterName  cluster
   * @param hostName     host name
   * @param ui           uri information
   *
   * @return a host resource instance
   */
  ResourceInstance createHostResource(String clusterName, String hostName, UriInfo ui) {
    boolean isAttached = ui.getRequestUri().toString().contains("/clusters/");

    Map<Resource.Type,String> mapIds = new HashMap<Resource.Type, String>();
    mapIds.put(Resource.Type.Host, hostName);
    if (isAttached) {
      mapIds.put(Resource.Type.Cluster, clusterName);
    }

    return createResource(Resource.Type.Host, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/KeyService.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.api.services;

import com.google.inject.Inject;
import org.apache.ambari.server.utils.StageUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.xml.bind.JAXBException;
import java.io.IOException;
import java.util.Collection;

@Path("/keys/")
public class KeyService {
  private static final Logger log = LoggerFactory.getLogger(KeyService.class);
  private static PersistKeyValueImpl persistKeyVal;

  @Inject
  public static void init(PersistKeyValueImpl instance) {
    persistKeyVal = instance;
  }

  @Path("{number}")
  @GET
  @Produces("text/plain")
  public String getKeys(@PathParam("number") int number) throws IOException, JAXBException {
    Collection<String> keys = persistKeyVal.generateKeys(number);
    String result = StageUtils.jaxbToString(keys);
    log.info("Returning keys {}", result);
    return result;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/LogoutService.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.api.services;

import org.springframework.security.core.context.SecurityContextHolder;

import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Response;

/**
 * Service performing logout of current user
 */
@Path("/logout")
public class LogoutService {

  @GET
  @Produces("text/plain")
  public Response performLogout() {
    SecurityContextHolder.clearContext();
    return Response.status(Response.Status.OK).build();
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/PersistenceManager.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.RequestStatus;

import java.util.Map;
import java.util.Set;

/**
 * Persistence manager which is responsible for persisting a resource state to the back end.
 * This includes create, update and delete operations.
 */
public interface PersistenceManager {
  /**
   * Persist a resource to the back end.
   *
   *
   *
   * @param resource       resource instance for request
   * @param setProperties  properties to be persisted.
   *
   * @return the request state.
   *
   */
  public RequestStatus persist(ResourceInstance resource, Set<Map<String, Object>> setProperties);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/PersistKeyValueImpl.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import com.google.inject.Inject;
import com.google.inject.Singleton;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.dao.KeyValueDAO;
import org.apache.ambari.server.orm.entities.KeyValueEntity;

import javax.ws.rs.WebApplicationException;
import javax.ws.rs.core.Response;
import java.util.*;

@Singleton
public class PersistKeyValueImpl {

  @Inject
  KeyValueDAO keyValueDAO;

  public String generateKey() {
    return UUID.randomUUID().toString();
  }

  public Collection<String> generateKeys(int number) {
    List<String> keys = new ArrayList<String>(number);
    for (int i = 0; i < number; i++) {
      keys.add(generateKey());
    }
    return keys;
  }

  public synchronized String getValue(String key) {
    KeyValueEntity keyValueEntity = keyValueDAO.findByKey(key);
    if (keyValueEntity != null) {
      return keyValueEntity.getValue();
    }
    throw new WebApplicationException(Response.Status.NOT_FOUND);
  }

  public synchronized String put(String value) {
    String key = generateKey();
    put(key, value);
    return key;
  }

  @Transactional
  public synchronized void put(String key, String value) {
    KeyValueEntity keyValueEntity = keyValueDAO.findByKey(key);
    if (keyValueEntity != null) {
      keyValueEntity.setValue(value);
      keyValueDAO.merge(keyValueEntity);
    } else {
      keyValueEntity = new KeyValueEntity();
      keyValueEntity.setKey(key);
      keyValueEntity.setValue(value);
      keyValueDAO.create(keyValueEntity);
    }
  }
  
  public synchronized Map<String, String> getAllKeyValues() {
    Map<String, String> map = new HashMap<String, String>();
    for (KeyValueEntity keyValueEntity : keyValueDAO.findAll()) {
      map.put(keyValueEntity.getKey(), keyValueEntity.getValue());
    }
    return map;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/PersistKeyValueService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Map;

import javax.ws.rs.*;
import javax.ws.rs.core.Response;
import javax.xml.bind.JAXBException;

import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;
import org.apache.ambari.server.utils.StageUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;

@Path("/persist/")
public class PersistKeyValueService {
  private static PersistKeyValueImpl persistKeyVal;
  private static Log LOG = LogFactory.getLog(PersistKeyValueService.class);

  @Inject
  public static void init(PersistKeyValueImpl instance) {
    persistKeyVal = instance;
  }

  @SuppressWarnings("unchecked")
  @POST
  @Produces("text/plain")
  public Response update(String keyValues)
      throws WebApplicationException, InvalidStateTransitionException,
      JAXBException, IOException {
    LOG.info("Received message from UI " + keyValues);
    Map<String, String> keyValuesMap = StageUtils.fromJson(keyValues, Map.class);
    /* Call into the heartbeat handler */

    for (Map.Entry<String, String> keyValue: keyValuesMap.entrySet()) {
      persistKeyVal.put(keyValue.getKey(), keyValue.getValue());
    }
    return Response.status(Response.Status.ACCEPTED).build();
  }

  @SuppressWarnings("unchecked")
  @PUT
  @Produces("text/plain")
  public String store(String values) throws IOException, JAXBException {
    LOG.info("Received message from UI " + values);
    Collection<String> valueCollection = StageUtils.fromJson(values, Collection.class);
    Collection<String> keys = new ArrayList<String>(valueCollection.size());
    for (String s : valueCollection) {
      keys.add(persistKeyVal.put(s));
    }
    String stringRet = StageUtils.jaxbToString(keys);
    LOG.info("Returning " + stringRet);
    return stringRet;
  }
  
  @GET
  @Produces("text/plain")
  @Path("{keyName}")
  public String getKey( @PathParam("keyName") String keyName) {
    LOG.info("Looking for keyName " + keyName);
    return persistKeyVal.getValue(keyName);
  }
  
  @GET
  @Produces("text/plain")
  public String getAllKeyValues() throws JAXBException, IOException {
    Map<String, String> ret = persistKeyVal.getAllKeyValues();
    String stringRet = StageUtils.jaxbToString(ret);
    LOG.info("Returning " + stringRet);
    return stringRet;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/PostRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;

/**
 * A POST request.
 */
public class PostRequest extends BaseRequest {
  /**
   * Constructor.
   *
   * @param headers     http headers
   * @param body        http body
   * @param uriInfo     uri information
   * @param resource    associated resource definition
   */
  public PostRequest(HttpHeaders headers, String body, UriInfo uriInfo, ResourceInstance resource) {
    super(headers, body, uriInfo, resource);
  }

  @Override
  public Type getRequestType() {
    return Type.POST;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/PutRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;

/**
 * A PUT request.
 */
public class PutRequest extends BaseRequest {
  /**
   * Constructor.
   *
   * @param headers     http headers
   * @param body        http body
   * @param uriInfo     uri information
   * @param resource    associated resource definition
   */
  public PutRequest(HttpHeaders headers, String body, UriInfo uriInfo, ResourceInstance resource) {
    super(headers, body, uriInfo, resource);
  }

  @Override
  public Type getRequestType() {
    return Type.PUT;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/QueryCreateRequest.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;
import java.util.Map;
import java.util.Set;

/**
 * Request for creating sub-resources of instances based on a query.
 */
public class QueryCreateRequest extends RequestImpl {
  /**
   * Constructor.
   *
   * @param headers      http headers
   * @param body         http body
   * @param uriInfo      uri information
   * @param requestType  http request type
   * @param resource     associated resource instance
   */
  public QueryCreateRequest(HttpHeaders headers, String body, UriInfo uriInfo, Type requestType, ResourceInstance resource) {
    super(headers, body, uriInfo, requestType, resource);
  }

  @Override
  public Set<Map<String, Object>> getHttpBodyProperties() {
    String httpBody = getHttpBody();
    //strip array name
    int startIdx = httpBody.indexOf("[");
    int endIdx = httpBody.lastIndexOf("]");

    return getHttpBodyParser().parse(httpBody.substring(startIdx, endIdx + 1));
  }

  @Override
  public Type getRequestType() {
    return Type.QUERY_POST;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/QueryPostRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;
import java.util.Map;
import java.util.Set;

/**
 * Request for creating sub-resources of instances based on a query.
 */
public class QueryPostRequest extends PostRequest {
  /**
   * Constructor.
   *
   * @param headers      http headers
   * @param body         http body
   * @param uriInfo      uri information
   * @param resource     associated resource instance
   */
  public QueryPostRequest(HttpHeaders headers, String body, UriInfo uriInfo, ResourceInstance resource) {
    super(headers, body, uriInfo, resource);
  }

  @Override
  public Set<Map<String, Object>> getHttpBodyProperties() {
    String httpBody = getHttpBody();
    //strip array name
    int startIdx = httpBody.indexOf("[");
    int endIdx = httpBody.lastIndexOf("]");

    return getHttpBodyParser().parse(httpBody.substring(startIdx, endIdx + 1));
  }

  @Override
  public Type getRequestType() {
    return Type.QUERY_POST;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/Request.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceDefinition;
import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.api.services.serializers.ResultSerializer;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.TemporalInfo;

import java.util.List;
import java.util.Map;
import java.util.Set;

/**
 * Provides information on the current request.
 */
public interface Request {

  /**
   * Enum of request types.
   */
  public enum Type {
    GET,
    POST,
    PUT,
    DELETE,
    QUERY_POST
  }

  /**
   * Obtain the resource definition which corresponds to the resource being operated on by the request.
   * The resource definition provides information about the resource type;
   *
   * @return the associated {@link ResourceDefinition}
   */
  public ResourceInstance getResource();

  /**
   * Obtain the URI of this request.
   *
   * @return the request uri
   */
  public String getURI();

  /**
   * Obtain the http request type.  Type is one of {@link Type}.
   *
   * @return the http request type
   */
  public Type getRequestType();

  /**
   * Obtain the api version of the request.  The api version is specified in the request URI.
   *
   * @return the api version of the request
   */
  public int getAPIVersion();

  /**
   * Obtain the query predicate that was built from the user provided predicate fields in the query string.
   * If multiple predicates are supplied, then they will be combined using the appropriate grouping predicate
   * such as 'AND'.
   *
   * @return the user defined predicate
   */
  public Predicate getQueryPredicate();

  /**
   * Obtain the partial response fields and associated temporal information which were provided
   * in the query string of the request uri.
   *
   * @return map of partial response propertyId to temporal information
   */
  public Map<String, TemporalInfo> getFields();

  /**
   * Obtain the result serializer for the request. The default serializer is of type JSON.
   *
   * @return the result serializer for the request
   */
  public ResultSerializer getResultSerializer();

  /**
   * Obtain the processor which processes the result returned from the request handler.
   * The post processor adds additional information such as href fields to the result.
   *
   * @return the result processor associated with the request
   */
  public ResultPostProcessor getResultPostProcessor();

  /**
   * Obtain the http headers associated with the request.
   *
   * @return the http headers
   */
  public Map<String, List<String>> getHttpHeaders();

  /**
   * Obtain the http body associated with the request.
   *
   * @return the http body
   */
  public String getHttpBody();

  /**
   * Obtain the properties which have been parsed from the http body.
   *
   * @return a set of maps containing the properties contained in the http body
   */
  public Set<Map<String, Object>> getHttpBodyProperties();
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/RequestFactory.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;

/**
 * Factory for {@link Request} instances.
 */
public class RequestFactory {
  /**
   * Create a request instance.
   *
   * @param headers      http headers
   * @param uriInfo      uri information
   * @param requestType  http request type
   * @param resource     associated resource instance
   *
   * @return a new Request instance
   */
  public Request createRequest(HttpHeaders headers, String body, UriInfo uriInfo, Request.Type requestType,
                               ResourceInstance resource) {
    switch (requestType) {
      case GET:
        return new GetRequest(headers, body, uriInfo, resource);
      case PUT:
        return new PutRequest(headers, body, uriInfo, resource);
      case DELETE:
        return new DeleteRequest(headers, body, uriInfo, resource);
      case POST:
        return (uriInfo.getQueryParameters().isEmpty() || body == null) ?
            new PostRequest(headers, body, uriInfo, resource) :
            new QueryPostRequest(headers, body, uriInfo, resource);
      default:
        throw new IllegalArgumentException("Invalid request type: " + requestType);
    }
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/RequestImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.*;
import org.apache.ambari.server.api.services.parsers.JsonPropertyParser;
import org.apache.ambari.server.api.services.parsers.RequestBodyParser;
import org.apache.ambari.server.api.services.serializers.JsonSerializer;
import org.apache.ambari.server.api.services.serializers.ResultSerializer;
import org.apache.ambari.server.controller.internal.TemporalInfoImpl;
import org.apache.ambari.server.controller.predicate.*;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.TemporalInfo;

import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.UriInfo;
import java.io.UnsupportedEncodingException;
import java.net.URLDecoder;
import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

/**
 * Request implementation.
 */
public class RequestImpl implements Request {

  /**
   * URI information
   */
  private UriInfo m_uriInfo;

  /**
   * Http headers
   */
  private HttpHeaders m_headers;

  /**
   * Http Body
   */
  private String m_body;

  /**
   * Http request type
   */
  private Type m_type;

  /**
   * Predicate operators.
   */
  private Pattern m_pattern = Pattern.compile("!=|>=|<=|=|>|<");

  /**
   * Associated resource definition
   */
  private ResourceInstance m_resource;


  /**
   * Constructor.
   *
   * @param headers      http headers
   * @param body         http body
   * @param uriInfo      uri information
   * @param requestType  http request type
   * @param resource     associated resource definition
   */
  public RequestImpl(HttpHeaders headers, String body, UriInfo uriInfo,
                     Type requestType, ResourceInstance resource) {

    m_headers  = headers;
    m_body     = body;
    m_uriInfo  = uriInfo;
    m_type     = requestType;
    m_resource = resource;
  }

  @Override
  public ResourceInstance getResource() {
    return m_resource;
  }

  @Override
  public String getURI() {
    try {
      return URLDecoder.decode(m_uriInfo.getRequestUri().toString(), "UTF-8");
    } catch (UnsupportedEncodingException e) {
      throw new RuntimeException("Unable to decode URI: " + e, e);
    }
  }

  @Override
  public Type getRequestType() {
    return m_type;
  }

  @Override
  public int getAPIVersion() {
    return 0;
  }

  @Override
  public Predicate getQueryPredicate() {
    //todo: parse during init
    //not using getQueryParameters because it assumes '=' operator
    String uri = getURI();
    int qsBegin = uri.indexOf("?");

    if (qsBegin == -1) return null;

    String[] tokens = uri.substring(qsBegin + 1).split("&");

    Set<BasePredicate> setPredicates = new HashSet<BasePredicate>();
    for (String outerToken : tokens) {
      if (outerToken != null &&  !outerToken.startsWith("fields")) {
        setPredicates.add(outerToken.contains("|") ?
            handleOrPredicate(outerToken) : createPredicate(outerToken));
      }
    }

    if (setPredicates.size() == 1) {
      return setPredicates.iterator().next();
    } else if (setPredicates.size() > 1) {
      return new AndPredicate(setPredicates.toArray(new BasePredicate[setPredicates.size()]));
    } else {
      return null;
    }
  }

  @Override
  public Map<String, TemporalInfo> getFields() {
    Map<String, TemporalInfo> mapProperties;
    String partialResponseFields = m_uriInfo.getQueryParameters().getFirst("fields");
    if (partialResponseFields == null) {
      mapProperties = Collections.emptyMap();
    } else {
      Set<String> setMatches = new HashSet<String>();
      // Pattern basically splits a string using ',' as the deliminator unless ',' is between '[' and ']'.
      // Actually, captures char sequences between ',' and all chars between '[' and ']' including ','.
      Pattern re = Pattern.compile("[^,\\[]*?\\[[^\\]]*?\\]|[^,]+");
      Matcher m = re.matcher(partialResponseFields);
      while (m.find()){
        for (int groupIdx = 0; groupIdx < m.groupCount() + 1; groupIdx++) {
          setMatches.add(m.group(groupIdx));
        }
      }

      mapProperties = new HashMap<String, TemporalInfo>(setMatches.size());
      for (String field : setMatches) {
        TemporalInfo temporalInfo = null;
        if (field.contains("[")) {
          String[] temporalData = field.substring(field.indexOf('[') + 1,
              field.indexOf(']')).split(",");
          field = field.substring(0, field.indexOf('['));
          long start = Long.parseLong(temporalData[0].trim());
          long end   = -1;
          long step  = -1;
          if (temporalData.length >= 2) {
            end = Long.parseLong(temporalData[1].trim());
            if (temporalData.length == 3) {
              step = Long.parseLong(temporalData[2].trim());
            }
          }
          temporalInfo = new TemporalInfoImpl(start, end, step);
        }
        mapProperties.put(field, temporalInfo);
      }
    }

    return mapProperties;
  }

  @Override
  public Map<String, List<String>> getHttpHeaders() {
    return m_headers.getRequestHeaders();
  }

  @Override
  public String getHttpBody() {
    return m_body;
  }

  @Override
  public Set<Map<String, Object>> getHttpBodyProperties() {
    return getHttpBodyParser().parse(getHttpBody());
  }

  @Override
  public ResultSerializer getResultSerializer() {
    return new JsonSerializer();
  }

  @Override
  public ResultPostProcessor getResultPostProcessor() {
    //todo: Need to reconsider post processor creation and association with a resource type.
    //todo: mutating operations return request resources which aren't children of all resources.
    return getRequestType() == Type.GET ? new ResultPostProcessorImpl(this) : new NullPostProcessor();
  }

  @Override
  public PersistenceManager getPersistenceManager() {
    switch (getRequestType()) {
      case POST:
      case QUERY_POST:
        return new CreatePersistenceManager();
      case PUT:
        return new UpdatePersistenceManager();
      case DELETE:
        return new DeletePersistenceManager();
      case GET:
        throw new IllegalStateException("Tried to get persistence manager for get operation");
      default:
        throw new IllegalStateException("Tried to get persistence manager for unknown operation type");
    }
  }

  private BasePredicate createPredicate(String token) {

    Matcher m = m_pattern.matcher(token);
    m.find();

    String propertyId = token.substring(0, m.start());
    String     value      = token.substring(m.end());
    String     operator   = m.group();

    if (operator.equals("=")) {
      return new EqualsPredicate<String>(propertyId, value);
    } else if (operator.equals("!=")) {
      return new NotPredicate(new EqualsPredicate<String>(propertyId, value));
    } else if (operator.equals("<")) {
      return new LessPredicate<String>(propertyId, value);
    } else if (operator.equals(">"))  {
      return new GreaterPredicate<String>(propertyId, value);
    } else if (operator.equals("<=")) {
      return new LessEqualsPredicate<String>(propertyId, value);
    } else if (operator.equals(">=")) {
      return new GreaterEqualsPredicate<String>(propertyId, value);
    } else {
      throw new RuntimeException("Unknown operator provided in predicate: " + operator);
    }
  }

  private BasePredicate handleOrPredicate(String predicate) {
    Set<BasePredicate> setPredicates = new HashSet<BasePredicate>();
    String[] tokens = predicate.split("\\|");
    for (String tok : tokens) {
      setPredicates.add(createPredicate(tok));
    }

    return new OrPredicate(setPredicates.toArray(new BasePredicate[setPredicates.size()]));
  }

  protected RequestBodyParser getHttpBodyParser() {
    return new JsonPropertyParser();
  }

  private static class NullPostProcessor implements ResultPostProcessor {
    @Override
    public void process(Result result) {
      //no-op
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/RequestService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;


import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;
import java.util.HashMap;
import java.util.Map;


/**
 * Service responsible for request resource requests.
 */
public class RequestService extends BaseService {
  /**
   * Parent cluster name.
   */
  private String m_clusterName;


  /**
   * Constructor.
   *
   * @param clusterName cluster id
   */
  public RequestService(String clusterName) {
    m_clusterName = clusterName;
  }

  /**
   * Handles URL: /clusters/{clusterID}/requests/{requestID}
   * Get a specific request.
   *
   * @param headers    http headers
   * @param ui         uri info
   * @param requestId  request id
   *
   * @return request resource representation
   */
  @GET
  @Path("{requestId}")
  @Produces("text/plain")
  public Response getRequest(@Context HttpHeaders headers, @Context UriInfo ui,
                             @PathParam("requestId") String requestId) {

    return handleRequest(headers, null, ui, Request.Type.GET,
        createRequestResource(m_clusterName, requestId));
  }

  /**
   * Handles URL: /clusters/{clusterId}/requests
   * Get all requests for a cluster.
   *
   * @param headers http headers
   * @param ui      uri info
   *
   * @return request collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getRequests(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET,
        createRequestResource(m_clusterName, null));
  }

  /**
   * Gets the tasks sub-resource.
   */
  @Path("{requestId}/tasks")
  public TaskService getTaskHandler(@PathParam("requestId") String requestId) {
    return new TaskService(m_clusterName, requestId);
  }

  /**
   * Create a request resource instance.
   *
   * @param clusterName  cluster name
   * @param requestId    request id
   *
   * @return a request resource instance
   */
  ResourceInstance createRequestResource(String clusterName, String requestId) {
    Map<Resource.Type,String> mapIds = new HashMap<Resource.Type, String>();
    mapIds.put(Resource.Type.Cluster, clusterName);
    mapIds.put(Resource.Type.Request, requestId);

    return createResource(Resource.Type.Request, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ResponseFactory.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import javax.ws.rs.core.Response;

/**
 * Factory for creating jax-rs responses from results.
 */
public class ResponseFactory {
  /**
   * Create a response from a provided result.
   *
   * @param requestType  request type
   * @param result       the result to wrap
   * @param synchronous  if the request has been handled synchronously
   *
   * @return a new jax-rs Response instance for the provided result
   */
  public Response createResponse(Request.Type requestType, Object result, boolean synchronous) {

    int status = 200;

    if (synchronous) {
      if (requestType == Request.Type.POST) {
        //todo: for now not providing a url for create
        status = 201;
      }
    } else {
      status = 202;
    }

    return Response.status(status).entity(result).build();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/Result.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;


import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.api.util.TreeNode;

/**
 * Represents a result from a request handler invocation.
 */
public interface Result {

  public static enum STATUS { OK(200, "OK", false), CREATED(201, "Created", false), ACCEPTED(202, "Accepted", false),
    CONFLICT(409, "Resource Conflict", true), NOT_FOUND(404, "Not Found", true), BAD_REQUEST(400, "Bad Request", true),
    UNAUTHORIZED(401, "Unauthorized", true), FORBIDDEN(403, "Forbidden", true),
    SERVER_ERROR(500, "Internal Server Error", true);

    private int    m_code;
    private String m_desc;
    private boolean m_isErrorState;

    private STATUS(int code, String description, boolean isErrorState) {
      m_code = code;
      m_desc = description;
      m_isErrorState = isErrorState;
    }

    public int getStatus() {
      return m_code;
    }

    public String getDescription() {
      return m_desc;
    }

    public boolean isErrorState() {
      return m_isErrorState;
    }

    @Override
    public String toString() {
      return getDescription();
    }
  };

  /**
   * Obtain the results of the request invocation as a Tree structure.
   *
   * @return the results of the request a a Tree structure
   */
  public TreeNode<Resource> getResultTree();

  /**
   * Determine whether the request was handled synchronously.
   * If the request is synchronous, all work was completed prior to returning.
   *
   * @return true if the request was synchronous, false if it was asynchronous
   */
  public boolean isSynchronous();

  public ResultStatus getStatus();

  public void setResultStatus(ResultStatus status);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ResultImpl.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;


import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.api.util.TreeNode;
import org.apache.ambari.server.api.util.TreeNodeImpl;


/**
 * Result implementation.
 */
public class ResultImpl implements Result {

  /**
   * Whether the request was handled synchronously.
   */
  private boolean m_synchronous;

  /**
   * Result status.
   */
  private ResultStatus m_status;

  /**
   * Tree structure which holds the results
   */
  private TreeNode<Resource> m_tree = new TreeNodeImpl<Resource>(null, null, null);


  /**
   * Constructor.
   *
   * @param synchronous true if request was handled synchronously, false otherwise
   */
  public ResultImpl(boolean synchronous) {
    m_synchronous = synchronous;
  }

  /**
   * Constructor.
   *
   * @param status  result status
   */
  public ResultImpl(ResultStatus status) {
    m_status = status;
  }

  @Override
  public TreeNode<Resource> getResultTree() {
    return m_tree;
  }

  @Override
  public boolean isSynchronous() {
    return m_synchronous;
  }

  @Override
  public ResultStatus getStatus() {
    return m_status;
  }

  @Override
  public void setResultStatus(ResultStatus status) {
    m_status = status;
  }
}

"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ResultPostProcessor.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

/**
 * Processor which processes result objects prior to them being returned to the service.
 * Processing can include adding additional data such as hrefs, or modifying/deleting existing data.
 */
public interface ResultPostProcessor {
  /**
   * Process the given result.
   * The passed in process is directly modified.
   *
   * @param result the result to process.
   */
  public void process(Result result);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ResultPostProcessorImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.RequestResourceDefinition;
import org.apache.ambari.server.api.resources.ResourceDefinition;
import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.api.util.TreeNode;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * Processes returned results to add href's and other content.
 */
public class ResultPostProcessorImpl implements ResultPostProcessor {
  /**
   * the associated request
   */
  private Request m_request;

  /**
   * Map of resource post processors keyed by resource type.
   * These are used to act on specific resource types contained in the result.
   */
  Map<Resource.Type, List<ResourceDefinition.PostProcessor>>
      m_mapPostProcessors = new HashMap<Resource.Type, List<ResourceDefinition.PostProcessor>>();


  /**
   * Constructor.
   *
   * @param request the associated request
   */
  public ResultPostProcessorImpl(Request request) {
    m_request = request;

    registerResourceProcessors(m_request.getResource());
  }

  @Override
  public void process(Result result) {
    processNode(result.getResultTree(), m_request.getURI());
  }

  /**
   * Process a node of the result tree.  Recursively calls child nodes.
   *
   * @param node the node to process
   * @param href the current href
   */
  private void processNode(TreeNode<Resource> node, String href) {
    Resource r = node.getObject();
    if (r != null) {
      List<ResourceDefinition.PostProcessor> listProcessors =
          m_mapPostProcessors.get(r.getType());
      for (ResourceDefinition.PostProcessor processor : listProcessors) {
        processor.process(m_request, node, href);
      }
      href = node.getProperty("href");
      int i = href.indexOf('?');
      if (i != -1) {
        href = href.substring(0, i);
      }
    } else {
      String isItemsCollection = node.getProperty("isCollection");
      if (node.getName() == null && "true".equals(isItemsCollection)) {
        node.setName("items");
        node.setProperty("href", href);
      }
    }
    for (TreeNode<Resource> child : node.getChildren()) {
      processNode(child, href);
    }
  }

  /**
   * Registers the resource processors.
   * Recursively registers child resource processors.
   *
   * @param resource the root resource
   */
  private void registerResourceProcessors(ResourceInstance resource) {
    //todo: reconsider registration mechanism
    Resource.Type type = resource.getResourceDefinition().getType();
    List<ResourceDefinition.PostProcessor> listProcessors = m_mapPostProcessors.get(type);
    if (listProcessors == null) {
      listProcessors = new ArrayList<ResourceDefinition.PostProcessor>();
      m_mapPostProcessors.put(type, listProcessors);
    }
    listProcessors.addAll(resource.getResourceDefinition().getPostProcessors());

    for (ResourceInstance child : resource.getSubResources().values()) {
      // avoid cycle
      if (!m_mapPostProcessors.containsKey(child.getResourceDefinition().getType())) {
        registerResourceProcessors(child);
      }
    }

    // always add Request post processors since they may be returned but will not be a child
    m_mapPostProcessors.put(Resource.Type.Request, new RequestResourceDefinition().getPostProcessors());
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ResultStatus.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

/**
 * Result status information.
 */
public class ResultStatus {

  /**
   * STATUS enum. Maps a status to a status code.
   */
  public static enum STATUS { OK(200, "OK", false), CREATED(201, "Created", false), ACCEPTED(202, "Accepted", false),
    CONFLICT(409, "Resource Conflict", true), NOT_FOUND(404, "Not Found", true), BAD_REQUEST(400, "Bad Request", true),
    UNAUTHORIZED(401, "Unauthorized", true), FORBIDDEN(403, "Forbidden", true),
    SERVER_ERROR(500, "Internal Server Error", true);

    /**
     * Status code
     */
    private int m_code;

    /**
     * Description
     */
    private String m_desc;

    /**
     * whether this is an error state
     */
    private boolean m_isErrorState;

    /**
     * Constructor.
     *
     * @param code         status code
     * @param description  description
     * @param isErrorState whether this is an error state
     */
    private STATUS(int code, String description, boolean isErrorState) {
      m_code = code;
      m_desc = description;
      m_isErrorState = isErrorState;
    }

    /**
     * Obtain the status code.
     * This is an http response code.
     *
     * @return  the status code
     */
    public int getStatus() {
      return m_code;
    }

    /**
     * Obtain a brief description.
     *
     * @return the description
     */
    public String getDescription() {
      return m_desc;
    }

    /**
     * Whether this status is an error state
     *
     * @return true if this is an error state; false otherwise
     */
    public boolean isErrorState() {
      return m_isErrorState;
    }

    @Override
    public String toString() {
      return getDescription();
    }
  }

  /**
   * Status instance
   */
  private STATUS m_status;

  /**
   * Result status message
   */
  private String m_msg;

  /**
   * Constructor.
   *
   * @param status result status
   * @param msg    result msg.  Usually used in case of an error.
   */
  public ResultStatus(STATUS status, String msg) {
    m_status       = status;
    m_msg          = msg;
  }

  /**
   * Constructor.
   *
   * @param status  result status
   */
  public ResultStatus(STATUS status) {
    m_status = status;
  }

  /**
   * Constructor.
   *
   * @param status  result status
   * @param e       result exception
   */
  public ResultStatus(STATUS status, Exception e) {
    m_status = status;
    m_msg = e.toString();
  }

  /**
   * Obtain the result status.
   * The result status contains a status code and a description of the status.
   *
   * @return  the result status
   */
  public STATUS getStatus() {
    return m_status;
  }

  /**
   * Obtain the status code.
   * This is a shortcut to obtaining the status code from the associated result status.
   *
   * @return the status code
   */
  public int getStatusCode() {
    return m_status.getStatus();
  }

  /**
   * Determine whether the status is an error state.
   * This is a shortcut to getting this information from the associated result status.
   *
   * @return true if the status is a result state; false otherwise
   */
  public boolean isErrorState() {
    return m_status.isErrorState();
  }

  /**
   * Obtain the result message.
   * This message is usually used when an exception occurred.
   *
   * @return the result message
   */
  public String getMessage() {
    return m_msg;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/ServiceService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import javax.ws.rs.*;
import javax.ws.rs.core.*;
import java.util.HashMap;
import java.util.Map;

/**
 * Service responsible for services resource requests.
 */
public class ServiceService extends BaseService {
  /**
   * Parent cluster name.
   */
  private String m_clusterName;

  /**
   * Constructor.
   *
   * @param clusterName cluster id
   */
  public ServiceService(String clusterName) {
    m_clusterName = clusterName;
  }

  /**
   * Handles URL: /clusters/{clusterID}/services/{serviceID}
   * Get a specific service.
   *
   * @param headers     http headers
   * @param ui          uri info
   * @param serviceName service id
   * @return service resource representation
   */
  @GET
  @Path("{serviceName}")
  @Produces("text/plain")
  public Response getService(@Context HttpHeaders headers, @Context UriInfo ui,
                             @PathParam("serviceName") String serviceName) {

    return handleRequest(headers, null, ui, Request.Type.GET,
        createServiceResource(m_clusterName, serviceName));
  }

  /**
   * Handles URL: /clusters/{clusterId}/services
   * Get all services for a cluster.
   *
   * @param headers http headers
   * @param ui      uri info
   * @return service collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getServices(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET,
        createServiceResource(m_clusterName, null));
  }

  /**
   * Handles: POST /clusters/{clusterId}/services/{serviceId}
   * Create a specific service.
   *
   * @param body        http body
   * @param headers     http headers
   * @param ui          uri info
   * @param serviceName service id
   * @return information regarding the created service
   */
  @POST
  @Path("{serviceName}")
  @Produces("text/plain")
  public Response createService(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                @PathParam("serviceName") String serviceName) {

    return handleRequest(headers, body, ui, Request.Type.POST,
        createServiceResource(m_clusterName, serviceName));
  }

  /**
   * Handles: POST /clusters/{clusterId}/services
   * Create multiple services.
   *
   * @param body        http body
   * @param headers     http headers
   * @param ui          uri info
   * @return information regarding the created services
   */
  @POST
  @Produces("text/plain")
  public Response createServices(String body, @Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.POST,
        createServiceResource(m_clusterName, null));
  }

  /**
   * Handles: PUT /clusters/{clusterId}/services/{serviceId}
   * Update a specific service.
   *
   * @param body        http body
   * @param headers     http headers
   * @param ui          uri info
   * @param serviceName service id
   * @return information regarding the updated service
   */
  @PUT
  @Path("{serviceName}")
  @Produces("text/plain")
  public Response updateService(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                @PathParam("serviceName") String serviceName) {

    return handleRequest(headers, body, ui, Request.Type.PUT, createServiceResource(m_clusterName, serviceName));
  }

  /**
   * Handles: PUT /clusters/{clusterId}/services
   * Update multiple services.
   *
   * @param body        http body
   * @param headers     http headers
   * @param ui          uri info
   * @return information regarding the updated service
   */
  @PUT
  @Produces("text/plain")
  public Response updateServices(String body, @Context HttpHeaders headers, @Context UriInfo ui) {

    return handleRequest(headers, body, ui, Request.Type.PUT, createServiceResource(m_clusterName, null));
  }

  /**
   * Handles: DELETE /clusters/{clusterId}/services/{serviceId}
   * Delete a specific service.
   *
   * @param headers     http headers
   * @param ui          uri info
   * @param serviceName service id
   * @return information regarding the deleted service
   */
  @DELETE
  @Path("{serviceName}")
  @Produces("text/plain")
  public Response deleteService(@Context HttpHeaders headers, @Context UriInfo ui,
                                @PathParam("serviceName") String serviceName) {

    return handleRequest(headers, null, ui, Request.Type.DELETE, createServiceResource(m_clusterName, serviceName));
  }

  /**
   * Get the components sub-resource.
   *
   * @param serviceName service id
   * @return the components service
   */
  @Path("{serviceName}/components")
  public ComponentService getComponentHandler(@PathParam("serviceName") String serviceName) {

    return new ComponentService(m_clusterName, serviceName);
  }
  
  /**
   * Get the components sub-resource.
   *
   * @param serviceName service id
   * @return the action service
   */
  @Path("{serviceName}/actions")
  public ActionService getActionHandler(@PathParam("serviceName") String serviceName) {
    return new ActionService(m_clusterName, serviceName);
  }

  /**
   * Create a service resource instance.
   *
   *
   * @param clusterName  cluster name
   * @param serviceName  service name
   *
   * @return a service resource instance
   */
  ResourceInstance createServiceResource(String clusterName, String serviceName) {
    Map<Resource.Type,String> mapIds = new HashMap<Resource.Type, String>();
    mapIds.put(Resource.Type.Cluster, clusterName);
    mapIds.put(Resource.Type.Service, serviceName);

    return createResource(Resource.Type.Service, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/TaskService.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;
import java.util.HashMap;
import java.util.Map;

/**
 * Service responsible for task resource requests.
 */
public class TaskService extends BaseService {
  /**
   * Parent cluster id.
   */
  private String m_clusterName;

  /**
   * Parent request id.
   */
  private String m_requestId;

  /**
   * Constructor.
   *
   * @param clusterName  cluster id
   * @param requestId    request id
   */
  public TaskService(String clusterName, String requestId) {
    m_clusterName = clusterName;
    m_requestId = requestId;
  }

  /**
   * Handles GET: /clusters/{clusterID}/requests/{requestID}/tasks/{taskID}
   * Get a specific task.
   *
   * @param headers  http headers
   * @param ui       uri info
   * @param taskId   component id
   *
   * @return a task resource representation
   */
  @GET
  @Path("{taskId}")
  @Produces("text/plain")
  public Response getTask(@Context HttpHeaders headers, @Context UriInfo ui,
                          @PathParam("taskId") String taskId) {

    return handleRequest(headers, null, ui, Request.Type.GET,
        createTaskResource(m_clusterName, m_requestId, taskId));
  }

  /**
   * Handles GET: /clusters/{clusterID}/requests/{requestID}/tasks
   * Get all tasks for a request.
   *
   * @param headers http headers
   * @param ui      uri info
   *
   * @return task collection resource representation
   */
  @GET
  @Produces("text/plain")
  public Response getComponents(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET,
        createTaskResource(m_clusterName, m_requestId, null));
  }

  /**
   * Create a task resource instance.
   *
   * @param clusterName  cluster name
   * @param requestId    request id
   * @param taskId       task id
   *
   * @return a task resource instance
   */
  ResourceInstance createTaskResource(String clusterName, String requestId, String taskId) {
    Map<Resource.Type,String> mapIds = new HashMap<Resource.Type, String>();
    mapIds.put(Resource.Type.Cluster, clusterName);
    mapIds.put(Resource.Type.Request, requestId);
    mapIds.put(Resource.Type.Task, taskId);

    return createResource(Resource.Type.Task, mapIds);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/UpdatePersistenceManager.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services;


import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.UnsupportedPropertyException;

import java.util.Map;
import java.util.Set;


/**
 * Responsible for persisting the updating of a resource in the back end.
 */
public class UpdatePersistenceManager extends BasePersistenceManager {
  @Override
  public RequestStatus persist(ResourceInstance resource, Set<Map<String, Object>> setProperties) {
    try {
      return getClusterController().updateResources(resource.getResourceDefinition().getType(),
          createControllerRequest(setProperties), resource.getQuery().getPredicate());
    } catch (AmbariException e) {
      //todo: handle exception
      throw new RuntimeException("Update of resource failed: " + e, e);
    } catch (UnsupportedPropertyException e) {
      //todo: handle exception
      throw new RuntimeException("Update of resource failed: " + e, e);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/UserService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.api.services;

import javax.ws.rs.DELETE;
import javax.ws.rs.GET;
import javax.ws.rs.POST;
import javax.ws.rs.PUT;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.Response;
import javax.ws.rs.core.UriInfo;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.Resource;

import java.util.Collections;

/**
 * Service responsible for user requests.
 */
@Path("/users/")
public class UserService extends BaseService {

  /**
   * Gets all users.
   * Handles: GET /users requests.
   */
  @GET
  @Produces("text/plain")
  public Response getUsers(@Context HttpHeaders headers, @Context UriInfo ui) {
    return handleRequest(headers, null, ui, Request.Type.GET, createUserResource(null));
  } 

  /**
   * Gets a single user.
   * Handles: GET /users/{username} requests
   * 
   * @param headers     http headers
   * @param ui          uri info
   * @param userName    the username
   * @return information regarding the created user
   */
  @GET
  @Path("{userName}")
  @Produces("text/plain")
  public Response getUser(@Context HttpHeaders headers, @Context UriInfo ui,
      @PathParam("userName") String userName) {
    return handleRequest(headers, null, ui, Request.Type.GET, createUserResource(userName));
  }
  
  /**
   * Creates a user.
   * Handles: POST /users/{userName}
   *
   * @param headers     http headers
   * @param ui          uri info
   * @param userName    the username
   * @return information regarding the created user
   */
   @POST
   @Path("{userName}")
   @Produces("text/plain")
   public Response createUser(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                 @PathParam("userName") String userName) {

    return handleRequest(headers, body, ui, Request.Type.POST, createUserResource(userName));
  }
  
   
   /**
    * Updates a specific user.
    * Handles: PUT /users/{userName}
    *
    * @param headers     http headers
    * @param ui          uri info
    * @param userName   the username
    * @return information regarding the updated user
    */
   @PUT
   @Path("{userName}")
   @Produces("text/plain")
   public Response updateUser(String body, @Context HttpHeaders headers, @Context UriInfo ui,
                                 @PathParam("userName") String userName) {

     return handleRequest(headers, body, ui, Request.Type.PUT, createUserResource(userName));
   }
   
   /**
    * Deletes a user.
    * Handles:  DELETE /users/{userName}
    */
   @DELETE
   @Path("{userName}")
   @Produces("text/plain")
   public Response deleteUser(@Context HttpHeaders headers, @Context UriInfo ui,
                                 @PathParam("userName") String userName) {
     return handleRequest(headers, null, ui, Request.Type.DELETE, createUserResource(userName));
   }

  /**
   * Create a user resource instance.
   *
   * @param userName  user name
   *
   * @return a user resource instance
   */
  private ResourceInstance createUserResource(String userName) {
    return createResource(Resource.Type.User,
        Collections.singletonMap(Resource.Type.User, userName));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/parsers/JsonPropertyParser.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services.parsers;

import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.codehaus.jackson.JsonNode;
import org.codehaus.jackson.map.ObjectMapper;

import java.io.IOException;
import java.util.*;

/**
 * JSON parser which parses a JSON string into a map of properties and values.
 */
public class JsonPropertyParser implements RequestBodyParser {
  private Set<Map<String, Object>> m_setProperties = new HashSet<Map<String, Object>>();


  @Override
  public Set<Map<String, Object>> parse(String s) {

    ObjectMapper mapper = new ObjectMapper();

    if (s != null && ! s.isEmpty()) {
      s = ensureArrayFormat(s);
      try {
        JsonNode[] nodes = mapper.readValue(s, JsonNode[].class);
        for(JsonNode node : nodes) {
          Map<String, Object> mapProperties = new HashMap<String, Object>();
          processNode(node, "", mapProperties);
          m_setProperties.add(mapProperties);
        }
      } catch (IOException e) {
        throw new RuntimeException("Unable to parse json: " + e, e);
      }
    }
    return m_setProperties;
  }

  private void processNode(JsonNode node, String path, Map<String, Object> mapProperties) {
    Iterator<String> iter = node.getFieldNames();
    String name;
    while (iter.hasNext()) {
      name = iter.next();
      JsonNode child = node.get(name);
      if (child.isContainerNode()) {
        processNode(child, path.isEmpty() ? name : path + '.' + name, mapProperties);
      } else {
        mapProperties.put(PropertyHelper.getPropertyId(path, name), child.asText());
      }
    }
  }

  private String ensureArrayFormat(String s) {
    return s.startsWith("[") ? s : '[' + s + ']';
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/parsers/RequestBodyParser.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services.parsers;

import java.util.Map;
import java.util.Set;

/**
 * Parse the provided String into a map of properties and associated values.
 */
public interface RequestBodyParser {
  /**
   * Parse the provided string into a map of properties and values.
   * The key contains both the category hierarchy and the property name.
   *
   * @param s  the string body to be parsed
   *
   * @return a set of maps of properties or an empty set if no properties exist
   */
  public Set<Map<String, Object>> parse(String s);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/persistence/PersistenceManager.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services.persistence;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.*;

import java.util.Map;
import java.util.Set;

/**
 * Persistence manager which is responsible for persisting a resource state to the back end.
 * This includes create, update and delete operations.
 */
public interface PersistenceManager {

  public RequestStatus create(ResourceInstance resource, Set<Map<String, Object>> setProperties)
      throws UnsupportedPropertyException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException,
             SystemException;

  public RequestStatus update(ResourceInstance resource, Set<Map<String, Object>> setProperties)
      throws UnsupportedPropertyException, SystemException, NoSuchParentResourceException, NoSuchResourceException;


  public RequestStatus delete(ResourceInstance resource, Set<Map<String, Object>> setProperties)
      throws UnsupportedPropertyException, SystemException, NoSuchParentResourceException, NoSuchResourceException;
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/persistence/PersistenceManagerImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services.persistence;

import org.apache.ambari.server.api.resources.ResourceInstance;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.HashMap;
import java.util.Map;
import java.util.Set;

/**
 * Persistence Manager implementation.
 */
public class PersistenceManagerImpl implements PersistenceManager {

  /**
   * Cluster Controller reference.
   */
  private ClusterController m_controller;

  /**
   * Constructor.
   *
   * @param controller  the cluster controller
   */
  public PersistenceManagerImpl(ClusterController controller) {
    m_controller = controller;
  }

  @Override
  public RequestStatus create(ResourceInstance resource, Set<Map<String, Object>> setProperties)
      throws UnsupportedPropertyException,
             SystemException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException {

    Map<Resource.Type, String> mapResourceIds = resource.getIds();
    Resource.Type type = resource.getResourceDefinition().getType();
    Schema schema = m_controller.getSchema(type);

    if (setProperties.size() == 0) {
      setProperties.add(new HashMap<String, Object>());
    }

    for (Map<String, Object> mapProperties : setProperties) {
      for (Map.Entry<Resource.Type, String> entry : mapResourceIds.entrySet()) {
        String property = schema.getKeyPropertyId(entry.getKey());
        if (! mapProperties.containsKey(property)) {
          mapProperties.put(property, entry.getValue());
        }
      }
    }
    return m_controller.createResources(type, createControllerRequest(setProperties));
  }

  @Override
  public RequestStatus update(ResourceInstance resource, Set<Map<String, Object>> setProperties)
      throws UnsupportedPropertyException, SystemException, NoSuchParentResourceException, NoSuchResourceException {

    return m_controller.updateResources(resource.getResourceDefinition().getType(),
        createControllerRequest(setProperties), resource.getQuery().getPredicate());
  }

  @Override
  public RequestStatus delete(ResourceInstance resource, Set<Map<String, Object>> setProperties)
      throws UnsupportedPropertyException, SystemException, NoSuchParentResourceException, NoSuchResourceException {
    //todo: need to account for multiple resources and user predicate
    return m_controller.deleteResources(resource.getResourceDefinition().getType(),
        resource.getQuery().getPredicate());

  }

  protected Request createControllerRequest(Set<Map<String, Object>> setProperties) {
    return PropertyHelper.getCreateRequest(setProperties);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/serializers/JsonSerializer.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services.serializers;

import org.apache.ambari.server.api.services.ResultStatus;
import org.apache.ambari.server.api.services.Result;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.api.util.TreeNode;
import org.codehaus.jackson.JsonFactory;
import org.codehaus.jackson.JsonGenerator;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.util.DefaultPrettyPrinter;

import java.io.*;
import java.nio.charset.Charset;
import java.util.Map;

/**
 * JSON serializer.
 * Responsible for representing a result as JSON.
 */
public class JsonSerializer implements ResultSerializer {

  /**
   * Factory used to create JSON generator.
   */
  JsonFactory m_factory = new JsonFactory();

  ObjectMapper m_mapper = new ObjectMapper(m_factory);

  /**
   * Generator which writes JSON.
   */
  JsonGenerator m_generator;


  @Override
  public Object serialize(Result result) {
    try {
      ByteArrayOutputStream bytesOut = init();

      if (result.getStatus().isErrorState()) {
        return serializeError(result.getStatus());
      }

      processNode(result.getResultTree());

      m_generator.close();
      return bytesOut.toString("UTF-8");
    } catch (IOException e) {
      //todo: exception handling.  Create ResultStatus 500 and call serializeError
      throw new RuntimeException("Unable to serialize to json: " + e, e);
    }
  }

  @Override
  public Object serializeError(ResultStatus error) {
    try {
      ByteArrayOutputStream bytesOut = init();
      //m_mapper.writeValue(m_generator, error);
      m_generator.writeStartObject();
      m_generator.writeNumberField("status", error.getStatus().getStatus());
      m_generator.writeStringField("message", error.getMessage());
      m_generator.writeEndObject();
      m_generator.close();
      return bytesOut.toString("UTF-8");

    } catch (IOException e) {
      //todo: exception handling
      throw new RuntimeException("Unable to serialize to json: " + e, e);
    }
  }

  private ByteArrayOutputStream init() throws IOException {
    ByteArrayOutputStream bytesOut = new ByteArrayOutputStream();
    m_generator = createJsonGenerator(bytesOut);

    DefaultPrettyPrinter p = new DefaultPrettyPrinter();
    p.indentArraysWith(new DefaultPrettyPrinter.Lf2SpacesIndenter());
    m_generator.setPrettyPrinter(p);

    return bytesOut;
  }

  private void processNode(TreeNode<Resource> node) throws IOException {
    String name = node.getName();
    Resource r = node.getObject();

    if (r == null) {
      if (name != null) {
        if (node.getParent() == null) {
          m_generator.writeStartObject();
          writeHref(node);
        }
        m_generator.writeArrayFieldStart(name);
      }
    } else {
      m_generator.writeStartObject();
      writeHref(node);
      // resource props
      handleResourceProperties(r.getProperties());
    }

    for (TreeNode<Resource> child : node.getChildren()) {
      processNode(child);
    }

    if (r == null) {
      if (name != null) {
        m_generator.writeEndArray();
        if (node.getParent() == null) {
          m_generator.writeEndObject();
        }
      }
    } else {
      m_generator.writeEndObject();
    }
  }

  private void handleResourceProperties(TreeNode<Map<String, Object>> node) throws IOException {
    String category = node.getName();

    if (category != null) {
      m_generator.writeFieldName(category);
      m_generator.writeStartObject();
    }

    for (Map.Entry<String, Object> entry : node.getObject().entrySet()) {
      m_generator.writeFieldName(entry.getKey());
      m_mapper.writeValue(m_generator, entry.getValue());
    }

    for (TreeNode<Map<String, Object>> n : node.getChildren()) {
      handleResourceProperties(n);
    }

    if (category != null) {
      m_generator.writeEndObject();
    }
  }

  private JsonGenerator createJsonGenerator(ByteArrayOutputStream baos) throws IOException {
    JsonGenerator generator = m_factory.createJsonGenerator(new OutputStreamWriter(baos,
        Charset.forName("UTF-8").newEncoder()));

    DefaultPrettyPrinter p = new DefaultPrettyPrinter();
    p.indentArraysWith(new DefaultPrettyPrinter.Lf2SpacesIndenter());
    generator.setPrettyPrinter(p);

    return generator;
  }

  private void writeHref(TreeNode<Resource> node) throws IOException {
    String hrefProp = node.getProperty("href");
    if (hrefProp != null) {
      m_generator.writeStringField("href", hrefProp);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/services/serializers/ResultSerializer.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.services.serializers;


import org.apache.ambari.server.api.services.ResultStatus;
import org.apache.ambari.server.api.services.Result;

/**
 * Format internal result to format expected by client.
 */
public interface ResultSerializer {
  /**
   * Serialize the given result to a format expected by client.
   *
   *
   * @param result  internal result
   * @return the serialized result
   */
  Object serialize(Result result);

  /**
   * Serialize an error result to the format expected by the client.
   *
   * @param error  the error result
   *
   * @return the serialized error result
   */
  Object serializeError(ResultStatus error);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/util/TreeNode.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.util;

import java.util.Collection;

/**
 * Tree where each node can have a name, properties and an associated object.
 */
public interface TreeNode<T> {
  /**
   * Obtain the parent node or null if this node is the root.
   *
   * @return the parent node or null if this node is the root
   */
  public TreeNode<T> getParent();

  /**
   * Obtain the list of child nodes.
   *
   * @return a list of child nodes or an empty list if a leaf node
   */
  public Collection<TreeNode<T>> getChildren();

  /**
   * Obtain the object associated with this node.
   *
   * @return the object associated with this node or null
   */
  public T getObject();

  /**
   * Obtain the name of the node.
   *
   * @return the name of the node or null
   */
  public String getName();

  /**
   * Set the name of the node.
   *
   * @param name the name to set
   */
  public void setName(String name);

  /**
   * Set the parent node.
   *
   * @param parent the parent node to set
   */
  public void setParent(TreeNode<T> parent);

  /**
   * Add a child node for the provided object.
   *
   * @param child the object associated with the new child node
   * @param name  the name of the child node
   * @return the newly created child node
   */
  public TreeNode<T> addChild(T child, String name);

  /**
   * Add the specified child node.
   *
   * @param child the child node to add
   * @return the added child node
   */
  public TreeNode<T> addChild(TreeNode<T> child);

  /**
   * Set a property on the node.
   *
   * @param name  the name of the property
   * @param value the value of the property
   */
  public void setProperty(String name, String value);

  /**
   * Get the specified node property.
   *
   * @param name property name
   * @return the requested property value or null
   */
  public String getProperty(String name);

  /**
   * Find a child node by name.
   * The name may contain '/' to delimit names to find a child more then one level deep.
   * To find a node named 'bar' that is a child of a child named 'foo', use the name 'foo/bar'.
   *
   * @param name  the name of the child.  May contain the '/' path separator.
   *
   * @return the requested node or null if the child was not found
   */
  public TreeNode<T> getChild(String name);
}
"
ambari-server/src/main/java/org/apache/ambari/server/api/util/TreeNodeImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.api.util;

import java.util.Collection;
import java.util.HashMap;
import java.util.Map;

/**
 * Basic implementation of TreeNode.
 */
public class TreeNodeImpl<T> implements TreeNode<T> {

  /**
   * name of the node
   */
  private String m_name;

  /**
   * parent of the node
   */
  private TreeNode<T> m_parent;

  /**
   * child nodes
   */
  private Map<String, TreeNode<T>> m_mapChildren = new HashMap<String, TreeNode<T>>();

  /**
   * associated object
   */
  private T m_object;

  /**
   * properties
   */
  private Map<String, String> m_mapNodeProps;

  /**
   * Constructor.
   *
   * @param parent parent node
   * @param object associated object
   * @param name   node name
   */
  public TreeNodeImpl(TreeNode<T> parent, T object, String name) {
    m_parent = parent;
    m_object = object;
    m_name = name;
  }

  @Override
  public TreeNode<T> getParent() {
    return m_parent;
  }

  @Override
  public Collection<TreeNode<T>> getChildren() {
    return m_mapChildren.values();
  }

  @Override
  public T getObject() {
    return m_object;
  }

  @Override
  public void setName(String name) {
    m_name = name;
  }

  @Override
  public String getName() {
    return m_name;
  }

  @Override
  public void setParent(TreeNode<T> parent) {
    m_parent = parent;
  }

  @Override
  public TreeNode<T> addChild(T child, String name) {
    TreeNodeImpl<T> node = new TreeNodeImpl<T>(this, child, name);
    m_mapChildren.put(name, node);

    return node;
  }

  @Override
  public TreeNode<T> addChild(TreeNode<T> child) {
    child.setParent(this);
    m_mapChildren.put(child.getName(), child);

    return child;
  }

  @Override
  public void setProperty(String name, String value) {
    if (m_mapNodeProps == null) {
      m_mapNodeProps = new HashMap<String, String>();
    }
    m_mapNodeProps.put(name, value);
  }

  @Override
  public String getProperty(String name) {
    return m_mapNodeProps == null ? null : m_mapNodeProps.get(name);
  }

  @Override
  public TreeNode<T> getChild(String name) {
    if (name != null && name.contains("/")) {
      int i = name.indexOf('/');
      String s = name.substring(0, i);
      TreeNode<T> node = m_mapChildren.get(s);
      return node == null ? null : node.getChild(name.substring(i + 1));
    } else {
      return m_mapChildren.get(name);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/BootStrapImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.bootstrap;

import java.io.File;
import java.io.IOException;
import java.net.InetAddress;
import java.util.ArrayList;
import java.util.List;

import org.apache.ambari.server.bootstrap.BSResponse.BSRunStat;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;
import com.google.inject.Singleton;

@Singleton
public class BootStrapImpl {
  private File bootStrapDir;
  private String bootScript;
  private String bootSetupAgentScript;
  private String bootSetupAgentPassword;
  private BSRunner bsRunner;
  private String masterHostname;
  long timeout;

  private static Log LOG = LogFactory.getLog(BootStrapImpl.class);

  /* Monotonically increasing requestid for the bootstrap api to query on */
  int requestId = 0;
  private FifoLinkedHashMap<Long, BootStrapStatus> bsStatus;


  @Inject
  public BootStrapImpl(Configuration conf) throws IOException {
    this.bootStrapDir = conf.getBootStrapDir();
    this.bootScript = conf.getBootStrapScript();
    this.bootSetupAgentScript = conf.getBootSetupAgentScript();
    this.bootSetupAgentPassword = conf.getBootSetupAgentPassword();
    this.bsStatus = new FifoLinkedHashMap<Long, BootStrapStatus>();
    this.masterHostname = conf.getMasterHostname(
        InetAddress.getLocalHost().getCanonicalHostName());
  }

  /**
   * Return {@link BootStrapStatus} for a given responseId.
   * @param requestId the responseId for which the status needs to be returned.
   * @return status for a specific response id. A response Id of -1 means the
   * latest responseId.
   */
  public synchronized BootStrapStatus getStatus(long requestId) {
    if (! bsStatus.containsKey(Long.valueOf(requestId))) {
      return null;
    }
    return bsStatus.get(Long.valueOf(requestId));
  }

  /**
   * update status of a request. Mostly called by the status collector thread.
   * @param requestId the request id.
   * @param status the status of the update.
   */
  synchronized void updateStatus(long requestId, BootStrapStatus status) {
    bsStatus.put(Long.valueOf(requestId), status);
  }


  public synchronized void init() throws IOException {
    if (!bootStrapDir.exists()) {
      boolean mkdirs = bootStrapDir.mkdirs();
      if (!mkdirs) throw new IOException("Unable to make directory for " +
          "bootstrap " + bootStrapDir);
    }
  }

  public  synchronized BSResponse runBootStrap(SshHostInfo info) {
    BSResponse response = new BSResponse();
    /* Run some checks for ssh host */
    LOG.info("BootStrapping hosts " + info.hostListAsString());
    if (bsRunner != null) {
      response.setLog("BootStrap in Progress: Cannot Run more than one.");
      response.setStatus(BSRunStat.ERROR);

      return response;
    }
    requestId++;

    bsRunner = new BSRunner(this, info, bootStrapDir.toString(),
        bootScript, bootSetupAgentScript, bootSetupAgentPassword, requestId, 0L,
        this.masterHostname, info.isVerbose());
    bsRunner.start();
    response.setStatus(BSRunStat.OK);
    response.setLog("Running Bootstrap now.");
    response.setRequestId(requestId);
    return response;
  }

  /**
   * @param hosts
   * @return
   */
  public synchronized List<BSHostStatus> getHostInfo(List<String> hosts) {
    List<BSHostStatus> statuses = new ArrayList<BSHostStatus>();

    if (null == hosts || 0 == hosts.size() || (hosts.size() == 1 && hosts.get(0).equals("*"))) {
      for (BootStrapStatus status : bsStatus.values()) {
        if (null != status.getHostsStatus())
          statuses.addAll(status.getHostsStatus());
      }
    } else {
      // TODO make bootstrapping a bit more robust then stop looping
      for (BootStrapStatus status : bsStatus.values()) {
        for (BSHostStatus hostStatus : status.getHostsStatus()) {
          if (-1 != hosts.indexOf(hostStatus.getHostName())) {
            statuses.add(hostStatus);
          }
        }
      }
    }

    return statuses;
  }

  /**
   *
   */
  public synchronized void reset() {
    bsRunner = null;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/BootStrapPostStatus.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.bootstrap;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlElement;
import javax.xml.bind.annotation.XmlEnum;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlType;

/**
 * Class captures immediate response to a bootstrap api call.
 * If the api call is ok, the return should return that its ok.
 */
@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
@XmlType(name = "", propOrder = {})
public class BootStrapPostStatus {
  @XmlType(name="status")
  @XmlEnum
  public enum BSPostStat {
    OK,
    ERROR
  }

  @XmlElement
  private BSPostStat postStatus;
  @XmlElement
  private String log;
  @XmlElement
  private long requestId;

  public long getRequestId() {
    return this.requestId;
  }

  public void setRequestId(long requestId) {
    this.requestId = requestId;
  }

  public BSPostStat getStatus() {
    return this.postStatus;
  }

  public void setStatus(BSPostStat status) {
    this.postStatus  = status;
  }

  public String getLog() {
    return this.log;
  }

  public void setLog(String log) {
    this.log = log;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/BootStrapStatus.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.bootstrap;

import java.util.List;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlElement;
import javax.xml.bind.annotation.XmlEnum;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlType;


/**
 * Status of a bootstrap operation. Operation is successful or error
 * and explains all the info regarding the operation on each host.
 *
 */
@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
@XmlType(name = "", propOrder = {})
public class BootStrapStatus {
  @XmlType(name="status")
  @XmlEnum
  public enum BSStat {
    RUNNING,
    SUCCESS,
    ERROR
  }

  @XmlElement
  private BSStat status;

  @XmlElement
  private List<BSHostStatus> hostsStatus;

  @XmlElement
  private String log;

  public void setStatus(BSStat status) {
    this.status = status;
  }

  public BSStat getStatus() {
    return this.status;
  }

  public void setHostsStatus(List<BSHostStatus> hostsStatus) {
    this.hostsStatus = hostsStatus;
  }

  public List<BSHostStatus> getHostsStatus() {
    return this.hostsStatus;
  }

  public void setLog(String log) {
    this.log = log;
  }

  public String getLog() {
    return this.log;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/BSHostStatus.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.bootstrap;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlElement;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlType;

/**
 *  BootStrap Status for a host.
 */
@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
@XmlType(name = "", propOrder = {})
public class BSHostStatus {
  @XmlElement
  private String hostName;
  @XmlElement
  private String status;
  @XmlElement
  private String statusCode;
  @XmlElement
  private String statusAction;
  @XmlElement
  private String log;


  public void setStatus(String status) {
    this.status = status;
  }

  public String getStatus() {
    return this.status;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  public String getHostName() {
    return this.hostName;
  }

  public String getLog() {
    return this.log;
  }

  public void setLog(String log) {
    this.log = log;
  }
  
  public String getStatusCode() {
    return statusCode;
  }
  
  public void setStatusCode(String code) {
    statusCode = code;
  }
  
  public String getStatusAction() {
    return statusAction;
  }
  
  public void setStatusAction(String action) {
    statusAction = action;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/BSHostStatusCollector.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.bootstrap;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.apache.commons.io.FileUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

/**
 * Runnable class that gets the hoststatus output by looking at the files
 * in a certain directory. Only meant to be useful for bootstrap as of now.
 */
class BSHostStatusCollector {
  private File requestIdDir;
  private List<BSHostStatus> hostStatus;
  private static final String logFileFilter = ".log";
  private static final String doneFileFilter = ".done";
  private static Log LOG = LogFactory.getLog(BSHostStatusCollector.class);

  private List<String> hosts;

  public BSHostStatusCollector(File requestIdDir, List<String> hosts) {
    this.requestIdDir = requestIdDir;
    this.hosts = hosts;
  }

  public List<BSHostStatus> getHostStatus() {
    return hostStatus;
  }

  public void run() {
    LOG.info("Request directory " + requestIdDir);
    hostStatus = new ArrayList<BSHostStatus>();
    if (hosts == null) {
      return;
    }
    File done;
    File log;
    LOG.info("HostList for polling on " + hosts);
    for (String host : hosts) {
      /* Read through the files and gather output */
      BSHostStatus status = new BSHostStatus();
      status.setHostName(host);
      done = new File(requestIdDir, host + doneFileFilter);
      log = new File(requestIdDir, host + logFileFilter);
      if (LOG.isDebugEnabled()) {
        LOG.debug("Polling bootstrap status for host"
            + ", requestDir=" + requestIdDir
            + ", host=" + host
            + ", doneFileExists=" + done.exists()
            + ", logFileExists=" + log.exists());
      }
      if (!done.exists()) {
        status.setStatus("RUNNING");
      } else {
        status.setStatus("FAILED");
        try {
          String statusCode = FileUtils.readFileToString(done).trim();
          if (statusCode.equals("0")) {
            status.setStatus("DONE");
          }
          
          updateStatus(status, statusCode);
        } catch (IOException e) {
          LOG.info("Error reading done file " + done);
        }
      }
      if (!log.exists()) {
        status.setLog("");
      } else {
        String logString = "";
        BufferedReader reader = null;
        try {
          StringBuilder sb = new StringBuilder();
          reader = new BufferedReader(new FileReader(log));

          String line = null;
          while (null != (line = reader.readLine())) {
            if (line.startsWith("tcgetattr:") || line.startsWith("tput:"))
              continue;

            if (0 != sb.length() || 0 == line.length())
              sb.append('\n');

            if (-1 != line.indexOf ("\\n"))
              sb.append(line.replace("\\n", "\n"));
            else
              sb.append(line);
          }
          
          logString = sb.toString();
        } catch (IOException e) {
          LOG.info("Error reading log file " + log);
        }
        finally {
          try {
            reader.close();
          }
          catch (Exception e) {
          }
        }
        status.setLog(logString);
      }
      hostStatus.add(status);
    }
  }
  
  private void updateStatus(BSHostStatus status, String statusCode) {
    
    status.setStatusCode(statusCode);
    
    int reason = -1;
    try {
      reason = Integer.parseInt(statusCode);
    } catch (Exception e) {
    }
    
    switch (reason) {
    // case X: (as we find them)
    case 2:
      status.setStatusAction("Processing could not continue because the file was not found.");
      break;
    case 255:
    default:
      if (null != status.getLog()) {
        String lowerLog = status.getLog().toLowerCase();
        if (-1 != lowerLog.indexOf("permission denied") && -1 != lowerLog.indexOf("publickey")) {
          status.setStatusAction("Use correct SSH key");
        } else if (-1 != lowerLog.indexOf("connect to host")) {
          status.setStatusAction("Please verify that the hostname '" + status.getHostName() + "' is correct.");
        }
      }
      break;
    }
    
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/BSResponse.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.bootstrap;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlElement;
import javax.xml.bind.annotation.XmlEnum;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlType;

/**
 * Class captures immediate response to a bootstrap api call.
 * If the api call is ok, the return should return that its ok.
 */
@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
@XmlType(name = "", propOrder = {})
public class BSResponse {
  @XmlType(name="status")
  @XmlEnum
  public enum BSRunStat {
    OK,
    ERROR
  }

  @XmlElement
  private BSRunStat status;
  @XmlElement
  private String log;
  @XmlElement
  private long requestId;

  public long getRequestId() {
    return this.requestId;
  }

  public void setRequestId(long requestId) {
    this.requestId = requestId;
  }

  public BSRunStat getStatus() {
    return this.status;
  }

  public void setStatus(BSRunStat status) {
    this.status  = status;
  }

  public String getLog() {
    return this.log;
  }

  public void setLog(String log) {
    this.log = log;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/BSRunner.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.bootstrap;

import java.io.File;
import java.io.IOException;
import java.io.StringWriter;
import java.util.List;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledFuture;
import java.util.concurrent.TimeUnit;

import org.apache.ambari.server.bootstrap.BootStrapStatus.BSStat;
import org.apache.commons.io.FileUtils;
import org.apache.commons.io.IOUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

/**
 * @author ncole
 *
 */
class BSRunner extends Thread {
  private static Log LOG = LogFactory.getLog(BSRunner.class);

  private  boolean finished = false;
  private SshHostInfo sshHostInfo;
  private File bootDir;
  private String bsScript;
  private File requestIdDir;
  private File sshKeyFile;
  private int requestId;
  private String agentSetupScript;
  private String agentSetupPassword;
  private String ambariHostname;
  private boolean verbose;
  private BootStrapImpl bsImpl;

  public BSRunner(BootStrapImpl impl, SshHostInfo sshHostInfo, String bootDir,
      String bsScript, String agentSetupScript, String agentSetupPassword,
      int requestId, long timeout, String hostName, boolean isVerbose)
  {
    this.requestId = requestId;
    this.sshHostInfo = sshHostInfo;
    this.bsScript = bsScript;
    this.bootDir = new File(bootDir);
    this.requestIdDir = new File(bootDir, Integer.toString(requestId));
    this.sshKeyFile = new File(this.requestIdDir, "sshKey");
    this.agentSetupScript = agentSetupScript;
    this.agentSetupPassword = agentSetupPassword;
    this.ambariHostname = hostName;
    this.verbose = isVerbose;
    this.bsImpl = impl;
    BootStrapStatus status = new BootStrapStatus();
    status.setLog("RUNNING");
    status.setStatus(BSStat.RUNNING);
    bsImpl.updateStatus(requestId, status);
  }

  /**
   * Update the gathered data from reading output
   *
   */
  private class BSStatusCollector implements Runnable {
    @Override
    public void run() {
      BSHostStatusCollector collector = new BSHostStatusCollector(requestIdDir,
          sshHostInfo.getHosts());
      collector.run();
      List<BSHostStatus> hostStatus = collector.getHostStatus();
      BootStrapStatus status = new BootStrapStatus();
      status.setHostsStatus(hostStatus);
      status.setLog("");
      status.setStatus(BSStat.RUNNING);
      bsImpl.updateStatus(requestId, status);
    }
  }

  private String createHostString(List<String> list) {
    StringBuilder ret = new StringBuilder();
    if (list == null) {
      return "";
    }

    int i = 0;
    for (String host: list) {
      ret.append(host);
      if (i++ != list.size()-1)
        ret.append(",");
    }
    return ret.toString();
  }

  /** Create request id dir for each bootstrap call **/
  private void createRunDir() throws IOException {
    if (!bootDir.exists()) {
      // create the bootdir directory.
      if (! bootDir.mkdirs()) {
        throw new IOException("Cannot create " + bootDir);
      }
    }
    /* create the request id directory */
    if (requestIdDir.exists()) {
      /* delete the directory and make sure we start back */
      FileUtils.deleteDirectory(requestIdDir);
    }
    /* create the directory for the run dir */
    if (! requestIdDir.mkdirs()) {
      throw new IOException("Cannot create " + requestIdDir);
    }
  }

  private void writeSshKeyFile(String data) throws IOException {
    FileUtils.writeStringToFile(sshKeyFile, data);
  }

  public synchronized void finished() {
    this.finished = true;
  }

  @Override
  public void run() {
    String hostString = createHostString(sshHostInfo.getHosts());
    String commands[] = new String[6];
    String shellCommand[] = new String[3];
    BSStat stat = BSStat.RUNNING;
    String scriptlog = "";
    try {
      createRunDir();
      if (LOG.isDebugEnabled()) {
        // FIXME needs to be removed later
        // security hole
        LOG.debug("Using ssh key=\""
            + sshHostInfo.getSshKey() + "\"");
      }

      writeSshKeyFile(sshHostInfo.getSshKey());
      /* Running command:
       * script hostlist bsdir sshkeyfile
       */
      shellCommand[0] = "sh";
      shellCommand[1] = "-c";
      
      commands[0] = this.bsScript;
      commands[1] = hostString;
      commands[2] = this.requestIdDir.toString();
      commands[3] = this.sshKeyFile.toString();
      commands[4] = this.agentSetupScript.toString();
      commands[5] = this.ambariHostname;
      LOG.info("Host= " + hostString + " bs=" + this.bsScript + " requestDir=" +
          requestIdDir + " keyfile=" + this.sshKeyFile + " server=" + this.ambariHostname);

      String[] env = new String[] { "AMBARI_PASSPHRASE=" + agentSetupPassword };
      if (this.verbose)
        env = new String[] { env[0], " BS_VERBOSE=\"-vvv\" " };

      StringBuilder commandString = new StringBuilder();
      for (String comm : commands) {
        commandString.append(" " + comm);
      }   
     
      if (LOG.isDebugEnabled()) {
        LOG.debug(commandString);
      }
      
      String bootStrapOutputFile = requestIdDir + File.separator + "bootstrap.out";
      String bootStrapErrorFile = requestIdDir + File.separator + "bootstrap.err";
      commandString.append(
          " 1> " + bootStrapOutputFile + " 2>" + bootStrapErrorFile);
      
      shellCommand[2] = commandString.toString();
      Process process = Runtime.getRuntime().exec(shellCommand, env);

      /** Startup a scheduled executor service to look through the logs
       */
      ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
      BSStatusCollector statusCollector = new BSStatusCollector();
      ScheduledFuture<?> handle = scheduler.scheduleWithFixedDelay(statusCollector,
          0, 10, TimeUnit.SECONDS);
      LOG.info("Kicking off the scheduler for polling on logs in " +
          this.requestIdDir);
      try {

        LOG.info("Bootstrap output, log="
              + bootStrapErrorFile + " " + bootStrapOutputFile);
        int exitCode = process.waitFor();
        String outMesg = "";
        String errMesg = "";
        try {
          outMesg = FileUtils.readFileToString(new File(bootStrapOutputFile));
          errMesg = FileUtils.readFileToString(new File(bootStrapErrorFile));
        } catch(IOException io) {
          LOG.info("Error in reading files ", io);
        }
        scriptlog = outMesg + "\n\n" + errMesg;
        LOG.info("Script log Mesg " + scriptlog);
        if (exitCode != 0) {
          stat = BSStat.ERROR;
        } else {
          stat = BSStat.SUCCESS;
        }

        scheduler.schedule(new BSStatusCollector(), 0, TimeUnit.SECONDS);
        long startTime = System.currentTimeMillis();
        while (true) {
          if (LOG.isDebugEnabled()) {
            LOG.debug("Waiting for hosts status to be updated");
          }
          boolean pendingHosts = false;
          BootStrapStatus tmpStatus = bsImpl.getStatus(requestId);
          for (BSHostStatus status : tmpStatus.getHostsStatus()) {
            if (status.getStatus().equals("RUNNING")) {
              pendingHosts = true;
            }
          }
          if (LOG.isDebugEnabled()) {
            LOG.debug("Whether hosts status yet to be updated, pending="
                + pendingHosts);
          }
          if (!pendingHosts) {
            break;
          }
          try {
            Thread.sleep(1000);
          } catch (InterruptedException e) {
            // continue
          }
          long now = System.currentTimeMillis();
          if (now >= (startTime+15000)) {
            LOG.warn("Gave up waiting for hosts status to be updated");
            break;
          }
        }
      } catch (InterruptedException e) {
        throw new IOException(e);
      } finally {
        handle.cancel(true);
        /* schedule a last update */
        scheduler.schedule(new BSStatusCollector(), 0, TimeUnit.SECONDS);
        scheduler.shutdownNow();
        try {
          scheduler.awaitTermination(10, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
          LOG.info("Interruped while waiting for scheduler");
        }
        process.destroy();
      }
    } catch(IOException io) {
      LOG.info("Error executing bootstrap " + io.getMessage());
      stat = BSStat.ERROR;
    } finally {
      /* get the bstatus */
      BootStrapStatus tmpStatus = bsImpl.getStatus(requestId);
      tmpStatus.setLog(scriptlog);
      tmpStatus.setStatus(stat);
      bsImpl.updateStatus(requestId, tmpStatus);
      bsImpl.reset();
      finished();
    }
  }

  public synchronized boolean isRunning() {
    return !this.finished;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/FifoLinkedHashMap.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.bootstrap;

import java.util.LinkedHashMap;
import java.util.Map;

/**
 * Only Store the most recent 100 Key Value Pairs.
 *
 */
@SuppressWarnings("serial")
public class FifoLinkedHashMap<K, V> extends
LinkedHashMap<K, V> {
  public static final int MAX_ENTRIES = 100;
  protected boolean removeEldestEntry(Map.Entry<K,
      V> eldest) {
    return size() > MAX_ENTRIES;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/bootstrap/SshHostInfo.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.bootstrap;

import java.util.ArrayList;
import java.util.List;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlElement;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlType;

/**
 * Information that the API needs to provide to run bootstrap on hosts.
 *
 */
@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
@XmlType(name = "", propOrder = {})
public class SshHostInfo {

  @XmlElement
  private String sshKey;

  @XmlElement
  private List<String>  hosts = new ArrayList<String>();
  
  @XmlElement
  private boolean verbose = false;

  public String getSshKey() {
    return sshKey;
  }

  public void setSshKey(String sshKey) {
    this.sshKey = sshKey;
  }

  public void setHosts(List<String> hosts) {
    this.hosts = hosts;
  }

  public List<String> getHosts() {
    return this.hosts;
  }
  
  public boolean isVerbose() {
    return verbose;
  }
  
  public void setVerbose(boolean verbose) {
    this.verbose = verbose;
  }

  public String hostListAsString() {
    StringBuilder ret = new StringBuilder();
    if (this.hosts == null) {
      return "";
    }
    for (String host : this.hosts) {
      ret.append(host).append(":");
    }
    return ret.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/configuration/Configuration.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.configuration;

import com.google.inject.Singleton;
import org.apache.ambari.server.orm.PersistenceType;
import org.apache.ambari.server.security.ClientSecurityType;
import org.apache.ambari.server.security.authorization.LdapServerProperties;
import org.apache.commons.io.FileUtils;
import org.apache.commons.lang.RandomStringUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.File;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStream;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;


/**
 * Ambari configuration.
 * Reads properties from ambari.properties
 */
@Singleton
public class Configuration {

  public static final String CONFIG_FILE = "ambari.properties";
  public static final String BOOTSTRAP_DIR = "bootstrap.dir";
  public static final String BOOTSTRAP_DIR_DEFAULT = "/var/run/ambari-server/bootstrap";
  public static final String WEBAPP_DIR = "webapp.dir";
  public static final String BOOTSTRAP_SCRIPT = "bootstrap.script";
    public static final String BOOTSTRAP_SCRIPT_DEFAULT =  "/usr/bin/ambari_bootstrap";
  public static final String BOOTSTRAP_SETUP_AGENT_SCRIPT = "bootstrap.setup_agent.script";
  public static final String BOOTSTRAP_SETUP_AGENT_PASSWORD = "bootstrap.setup_agent.password";
  public static final String BOOTSTRAP_MASTER_HOSTNAME = "bootstrap.master_host_name";
  public static final String API_AUTHENTICATE = "api.authenticate";
  public static final String API_USE_SSL = "api.ssl";
  public static final String SRVR_KSTR_DIR_KEY = "security.server.keys_dir";
  public static final String SRVR_CRT_NAME_KEY = "security.server.cert_name";
  public static final String SRVR_KEY_NAME_KEY = "security.server.key_name";
  public static final String KSTR_NAME_KEY =
      "security.server.keystore_name";
  public static final String SRVR_CRT_PASS_FILE_KEY =
      "security.server.crt_pass_file";
  public static final String SRVR_CRT_PASS_KEY = "security.server.crt_pass";
  public static final String SRVR_CRT_PASS_LEN_KEY = "security.server.crt_pass.len";
  public static final String PASSPHRASE_ENV_KEY =
      "security.server.passphrase_env_var";
  public static final String PASSPHRASE_KEY = "security.server.passphrase";
  public static final String RESOURCES_DIR_KEY = "resources.dir";
  public static final String METADETA_DIR_PATH = "metadata.path";


  public static final String CLIENT_SECURITY_KEY = "client.security";
  public static final String LDAP_USE_SSL_KEY = "authorization.ldap.useSSL";
  public static final String LDAP_PRIMARY_URL_KEY =
      "authorization.ldap.primaryUrl";
  public static final String LDAP_SECONDARY_URL_KEY =
      "authorization.ldap.secondaryUrl";
  public static final String LDAP_BASE_DN_KEY =
      "authorization.ldap.baseDn";
  public static final String LDAP_BIND_ANONYMOUSLY_KEY =
      "authorization.ldap.bindAnonymously";
  public static final String LDAP_MANAGER_DN_KEY =
      "authorization.ldap.managerDn";
  public static final String LDAP_MANAGER_PASSWORD_KEY =
      "authorization.ldap.managerPassword";
  public static final String LDAP_USERNAME_ATTRIBUTE_KEY =
      "authorization.ldap.usernameAttribute";

  public static final String USER_ROLE_NAME_KEY =
      "authorization.userRoleName";
  public static final String ADMIN_ROLE_NAME_KEY =
      "authorization.adminRoleName";

  public static final String PERSISTENCE_IN_MEMORY_KEY =
      "server.persistence.inMemory";
  public static final String SERVER_JDBC_USER_NAME_KEY =
      "server.jdbc.user.name";
  private static final String SERVER_JDBC_USER_NAME_DEFAULT =
      "ambari-server";
  public static final String SERVER_JDBC_USER_PASSWD_KEY =
      "server.jdbc.user.passwd";
  private static final String SERVER_JDBC_USER_PASSWD_DEFAULT =
      "bigdata";

  public static final String OS_VERSION_KEY =
      "server.os_type";

  public static final String SRVR_HOSTS_MAPPING = 
      "server.hosts.mapping";
  
  private static final String SRVR_KSTR_DIR_DEFAULT = ".";
  public static final String SRVR_CRT_NAME_DEFAULT = "ca.crt";
  public static final String SRVR_KEY_NAME_DEFAULT = "ca.key";
  public static final String KSTR_NAME_DEFAULT = "keystore.p12";
  private static final String SRVR_CRT_PASS_FILE_DEFAULT ="pass.txt";
  private static final String SRVR_CRT_PASS_LEN_DEFAULT = "50";
  private static final String PASSPHRASE_ENV_DEFAULT = "AMBARI_PASSPHRASE";
  private static final String RESOURCES_DIR_DEFAULT =
      "/var/share/ambari/resources/";

  private static final String CLIENT_SECURITY_DEFAULT = "local";

  private static final String USER_ROLE_NAME_DEFAULT = "user";
  private static final String ADMIN_ROLE_NAME_DEFAULT = "admin";
  private static final String LDAP_BIND_ANONYMOUSLY_DEFAULT = "true";

  //TODO For embedded server only - should be removed later
  private static final String LDAP_PRIMARY_URL_DEFAULT = "localhost:33389";
  private static final String LDAP_BASE_DN_DEFAULT = "dc=ambari,dc=apache,dc=org";
  private static final String LDAP_USERNAME_ATTRIBUTE_DEFAULT = "uid";

  //TODO for development purposes only, should be changed to 'false'
  private static final String PERSISTENCE_IN_MEMORY_DEFAULT = "true";


  private static final Logger LOG = LoggerFactory.getLogger(
      Configuration.class);

  private Properties properties;


  private Map<String, String> configsMap;


  public Configuration() {
    this(readConfigFile());
  }

  /**
   * For Testing only. This is to be able to create Configuration object
   * for testing.
   * @param properties properties to use for testing using the Conf object.
   */
  public Configuration(Properties properties) {
    this.properties = properties;

    configsMap = new HashMap<String, String>();
    configsMap.put(SRVR_KSTR_DIR_KEY, properties.getProperty(
        SRVR_KSTR_DIR_KEY, SRVR_KSTR_DIR_DEFAULT));
    configsMap.put(SRVR_KSTR_DIR_KEY, properties.getProperty(
        SRVR_KSTR_DIR_KEY, SRVR_KSTR_DIR_DEFAULT));
    configsMap.put(SRVR_CRT_NAME_KEY, properties.getProperty(
        SRVR_CRT_NAME_KEY, SRVR_CRT_NAME_DEFAULT));
    configsMap.put(SRVR_KEY_NAME_KEY, properties.getProperty(
        SRVR_KEY_NAME_KEY, SRVR_KEY_NAME_DEFAULT));
    configsMap.put(KSTR_NAME_KEY, properties.getProperty(
        KSTR_NAME_KEY, KSTR_NAME_DEFAULT));
    configsMap.put(SRVR_CRT_PASS_FILE_KEY, properties.getProperty(
     SRVR_CRT_PASS_FILE_KEY, SRVR_CRT_PASS_FILE_DEFAULT));
    configsMap.put(PASSPHRASE_ENV_KEY, properties.getProperty(
        PASSPHRASE_ENV_KEY, PASSPHRASE_ENV_DEFAULT));
    configsMap.put(PASSPHRASE_KEY, System.getenv(configsMap.get(
        PASSPHRASE_ENV_KEY)));
    configsMap.put(USER_ROLE_NAME_KEY, properties.getProperty(
        USER_ROLE_NAME_KEY, USER_ROLE_NAME_DEFAULT));
    configsMap.put(ADMIN_ROLE_NAME_KEY, properties.getProperty(
        ADMIN_ROLE_NAME_KEY, ADMIN_ROLE_NAME_DEFAULT));
    configsMap.put(RESOURCES_DIR_KEY, properties.getProperty(
        RESOURCES_DIR_KEY, RESOURCES_DIR_DEFAULT));
    configsMap.put(SRVR_CRT_PASS_LEN_KEY, properties.getProperty(
     SRVR_CRT_PASS_LEN_KEY, SRVR_CRT_PASS_LEN_DEFAULT));

    File passFile = new File(configsMap.get(SRVR_KSTR_DIR_KEY) + File.separator
        + configsMap.get(SRVR_CRT_PASS_FILE_KEY));
    String randStr = null;

    if (!passFile.exists()) {
      LOG.info("Generation of file with password");
      try {
        randStr = RandomStringUtils.randomAlphanumeric(Integer
            .parseInt(configsMap.get(SRVR_CRT_PASS_LEN_KEY)));
        FileUtils.writeStringToFile(passFile, randStr);

      } catch (IOException e) {
          e.printStackTrace();
          throw new RuntimeException(
            "Error reading certificate password from file");
      }
    } else {
        LOG.info("Reading password from existing file");
      try {
        randStr = FileUtils.readFileToString(passFile);
      } catch (IOException e) {
        e.printStackTrace();
      }
    }
    configsMap.put(SRVR_CRT_PASS_KEY, randStr);
  }


  /**
   * Find, read, and parse the configuration file.
   * @return the properties that were found or empty if no file was found
   */
  private static Properties readConfigFile() {
    Properties properties = new Properties();

    //Get property file stream from classpath
    InputStream inputStream = Configuration.class.getClassLoader().getResourceAsStream(CONFIG_FILE);

    if (inputStream == null)
      throw new RuntimeException(CONFIG_FILE + " not found in classpath");


    // load the properties
    try {
      properties.load(inputStream);
    } catch (FileNotFoundException fnf) {
      LOG.info("No configuration file " + CONFIG_FILE + " found in classpath.", fnf);
    } catch (IOException ie) {
      throw new IllegalArgumentException("Can't read configuration file " +
       CONFIG_FILE, ie);
    }

    return properties;
  }

  public File getBootStrapDir() {
    String fileName = properties.getProperty(BOOTSTRAP_DIR);
    if (fileName == null) {
        fileName = BOOTSTRAP_DIR_DEFAULT;
    }
    return new File(fileName);
  }

  public String getBootStrapScript() {
    String bootscript = properties.getProperty(BOOTSTRAP_SCRIPT);
    if (bootscript == null) {
      return BOOTSTRAP_SCRIPT_DEFAULT;
    }
    return bootscript;
  }

  public String getBootSetupAgentScript() {
    return properties.getProperty(BOOTSTRAP_SETUP_AGENT_SCRIPT,
        "/usr/lib/python2.6/site-packages/ambari_server/setupAgent.py");
  }

  public String getBootSetupAgentPassword() {
    String pass = configsMap.get(PASSPHRASE_KEY);

    if (null != pass)
      return pass;

    // fallback
    return properties.getProperty(BOOTSTRAP_SETUP_AGENT_PASSWORD, "password");
  }

  /**
   * Get the map with server config parameters.
   * Keys - public constants of this class
   * @return the map with server config parameters
   */
  public Map<String, String> getConfigsMap() {
    return configsMap;
  }

  /**
   * Gets client security type
   * @return appropriate ClientSecurityType
   */
  public ClientSecurityType getClientSecurityType() {
    return ClientSecurityType.fromString(properties.getProperty(CLIENT_SECURITY_KEY));
  }

  public void setClientSecurityType(ClientSecurityType type) {
    properties.setProperty(CLIENT_SECURITY_KEY, type.toString());
  }

  public String getWebAppDir() {
    LOG.info("Web App DIR test " + properties.getProperty(WEBAPP_DIR));
    return properties.getProperty(WEBAPP_DIR, "web");
  }

  /**
   * Get the file that will be used for host mapping.
   * @return null if such a file is not present, value if present.
   */
  public String getHostsMapFile() {
    LOG.info("Hosts Mapping File " +  properties.getProperty(SRVR_HOSTS_MAPPING));
    return properties.getProperty(SRVR_HOSTS_MAPPING);
  }
  
  /**
   * Gets ambari stack-path
   * @return String
   */
  public String getMetadataPath() {
    return properties.getProperty(METADETA_DIR_PATH);
  }

  /**
   * Check to see if the API should be authenticated or not
   * @return false if not, true if the authentication is enabled.
   */
  public boolean getApiAuthentication() {
    return ("true".equals(properties.getProperty(API_AUTHENTICATE, "false")));
  }

  /**
   * Check to see if the API should be authenticated via ssl or not
   * @return false if not, true if ssl needs to be used.
   */
  public boolean getApiSSLAuthentication() {
    return ("true".equals(properties.getProperty(API_USE_SSL, "false")));
  }


  public PersistenceType getPersistenceType() {
    String value = properties.getProperty(PERSISTENCE_IN_MEMORY_KEY, PERSISTENCE_IN_MEMORY_DEFAULT);
    if ("true".equalsIgnoreCase(value)) {
      return PersistenceType.IN_MEMORY;
    } else {
      return PersistenceType.POSTGRES;
    }
  }

  public String getDatabaseUser() {
    return properties.getProperty(SERVER_JDBC_USER_NAME_KEY, SERVER_JDBC_USER_NAME_DEFAULT);
  }

  public String getDatabasePassword() {
    String filePath = properties.getProperty(SERVER_JDBC_USER_PASSWD_KEY);
    if (filePath == null) {
      LOG.debug("DB password file not specified - using default");
      return SERVER_JDBC_USER_PASSWD_DEFAULT;
    } else {
      LOG.debug("Reading password from file {}", filePath);
      String password;
      try {
        password = FileUtils.readFileToString(new File(filePath));
      } catch (IOException e) {
        throw new RuntimeException("Unable to read database password", e);
      }
      return password;
    }
  }

  /**
   * Gets parameters of LDAP server to connect to
   * @return LdapServerProperties object representing connection parameters
   */
  public LdapServerProperties getLdapServerProperties() {
    LdapServerProperties ldapServerProperties = new LdapServerProperties();

    ldapServerProperties.setPrimaryUrl(properties.getProperty(
        LDAP_PRIMARY_URL_KEY, LDAP_PRIMARY_URL_DEFAULT));
    ldapServerProperties.setSecondaryUrl(properties.getProperty(
        LDAP_SECONDARY_URL_KEY));
    ldapServerProperties.setUseSsl("true".equalsIgnoreCase(properties.
        getProperty(LDAP_USE_SSL_KEY)));
    ldapServerProperties.setAnonymousBind("true".
        equalsIgnoreCase(properties.getProperty(LDAP_BIND_ANONYMOUSLY_KEY,
            LDAP_BIND_ANONYMOUSLY_DEFAULT)));
    ldapServerProperties.setManagerDn(properties.getProperty(
        LDAP_MANAGER_DN_KEY));
    ldapServerProperties.setManagerPassword(properties.getProperty(
        LDAP_MANAGER_PASSWORD_KEY));
    ldapServerProperties.setBaseDN(properties.getProperty
        (LDAP_BASE_DN_KEY, LDAP_BASE_DN_DEFAULT));
    ldapServerProperties.setUsernameAttribute(properties.
        getProperty(LDAP_USERNAME_ATTRIBUTE_KEY, LDAP_USERNAME_ATTRIBUTE_DEFAULT));

    return ldapServerProperties;
  }

  public String getServerOsType() {
    return properties.getProperty(OS_VERSION_KEY, "");
  }

  public String getMasterHostname(String defaultValue) {
    return properties.getProperty(BOOTSTRAP_MASTER_HOSTNAME, defaultValue);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ActionRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller;

import java.util.Map;

public class ActionRequest {
  private String clusterName; 

  private String serviceName;
  
  private String actionName; //for CREATE only

  private Map<String, String> parameters; //for CREATE only

  public ActionRequest(String clusterName, String serviceName,
      String actionName, Map<String, String> params) {
    this.clusterName = clusterName;
    this.serviceName = serviceName;
    this.actionName = actionName;
    this.parameters = params;
  }

  public String getClusterName() {
    return clusterName;
  }

  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  public String getActionName() {
    return actionName;
  }

  public void setActionName(String actionName) {
    this.actionName = actionName;
  }

  public Map<String, String> getParameters() {
    return parameters;
  }

  public void setParameters(Map<String, String> parameters) {
    this.parameters = parameters;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ActionResponse.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller;


public class ActionResponse {
  private String clusterName; 

  private String serviceName;
  
  private String actionName;

  public String getClusterName() {
    return clusterName;
  }

  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  public String getActionName() {
    return actionName;
  }

  public void setActionName(String actionName) {
    this.actionName = actionName;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariManagementController.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.ObjectNotFoundException;
import org.apache.ambari.server.ParentObjectNotFoundException;

import java.util.Map;
import java.util.Set;

/**
 * Management controller interface.
 */
public interface AmbariManagementController {

  // ----- Create -----------------------------------------------------------

  /**
   * Create the cluster defined by the attributes in the given request object.
   *
   * @param request  the request object which defines the cluster to be created
   *
   * @throws AmbariException thrown if the cluster cannot be created
   */
  public void createCluster(ClusterRequest request) throws AmbariException;

  /**
   * Create the service defined by the attributes in the given request object.
   *
   * @param requests  the request object which defines the service to be created
   *
   * @throws AmbariException thrown if the service cannot be created
   */
  public void createServices(Set<ServiceRequest> requests)
      throws AmbariException, ParentObjectNotFoundException;

  /**
   * Create the component defined by the attributes in the given request object.
   *
   * @param requests  the request object which defines the component to be created
   *
   * @throws AmbariException thrown if the component cannot be created
   */
  public void createComponents(Set<ServiceComponentRequest> requests)
      throws AmbariException;

  /**
   * Create the host defined by the attributes in the given request object.
   *
   * @param requests  the request object which defines the host to be created
   *
   * @throws AmbariException thrown if the host cannot be created
   */
  public void createHosts(Set<HostRequest> requests)
      throws AmbariException;

  /**
   * Create the host component defined by the attributes in the given request object.
   *
   * @param requests  the request object which defines the host component to be created
   *
   * @throws AmbariException thrown if the host component cannot be created
   */
  public void createHostComponents(
      Set<ServiceComponentHostRequest> requests) throws AmbariException;

  /**
   * Creates a configuration.
   *
   * @param request the request object which defines the configuration.
   *
   * @throws AmbariException when the configuration cannot be created.
   */
  public void createConfiguration(ConfigurationRequest request)
      throws AmbariException;
  
  /**
   * Creates users.
   * 
   * @param requests the request objects which defines the user.
   * 
   * @throws AmbariException when the user cannot be created.
   */
  public void createUsers(Set<UserRequest> requests) throws AmbariException;


  // ----- Read -------------------------------------------------------------

  /**
   * Get the clusters identified by the given request objects.
   *
   * @param requests  the request objects which identify the clusters to be returned
   *
   * @return a set of cluster responses
   *
   * @throws AmbariException thrown if the resource cannot be read
   */
  public Set<ClusterResponse> getClusters(Set<ClusterRequest> requests)
      throws AmbariException;

  /**
   * Get the services identified by the given request objects.
   *
   * @param requests  the request objects which identify the services
   * to be returned
   *
   * @return a set of service responses
   *
   * @throws AmbariException thrown if the resource cannot be read
   */
  public Set<ServiceResponse> getServices(Set<ServiceRequest> requests)
      throws AmbariException;

  /**
   * Get the components identified by the given request objects.
   *
   * @param requests  the request objects which identify the components to be returned
   *
   * @return a set of component responses
   *
   * @throws AmbariException thrown if the resource cannot be read
   */
  public Set<ServiceComponentResponse> getComponents(
      Set<ServiceComponentRequest> requests) throws AmbariException;

  /**
   * Get the hosts identified by the given request objects.
   *
   * @param requests  the request objects which identify the hosts to be returned
   *
   * @return a set of host responses
   *
   * @throws AmbariException thrown if the resource cannot be read
   */
  public Set<HostResponse> getHosts(Set<HostRequest> requests)
      throws AmbariException;

  /**
   * Get the host components identified by the given request objects.
   *
   * @param requests  the request objects which identify the host components
   * to be returned
   *
   * @return a set of host component responses
   *
   * @throws AmbariException thrown if the resource cannot be read
   */
  public Set<ServiceComponentHostResponse> getHostComponents(
      Set<ServiceComponentHostRequest> requests) throws AmbariException;

  /**
   * Gets the configurations identified by the given request objects.
   *
   * @param requests   the request objects
   *
   * @return  a set of configuration responses
   *
   * @throws AmbariException if the configurations could not be read
   */
  public Set<ConfigurationResponse> getConfigurations(
      Set<ConfigurationRequest> requests) throws AmbariException;

  /**
   * Gets the request status identified by the given request object.
   *
   * @param request   the request object
   *
   * @return  a set of request status responses
   *
   * @throws AmbariException if the request status could not be read
   */
  public Set<RequestStatusResponse> getRequestStatus(RequestStatusRequest request)
      throws AmbariException;

  /**
   * Gets the task status identified by the given request objects.
   *
   * @param requests   the request objects
   *
   * @return  a set of task status responses
   *
   * @throws AmbariException if the configurations could not be read
   */
  public Set<TaskStatusResponse> getTaskStatus(Set<TaskStatusRequest> requests)
      throws AmbariException;

  /**
   * Gets the users identified by the given request objects.
   *
   * @param requests  the request objects
   * 
   * @return  a set of user responses
   * 
   * @throws AmbariException if the users could not be read
   */
  public Set<UserResponse> getUsers(Set<UserRequest> requests)
      throws AmbariException;
  
  /**
   * Gets the host component config mappings
   * 
   * @param request the host component request
   * 
   * @return the configuration mappings
   * 
   * @throws AmbariException
   */
  public Map<String, String> getHostComponentDesiredConfigMapping(
      ServiceComponentHostRequest request) throws AmbariException;

  // ----- Update -----------------------------------------------------------

  /**
   * Update the cluster identified by the given request object with the
   * values carried by the given request object.
   *
   * @param request    the request object which defines which cluster to
   *                   update and the values to set
   *
   * @return a track action response
   *
   * @throws AmbariException thrown if the resource cannot be updated
   */
  public RequestStatusResponse updateCluster(ClusterRequest request)
      throws AmbariException;

  /**
   * Update the service identified by the given request object with the
   * values carried by the given request object.
   *
   * @param requests    the request object which defines which service to
   *                   update and the values to set
   *
   * @return a track action response
   *
   * @throws AmbariException thrown if the resource cannot be updated
   */
  public RequestStatusResponse updateServices(Set<ServiceRequest> requests)
      throws AmbariException;

  /**
   * Update the component identified by the given request object with the
   * values carried by the given request object.
   *
   * @param requests    the request object which defines which component to
   *                   update and the values to set
   *
   * @return a track action response
   *
   * @throws AmbariException thrown if the resource cannot be updated
   */
  public RequestStatusResponse updateComponents(
      Set<ServiceComponentRequest> requests) throws AmbariException;

  /**
   * Update the host identified by the given request object with the
   * values carried by the given request object.
   *
   * @param requests    the request object which defines which host to
   *                   update and the values to set
   *
   * @throws AmbariException thrown if the resource cannot be updated
   */
  public void updateHosts(Set<HostRequest> requests)
      throws AmbariException;

  /**
   * Update the host component identified by the given request object with the
   * values carried by the given request object.
   *
   * @param requests    the request object which defines which host component to
   *                   update and the values to set
   *
   * @return a track action response
   *
   * @throws AmbariException thrown if the resource cannot be updated
   */
  public RequestStatusResponse updateHostComponents(
      Set<ServiceComponentHostRequest> requests) throws AmbariException;
  
  /**
   * Updates the users specified.
   * 
   * @param requests  the users to modify
   * 
   * @throws  AmbariException if the resources cannot be updated
   */
  public void updateUsers(Set<UserRequest> requests) throws AmbariException;


  // ----- Delete -----------------------------------------------------------

  /**
   * Delete the cluster identified by the given request object.
   *
   * @param request  the request object which identifies which cluster to delete
   *
   * @throws AmbariException thrown if the resource cannot be deleted
   */
  public void deleteCluster(ClusterRequest request) throws AmbariException;

  /**
   * Delete the service identified by the given request object.
   *
   * @param requests  the request object which identifies which service to delete
   *
   * @return a track action response
   *
   * @throws AmbariException thrown if the resource cannot be deleted
   */
  public RequestStatusResponse deleteServices(Set<ServiceRequest> requests)
      throws AmbariException;

  /**
   * Delete the component identified by the given request object.
   *
   * @param requests  the request object which identifies which component to delete
   *
   * @return a track action response
   *
   * @throws AmbariException thrown if the resource cannot be deleted
   */
  public RequestStatusResponse deleteComponents(
      Set<ServiceComponentRequest> requests) throws AmbariException;

  /**
   * Delete the host identified by the given request object.
   *
   * @param requests  the request object which identifies which host to delete
   *
   * @return a track action response
   *
   * @throws AmbariException thrown if the resource cannot be deleted
   */
  public void deleteHosts(Set<HostRequest> requests)
      throws AmbariException;

  /**
   * Delete the host component identified by the given request object.
   *
   * @param requests  the request object which identifies which host component to delete
   *
   * @return a track action response
   *
   * @throws AmbariException thrown if the resource cannot be deleted
   */
  public RequestStatusResponse deleteHostComponents(
      Set<ServiceComponentHostRequest> requests) throws AmbariException;
  
  /**
   * Deletes the users specified.
   * 
   * @param requests  the users to delete
   * 
   * @throws  AmbariException if the resources cannot be deleted
   */
  public void deleteUsers(Set<UserRequest> requests) throws AmbariException;  

  public RequestStatusResponse createActions(Set<ActionRequest> request)
      throws AmbariException;

  public Set<ActionResponse> getActions(Set<ActionRequest> request)
      throws AmbariException;
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariManagementControllerImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.net.InetAddress;
import java.util.*;
import java.util.Map.Entry;

import org.apache.ambari.server.*;
import org.apache.ambari.server.actionmanager.ActionManager;
import org.apache.ambari.server.actionmanager.HostRoleCommand;
import org.apache.ambari.server.actionmanager.RequestStatus;
import org.apache.ambari.server.actionmanager.Stage;
import org.apache.ambari.server.actionmanager.StageFactory;
import org.apache.ambari.server.agent.ExecutionCommand;
import org.apache.ambari.server.api.services.AmbariMetaInfo;
import org.apache.ambari.server.metadata.ActionMetadata;
import org.apache.ambari.server.metadata.RoleCommandOrder;
import org.apache.ambari.server.security.authorization.User;
import org.apache.ambari.server.security.authorization.Users;
import org.apache.ambari.server.stageplanner.RoleGraph;
import org.apache.ambari.server.state.Cluster;
import org.apache.ambari.server.state.Clusters;
import org.apache.ambari.server.state.ComponentInfo;
import org.apache.ambari.server.state.Config;
import org.apache.ambari.server.state.ConfigFactory;
import org.apache.ambari.server.state.Host;
import org.apache.ambari.server.state.RepositoryInfo;
import org.apache.ambari.server.state.Service;
import org.apache.ambari.server.state.ServiceComponent;
import org.apache.ambari.server.state.ServiceComponentFactory;
import org.apache.ambari.server.state.ServiceComponentHost;
import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostFactory;
import org.apache.ambari.server.state.ServiceFactory;
import org.apache.ambari.server.state.StackId;
import org.apache.ambari.server.state.StackInfo;
import org.apache.ambari.server.state.State;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostInstallEvent;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostOpInProgressEvent;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostStartEvent;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostStopEvent;
import org.apache.ambari.server.utils.StageUtils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.gson.Gson;
import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.Singleton;

@Singleton
public class AmbariManagementControllerImpl implements
    AmbariManagementController {

  private final static Logger LOG =
      LoggerFactory.getLogger(AmbariManagementControllerImpl.class);

  private final Clusters clusters;

  private String baseLogDir = "/tmp/ambari/";

  private final ActionManager actionManager;

  @SuppressWarnings("unused")
  private final Injector injector;

  private final Gson gson;

  private static RoleCommandOrder rco;
  static {
    rco = new RoleCommandOrder();
    RoleCommandOrder.initialize();
  }

  @Inject
  private ServiceFactory serviceFactory;
  @Inject
  private ServiceComponentFactory serviceComponentFactory;
  @Inject
  private ServiceComponentHostFactory serviceComponentHostFactory;
  @Inject
  private ConfigFactory configFactory;
  @Inject
  private StageFactory stageFactory;
  @Inject
  private ActionMetadata actionMetadata;
  @Inject
  private AmbariMetaInfo ambariMetaInfo;
  @Inject
  private Users users;
  @Inject
  private HostsMap hostsMap;
  
  final private String masterHostname;

  final private static String JDK_RESOURCE_LOCATION =
      "/resources/";
 
  final private String jdkResourceUrl;

  @Inject
  public AmbariManagementControllerImpl(ActionManager actionManager,
      Clusters clusters, Injector injector) throws Exception {
    this.clusters = clusters;
    this.actionManager = actionManager;
    this.injector = injector;
    injector.injectMembers(this);
    this.gson = injector.getInstance(Gson.class);
    LOG.info("Initializing the AmbariManagementControllerImpl");
    this.masterHostname =  InetAddress.getLocalHost().getCanonicalHostName();
    this.jdkResourceUrl = "http://" + masterHostname + ":"
        + AmbariServer.getResourcesPort()
        + JDK_RESOURCE_LOCATION;
  }

  @Override
  public void createCluster(ClusterRequest request)
      throws AmbariException {
    if (request.getClusterName() == null
        || request.getClusterName().isEmpty()
        || request.getClusterId() != null) {
      throw new IllegalArgumentException("Cluster name should be provided" +
          " and clusterId should be null");
    }

    if (LOG.isDebugEnabled()) {
      LOG.debug("Received a createCluster request"
          + ", clusterName=" + request.getClusterName()
          + ", request=" + request);
    }

    if (request.getStackVersion() == null
        || request.getStackVersion().isEmpty()) {
      throw new IllegalArgumentException("Stack information should be"
          + " provided when creating a cluster");
    }
    StackId stackId = new StackId(request.getStackVersion());
    StackInfo stackInfo = ambariMetaInfo.getStackInfo(stackId.getStackName(),
        stackId.getStackVersion());
    if (stackInfo == null) {
      throw new StackNotFoundException(stackId.getStackName(),
          stackId.getStackVersion());
    }

    // FIXME add support for desired configs at cluster level

    boolean foundInvalidHosts = false;
    StringBuilder invalidHostsStr = new StringBuilder();
    if (request.getHostNames() != null) {
      for (String hostname : request.getHostNames()) {
        try {
          clusters.getHost(hostname);
        } catch (HostNotFoundException e) {
          if (foundInvalidHosts) {
            invalidHostsStr.append(",");
          }
          foundInvalidHosts = true;
          invalidHostsStr.append(hostname);
        }
      }
    }
    if (foundInvalidHosts) {
      throw new HostNotFoundException(invalidHostsStr.toString());
    }

    clusters.addCluster(request.getClusterName());
    Cluster c = clusters.getCluster(request.getClusterName());
    if (request.getStackVersion() != null) {
      c.setDesiredStackVersion(
          new StackId(request.getStackVersion()));
    }

    if (request.getHostNames() != null) {
      clusters.mapHostsToCluster(request.getHostNames(),
          request.getClusterName());
    }

  }

  @Override
  public synchronized void createServices(Set<ServiceRequest> requests)
      throws AmbariException {

    if (requests.isEmpty()) {
      LOG.warn("Received an empty requests set");
      return;
    }

    // do all validation checks
    Map<String, Set<String>> serviceNames = new HashMap<String, Set<String>>();
    Set<String> duplicates = new HashSet<String>();
    for (ServiceRequest request : requests) {
      if (request.getClusterName() == null
          || request.getClusterName().isEmpty()
          || request.getServiceName() == null
          || request.getServiceName().isEmpty()) {
        throw new IllegalArgumentException("Cluster name and service name"
            + " should be provided when creating a service");
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a createService request"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + request.getServiceName()
            + ", request=" + request);
      }

      if (!serviceNames.containsKey(request.getClusterName())) {
        serviceNames.put(request.getClusterName(), new HashSet<String>());
      }
      if (serviceNames.get(request.getClusterName())
          .contains(request.getServiceName())) {
        // throw error later for dup
        duplicates.add(request.getServiceName());
        continue;
      }
      serviceNames.get(request.getClusterName()).add(request.getServiceName());

      if (request.getDesiredState() != null
          && !request.getDesiredState().isEmpty()) {
        State state = State.valueOf(request.getDesiredState());
        if (!state.isValidDesiredState()
            || state != State.INIT) {
          throw new IllegalArgumentException("Invalid desired state"
              + " only INIT state allowed during creation"
              + ", providedDesiredState=" + request.getDesiredState());
        }
      }

      Cluster cluster;
      try {
        cluster = clusters.getCluster(request.getClusterName());
      } catch (ClusterNotFoundException e) {
        throw new ParentObjectNotFoundException("Attempted to add a service to a cluster which doesn't exist", e);
      }
      try {
        Service s = cluster.getService(request.getServiceName());
        if (s != null) {
          // throw error later for dup
          duplicates.add(request.getServiceName());
          continue;
        }
      } catch (ServiceNotFoundException e) {
        // Expected
      }

      StackId stackId = cluster.getDesiredStackVersion();
      if (!ambariMetaInfo.isValidService(stackId.getStackName(),
          stackId.getStackVersion(), request.getServiceName())) {
        throw new IllegalArgumentException("Unsupported or invalid service"
            + " in stack"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + request.getServiceName()
            + ", stackInfo=" + stackId.getStackId());
      }
    }

    // ensure only a single cluster update
    if (serviceNames.size() != 1) {
      throw new IllegalArgumentException("Invalid arguments, updates allowed"
          + "on only one cluster at a time");
    }

    // Validate dups
    if (!duplicates.isEmpty()) {
      StringBuilder svcNames = new StringBuilder();
      boolean first = true;
      for (String svcName : duplicates) {
        if (!first) {
          svcNames.append(",");
        }
        first = false;
        svcNames.append(svcName);
      }
      String clusterName = requests.iterator().next().getClusterName();
      String msg;
      if (duplicates.size() == 1) {
        msg = "Attempted to create a service which already exists: "
            + ", clusterName=" + clusterName  + " serviceName=" + svcNames.toString();
      } else {
        msg = "Attempted to create services which already exist: "
            + ", clusterName=" + clusterName  + " serviceNames=" + svcNames.toString();
      }
      throw new DuplicateResourceException(msg);
    }

    // now to the real work
    for (ServiceRequest request : requests) {
      Cluster cluster = clusters.getCluster(request.getClusterName());

      // FIXME initialize configs based off service.configVersions
      Map<String, Config> configs = new HashMap<String, Config>();

      State state = State.INIT;

      // Already checked that service does not exist
      Service s = serviceFactory.createNew(cluster, request.getServiceName());

      s.setDesiredState(state);
      s.updateDesiredConfigs(configs);
      s.setDesiredStackVersion(cluster.getDesiredStackVersion());
      cluster.addService(s);
      s.persist();
    }

  }

  @Override
  public synchronized void createComponents(
      Set<ServiceComponentRequest> requests) throws AmbariException {

    if (requests.isEmpty()) {
      LOG.warn("Received an empty requests set");
      return;
    }

    // do all validation checks
    Map<String, Map<String, Set<String>>> componentNames =
        new HashMap<String, Map<String,Set<String>>>();
    Set<String> duplicates = new HashSet<String>();

    for (ServiceComponentRequest request : requests) {
      if (request.getClusterName() == null
          || request.getClusterName().isEmpty()
          || request.getComponentName() == null
          || request.getComponentName().isEmpty()) {
        throw new IllegalArgumentException("Invalid arguments"
            + ", clustername and componentname should be"
            + " non-null and non-empty when trying to create a"
            + " component");
      }

      Cluster cluster;
      try {
        cluster = clusters.getCluster(request.getClusterName());
      } catch (ClusterNotFoundException e) {
        throw new ParentObjectNotFoundException(
            "Attempted to add a component to a cluster which doesn't exist:", e);
      }

      if (request.getServiceName() == null
          || request.getServiceName().isEmpty()) {
        StackId stackId = cluster.getDesiredStackVersion();
        String serviceName =
            ambariMetaInfo.getComponentToService(stackId.getStackName(),
                stackId.getStackVersion(), request.getComponentName());
        if (LOG.isDebugEnabled()) {
          LOG.debug("Looking up service name for component"
              + ", componentName=" + request.getComponentName()
              + ", serviceName=" + serviceName);
        }

        if (serviceName == null
            || serviceName.isEmpty()) {
          throw new AmbariException("Could not find service for component"
              + ", componentName=" + request.getComponentName()
              + ", clusterName=" + cluster.getClusterName()
              + ", stackInfo=" + stackId.getStackId());
        }
        request.setServiceName(serviceName);
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a createComponent request"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + request.getServiceName()
            + ", componentName=" + request.getComponentName()
            + ", request=" + request);
      }

      if (!componentNames.containsKey(request.getClusterName())) {
        componentNames.put(request.getClusterName(),
            new HashMap<String, Set<String>>());
      }
      if (!componentNames.get(request.getClusterName())
          .containsKey(request.getServiceName())) {
        componentNames.get(request.getClusterName()).put(
            request.getServiceName(), new HashSet<String>());
      }
      if (componentNames.get(request.getClusterName())
          .get(request.getServiceName()).contains(request.getComponentName())){
        // throw error later for dup
        duplicates.add("[clusterName=" + request.getClusterName() + ", serviceName=" + request.getServiceName() +
            ", componentName=" + request.getComponentName() + "]");
        continue;
      }
      componentNames.get(request.getClusterName())
          .get(request.getServiceName()).add(request.getComponentName());

      if (request.getDesiredState() != null
          && !request.getDesiredState().isEmpty()) {
        State state = State.valueOf(request.getDesiredState());
        if (!state.isValidDesiredState()
            || state != State.INIT) {
          throw new IllegalArgumentException("Invalid desired state"
              + " only INIT state allowed during creation"
              + ", providedDesiredState=" + request.getDesiredState());
        }
      }

      Service s;
      try {
        s = cluster.getService(request.getServiceName());
      } catch (ServiceNotFoundException e) {
        throw new ParentObjectNotFoundException(
            "Attempted to add a component to a service which doesn't exist:", e);
      }
      try {
        ServiceComponent sc = s.getServiceComponent(request.getComponentName());
        if (sc != null) {
          // throw error later for dup
          duplicates.add("[clusterName=" + request.getClusterName() + ", serviceName=" + request.getServiceName() +
              ", componentName=" + request.getComponentName() + "]");
          continue;
        }
      } catch (AmbariException e) {
        // Expected
      }

      StackId stackId = s.getDesiredStackVersion();
      if (!ambariMetaInfo.isValidServiceComponent(stackId.getStackName(),
          stackId.getStackVersion(), s.getName(), request.getComponentName())) {
        throw new IllegalArgumentException("Unsupported or invalid component"
            + " in stack"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + request.getServiceName()
            + ", componentName=" + request.getComponentName()
            + ", stackInfo=" + stackId.getStackId());
      }
    }

    // ensure only a single cluster update
    if (componentNames.size() != 1) {
      throw new IllegalArgumentException("Invalid arguments, updates allowed"
          + "on only one cluster at a time");
    }

    // Validate dups
    if (!duplicates.isEmpty()) {
      StringBuilder names = new StringBuilder();
      boolean first = true;
      for (String cName : duplicates) {
        if (!first) {
          names.append(",");
        }
        first = false;
        names.append(cName);
      }
      String msg;
      if (duplicates.size() == 1) {
        msg = "Attempted to create a component which already exists: ";
      } else {
        msg = "Attempted to create components which already exist: ";
      }
      throw new DuplicateResourceException(msg + names.toString());
    }


    // now doing actual work
    for (ServiceComponentRequest request : requests) {
      Cluster cluster = clusters.getCluster(request.getClusterName());
      Service s = cluster.getService(request.getServiceName());
      ServiceComponent sc = serviceComponentFactory.createNew(s,
          request.getComponentName());
      sc.setDesiredStackVersion(s.getDesiredStackVersion());

      if (request.getDesiredState() != null
          && !request.getDesiredState().isEmpty()) {
        State state = State.valueOf(request.getDesiredState());
        sc.setDesiredState(state);
      } else {
        sc.setDesiredState(s.getDesiredState());
      }

      // FIXME fix config versions to configs conversion
      Map<String, Config> configs = new HashMap<String, Config>();
      if (request.getConfigVersions() != null) {
      }

      sc.updateDesiredConfigs(configs);
      s.addServiceComponent(sc);
      sc.persist();
    }

  }

  @Override
  public synchronized void createHosts(Set<HostRequest> requests)
      throws AmbariException {

    if (requests.isEmpty()) {
      LOG.warn("Received an empty requests set");
      return;
    }

    Set<String> duplicates = new HashSet<String>();
    Set<String> unknowns = new HashSet<String>();
    Set<String> allHosts = new HashSet<String>();
    for (HostRequest request : requests) {
      if (request.getHostname() == null
          || request.getHostname().isEmpty()) {
        throw new IllegalArgumentException("Invalid arguments, hostname"
            + " cannot be null");
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a createHost request"
            + ", hostname=" + request.getHostname()
            + ", request=" + request);
      }

      if (allHosts.contains(request.getHostname())) {
        // throw dup error later
        duplicates.add(request.getHostname());
        continue;
      }
      allHosts.add(request.getHostname());

      try {
        // ensure host is registered
        clusters.getHost(request.getHostname());
      }
      catch (HostNotFoundException e) {
        unknowns.add(request.getHostname());
        continue;
      }

      if (request.getClusterName() != null) {
        try {
          // validate that cluster_name is valid
          clusters.getCluster(request.getClusterName());
        } catch (ClusterNotFoundException e) {
          throw new ParentObjectNotFoundException("Attempted to add a host to a cluster which doesn't exist: "
              + " clusterName=" + request.getClusterName());
        }
      }
    }

    if (!duplicates.isEmpty()) {
      StringBuilder names = new StringBuilder();
      boolean first = true;
      for (String hName : duplicates) {
        if (!first) {
          names.append(",");
        }
        first = false;
        names.append(hName);
      }
      throw new IllegalArgumentException("Invalid request contains"
          + " duplicate hostnames"
          + ", hostnames=" + names.toString());
    }

    if (!unknowns.isEmpty()) {
      StringBuilder names = new StringBuilder();
      boolean first = true;
      for (String hName : unknowns) {
        if (!first) {
          names.append(",");
        }
        first = false;
        names.append(hName);
      }

      throw new IllegalArgumentException("Attempted to add unknown hosts to a cluster.  " +
          "These hosts have not been registered with the server: " + names.toString());
    }

    for (HostRequest request : requests) {
      if (request.getClusterName() != null) {
        clusters.mapHostToCluster(request.getHostname(), request.getClusterName());
      }

      if (request.getHostAttributes() != null) {
        clusters.getHost(request.getHostname()).
            setHostAttributes(request.getHostAttributes());
      }
    }
  }

  @Override
  public synchronized void createHostComponents(Set<ServiceComponentHostRequest> requests)
      throws AmbariException {

    if (requests.isEmpty()) {
      LOG.warn("Received an empty requests set");
      return;
    }

    // do all validation checks
    Map<String, Map<String, Map<String, Set<String>>>> hostComponentNames =
        new HashMap<String, Map<String, Map<String, Set<String>>>>();
    Set<String> duplicates = new HashSet<String>();
    for (ServiceComponentHostRequest request : requests) {
      if (request.getClusterName() == null
          || request.getClusterName().isEmpty()
          || request.getComponentName() == null
          || request.getComponentName().isEmpty()
          || request.getHostname() == null
          || request.getHostname().isEmpty()) {
        throw new IllegalArgumentException("Invalid arguments,"
            + " clustername, componentname and hostname should not be null"
            + " when trying to create a hostcomponent");
      }

      Cluster cluster;
      try {
        cluster = clusters.getCluster(request.getClusterName());
      } catch (ClusterNotFoundException e) {
        throw new ParentObjectNotFoundException(
            "Attempted to add a host_component to a cluster which doesn't exist: ", e);
      }

      if (request.getServiceName() == null
          || request.getServiceName().isEmpty()) {
        StackId stackId = cluster.getDesiredStackVersion();
        String serviceName =
            ambariMetaInfo.getComponentToService(stackId.getStackName(),
                stackId.getStackVersion(), request.getComponentName());
        if (LOG.isDebugEnabled()) {
          LOG.debug("Looking up service name for component"
              + ", componentName=" + request.getComponentName()
              + ", serviceName=" + serviceName);
        }
        if (serviceName == null
            || serviceName.isEmpty()) {
          throw new AmbariException("Could not find service for component"
              + ", componentName=" + request.getComponentName()
              + ", clusterName=" + cluster.getClusterName()
              + ", stackInfo=" + stackId.getStackId());
        }
        request.setServiceName(serviceName);
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a createHostComponent request"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + request.getServiceName()
            + ", componentName=" + request.getComponentName()
            + ", hostname=" + request.getHostname()
            + ", request=" + request);
      }

      if (!hostComponentNames.containsKey(request.getClusterName())) {
        hostComponentNames.put(request.getClusterName(),
            new HashMap<String, Map<String,Set<String>>>());
      }
      if (!hostComponentNames.get(request.getClusterName())
          .containsKey(request.getServiceName())) {
        hostComponentNames.get(request.getClusterName()).put(
            request.getServiceName(), new HashMap<String, Set<String>>());
      }
      if (!hostComponentNames.get(request.getClusterName())
          .get(request.getServiceName())
          .containsKey(request.getComponentName())) {
        hostComponentNames.get(request.getClusterName())
            .get(request.getServiceName()).put(request.getComponentName(),
                new HashSet<String>());
      }
      if (hostComponentNames.get(request.getClusterName())
          .get(request.getServiceName()).get(request.getComponentName())
          .contains(request.getHostname())) {
        duplicates.add("[clusterName=" + request.getClusterName() + ", hostName=" + request.getHostname() +
            ", componentName=" +request.getComponentName() +']');
        continue;
      }
      hostComponentNames.get(request.getClusterName())
          .get(request.getServiceName()).get(request.getComponentName())
          .add(request.getHostname());

      if (request.getDesiredState() != null
          && !request.getDesiredState().isEmpty()) {
        State state = State.valueOf(request.getDesiredState());
        if (!state.isValidDesiredState()
            || state != State.INIT) {
          throw new IllegalArgumentException("Invalid desired state"
              + " only INIT state allowed during creation"
              + ", providedDesiredState=" + request.getDesiredState());
        }
      }

      Service s;
      try {
        s = cluster.getService(request.getServiceName());
      } catch (ServiceNotFoundException e) {
        throw new IllegalArgumentException(
            "The service[" + request.getServiceName() + "] associated with the component[" +
            request.getComponentName() + "] doesn't exist for the cluster[" + request.getClusterName() + "]");
      }
      ServiceComponent sc = s.getServiceComponent(
          request.getComponentName());

      Host host;
      try {
        host = clusters.getHost(request.getHostname());
      } catch (HostNotFoundException e) {
        throw new ParentObjectNotFoundException(
            "Attempted to add a host_component to a host that doesn't exist: ", e);
      }
      Set<Cluster> mappedClusters =
          clusters.getClustersForHost(request.getHostname());
      boolean validCluster = false;
      if (LOG.isDebugEnabled()) {
        LOG.debug("Looking to match host to cluster"
            + ", hostnameViaReg=" + host.getHostName()
            + ", hostname=" + request.getHostname()
            + ", clusterName=" + request.getClusterName()
            + ", hostClusterMapCount=" + mappedClusters.size());
      }
      for (Cluster mappedCluster : mappedClusters) {
        if (LOG.isDebugEnabled()) {
          LOG.debug("Host belongs to cluster"
              + ", hostname=" + request.getHostname()
              + ", clusterName=" + mappedCluster.getClusterName());
        }
        if (mappedCluster.getClusterName().equals(
            request.getClusterName())) {
          validCluster = true;
          break;
        }
      }
      if (!validCluster) {
        throw new ParentObjectNotFoundException("Attempted to add a host_component to a host that doesn't exist: " +
            "clusterName=" + request.getClusterName() + ", hostName=" + request.getHostname());
      }
      try {
        ServiceComponentHost sch = sc.getServiceComponentHost(
            request.getHostname());
        if (sch != null) {
          duplicates.add("[clusterName=" + request.getClusterName() + ", hostName=" + request.getHostname() +
              ", componentName=" +request.getComponentName() +']');
          continue;
        }
      } catch (AmbariException e) {
        // Expected
      }
    }

    // ensure only a single cluster update
    if (hostComponentNames.size() != 1) {
      throw new IllegalArgumentException("Invalid arguments - updates allowed"
          + " on only one cluster at a time");
    }

    if (!duplicates.isEmpty()) {
      StringBuilder names = new StringBuilder();
      boolean first = true;
      for (String hName : duplicates) {
        if (!first) {
          names.append(",");
        }
        first = false;
        names.append(hName);
      }
      String msg;
      if (duplicates.size() == 1) {
        msg = "Attempted to create a host_component which already exists: ";
      } else {
        msg = "Attempted to create host_component's which already exist: ";
      }
      throw new DuplicateResourceException(msg + names.toString());
    }

    // now doing actual work
    for (ServiceComponentHostRequest request : requests) {
      Cluster cluster = clusters.getCluster(request.getClusterName());
      Service s = cluster.getService(request.getServiceName());
      ServiceComponent sc = s.getServiceComponent(
          request.getComponentName());

      StackId stackId = sc.getDesiredStackVersion();
      ComponentInfo compInfo = ambariMetaInfo.getComponentCategory(
          stackId.getStackName(), stackId.getStackVersion(),
          s.getName(), sc.getName());
      boolean isClient = compInfo.isClient();

      ServiceComponentHost sch =
          serviceComponentHostFactory.createNew(sc, request.getHostname(),
              isClient);

      if (request.getDesiredState() != null
          && !request.getDesiredState().isEmpty()) {
        State state = State.valueOf(request.getDesiredState());
        sch.setDesiredState(state);
      } 

      sch.setDesiredStackVersion(sc.getDesiredStackVersion());

      // TODO fix config versions to configs conversion
      Map<String, Config> configs = new HashMap<String, Config>();
      if (request.getConfigVersions() != null) {
      }

      sch.updateDesiredConfigs(configs);
      sc.addServiceComponentHost(sch);
      sch.persist();
    }

  }

  public synchronized void createConfiguration(
      ConfigurationRequest request) throws AmbariException {
    if (null == request.getClusterName() || request.getClusterName().isEmpty()
        || null == request.getType() || request.getType().isEmpty()
        || null == request.getVersionTag() || request.getVersionTag().isEmpty()
        || null == request.getConfigs() || request.getConfigs().isEmpty()) {
      throw new IllegalArgumentException("Invalid Arguments,"
          + " clustername, config type, config version and configs should not"
          + " be null or empty");
    }

    Cluster cluster = clusters.getCluster(request.getClusterName());

    Map<String, Config> configs = cluster.getDesiredConfigsByType(
        request.getType());
    if (null == configs) {
      configs = new HashMap<String, Config>();
    }

    Config config = configs.get(request.getVersionTag());
    if (configs.containsKey(request.getVersionTag())) {
      throw new AmbariException("Configuration with that tag exists for '"
          + request.getType() + "'");
    }

    config = configFactory.createNew (cluster, request.getType(),
        request.getConfigs());
    config.setVersionTag(request.getVersionTag());

    config.persist();

    cluster.addDesiredConfig(config);
  }

  @Override
  public void createUsers(Set<UserRequest> requests) throws AmbariException {

    for (UserRequest request : requests) {

      if (null == request.getUsername() || request.getUsername().isEmpty() ||
          null == request.getPassword() || request.getPassword().isEmpty()) {
        throw new AmbariException("Username and password must be supplied.");
      }

      User user = users.getAnyUser(request.getUsername());
      if (null != user)
        throw new AmbariException("User already exists.");

      users.createUser(request.getUsername(), request.getPassword());

      if (0 != request.getRoles().size()) {
        user = users.getAnyUser(request.getUsername());
        if (null != user) {
          for (String role : request.getRoles()) {
            if (!user.getRoles().contains(role))
              users.addRoleToUser(user, role);
          }
        }
      }
    }

  }

  private Stage createNewStage(Cluster cluster, long requestId) {
    String logDir = baseLogDir + "/" + requestId;
    Stage stage = new Stage(requestId, logDir, cluster.getClusterName());
    return stage;
  }

  private void createHostAction(Cluster cluster,
      Stage stage, ServiceComponentHost scHost,
      Map<String, Map<String, String>> configurations,
      RoleCommand command,
      long nowTimestamp,
      ServiceComponentHostEvent event) throws AmbariException {

    stage.addHostRoleExecutionCommand(scHost.getHostName(), Role.valueOf(scHost
        .getServiceComponentName()), command,
        event, scHost.getClusterName(),
        scHost.getServiceName());
    ExecutionCommand execCmd = stage.getExecutionCommandWrapper(scHost.getHostName(),
        scHost.getServiceComponentName()).getExecutionCommand();

    // Generate cluster host info
    execCmd.setClusterHostInfo(
        StageUtils.getClusterHostInfo(cluster, hostsMap));

    Host host = clusters.getHost(scHost.getHostName());

    execCmd.setConfigurations(configurations);

    // send stack info to agent
    StackId stackId = scHost.getDesiredStackVersion();
    Map<String, List<RepositoryInfo>> repos = ambariMetaInfo.getRepository(
        stackId.getStackName(), stackId.getStackVersion());
    String repoInfo = "";
    if (!repos.containsKey(host.getOsType())) {
      // FIXME should this be an error?
      LOG.warn("Could not retrieve repo information for host"
          + ", hostname=" + scHost.getHostName()
          + ", clusterName=" + cluster.getClusterName()
          + ", stackInfo=" + stackId.getStackId());
    } else {
      repoInfo = gson.toJson(repos.get(host.getOsType()));
    }

    if (LOG.isDebugEnabled()) {
      LOG.debug("Sending repo information to agent"
          + ", hostname=" + scHost.getHostName()
          + ", clusterName=" + cluster.getClusterName()
          + ", stackInfo=" + stackId.getStackId()
          + ", repoInfo=" + repoInfo);
    }

    Map<String, String> params = new TreeMap<String, String>();
    params.put("repo_info", repoInfo);
    params.put("jdk_location", this.jdkResourceUrl);
    execCmd.setHostLevelParams(params);

    Map<String, String> roleParams = new TreeMap<String, String>();
    execCmd.setRoleParams(roleParams);

    return;
  }

  private synchronized Set<ClusterResponse> getClusters(ClusterRequest request)
      throws AmbariException {

    Set<ClusterResponse> response = new HashSet<ClusterResponse>();

    if (LOG.isDebugEnabled()) {
      LOG.debug("Received a getClusters request"
          + ", clusterName=" + request.getClusterName()
          + ", clusterId=" + request.getClusterId()
          + ", stackInfo=" + request.getStackVersion());
    }

    if (request.getClusterName() != null) {
      Cluster c = clusters.getCluster(request.getClusterName());
      response.add(c.convertToResponse());
      return response;
    } else if (request.getClusterId() != null) {
      Cluster c = clusters.getClusterById(request.getClusterId());
      response.add(c.convertToResponse());
      return response;
    }

    Map<String, Cluster> allClusters = clusters.getClusters();
    for (Cluster c : allClusters.values()) {
      if (request.getStackVersion() != null) {
        if (!request.getStackVersion().equals(
            c.getDesiredStackVersion().getStackId())) {
          // skip non matching stack versions
          continue;
        }
      }
      response.add(c.convertToResponse());
    }
    StringBuilder builder = new StringBuilder();
    if (LOG.isDebugEnabled()) {
      clusters.debugDump(builder);
      LOG.debug("Cluster State for cluster " + builder.toString());
    }
    return response;
  }

  private synchronized Set<ServiceResponse> getServices(ServiceRequest request)
      throws AmbariException {
    if (request.getClusterName() == null
        || request.getClusterName().isEmpty()) {
      throw new AmbariException("Invalid arguments, cluster name"
          + " cannot be null");
    }
    String clusterName = request.getClusterName();
    final Cluster cluster;
    try {
      cluster = clusters.getCluster(clusterName);
    } catch (ObjectNotFoundException e) {
      throw new ParentObjectNotFoundException("Parent Cluster resource doesn't exist", e);
    }

    Set<ServiceResponse> response = new HashSet<ServiceResponse>();
    if (request.getServiceName() != null) {
      Service s = cluster.getService(request.getServiceName());
      response.add(s.convertToResponse());
      return response;
    }

    // TODO support search on predicates?

    boolean checkDesiredState = false;
    State desiredStateToCheck = null;
    if (request.getDesiredState() != null
        && !request.getDesiredState().isEmpty()) {
      desiredStateToCheck = State.valueOf(request.getDesiredState());
      if (!desiredStateToCheck.isValidDesiredState()) {
        throw new IllegalArgumentException("Invalid arguments, invalid desired"
            + " state, desiredState=" + desiredStateToCheck);
      }
      checkDesiredState = true;
    }

    for (Service s : cluster.getServices().values()) {
      if (checkDesiredState
          && (desiredStateToCheck != s.getDesiredState())) {
        // skip non matching state
        continue;
      }
      response.add(s.convertToResponse());
    }
    return response;

  }

  private synchronized Set<ServiceComponentResponse> getComponents(
      ServiceComponentRequest request) throws AmbariException {
    if (request.getClusterName() == null
        || request.getClusterName().isEmpty()) {
      throw new IllegalArgumentException("Invalid arguments, cluster name"
          + " should be non-null");
    }

    final Cluster cluster;
    try {
      cluster = clusters.getCluster(request.getClusterName());
    } catch (ObjectNotFoundException e) {
      throw new ParentObjectNotFoundException("Parent Cluster resource doesn't exist", e);
    }

    Set<ServiceComponentResponse> response =
        new HashSet<ServiceComponentResponse>();

    if (request.getComponentName() != null) {
      if (request.getServiceName() == null) {
        StackId stackId = cluster.getDesiredStackVersion();
        String serviceName =
            ambariMetaInfo.getComponentToService(stackId.getStackName(),
                stackId.getStackVersion(), request.getComponentName());
        if (LOG.isDebugEnabled()) {
          LOG.debug("Looking up service name for component"
              + ", componentName=" + request.getComponentName()
              + ", serviceName=" + serviceName);
        }
        if (serviceName == null
            || serviceName.isEmpty()) {
          throw new AmbariException("Could not find service for component"
              + ", componentName=" + request.getComponentName()
              + ", clusterName=" + cluster.getClusterName()
              + ", stackInfo=" + stackId.getStackId());
        }
        request.setServiceName(serviceName);
      }

      final Service s;
      try {
        s = cluster.getService(request.getServiceName());
      } catch (ObjectNotFoundException e) {
        throw new ParentObjectNotFoundException("Parent Service resource doesn't exist", e);
      }

      ServiceComponent sc = s.getServiceComponent(request.getComponentName());
      response.add(sc.convertToResponse());
      return response;
    }

    boolean checkDesiredState = false;
    State desiredStateToCheck = null;
    if (request.getDesiredState() != null
        && !request.getDesiredState().isEmpty()) {
      desiredStateToCheck = State.valueOf(request.getDesiredState());
      if (!desiredStateToCheck.isValidDesiredState()) {
        throw new IllegalArgumentException("Invalid arguments, invalid desired"
            + " state, desiredState=" + desiredStateToCheck);
      }
      checkDesiredState = true;
    }

    Set<Service> services = new HashSet<Service>();
    if (request.getServiceName() != null
        && !request.getServiceName().isEmpty()) {
      services.add(cluster.getService(request.getServiceName()));
    } else {
      services.addAll(cluster.getServices().values());
    }

    for (Service s : services) {
      // filter on request.getDesiredState()
      for (ServiceComponent sc : s.getServiceComponents().values()) {
        if (checkDesiredState
            && (desiredStateToCheck != sc.getDesiredState())) {
          // skip non matching state
          continue;
        }
        response.add(sc.convertToResponse());
      }
    }
    return response;
  }

  private synchronized Set<HostResponse> getHosts(HostRequest request)
      throws AmbariException {

    //TODO/FIXME host can only belong to a single cluster so get host directly from Cluster
    //TODO/FIXME what is the requirement for filtering on host attributes?

    List<Host>        hosts;
    Set<HostResponse> response = new HashSet<HostResponse>();
    Cluster           cluster  = null;

    String clusterName = request.getClusterName();
    String hostName    = request.getHostname();

    if (clusterName != null) {
      //validate that cluster exists, throws exception if it doesn't.
      try {
        cluster = clusters.getCluster(clusterName);
      } catch (ObjectNotFoundException e) {
        throw new ParentObjectNotFoundException("Parent Cluster resource doesn't exist", e);
      }
    }

    if (hostName == null) {
      hosts = clusters.getHosts();
    } else {
      hosts = new ArrayList<Host>();
      hosts.add(clusters.getHost(request.getHostname()));
    }

    for (Host h : hosts) {
      if (clusterName != null) {
        if (clusters.getClustersForHost(h.getHostName()).contains(cluster)) {
          HostResponse r = h.convertToResponse();
          r.setClusterName(clusterName);
          response.add(r);
        } else if (hostName != null) {
          throw new HostNotFoundException(hostName);
        }
      } else {
        HostResponse r = h.convertToResponse();

        Set<Cluster> clustersForHost = clusters.getClustersForHost(h.getHostName());
        //todo: host can only belong to a single cluster
        if (clustersForHost != null && clustersForHost.size() != 0) {
          r.setClusterName(clustersForHost.iterator().next().getClusterName());
        }
        response.add(r);
      }
    }
    return response;
  }

  private synchronized Set<ServiceComponentHostResponse> getHostComponents(
      ServiceComponentHostRequest request) throws AmbariException {
    if (request.getClusterName() == null
        || request.getClusterName().isEmpty()) {
      throw new IllegalArgumentException("Invalid arguments, cluster name should not be null");
    }

    final Cluster cluster;
    try {
      cluster = clusters.getCluster(request.getClusterName());
    } catch (ClusterNotFoundException e) {
      throw new ParentObjectNotFoundException("Parent Cluster resource doesn't exist", e);
    }

    if (request.getHostname() != null) {
      try {
        if (! clusters.getClustersForHost(request.getHostname()).contains(cluster)) {
          // case where host exists but not associated with given cluster
          throw new ParentObjectNotFoundException("Parent Host resource doesn't exist",
              new HostNotFoundException(request.getClusterName(), request.getHostname()));
        }
      } catch (HostNotFoundException e) {
        // creating new HostNotFoundException to add cluster name
        throw new ParentObjectNotFoundException("Parent Host resource doesn't exist",
            new HostNotFoundException(request.getClusterName(), request.getHostname()));
      }
    }

    if (request.getComponentName() != null) {
      if (request.getServiceName() == null
          || request.getServiceName().isEmpty()) {
        StackId stackId = cluster.getDesiredStackVersion();
        String serviceName =
            ambariMetaInfo.getComponentToService(stackId.getStackName(),
                stackId.getStackVersion(), request.getComponentName());
        if (LOG.isDebugEnabled()) {
          LOG.debug("Looking up service name for component"
              + ", componentName=" + request.getComponentName()
              + ", serviceName=" + serviceName
              + ", stackInfo=" + stackId.getStackId());
        }
        if (serviceName == null
            || serviceName.isEmpty()) {
          throw new ServiceComponentHostNotFoundException(
              cluster.getClusterName(), null, request.getComponentName(),request.getHostname());
        }
        request.setServiceName(serviceName);
      }
    }

    Set<Service> services = new HashSet<Service>();
    if (request.getServiceName() != null && !request.getServiceName().isEmpty()) {
      services.add(cluster.getService(request.getServiceName()));
    } else {
      services.addAll(cluster.getServices().values());
    }

    Set<ServiceComponentHostResponse> response =
        new HashSet<ServiceComponentHostResponse>();

    boolean checkDesiredState = false;
    State desiredStateToCheck = null;
    if (request.getDesiredState() != null
        && !request.getDesiredState().isEmpty()) {
      desiredStateToCheck = State.valueOf(request.getDesiredState());
      if (!desiredStateToCheck.isValidDesiredState()) {
        throw new IllegalArgumentException("Invalid arguments, invalid desired"
            + " state, desiredState=" + desiredStateToCheck);
      }
      checkDesiredState = true;
    }

    for (Service s : services) {
      // filter on component name if provided
      Set<ServiceComponent> components = new HashSet<ServiceComponent>();
      if (request.getComponentName() != null) {
        components.add(s.getServiceComponent(request.getComponentName()));
      } else {
        components.addAll(s.getServiceComponents().values());
      }
      for(ServiceComponent sc : components) {
        if (request.getComponentName() != null) {
          if (!sc.getName().equals(request.getComponentName())) {
            continue;
          }
        }

        // filter on hostname if provided
        // filter on desired state if provided

        if (request.getHostname() != null) {
          try {
            ServiceComponentHost sch = sc.getServiceComponentHost(
                request.getHostname());
            if (checkDesiredState
                && (desiredStateToCheck != sch.getDesiredState())) {
              continue;
            }
            ServiceComponentHostResponse r = sch.convertToResponse();
            response.add(r);
          } catch (ServiceComponentHostNotFoundException e) {
            if (request.getServiceName() != null && request.getComponentName() != null) {
              throw new ServiceComponentHostNotFoundException(cluster.getClusterName(),
                  request.getServiceName(), request.getComponentName(),request.getHostname());
            } else {
              // ignore this since host_component was not specified
              // this is an artifact of how we get host_components and can happen
              // in case where we get all host_components for a host
            }

          }
        } else {
          for (ServiceComponentHost sch :
              sc.getServiceComponentHosts().values()) {
            if (checkDesiredState
                && (desiredStateToCheck != sch.getDesiredState())) {
              continue;
            }
            ServiceComponentHostResponse r = sch.convertToResponse();
            response.add(r);
          }
        }
      }
    }
    return response;
  }


  private synchronized Set<ConfigurationResponse> getConfigurations(
      ConfigurationRequest request) throws AmbariException {
    if (request.getClusterName() == null) {
      throw new IllegalArgumentException("Invalid arguments, cluster name"
          + " should not be null");
    }

    Cluster cluster = clusters.getCluster(request.getClusterName());

    Set<ConfigurationResponse> responses = new HashSet<ConfigurationResponse>();

    // !!! if only one, then we need full properties
    if (null != request.getType() && null != request.getVersionTag()) {
      Config config = cluster.getDesiredConfig(request.getType(),
          request.getVersionTag());
      if (null != config) {
        ConfigurationResponse response = new ConfigurationResponse(
            cluster.getClusterName(), config.getType(), config.getVersionTag(),
            config.getProperties());
        responses.add(response);
      }
    }
    else {
      if (null != request.getType()) {
        Map<String, Config> configs = cluster.getDesiredConfigsByType(
            request.getType());

        if (null != configs) {
          for (Entry<String, Config> entry : configs.entrySet()) {
            ConfigurationResponse response = new ConfigurationResponse(
                cluster.getClusterName(), request.getType(),
                entry.getValue().getVersionTag(), new HashMap<String, String>());
            responses.add(response);
          }
        }
      } else {
        // !!! all configuration
        Collection<Config> all = cluster.getAllConfigs();

        for (Config config : all) {
          ConfigurationResponse response = new ConfigurationResponse(
             cluster.getClusterName(), config.getType(), config.getVersionTag(),
             new HashMap<String, String>());

          responses.add(response);
        }
      }
    }

    return responses;

  }


  @Override
  public synchronized RequestStatusResponse updateCluster(ClusterRequest request)
      throws AmbariException {
    // for now only update host list supported
    if (request.getClusterName() == null
        || request.getClusterName().isEmpty()) {
      throw new IllegalArgumentException("Invalid arguments, cluster name"
          + " should not be null");
    }

    if (LOG.isDebugEnabled()) {
      LOG.debug("Received a updateCluster request"
          + ", clusterName=" + request.getClusterName()
          + ", request=" + request);
    }

    final Cluster c = clusters.getCluster(request.getClusterName());
    clusters.mapHostsToCluster(request.getHostNames(),
        request.getClusterName());

    if (!request.getStackVersion().equals(
        c.getDesiredStackVersion().getStackId())) {
      throw new IllegalArgumentException("Update of desired stack version"
          + " not supported");
    }

    return null;
  }

  // FIXME refactor code out of all update functions
  /*
  private TrackActionResponse triggerStateChange(State newState, Service s,
      ServiceComponent sc, ServiceComponentHost sch) {
    return null;
  }
  */
  
  private String getJobTrackerHost(Cluster cluster) {
    try {
      Service svc = cluster.getService("MAPREDUCE");
      ServiceComponent sc = svc.getServiceComponent(Role.JOBTRACKER.toString());
      if (sc.getServiceComponentHosts() != null
          && !sc.getServiceComponentHosts().isEmpty()) {
        return sc.getServiceComponentHosts().keySet().iterator().next();
      }
    } catch (AmbariException ex) {
      return null;
    }
    return null;
  }

  private RequestStatusResponse doStageCreation(Cluster cluster,
      Map<State, List<Service>> changedServices,
      Map<State, List<ServiceComponent>> changedComps,
      Map<String, Map<State, List<ServiceComponentHost>>> changedScHosts)
          throws AmbariException {

    // TODO handle different transitions?
    // Say HDFS to stopped and MR to started, what order should actions be done
    // in?

    // TODO additional validation?
    // verify all configs
    // verify all required components

    if ((changedServices == null || changedServices.isEmpty())
        && (changedComps == null || changedComps.isEmpty())
        && (changedScHosts == null || changedScHosts.isEmpty())) {
      return null;
    }

    Long requestId = null;
    List<Stage> stages = null;

    Set<String> smokeTestServices =
        new HashSet<String>();

    // smoke test any service that goes from installed to started
    if (changedServices != null) {
      for (Entry<State, List<Service>> entry : changedServices.entrySet()) {
        if (State.STARTED != entry.getKey()) {
          continue;
        }
        for (Service s : entry.getValue()) {
          if (State.INSTALLED == s.getDesiredState()) {
            smokeTestServices.add(s.getName());
          }
        }
      }
    }

    Map<String, Map<String, Integer>> changedComponentCount =
        new HashMap<String, Map<String, Integer>>();
    for (Map<State, List<ServiceComponentHost>> stateScHostMap :
      changedScHosts.values()) {
      for (Entry<State, List<ServiceComponentHost>> entry :
          stateScHostMap.entrySet()) {
        if (State.STARTED != entry.getKey()) {
          continue;
        }
        for (ServiceComponentHost sch : entry.getValue()) {
          if (State.START_FAILED != sch.getState()
              && State.INSTALLED != sch.getState()) {
            continue;
          }
          if (!changedComponentCount.containsKey(sch.getServiceName())) {
            changedComponentCount.put(sch.getServiceName(),
                new HashMap<String, Integer>());
          }
          if (!changedComponentCount.get(sch.getServiceName())
              .containsKey(sch.getServiceComponentName())) {
            changedComponentCount.get(sch.getServiceName())
                .put(sch.getServiceComponentName(), 1);
          } else {
            Integer i = changedComponentCount.get(sch.getServiceName())
                .get(sch.getServiceComponentName());
            changedComponentCount.get(sch.getServiceName())
              .put(sch.getServiceComponentName(), ++i);
          }
        }
      }
    }

    for (Entry<String, Map<String, Integer>> entry :
        changedComponentCount.entrySet()) {
      String serviceName = entry.getKey();
      // smoke test service if more than one component is started
      if (entry.getValue().size() > 1) {
        smokeTestServices.add(serviceName);
        continue;
      }
      for (String componentName :
        changedComponentCount.get(serviceName).keySet()) {
        ServiceComponent sc = cluster.getService(serviceName)
            .getServiceComponent(componentName);
        StackId stackId = sc.getDesiredStackVersion();
        ComponentInfo compInfo = ambariMetaInfo.getComponentCategory(
            stackId.getStackName(), stackId.getStackVersion(), serviceName,
            componentName);
        if (compInfo.isMaster()) {
          smokeTestServices.add(serviceName);
        }

        // FIXME if master check if we need to run a smoke test for the master
      }
    }

    if (!changedScHosts.isEmpty()
        || !smokeTestServices.isEmpty()) {
      long nowTimestamp = System.currentTimeMillis();
      requestId = Long.valueOf(actionManager.getNextRequestId());

      // FIXME cannot work with a single stage
      // multiple stages may be needed for reconfigure
      long stageId = 0;
      Stage stage = createNewStage(cluster, requestId.longValue());
      stage.setStageId(stageId);
      //HACK
      String jobtrackerHost = this.getJobTrackerHost(cluster);
      for (String compName : changedScHosts.keySet()) {
        for (State newState : changedScHosts.get(compName).keySet()) {
          for (ServiceComponentHost scHost :
              changedScHosts.get(compName).get(newState)) {
            RoleCommand roleCommand;
            State oldSchState = scHost.getState();
            ServiceComponentHostEvent event;
            switch(newState) {
              case INSTALLED:
                if (oldSchState == State.INIT
                    || oldSchState == State.UNINSTALLED
                    || oldSchState == State.INSTALLED
                    || oldSchState == State.INSTALLING
                    || oldSchState == State.INSTALL_FAILED) {
                  roleCommand = RoleCommand.INSTALL;
                  event = new ServiceComponentHostInstallEvent(
                      scHost.getServiceComponentName(), scHost.getHostName(),
                      nowTimestamp,
                      scHost.getDesiredStackVersion().getStackId());
                } else if (oldSchState == State.STARTED
                    || oldSchState == State.START_FAILED
                    || oldSchState == State.INSTALLED
                    || oldSchState == State.STOP_FAILED) {
                  roleCommand = RoleCommand.STOP;
                  event = new ServiceComponentHostStopEvent(
                      scHost.getServiceComponentName(), scHost.getHostName(),
                      nowTimestamp);
                } else {
                  throw new AmbariException("Invalid transition for"
                      + " servicecomponenthost"
                      + ", clusterName=" + cluster.getClusterName()
                      + ", clusterId=" + cluster.getClusterId()
                      + ", serviceName=" + scHost.getServiceName()
                      + ", componentName=" + scHost.getServiceComponentName()
                      + ", hostname=" + scHost.getHostName()
                      + ", currentState=" + oldSchState
                      + ", newDesiredState=" + newState);
                }
                break;
              case STARTED:
                StackId stackId = scHost.getDesiredStackVersion();
                ComponentInfo compInfo = ambariMetaInfo.getComponentCategory(
                    stackId.getStackName(), stackId.getStackVersion(), scHost.getServiceName(),
                    scHost.getServiceComponentName());
                if (oldSchState == State.INSTALLED
                    || oldSchState == State.START_FAILED || oldSchState == State.STARTING) {
                  roleCommand = RoleCommand.START;
                  event = new ServiceComponentHostStartEvent(
                      scHost.getServiceComponentName(), scHost.getHostName(),
                      nowTimestamp, scHost.getDesiredConfigVersionsRecursive());
                } else {
                  String error = "Invalid transition for"
                      + " servicecomponenthost"
                      + ", clusterName=" + cluster.getClusterName()
                      + ", clusterId=" + cluster.getClusterId()
                      + ", serviceName=" + scHost.getServiceName()
                      + ", componentName=" + scHost.getServiceComponentName()
                      + ", hostname=" + scHost.getHostName()
                      + ", currentState=" + oldSchState
                      + ", newDesiredState=" + newState;
                  if (compInfo.isMaster()) {
                    throw new AmbariException(error);
                  } else {
                    LOG.info("Ignoring: " + error);
                    continue;
                  }
                }
                break;
              case UNINSTALLED:
                if (oldSchState == State.INSTALLED
                    || oldSchState == State.UNINSTALL_FAILED) {
                  roleCommand = RoleCommand.UNINSTALL;
                  event = new ServiceComponentHostStartEvent(
                      scHost.getServiceComponentName(), scHost.getHostName(),
                      nowTimestamp, scHost.getDesiredConfigVersionsRecursive());
                } else {
                  throw new AmbariException("Invalid transition for"
                      + " servicecomponenthost"
                      + ", clusterName=" + cluster.getClusterName()
                      + ", clusterId=" + cluster.getClusterId()
                      + ", serviceName=" + scHost.getServiceName()
                      + ", componentName=" + scHost.getServiceComponentName()
                      + ", hostname=" + scHost.getHostName()
                      + ", currentState=" + oldSchState
                      + ", newDesiredState=" + newState);
                }
                break;
              case INIT:
                throw new AmbariException("Unsupported transition to INIT for"
                    + " servicecomponenthost"
                    + ", clusterName=" + cluster.getClusterName()
                    + ", clusterId=" + cluster.getClusterId()
                    + ", serviceName=" + scHost.getServiceName()
                    + ", componentName=" + scHost.getServiceComponentName()
                    + ", hostname=" + scHost.getHostName()
                    + ", currentState=" + oldSchState
                    + ", newDesiredState=" + newState);
              default:
                throw new AmbariException("Unsupported state change operation"
                    + ", newState=" + newState.toString());
            }

            if (LOG.isDebugEnabled()) {
              LOG.debug("Create a new host action"
                  + ", requestId=" + requestId.longValue()
                  + ", componentName=" + scHost.getServiceComponentName()
                  + ", hostname=" + scHost.getHostName()
                  + ", roleCommand=" + roleCommand.name());
            }

            Map<String, Config> configs = scHost.getDesiredConfigs();
            // Clone configurations for the command
            Map<String, Map<String, String>> configurations =
                new TreeMap<String, Map<String, String>>();
            for (Config config : configs.values()) {
              if (LOG.isDebugEnabled()) {
                LOG.debug("Cloning configs for execution command"
                    + ", configType=" + config.getType()
                    + ", configVersionTag=" + config.getVersionTag()
                    + ", clusterName=" + scHost.getClusterName()
                    + ", serviceName=" + scHost.getServiceName()
                    + ", componentName=" + scHost.getServiceComponentName()
                    + ", hostname=" + scHost.getHostName());
              }
              configurations.put(config.getType(),
                  config.getProperties());
            }
            // HACK HACK HACK
            if ((!scHost.getHostName().equals(jobtrackerHost))
                && configurations.get("global") != null) {
              if (LOG.isDebugEnabled()) {
                LOG.debug("Setting rca_enabled to false for host "
                    + scHost.getHostName());
              }
              configurations.get("global").put("rca_enabled", "false");
            }
            createHostAction(cluster, stage, scHost, configurations,
                roleCommand, nowTimestamp, event);
          }
        }
      }

      for (String serviceName : smokeTestServices) {
        Service s = cluster.getService(serviceName);

        // find service component host
        String clientHost = getClientHostForRunningAction(cluster, s);
        String smokeTestRole =
            actionMetadata.getServiceCheckAction(serviceName);

        if (clientHost == null || smokeTestRole == null) {
          LOG.info("Nothing to do for service check as could not find role or"
              + " or host to run check on"
              + ", clusterName=" + cluster.getClusterName()
              + ", serviceName=" + serviceName
              + ", clientHost=" + clientHost
              + ", serviceCheckRole=" + smokeTestRole);
          continue;
        }

        stage.addHostRoleExecutionCommand(clientHost,
            Role.valueOf(smokeTestRole),
            RoleCommand.EXECUTE,
            new ServiceComponentHostOpInProgressEvent(null, clientHost,
                nowTimestamp), cluster.getClusterName(), serviceName);

        Map<String, Map<String, String>> configurations =
            new TreeMap<String, Map<String, String>>();
        Map<String, Config> allConfigs = cluster.getService(serviceName).getDesiredConfigs();
        if (allConfigs != null) {
          for (Map.Entry<String, Config> entry: allConfigs.entrySet()) {
            configurations.put(entry.getValue().getType(), entry.getValue().getProperties());
          }
        }
        
        stage.getExecutionCommandWrapper(clientHost,
            smokeTestRole).getExecutionCommand()
            .setConfigurations(configurations);

        // Generate cluster host info
        stage.getExecutionCommandWrapper(clientHost, smokeTestRole)
            .getExecutionCommand()
            .setClusterHostInfo(StageUtils.getClusterHostInfo(cluster, hostsMap));
      }

      RoleGraph rg = new RoleGraph(rco);
      rg.build(stage);
      stages = rg.getStages();

      if (LOG.isDebugEnabled()) {
        LOG.debug("Triggering Action Manager"
            + ", clusterName=" + cluster.getClusterName()
            + ", requestId=" + requestId.longValue()
            + ", stagesCount=" + stages.size());
      }
      actionManager.sendActions(stages);
    }

    if (changedServices != null) {
      for (Entry<State, List<Service>> entry : changedServices.entrySet()) {
        State newState = entry.getKey();
        for (Service s : entry.getValue()) {
          if (s.isClientOnlyService()
              && newState == State.STARTED) {
            continue;
          }
          s.setDesiredState(newState);
        }
      }
    }

    if (changedComps != null) {
      for (Entry<State, List<ServiceComponent>> entry :
          changedComps.entrySet()){
        State newState = entry.getKey();
        for (ServiceComponent sc : entry.getValue()) {
          sc.setDesiredState(newState);
        }
      }
    }

    for (Map<State, List<ServiceComponentHost>> stateScHostMap :
        changedScHosts.values()) {
      for (Entry<State, List<ServiceComponentHost>> entry :
          stateScHostMap.entrySet()) {
        State newState = entry.getKey();
        for (ServiceComponentHost sch : entry.getValue()) {
          sch.setDesiredState(newState);
        }
      }
    }

    if (stages == null || stages.isEmpty()
        || requestId == null) {
      return null;
    }
    return getRequestStatusResponse(requestId.longValue());
  }

  private boolean isValidStateTransition(State oldState,
      State newState) {
    switch(newState) {
      case INSTALLED:
        if (oldState == State.INIT
            || oldState == State.UNINSTALLED
            || oldState == State.INSTALLED
            || oldState == State.INSTALLING
            || oldState == State.STARTED
            || oldState == State.START_FAILED
            || oldState == State.INSTALL_FAILED
            || oldState == State.STOP_FAILED) {
          return true;
        }
        break;
      case STARTED:
        if (oldState == State.INSTALLED
            || oldState == State.STARTING
            || oldState == State.STARTED
            || oldState == State.START_FAILED) {
          return true;
        }
        break;
      case UNINSTALLED:
        if (oldState == State.INSTALLED
            || oldState == State.UNINSTALLED
            || oldState == State.UNINSTALL_FAILED) {
          return true;
        }
      case INIT:
        if (oldState == State.UNINSTALLED
            || oldState == State.INIT
            || oldState == State.WIPEOUT_FAILED) {
          return true;
        }
    }
    return false;
  }


  private boolean isValidDesiredStateTransition(State oldState,
      State newState) {
    switch(newState) {
      case INSTALLED:
        if (oldState == State.INIT
            || oldState == State.UNINSTALLED
            || oldState == State.INSTALLED
            || oldState == State.STARTED) {
          return true;
        }
        break;
      case STARTED:
        if (oldState == State.INSTALLED
            || oldState == State.STARTED) {
          return true;
        }
        break;
    }
    return false;
  }

  private void safeToUpdateConfigsForServiceComponentHost(
      ServiceComponentHost sch,
      State currentState, State newDesiredState)
          throws AmbariException {
    if (currentState == State.STARTED
        || currentState == State.STARTING) {
      throw new AmbariException("Changing of configs not supported"
          + " in STARTING or STARTED state"
          + ", clusterName=" + sch.getClusterName()
          + ", serviceName=" + sch.getServiceName()
          + ", componentName=" + sch.getServiceComponentName()
          + ", hostname=" + sch.getHostName()
          + ", currentState=" + currentState
          + ", newDesiredState=" + newDesiredState);
    }

    if (newDesiredState != null) {
      if (!(newDesiredState == State.INIT
          || newDesiredState == State.INSTALLED
          || newDesiredState == State.STARTED)) {
        throw new AmbariException("Changing of configs not supported"
            + " for this transition"
            + ", clusterName=" + sch.getClusterName()
            + ", serviceName=" + sch.getServiceName()
            + ", componentName=" + sch.getServiceComponentName()
            + ", hostname=" + sch.getHostName()
            + ", currentState=" + currentState
            + ", newDesiredState=" + newDesiredState);
      }
    }
  }

  private void safeToUpdateConfigsForServiceComponent(
      ServiceComponent sc,
      State currentDesiredState, State newDesiredState)
          throws AmbariException {
    for (ServiceComponentHost sch :
      sc.getServiceComponentHosts().values()) {
      safeToUpdateConfigsForServiceComponentHost(sch,
        sch.getState(), newDesiredState);
    }
  }

  private void safeToUpdateConfigsForService(Service service,
      State currentDesiredState, State newDesiredState)
          throws AmbariException {
    for (ServiceComponent component :
        service.getServiceComponents().values()) {
      safeToUpdateConfigsForServiceComponent(component,
          component.getDesiredState(), newDesiredState);
    }
  }

  @Override
  public synchronized RequestStatusResponse updateServices(
      Set<ServiceRequest> requests) throws AmbariException {

    if (requests.isEmpty()) {
      LOG.warn("Received an empty requests set");
      return null;
    }

    Map<State, List<Service>> changedServices
      = new HashMap<State, List<Service>>();
    Map<State, List<ServiceComponent>> changedComps =
        new HashMap<State, List<ServiceComponent>>();
    Map<String, Map<State, List<ServiceComponentHost>>> changedScHosts =
        new HashMap<String, Map<State, List<ServiceComponentHost>>>();

    Set<String> clusterNames = new HashSet<String>();
    Map<String, Set<String>> serviceNames = new HashMap<String, Set<String>>();
    Set<State> seenNewStates = new HashSet<State>();

    for (ServiceRequest request : requests) {
      if (request.getClusterName() == null
          || request.getClusterName().isEmpty()
          || request.getServiceName() == null
          || request.getServiceName().isEmpty()) {
        throw new IllegalArgumentException("Invalid arguments, cluster name"
            + " and service name should be provided to update services");
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a updateService request"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + request.getServiceName()
            + ", request=" + request.toString());
      }

      clusterNames.add(request.getClusterName());

      if (clusterNames.size() > 1) {
        throw new IllegalArgumentException("Updates to multiple clusters is not"
            + " supported");
      }

      if (!serviceNames.containsKey(request.getClusterName())) {
        serviceNames.put(request.getClusterName(), new HashSet<String>());
      }
      if (serviceNames.get(request.getClusterName())
          .contains(request.getServiceName())) {
        // TODO throw single exception
        throw new IllegalArgumentException("Invalid request contains duplicate"
            + " service names");
      }
      serviceNames.get(request.getClusterName()).add(request.getServiceName());

      Cluster cluster = clusters.getCluster(request.getClusterName());
      Service s = cluster.getService(request.getServiceName());
      State oldState = s.getDesiredState();
      State newState = null;
      if (request.getDesiredState() != null) {
        newState = State.valueOf(request.getDesiredState());
        if (!newState.isValidDesiredState()) {
          throw new IllegalArgumentException("Invalid arguments, invalid"
              + " desired state, desiredState=" + newState);
        }
      }

      if (request.getConfigVersions() != null) {
        safeToUpdateConfigsForService(s, oldState, newState);

        for (Entry<String,String> entry :
            request.getConfigVersions().entrySet()) {
          if (LOG.isDebugEnabled()) {
            LOG.debug("Attaching config to service"
                + ", clusterName=" + cluster.getClusterName()
                + ", serviceName=" + s.getName()
                + ", configType=" + entry.getKey()
                + ", configTag=" + entry.getValue());
          }
          Config config = cluster.getDesiredConfig(
              entry.getKey(), entry.getValue());
          if (null == config) {
            // throw error for invalid config
            throw new AmbariException("Trying to update service with"
                + " invalid configs"
                + ", clusterName=" + cluster.getClusterName()
                + ", clusterId=" + cluster.getClusterId()
                + ", serviceName=" + s.getName()
                + ", invalidConfigType=" + entry.getKey()
                + ", invalidConfigTag=" + entry.getValue());
          }
        }
      }


      if (newState == null) {
        if (LOG.isDebugEnabled()) {
          LOG.debug("Nothing to do for new updateService request"
              + ", clusterName=" + request.getClusterName()
              + ", serviceName=" + request.getServiceName()
              + ", newDesiredState=null");
        }
        continue;
      }

      seenNewStates.add(newState);

      if (newState != oldState) {
        if (!isValidDesiredStateTransition(oldState, newState)) {
          throw new AmbariException("Invalid transition for"
              + " service"
              + ", clusterName=" + cluster.getClusterName()
              + ", clusterId=" + cluster.getClusterId()
              + ", serviceName=" + s.getName()
              + ", currentDesiredState=" + oldState
              + ", newDesiredState=" + newState);

        }
        if (!changedServices.containsKey(newState)) {
          changedServices.put(newState, new ArrayList<Service>());
        }
        changedServices.get(newState).add(s);
      }

      // TODO should we check whether all servicecomponents and
      // servicecomponenthosts are in the required desired state?

      for (ServiceComponent sc : s.getServiceComponents().values()) {
        State oldScState = sc.getDesiredState();
        if (newState != oldScState) {
          if (sc.isClientComponent() &&
              !newState.isValidClientComponentState()) {
            continue;
          }
          if (!isValidDesiredStateTransition(oldScState, newState)) {
            throw new AmbariException("Invalid transition for"
                + " servicecomponent"
                + ", clusterName=" + cluster.getClusterName()
                + ", clusterId=" + cluster.getClusterId()
                + ", serviceName=" + sc.getServiceName()
                + ", componentName=" + sc.getName()
                + ", currentDesiredState=" + oldScState
                + ", newDesiredState=" + newState);
          }
          if (!changedComps.containsKey(newState)) {
            changedComps.put(newState, new ArrayList<ServiceComponent>());
          }
          changedComps.get(newState).add(sc);
        }
        if (LOG.isDebugEnabled()) {
          LOG.debug("Handling update to ServiceComponent"
              + ", clusterName=" + request.getClusterName()
              + ", serviceName=" + s.getName()
              + ", componentName=" + sc.getName()
              + ", currentDesiredState=" + oldScState
              + ", newDesiredState=" + newState);
        }
        for (ServiceComponentHost sch : sc.getServiceComponentHosts().values()){
          State oldSchState = sch.getState();
          if (newState == oldSchState) {
            sch.setDesiredState(newState);
            if (LOG.isDebugEnabled()) {
              LOG.debug("Ignoring ServiceComponentHost"
                  + ", clusterName=" + request.getClusterName()
                  + ", serviceName=" + s.getName()
                  + ", componentName=" + sc.getName()
                  + ", hostname=" + sch.getHostName()
                  + ", currentState=" + oldSchState
                  + ", newDesiredState=" + newState);
            }
            continue;
          }
          if (sc.isClientComponent() &&
              !newState.isValidClientComponentState()) {
            continue;
          }
          /** 
           * This is hack for now wherein we dont fail if the 
           * sch is in INSTALL_FAILED 
           */
          if (!isValidStateTransition(oldSchState, newState)) {
            String error = "Invalid transition for"
                + " servicecomponenthost"
                + ", clusterName=" + cluster.getClusterName()
                + ", clusterId=" + cluster.getClusterId()
                + ", serviceName=" + sch.getServiceName()
                + ", componentName=" + sch.getServiceComponentName()
                + ", hostname=" + sch.getHostName()
                + ", currentState=" + oldSchState
                + ", newDesiredState=" + newState;
            StackId sid = cluster.getDesiredStackVersion();
            
            if ( ambariMetaInfo.getComponentCategory(
                sid.getStackName(), sid.getStackVersion(), sc.getServiceName(),
                sch.getServiceComponentName()).isMaster()) {
              throw new AmbariException(error);
            } else {
              LOG.warn("Ignoring: " + error);
              continue;
            }
          }
          if (!changedScHosts.containsKey(sc.getName())) {
            changedScHosts.put(sc.getName(),
                new HashMap<State, List<ServiceComponentHost>>());
          }
          if (!changedScHosts.get(sc.getName()).containsKey(newState)) {
            changedScHosts.get(sc.getName()).put(newState,
                new ArrayList<ServiceComponentHost>());
          }
          if (LOG.isDebugEnabled()) {
            LOG.debug("Handling update to ServiceComponentHost"
                + ", clusterName=" + request.getClusterName()
                + ", serviceName=" + s.getName()
                + ", componentName=" + sc.getName()
                + ", hostname=" + sch.getHostName()
                + ", currentState=" + oldSchState
                + ", newDesiredState=" + newState);
          }
          changedScHosts.get(sc.getName()).get(newState).add(sch);
        }
      }
    }

    if (seenNewStates.size() > 1) {
      // TODO should we handle this scenario
      throw new IllegalArgumentException("Cannot handle different desired state"
          + " changes for a set of services at the same time");
    }

    for (ServiceRequest request : requests) {
      Cluster cluster = clusters.getCluster(request.getClusterName());
      Service s = cluster.getService(request.getServiceName());
      if (request.getConfigVersions() != null) {
        Map<String, Config> updated = new HashMap<String, Config>();

        for (Entry<String,String> entry : request.getConfigVersions().entrySet()) {
          Config config = cluster.getDesiredConfig(entry.getKey(), entry.getValue());
          updated.put(config.getType(), config);
        }

        if (!updated.isEmpty()) {
          if (LOG.isDebugEnabled()) {
            LOG.debug("Updating service configs, attaching configs"
                + ", clusterName=" + request.getClusterName()
                + ", serviceName=" + s.getName()
                + ", configCount=" + updated.size());
          }
          s.updateDesiredConfigs(updated);
          s.persist();
        }

        for (ServiceComponent sc : s.getServiceComponents().values()) {
          sc.deleteDesiredConfigs(updated.keySet());
          for (ServiceComponentHost sch :
            sc.getServiceComponentHosts().values()) {
            sch.deleteDesiredConfigs(updated.keySet());
            sch.persist();
          }
          sc.persist();
        }
      }
    }

    Cluster cluster = clusters.getCluster(clusterNames.iterator().next());

    return doStageCreation(cluster, changedServices,
        changedComps, changedScHosts);
  }

  @Override
  public synchronized RequestStatusResponse updateComponents(
      Set<ServiceComponentRequest> requests) throws AmbariException {

    if (requests.isEmpty()) {
      LOG.warn("Received an empty requests set");
      return null;
    }

    Map<State, List<ServiceComponent>> changedComps =
        new HashMap<State, List<ServiceComponent>>();
    Map<String, Map<State, List<ServiceComponentHost>>> changedScHosts =
        new HashMap<String, Map<State, List<ServiceComponentHost>>>();

    Set<String> clusterNames = new HashSet<String>();
    Map<String, Map<String, Set<String>>> componentNames =
        new HashMap<String, Map<String,Set<String>>>();
    Set<State> seenNewStates = new HashSet<State>();

    for (ServiceComponentRequest request : requests) {
      if (request.getClusterName() == null
          || request.getClusterName().isEmpty()
          || request.getComponentName() == null
          || request.getComponentName().isEmpty()) {
        throw new IllegalArgumentException("Invalid arguments, cluster name"
            + ", service name and component name should be provided to"
            + " update components");
      }

      Cluster cluster = clusters.getCluster(request.getClusterName());

      if (request.getServiceName() == null
          || request.getServiceName().isEmpty()) {
        StackId stackId = cluster.getDesiredStackVersion();
        String serviceName =
            ambariMetaInfo.getComponentToService(stackId.getStackName(),
                stackId.getStackVersion(), request.getComponentName());
        if (LOG.isDebugEnabled()) {
          LOG.debug("Looking up service name for component"
              + ", componentName=" + request.getComponentName()
              + ", serviceName=" + serviceName);
        }

        if (serviceName == null
            || serviceName.isEmpty()) {
          throw new AmbariException("Could not find service for component"
              + ", componentName=" + request.getComponentName()
              + ", clusterName=" + cluster.getClusterName()
              + ", stackInfo=" + stackId.getStackId());
        }
        request.setServiceName(serviceName);
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a updateComponent request"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + request.getServiceName()
            + ", componentName=" + request.getComponentName()
            + ", request=" + request);
      }

      clusterNames.add(request.getClusterName());

      if (clusterNames.size() > 1) {
        // FIXME throw correct error
        throw new IllegalArgumentException("Updates to multiple clusters is not"
            + " supported");
      }

      if (!componentNames.containsKey(request.getClusterName())) {
        componentNames.put(request.getClusterName(),
            new HashMap<String, Set<String>>());
      }
      if (!componentNames.get(request.getClusterName())
          .containsKey(request.getServiceName())) {
        componentNames.get(request.getClusterName()).put(
            request.getServiceName(), new HashSet<String>());
      }
      if (componentNames.get(request.getClusterName())
          .get(request.getServiceName()).contains(request.getComponentName())){
        // throw error later for dup
        throw new IllegalArgumentException("Invalid request contains duplicate"
            + " service components");
      }
      componentNames.get(request.getClusterName())
          .get(request.getServiceName()).add(request.getComponentName());

      Service s = cluster.getService(request.getServiceName());
      ServiceComponent sc = s.getServiceComponent(
        request.getComponentName());
      State oldState = sc.getDesiredState();
      State newState = null;
      if (request.getDesiredState() != null) {
        newState = State.valueOf(request.getDesiredState());
        if (!newState.isValidDesiredState()) {
          throw new IllegalArgumentException("Invalid arguments, invalid"
              + " desired state, desiredState=" + newState.toString());
        }
      }

      if (request.getConfigVersions() != null) {
        safeToUpdateConfigsForServiceComponent(sc, oldState, newState);

        for (Entry<String,String> entry :
            request.getConfigVersions().entrySet()) {
          Config config = cluster.getDesiredConfig(
              entry.getKey(), entry.getValue());
          if (null == config) {
            // throw error for invalid config
            throw new AmbariException("Trying to update servicecomponent with"
                + " invalid configs"
                + ", clusterName=" + cluster.getClusterName()
                + ", clusterId=" + cluster.getClusterId()
                + ", serviceName=" + s.getName()
                + ", componentName=" + sc.getName()
                + ", invalidConfigType=" + entry.getKey()
                + ", invalidConfigTag=" + entry.getValue());
          }
        }
      }

      if (newState == null) {
        if (LOG.isDebugEnabled()) {
          LOG.debug("Nothing to do for new updateServiceComponent request"
              + ", clusterName=" + request.getClusterName()
              + ", serviceName=" + request.getServiceName()
              + ", componentName=" + request.getComponentName()
              + ", newDesiredState=null");
        }
        continue;
      }

      if (sc.isClientComponent() &&
          !newState.isValidClientComponentState()) {
        throw new AmbariException("Invalid desired state for a client"
            + " component");
      }

      seenNewStates.add(newState);

      State oldScState = sc.getDesiredState();
      if (newState != oldScState) {
        if (!isValidDesiredStateTransition(oldScState, newState)) {
          // FIXME throw correct error
          throw new AmbariException("Invalid transition for"
              + " servicecomponent"
              + ", clusterName=" + cluster.getClusterName()
              + ", clusterId=" + cluster.getClusterId()
              + ", serviceName=" + sc.getServiceName()
              + ", componentName=" + sc.getName()
              + ", currentDesiredState=" + oldScState
              + ", newDesiredState=" + newState);
        }
        if (!changedComps.containsKey(newState)) {
          changedComps.put(newState, new ArrayList<ServiceComponent>());
        }
        if (LOG.isDebugEnabled()) {
          LOG.debug("Handling update to ServiceComponent"
              + ", clusterName=" + request.getClusterName()
              + ", serviceName=" + s.getName()
              + ", componentName=" + sc.getName()
              + ", currentDesiredState=" + oldScState
              + ", newDesiredState=" + newState);
        }
        changedComps.get(newState).add(sc);
      }

      for (ServiceComponentHost sch : sc.getServiceComponentHosts().values()) {
        State oldSchState = sch.getState();
        if (newState == oldSchState) {
          sch.setDesiredState(newState);
          if (LOG.isDebugEnabled()) {
            LOG.debug("Ignoring ServiceComponentHost"
                + ", clusterName=" + request.getClusterName()
                + ", serviceName=" + s.getName()
                + ", componentName=" + sc.getName()
                + ", hostname=" + sch.getHostName()
                + ", currentState=" + oldSchState
                + ", newDesiredState=" + newState);
          }
          continue;
        }
        if (!isValidStateTransition(oldSchState, newState)) {
          // FIXME throw correct error
          throw new AmbariException("Invalid transition for"
              + " servicecomponenthost"
              + ", clusterName=" + cluster.getClusterName()
              + ", clusterId=" + cluster.getClusterId()
              + ", serviceName=" + sch.getServiceName()
              + ", componentName=" + sch.getServiceComponentName()
              + ", hostname=" + sch.getHostName()
              + ", currentState=" + oldSchState
              + ", newDesiredState=" + newState);
        }
        if (!changedScHosts.containsKey(sc.getName())) {
          changedScHosts.put(sc.getName(),
              new HashMap<State, List<ServiceComponentHost>>());
        }
        if (!changedScHosts.get(sc.getName()).containsKey(newState)) {
          changedScHosts.get(sc.getName()).put(newState,
              new ArrayList<ServiceComponentHost>());
        }
        if (LOG.isDebugEnabled()) {
          LOG.debug("Handling update to ServiceComponentHost"
              + ", clusterName=" + request.getClusterName()
              + ", serviceName=" + s.getName()
              + ", componentName=" + sc.getName()
              + ", hostname=" + sch.getHostName()
              + ", currentState=" + oldSchState
              + ", newDesiredState=" + newState);
        }
        changedScHosts.get(sc.getName()).get(newState).add(sch);
      }
    }

    if (seenNewStates.size() > 1) {
      // FIXME should we handle this scenario
      throw new IllegalArgumentException("Cannot handle different desired"
          + " state changes for a set of service components at the same time");
    }

    // TODO additional validation?

    // TODO if all components reach a common state, should service state be
    // modified?

    for (ServiceComponentRequest request : requests) {
      Cluster cluster = clusters.getCluster(request.getClusterName());
      Service s = cluster.getService(request.getServiceName());
      ServiceComponent sc = s.getServiceComponent(
          request.getComponentName());
      if (request.getConfigVersions() != null) {
        Map<String, Config> updated = new HashMap<String, Config>();

        for (Entry<String,String> entry :
          request.getConfigVersions().entrySet()) {
          Config config = cluster.getDesiredConfig(
              entry.getKey(), entry.getValue());
          updated.put(config.getType(), config);
        }

        if (!updated.isEmpty()) {
          sc.updateDesiredConfigs(updated);
          for (ServiceComponentHost sch :
              sc.getServiceComponentHosts().values()) {
            sch.deleteDesiredConfigs(updated.keySet());
            sch.persist();
          }
          sc.persist();
        }
      }
    }

    Cluster cluster = clusters.getCluster(clusterNames.iterator().next());

    return doStageCreation(cluster, null,
        changedComps, changedScHosts);
  }

  @Override
  public synchronized void updateHosts(Set<HostRequest> requests)
      throws AmbariException {

    if (requests.isEmpty()) {
      LOG.warn("Received an empty requests set");
      return;
    }

    for (HostRequest request : requests) {
      if (request.getHostname() == null
          || request.getHostname().isEmpty()) {
        throw new IllegalArgumentException("Invalid arguments, hostname should"
            + " be provided");
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a updateHost request"
            + ", hostname=" + request.getHostname()
            + ", request=" + request);
      }

      Host h = clusters.getHost(request.getHostname());

      try {
        //todo: the below method throws an exception when trying to create a duplicate mapping.
        //todo: this is done to detect duplicates during host create.  Unless it is allowable to
        //todo: add a host to a cluster by modifying the cluster_name prop, we should not do this mapping here.
        //todo: Determine if it is allowable to associate a host to a cluster via this mechanism.
        clusters.mapHostToCluster(request.getHostname(), request.getClusterName());
      } catch (DuplicateResourceException e) {
        // do nothing
      }

      if (null != request.getHostAttributes())
        h.setHostAttributes(request.getHostAttributes());

      if (null != request.getRackInfo()) {
        h.setRackInfo(request.getRackInfo());
      }
      
      if (null != request.getPublicHostName()) {
        h.setPublicHostName(request.getPublicHostName());
      }

      //todo: if attempt was made to update a property other than those
      //todo: that are allowed above, should throw exception
    }
  }

  @Override
  public synchronized RequestStatusResponse updateHostComponents(
      Set<ServiceComponentHostRequest> requests) throws AmbariException {

    if (requests.isEmpty()) {
      LOG.warn("Received an empty requests set");
      return null;
    }

    Map<String, Map<State, List<ServiceComponentHost>>> changedScHosts =
        new HashMap<String, Map<State, List<ServiceComponentHost>>>();

    Set<String> clusterNames = new HashSet<String>();
    Map<String, Map<String, Map<String, Set<String>>>> hostComponentNames =
        new HashMap<String, Map<String, Map<String, Set<String>>>>();
    Set<State> seenNewStates = new HashSet<State>();

    for (ServiceComponentHostRequest request : requests) {
      if (request.getClusterName() == null
          || request.getClusterName().isEmpty()
          || request.getComponentName() == null
          || request.getComponentName().isEmpty()
          || request.getHostname() == null
          || request.getHostname().isEmpty()) {
        throw new IllegalArgumentException("Invalid arguments"
            + ", cluster name, component name and host name should be"
            + " provided to update host components");
      }

      Cluster cluster = clusters.getCluster(request.getClusterName());

      if (request.getServiceName() == null
          || request.getServiceName().isEmpty()) {
        StackId stackId = cluster.getDesiredStackVersion();
        String serviceName =
            ambariMetaInfo.getComponentToService(stackId.getStackName(),
                stackId.getStackVersion(), request.getComponentName());
        if (LOG.isDebugEnabled()) {
          LOG.debug("Looking up service name for component"
              + ", componentName=" + request.getComponentName()
              + ", serviceName=" + serviceName);
        }

        if (serviceName == null
            || serviceName.isEmpty()) {
          throw new AmbariException("Could not find service for component"
              + ", componentName=" + request.getComponentName()
              + ", clusterName=" + cluster.getClusterName()
              + ", stackInfo=" + stackId.getStackId());
        }
        request.setServiceName(serviceName);
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a createHostComponent request"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + request.getServiceName()
            + ", componentName=" + request.getComponentName()
            + ", hostname=" + request.getHostname()
            + ", request=" + request);
      }

      clusterNames.add(request.getClusterName());

      if (clusterNames.size() > 1) {
        throw new IllegalArgumentException("Updates to multiple clusters is not"
            + " supported");
      }

      if (!hostComponentNames.containsKey(request.getClusterName())) {
        hostComponentNames.put(request.getClusterName(),
            new HashMap<String, Map<String,Set<String>>>());
      }
      if (!hostComponentNames.get(request.getClusterName())
          .containsKey(request.getServiceName())) {
        hostComponentNames.get(request.getClusterName()).put(
            request.getServiceName(), new HashMap<String, Set<String>>());
      }
      if (!hostComponentNames.get(request.getClusterName())
          .get(request.getServiceName())
          .containsKey(request.getComponentName())) {
        hostComponentNames.get(request.getClusterName())
            .get(request.getServiceName()).put(request.getComponentName(),
                new HashSet<String>());
      }
      if (hostComponentNames.get(request.getClusterName())
          .get(request.getServiceName()).get(request.getComponentName())
          .contains(request.getHostname())) {
        throw new IllegalArgumentException("Invalid request contains duplicate"
            + " hostcomponents");
      }
      hostComponentNames.get(request.getClusterName())
          .get(request.getServiceName()).get(request.getComponentName())
          .add(request.getHostname());


      Service s = cluster.getService(request.getServiceName());
      ServiceComponent sc = s.getServiceComponent(
        request.getComponentName());
      ServiceComponentHost sch = sc.getServiceComponentHost(
        request.getHostname());
      State oldState = sch.getState();
      State newState = null;
      if (request.getDesiredState() != null) {
        newState = State.valueOf(request.getDesiredState());
        if (!newState.isValidDesiredState()) {
          throw new IllegalArgumentException("Invalid arguments, invalid"
              + " desired state, desiredState=" + newState.toString());
        }
      }

      if (request.getConfigVersions() != null) {
        safeToUpdateConfigsForServiceComponentHost(sch, oldState, newState);

        for (Entry<String,String> entry :
            request.getConfigVersions().entrySet()) {
          Config config = cluster.getDesiredConfig(
              entry.getKey(), entry.getValue());
          if (null == config) {
            throw new AmbariException("Trying to update servicecomponenthost"
                + " with invalid configs"
                + ", clusterName=" + cluster.getClusterName()
                + ", clusterId=" + cluster.getClusterId()
                + ", serviceName=" + s.getName()
                + ", componentName=" + sc.getName()
                + ", hostname=" + sch.getHostName()
                + ", invalidConfigType=" + entry.getKey()
                + ", invalidConfigTag=" + entry.getValue());
          }
        }
      }

      if (newState == null) {
        if (LOG.isDebugEnabled()) {
          LOG.debug("Nothing to do for new updateServiceComponentHost request"
              + ", clusterName=" + request.getClusterName()
              + ", serviceName=" + request.getServiceName()
              + ", componentName=" + request.getComponentName()
              + ", hostname=" + request.getHostname()
              + ", newDesiredState=null");
        }
        continue;
      }

      if (sc.isClientComponent() &&
          !newState.isValidClientComponentState()) {
        throw new IllegalArgumentException("Invalid desired state for a client"
            + " component");
      }

      seenNewStates.add(newState);

      State oldSchState = sch.getState();
      if (newState == oldSchState) {
        sch.setDesiredState(newState);
        if (LOG.isDebugEnabled()) {
          LOG.debug("Ignoring ServiceComponentHost"
              + ", clusterName=" + request.getClusterName()
              + ", serviceName=" + s.getName()
              + ", componentName=" + sc.getName()
              + ", hostname=" + sch.getHostName()
              + ", currentState=" + oldSchState
              + ", newDesiredState=" + newState);
        }
        continue;
      } 
      
      if (!isValidStateTransition(oldSchState, newState)) {
        throw new AmbariException("Invalid transition for"
            + " servicecomponenthost"
            + ", clusterName=" + cluster.getClusterName()
            + ", clusterId=" + cluster.getClusterId()
            + ", serviceName=" + sch.getServiceName()
            + ", componentName=" + sch.getServiceComponentName()
            + ", hostname=" + sch.getHostName()
            + ", currentState=" + oldSchState
            + ", newDesiredState=" + newState);
      }
      if (!changedScHosts.containsKey(sc.getName())) {
        changedScHosts.put(sc.getName(),
            new HashMap<State, List<ServiceComponentHost>>());
      }
      if (!changedScHosts.get(sc.getName()).containsKey(newState)) {
        changedScHosts.get(sc.getName()).put(newState,
            new ArrayList<ServiceComponentHost>());
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug("Handling update to ServiceComponentHost"
            + ", clusterName=" + request.getClusterName()
            + ", serviceName=" + s.getName()
            + ", componentName=" + sc.getName()
            + ", hostname=" + sch.getHostName()
            + ", currentState=" + oldSchState
            + ", newDesiredState=" + newState);
      }
      changedScHosts.get(sc.getName()).get(newState).add(sch);
    }

    if (seenNewStates.size() > 1) {
      // FIXME should we handle this scenario
      throw new IllegalArgumentException("Cannot handle different desired"
          + " state changes for a set of service components at the same time");
    }


    // TODO additional validation?
    for (ServiceComponentHostRequest request : requests) {
      Cluster cluster = clusters.getCluster(request.getClusterName());
      Service s = cluster.getService(request.getServiceName());
      ServiceComponent sc = s.getServiceComponent(
          request.getComponentName());
      ServiceComponentHost sch = sc.getServiceComponentHost(
          request.getHostname());
      if (request.getConfigVersions() != null) {
        Map<String, Config> updated = new HashMap<String, Config>();

        for (Entry<String,String> entry : request.getConfigVersions().entrySet()) {
          Config config = cluster.getDesiredConfig(
              entry.getKey(), entry.getValue());
          updated.put(config.getType(), config);

          if (!updated.isEmpty()) {
            sch.updateDesiredConfigs(updated);
            sch.persist();
          }
        }
      }
    }

    Cluster cluster = clusters.getCluster(clusterNames.iterator().next());

    return doStageCreation(cluster, null,
        null, changedScHosts);
  }

  @Override
  public synchronized void updateUsers(Set<UserRequest> requests) throws AmbariException {
    for (UserRequest request : requests) {
      User u = users.getAnyUser(request.getUsername());
      if (null == u)
        continue;

      if (null != request.getOldPassword() && null != request.getPassword()) {
        users.modifyPassword(u.getUserName(), request.getOldPassword(),
            request.getPassword());
      }

      if (request.getRoles().size() > 0) {
        for (String role : u.getRoles()) {
          users.removeRoleFromUser(u, role);
        }

        for (String role : request.getRoles()) {
          users.addRoleToUser(u, role);
        }
      }

    }
  }

  @Override
  public synchronized void deleteCluster(ClusterRequest request)
      throws AmbariException {
    throw new AmbariException("Delete cluster not supported");

    /*
    if (request.getClusterName() == null
        || request.getClusterName().isEmpty()) {
      // FIXME throw correct error
      throw new AmbariException("Invalid arguments");
    }
    LOG.info("Received a delete cluster request"
        + ", clusterName=" + request.getClusterName());
    if (request.getHostNames() != null) {
      // FIXME treat this as removing a host from a cluster?
    } else {
      // deleting whole cluster
      clusters.deleteCluster(request.getClusterName());
    }
    */
  }

  @Override
  public RequestStatusResponse deleteServices(Set<ServiceRequest> request)
      throws AmbariException {
    throw new AmbariException("Delete services not supported");
  }

  @Override
  public RequestStatusResponse deleteComponents(
      Set<ServiceComponentRequest> request) throws AmbariException {
    throw new AmbariException("Delete components not supported");
  }

  @Override
  public void deleteHosts(Set<HostRequest> request)
      throws AmbariException {
    throw new AmbariException("Delete hosts not supported");
  }

  @Override
  public RequestStatusResponse deleteHostComponents(
      Set<ServiceComponentHostRequest> request) throws AmbariException {
    throw new AmbariException("Delete host components not supported");
  }

  @Override
  public void deleteUsers(Set<UserRequest> requests)
    throws AmbariException {

    for (UserRequest r : requests) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a delete user request"
            + ", username=" + r.getUsername());
      }
      User u = users.getAnyUser(r.getUsername());
      if (null != u)
        users.removeUser(u);
    }
  }

  @Override
  public Set<ActionResponse> getActions(Set<ActionRequest> request)
      throws AmbariException {
    Set<ActionResponse> responses = new HashSet<ActionResponse>();

    for (ActionRequest actionRequest : request) {
      if (actionRequest.getServiceName() == null) {
        LOG.warn("No service name specified - skipping request");
        //TODO throw error?
        continue;
      }
      ActionResponse actionResponse = new ActionResponse();
      actionResponse.setClusterName(actionRequest.getClusterName());
      actionResponse.setServiceName(actionRequest.getServiceName());
      if (actionMetadata.getActions(actionRequest.getServiceName()) != null
          && !actionMetadata.getActions(actionRequest.getServiceName())
              .isEmpty()) {
        actionResponse.setActionName(actionMetadata.getActions(
            actionRequest.getServiceName()).get(0));
      }
      responses.add(actionResponse);
    }

    return responses;
  }

  public Set<RequestStatusResponse> getRequestsByStatus(RequestsByStatusesRequest request) {

    //TODO implement.  Throw UnsupportedOperationException if it is not supported.
    return Collections.emptySet();
  }

  private RequestStatusResponse getRequestStatusResponse(long requestId) {
    RequestStatusResponse response = new RequestStatusResponse(requestId);
    List<HostRoleCommand> hostRoleCommands =
        actionManager.getRequestTasks(requestId);
    List<ShortTaskStatus> tasks = new ArrayList<ShortTaskStatus>();

    for (HostRoleCommand hostRoleCommand : hostRoleCommands) {
      tasks.add(new ShortTaskStatus(hostRoleCommand));
    }
    response.setTasks(tasks);

    return response;
  }

  @Override
  public Set<RequestStatusResponse> getRequestStatus(
      RequestStatusRequest request) throws AmbariException{
    Set<RequestStatusResponse> response = new HashSet<RequestStatusResponse>();
    if (request.getRequestId() == null) {
      RequestStatus requestStatus = RequestStatus.IN_PROGRESS;
      if (request.getRequestStatus() != null) {
        requestStatus = RequestStatus.valueOf(request.getRequestStatus());
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a Get Request Status request"
            + ", requestId=null"
            + ", requestStatus=" + requestStatus);
      }
      List<Long> requestIds = actionManager.getRequestsByStatus(requestStatus);
      for (Long requestId : requestIds) {
        response.add(getRequestStatusResponse(requestId.longValue()));
      }
    } else {
      RequestStatusResponse requestStatusResponse = getRequestStatusResponse(
          request.getRequestId().longValue());

      //todo: correlate request with cluster
      if (requestStatusResponse.getTasks().size() == 0) {
        //todo: should be thrown lower in stack but we only want to throw if id was specified
        //todo: and we currently iterate over all id's and invoke for each if id is not specified
        throw new ObjectNotFoundException("Request resource doesn't exist.");
      } else {
        response.add(requestStatusResponse);
      }
    }
    return response;
  }

  @Override
  public Set<TaskStatusResponse> getTaskStatus(Set<TaskStatusRequest> requests)
      throws AmbariException {

    Collection<Long> requestIds = new ArrayList<Long>();
    Collection<Long> taskIds = new ArrayList<Long>();

    for (TaskStatusRequest request : requests) {
      if (request.getTaskId() != null) {
        taskIds.add(request.getTaskId());
      } else {
        requestIds.add(request.getRequestId());
      }
    }

    Set<TaskStatusResponse> responses = new HashSet<TaskStatusResponse>();
    for (HostRoleCommand command : actionManager.getTasksByRequestAndTaskIds(requestIds, taskIds)) {
      responses.add(new TaskStatusResponse(command));
    }

    return responses;
  }

  @Override
  public Set<ClusterResponse> getClusters(Set<ClusterRequest> requests) throws AmbariException {
    Set<ClusterResponse> response = new HashSet<ClusterResponse>();
    for (ClusterRequest request : requests) {
      try {
        response.addAll(getClusters(request));
      } catch (ClusterNotFoundException e) {
        if (requests.size() == 1) {
          // only throw exception if 1 request.
          // there will be > 1 request in case of OR predicate
          throw e;
        }
      }
    }
    return response;
  }

  @Override
  public Set<ServiceResponse> getServices(Set<ServiceRequest> requests)
      throws AmbariException {
    Set<ServiceResponse> response = new HashSet<ServiceResponse>();
    for (ServiceRequest request : requests) {
      try {
        response.addAll(getServices(request));
      } catch (ServiceNotFoundException e) {
        if (requests.size() == 1) {
          // only throw exception if 1 request.
          // there will be > 1 request in case of OR predicate
          throw e;
        }
      }
    }
    return response;
  }

  @Override
  public Set<ServiceComponentResponse> getComponents(
      Set<ServiceComponentRequest> requests) throws AmbariException {
    Set<ServiceComponentResponse> response =
        new HashSet<ServiceComponentResponse>();
    for (ServiceComponentRequest request : requests) {
      try {
        response.addAll(getComponents(request));
      } catch (ServiceComponentNotFoundException e) {
        if (requests.size() == 1) {
          // only throw exception if 1 request.
          // there will be > 1 request in case of OR predicate
          throw e;
        }
      }
    }
    return response;
  }

  @Override
  public Set<HostResponse> getHosts(Set<HostRequest> requests)
      throws AmbariException {
    Set<HostResponse> response = new HashSet<HostResponse>();
    for (HostRequest request : requests) {
      try {
        response.addAll(getHosts(request));
      } catch (HostNotFoundException e) {
        if (requests.size() == 1) {
          // only throw exception if 1 request.
          // there will be > 1 request in case of OR predicate
          throw e;
        }
      }
    }
    return response;
  }

  @Override
  public Set<ServiceComponentHostResponse> getHostComponents(
      Set<ServiceComponentHostRequest> requests) throws AmbariException {
    Set<ServiceComponentHostResponse> response =
        new HashSet<ServiceComponentHostResponse>();
    for (ServiceComponentHostRequest request : requests) {
      try {
        response.addAll(getHostComponents(request));
      } catch (ServiceComponentHostNotFoundException e) {
        if (requests.size() == 1) {
          // only throw exception if 1 request.
          // there will be > 1 request in case of OR predicate
          throw e;
        }
      } catch (ServiceNotFoundException e) {
        if (requests.size() == 1) {
          // only throw exception if 1 request.
          // there will be > 1 request in case of OR predicate
          // In 'OR' case, a host_component may be included in predicate
          // that has no corresponding service
          throw e;
        }
      } catch (ServiceComponentNotFoundException e) {
        if (requests.size() == 1) {
          // only throw exception if 1 request.
          // there will be > 1 request in case of OR predicate
          // In 'OR' case, a host_component may be included in predicate
          // that has no corresponding component
          throw e;
        }
      } catch (ParentObjectNotFoundException e) {
        // If there is only one request, always throw exception.
        // There will be > 1 request in case of OR predicate.

        // For HostNotFoundException, only throw exception if host_name is
        // provided in URL.  If host_name is part of query, don't throw exception.
        boolean throwException = true;
        if (requests.size() > 1 && HostNotFoundException.class.isInstance(e.getCause())) {
          for (ServiceComponentHostRequest r : requests) {
            if (r.getHostname() == null) {
              // host_name provided in query since all requests don't have host_name set
              throwException = false;
              break;
            }
          }
        }
        if (throwException) throw e;
      }
    }
    return response;
  }

  @Override
  public Set<ConfigurationResponse> getConfigurations(
      Set<ConfigurationRequest> requests) throws AmbariException {
    Set<ConfigurationResponse> response =
        new HashSet<ConfigurationResponse>();
    for (ConfigurationRequest request : requests) {
      response.addAll(getConfigurations(request));
    }
    return response;
  }

  @Override
  public Set<UserResponse> getUsers(Set<UserRequest> requests)
      throws AmbariException {

    Set<UserResponse> responses = new HashSet<UserResponse>();

    for (UserRequest r : requests) {

      if (LOG.isDebugEnabled()) {
        LOG.debug("Received a getUsers request"
            + ", userRequest=" + r.toString());
      }
      // get them all
      if (null == r.getUsername()) {
        for (User u : users.getAllUsers()) {
          UserResponse resp = new UserResponse(u.getUserName(), u.isLdapUser());
          resp.setRoles(new HashSet<String>(u.getRoles()));
          responses.add(resp);
        }
      } else {

        User u = users.getAnyUser(r.getUsername());
        if (null == u) {
          if (requests.size() == 1) {
            // only throw exceptin if there is a single request
            // if there are multiple requests, this indicates an OR predicate
            throw new ObjectNotFoundException("Cannot find user '"
                + r.getUsername() + "'");
          }
        } else {
          UserResponse resp = new UserResponse(u.getUserName(), u.isLdapUser());
          resp.setRoles(new HashSet<String>(u.getRoles()));
          responses.add(resp);
        }
      }
    }

    return responses;
  }

  @Override
  public Map<String, String> getHostComponentDesiredConfigMapping(ServiceComponentHostRequest request)
    throws AmbariException {

    Map<String, String> map = new HashMap<String, String>();

    for (ServiceComponentHostResponse r : getHostComponents(request)) {
      map.putAll(r.getDesiredConfigs());
    }

    return map;
  }

  private String getClientHostForRunningAction(Cluster cluster,
      Service service) throws AmbariException {
    StackId stackId = service.getDesiredStackVersion();
    ComponentInfo compInfo =
        ambariMetaInfo.getServiceInfo(stackId.getStackName(),
            stackId.getStackVersion(), service.getName()).getClientComponent();
    if (compInfo != null) {
      try {
        ServiceComponent serviceComponent =
            service.getServiceComponent(compInfo.getName());
        if (!serviceComponent.getServiceComponentHosts().isEmpty()) {
          return serviceComponent.getServiceComponentHosts()
              .keySet().iterator().next();
        }
      } catch (ServiceComponentNotFoundException e) {
        LOG.warn("Could not find required component to run action"
            + ", clusterName=" + cluster.getClusterName()
            + ", serviceName=" + service.getName()
            + ", componentName=" + compInfo.getName());


      }
    }

    // any component will do
    Map<String, ServiceComponent> components = service.getServiceComponents();
    if (components.isEmpty()) {
      return null;
    }

    for (ServiceComponent serviceComponent : components.values()) {
      if (serviceComponent.getServiceComponentHosts().isEmpty()) {
        continue;
      }
      return serviceComponent.getServiceComponentHosts()
          .keySet().iterator().next();
    }
    return null;
  }

  private void addServiceCheckAction(ActionRequest actionRequest, Stage stage)
      throws AmbariException {
    String clusterName = actionRequest.getClusterName();
    String componentName = actionMetadata.getClient(actionRequest
        .getServiceName());

    String hostName;
    if (componentName != null) {
      Map<String, ServiceComponentHost> components = clusters
          .getCluster(clusterName).getService(actionRequest.getServiceName())
          .getServiceComponent(componentName).getServiceComponentHosts();

      if (components.isEmpty()) {
        throw new AmbariException("Hosts not found, component="
            + componentName + ", service=" + actionRequest.getServiceName()
            + ", cluster=" + clusterName);
      }

      hostName = components.keySet().iterator().next();
    } else {
      Map<String, ServiceComponent> components = clusters
          .getCluster(clusterName).getService(actionRequest.getServiceName())
          .getServiceComponents();

      if (components.isEmpty()) {
        throw new AmbariException("Components not found, service="
            + actionRequest.getServiceName() + ", cluster=" + clusterName);
      }

      ServiceComponent serviceComponent = components.values().iterator()
          .next();

      if (serviceComponent.getServiceComponentHosts().isEmpty()) {
        throw new AmbariException("Hosts not found, component="
            + serviceComponent.getName() + ", service="
            + actionRequest.getServiceName() + ", cluster=" + clusterName);
      }

      hostName = serviceComponent.getServiceComponentHosts().keySet()
          .iterator().next();
    }

    stage.addHostRoleExecutionCommand(hostName, Role.valueOf(actionRequest
        .getActionName()), RoleCommand.EXECUTE,
        new ServiceComponentHostOpInProgressEvent(componentName, hostName,
            System.currentTimeMillis()), clusterName, actionRequest
            .getServiceName());

    stage.getExecutionCommandWrapper(hostName, actionRequest.getActionName()).getExecutionCommand()
        .setRoleParams(actionRequest.getParameters());

    Map<String, Map<String, String>> configurations = new TreeMap<String, Map<String, String>>();
    Map<String, Config> allConfigs = clusters.getCluster(clusterName)
        .getService(actionRequest.getServiceName()).getDesiredConfigs();
    if (allConfigs != null) {
      for (Map.Entry<String, Config> entry: allConfigs.entrySet()) {
        configurations.put(entry.getValue().getType(), entry.getValue().getProperties());
      }
    }
    
    stage.getExecutionCommandWrapper(hostName,
        actionRequest.getActionName()).getExecutionCommand()
        .setConfigurations(configurations); 
    
    // Generate cluster host info
    stage
        .getExecutionCommandWrapper(hostName, actionRequest.getActionName())
        .getExecutionCommand()
        .setClusterHostInfo(
            StageUtils.getClusterHostInfo(clusters.getCluster(clusterName), hostsMap));
  }

  private void addDecommissionDatanodeAction(
      ActionRequest decommissionRequest, Stage stage)
      throws AmbariException {
    // Find hdfs admin host, just decommission from namenode.
    String clusterName = decommissionRequest.getClusterName();
    String serviceName = decommissionRequest.getServiceName();
    String namenodeHost = clusters.getCluster(clusterName)
        .getService(serviceName).getServiceComponent(Role.NAMENODE.toString())
        .getServiceComponentHosts().keySet().iterator().next();

    String excludeFileTag = null;
    if (decommissionRequest.getParameters() != null
        && (decommissionRequest.getParameters().get("excludeFileTag") != null)) {
      excludeFileTag = decommissionRequest.getParameters()
          .get("excludeFileTag");
    }

    if (excludeFileTag == null) {
      throw new IllegalArgumentException("No exclude file specified"
          + " when decommissioning datanodes");
    }

    Config config = clusters.getCluster(clusterName).getDesiredConfig(
        "hdfs-exclude-file", excludeFileTag);

    Map<String, Map<String, String>> configurations =
        new TreeMap<String, Map<String, String>>();
    configurations.put(config.getType(), config.getProperties());

    Map<String, Config> hdfsSiteConfig = clusters.getCluster(clusterName).getService("HDFS")
        .getDesiredConfigs();
    if (hdfsSiteConfig != null) {
      for (Map.Entry<String, Config> entry: hdfsSiteConfig.entrySet()) {
        configurations
          .put(entry.getValue().getType(), entry.getValue().getProperties());
      }
    }
    
    stage.addHostRoleExecutionCommand(
        namenodeHost,
        Role.DECOMMISSION_DATANODE,
        RoleCommand.EXECUTE,
        new ServiceComponentHostOpInProgressEvent(Role.DECOMMISSION_DATANODE
            .toString(), namenodeHost, System.currentTimeMillis()),
        clusterName, serviceName);
    stage.getExecutionCommandWrapper(namenodeHost,
        Role.DECOMMISSION_DATANODE.toString()).getExecutionCommand()
        .setConfigurations(configurations);
    
  }

  @Override
  public RequestStatusResponse createActions(Set<ActionRequest> request)
      throws AmbariException {
    String clusterName = null;

    String logDir = ""; //TODO empty for now

    for (ActionRequest actionRequest : request) {
      if (actionRequest.getClusterName() == null
          || actionRequest.getClusterName().isEmpty()
          || actionRequest.getServiceName() == null
          || actionRequest.getServiceName().isEmpty()
          || actionRequest.getActionName() == null
          || actionRequest.getActionName().isEmpty()) {
        throw new AmbariException("Invalid action request : " + "cluster="
            + actionRequest.getClusterName() + ", service="
            + actionRequest.getServiceName() + ", action="
            + actionRequest.getActionName());
      } else if (clusterName == null) {
        clusterName = actionRequest.getClusterName();
      } else if (!clusterName.equals(actionRequest.getClusterName())) {
        throw new AmbariException("Requests for different clusters found");
      }
    }

    Stage stage = stageFactory.createNew(actionManager.getNextRequestId(),
        logDir, clusterName);
    stage.setStageId(0);
    for (ActionRequest actionRequest : request) {
      if (actionRequest.getActionName().contains("SERVICE_CHECK")) {
        addServiceCheckAction(actionRequest, stage);
      } else if (actionRequest.getActionName().equals("DECOMMISSION_DATANODE")) {
        addDecommissionDatanodeAction(actionRequest, stage);
      } else {
        throw new AmbariException("Unsupported action");
      }
    }
    RoleGraph rg = new RoleGraph(rco);
    rg.build(stage);
    List<Stage> stages = rg.getStages();
    if (stages != null && !stages.isEmpty()) {
      actionManager.sendActions(stages);
      return getRequestStatusResponse(stage.getRequestId());
    } else {
      throw new AmbariException("Stage was not created");
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/AmbariServer.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;


import java.io.File;
import java.net.BindException;
import java.util.Map;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.actionmanager.ActionManager;
import org.apache.ambari.server.agent.HeartBeatHandler;
import org.apache.ambari.server.agent.rest.AgentResource;
import org.apache.ambari.server.api.rest.BootStrapResource;
import org.apache.ambari.server.api.services.*;
import org.apache.ambari.server.bootstrap.BootStrapImpl;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.ambari.server.orm.GuiceJpaInitializer;
import org.apache.ambari.server.orm.PersistenceType;
import org.apache.ambari.server.resources.ResourceManager;
import org.apache.ambari.server.resources.api.rest.GetResource;
import org.apache.ambari.server.security.CertificateManager;
import org.apache.ambari.server.security.authorization.AmbariLdapAuthenticationProvider;
import org.apache.ambari.server.security.authorization.AmbariLocalUserDetailsService;
import org.apache.ambari.server.security.authorization.Users;
import org.apache.ambari.server.security.unsecured.rest.CertificateDownload;
import org.apache.ambari.server.security.unsecured.rest.CertificateSign;
import org.apache.ambari.server.state.Clusters;
import org.eclipse.jetty.server.Connector;
import org.eclipse.jetty.server.Server;
import org.eclipse.jetty.server.nio.SelectChannelConnector;
import org.eclipse.jetty.server.ssl.SslSelectChannelConnector;
import org.eclipse.jetty.servlet.DefaultServlet;
import org.eclipse.jetty.servlet.FilterHolder;
import org.eclipse.jetty.servlet.ServletContextHandler;
import org.eclipse.jetty.servlet.ServletHolder;
import org.eclipse.jetty.util.ssl.SslContextFactory;
import org.eclipse.jetty.util.thread.QueuedThreadPool;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.config.ConfigurableListableBeanFactory;
import org.springframework.context.support.ClassPathXmlApplicationContext;
import org.springframework.security.crypto.password.PasswordEncoder;
import org.springframework.web.context.WebApplicationContext;
import org.springframework.web.context.support.GenericWebApplicationContext;
import org.springframework.web.filter.DelegatingFilterProxy;

import com.google.inject.Guice;
import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.Singleton;
import com.google.inject.persist.Transactional;
import com.sun.jersey.spi.container.servlet.ServletContainer;

@Singleton
public class AmbariServer {
  private static Logger LOG = LoggerFactory.getLogger(AmbariServer.class);
  public static final int AGENT_ONE_WAY_AUTH = 8440;
  public static final int AGENT_TWO_WAY_AUTH = 8441;
  public static final int CLIENT_SSL_API_PORT = 8443;
  public static final int CLIENT_API_PORT = 8080;

  private Server server = null;
  private Server serverForAgent = null;

  public volatile boolean running = true; // true while controller runs

  final String CONTEXT_PATH = "/";
  final String SPRING_CONTEXT_LOCATION =
      "classpath:/webapp/WEB-INF/spring-security.xml";

  @Inject
  Configuration configs;
  @Inject
  CertificateManager certMan;
  @Inject
  Injector injector;
  @Inject
  AmbariMetaInfo ambariMetaInfo;

  public String getServerOsType() {
    return configs.getServerOsType();
  }

  public static int getResourcesPort() {
    return CLIENT_API_PORT;
  }

  private static AmbariManagementController clusterController = null;

  public static AmbariManagementController getController() {
    return clusterController;
  }

  public void run() throws Exception {
    performStaticInjection();
    addInMemoryUsers();
    server = new Server();
    serverForAgent = new Server();

    try {
      ClassPathXmlApplicationContext parentSpringAppContext =
          new ClassPathXmlApplicationContext();
      parentSpringAppContext.refresh();
      ConfigurableListableBeanFactory factory = parentSpringAppContext.
          getBeanFactory();
      factory.registerSingleton("guiceInjector",
          injector);
      factory.registerSingleton("passwordEncoder",
          injector.getInstance(PasswordEncoder.class));
      factory.registerSingleton("ambariLocalUserService",
          injector.getInstance(AmbariLocalUserDetailsService.class));
      factory.registerSingleton("ambariLdapAuthenticationProvider",
          injector.getInstance(AmbariLdapAuthenticationProvider.class));
      //Spring Security xml config depends on this Bean

      String[] contextLocations = {SPRING_CONTEXT_LOCATION};
      ClassPathXmlApplicationContext springAppContext = new
          ClassPathXmlApplicationContext(contextLocations, parentSpringAppContext);
      //setting ambari web context

      ServletContextHandler root = new ServletContextHandler(server, CONTEXT_PATH,
          ServletContextHandler.SECURITY | ServletContextHandler.SESSIONS);

      //Changing session cookie name to avoid conflicts
      root.getSessionHandler().getSessionManager().setSessionCookie("AMBARISESSIONID");

      GenericWebApplicationContext springWebAppContext = new GenericWebApplicationContext();
      springWebAppContext.setServletContext(root.getServletContext());
      springWebAppContext.setParent(springAppContext);
      /* Configure web app context */
      root.setResourceBase(configs.getWebAppDir());

      root.getServletContext().setAttribute(
          WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE,
          springWebAppContext);

      certMan.initRootCert();

      ServletContextHandler agentroot = new ServletContextHandler(serverForAgent,
          "/", ServletContextHandler.SESSIONS );

      ServletHolder rootServlet = root.addServlet(DefaultServlet.class, "/");
      rootServlet.setInitOrder(1);

      /* Configure default servlet for agent server */
      rootServlet = agentroot.addServlet(DefaultServlet.class, "/");
      rootServlet.setInitOrder(1);

      //Spring Security Filter initialization
      DelegatingFilterProxy springSecurityFilter = new DelegatingFilterProxy();
      springSecurityFilter.setTargetBeanName("springSecurityFilterChain");

      if (configs.getApiAuthentication()) {
        root.addFilter(new FilterHolder(springSecurityFilter), "/api/*", 1);
      }


      //Secured connector for 2-way auth
      SslSelectChannelConnector sslConnectorTwoWay = new  
          SslSelectChannelConnector();
      sslConnectorTwoWay.setPort(AGENT_TWO_WAY_AUTH);

      Map<String, String> configsMap = configs.getConfigsMap();
      String keystore = configsMap.get(Configuration.SRVR_KSTR_DIR_KEY) +
          File.separator + configsMap.get(Configuration.KSTR_NAME_KEY);
      String srvrCrtPass = configsMap.get(Configuration.SRVR_CRT_PASS_KEY);
      sslConnectorTwoWay.setKeystore(keystore);
      sslConnectorTwoWay.setTruststore(keystore);
      sslConnectorTwoWay.setPassword(srvrCrtPass);
      sslConnectorTwoWay.setKeyPassword(srvrCrtPass);
      sslConnectorTwoWay.setTrustPassword(srvrCrtPass);
      sslConnectorTwoWay.setKeystoreType("PKCS12");
      sslConnectorTwoWay.setTruststoreType("PKCS12");
      sslConnectorTwoWay.setNeedClientAuth(true);

      //Secured connector for 1-way auth
      //SslSelectChannelConnector sslConnectorOneWay = new SslSelectChannelConnector();
      SslContextFactory contextFactory = new SslContextFactory(true);
      //sslConnectorOneWay.setPort(AGENT_ONE_WAY_AUTH);
      contextFactory.setKeyStorePath(keystore);
      // sslConnectorOneWay.setKeystore(keystore);
      contextFactory.setTrustStore(keystore);
      // sslConnectorOneWay.setTruststore(keystore);
      contextFactory.setKeyStorePassword(srvrCrtPass);
      // sslConnectorOneWay.setPassword(srvrCrtPass);

      contextFactory.setKeyManagerPassword(srvrCrtPass);

      // sslConnectorOneWay.setKeyPassword(srvrCrtPass);

      contextFactory.setTrustStorePassword(srvrCrtPass);
      //sslConnectorOneWay.setTrustPassword(srvrCrtPass);

      contextFactory.setKeyStoreType("PKCS12");
      //sslConnectorOneWay.setKeystoreType("PKCS12");
      contextFactory.setTrustStoreType("PKCS12");

      //sslConnectorOneWay.setTruststoreType("PKCS12");
      contextFactory.setNeedClientAuth(false);
      // sslConnectorOneWay.setWantClientAuth(false);
      // sslConnectorOneWay.setNeedClientAuth(false);
      SslSelectChannelConnector sslConnectorOneWay = new SslSelectChannelConnector(contextFactory);
      sslConnectorOneWay.setPort(AGENT_ONE_WAY_AUTH);

      serverForAgent.setConnectors(new Connector[]{ sslConnectorOneWay, sslConnectorTwoWay});

      ServletHolder sh = new ServletHolder(ServletContainer.class);
      sh.setInitParameter("com.sun.jersey.config.property.resourceConfigClass",
          "com.sun.jersey.api.core.PackagesResourceConfig");
      sh.setInitParameter("com.sun.jersey.config.property.packages",
          "org.apache.ambari.server.api.rest;" +
              "org.apache.ambari.server.api.services;" +
          "org.apache.ambari.eventdb.webservice");
      root.addServlet(sh, "/api/v1/*");
      sh.setInitOrder(2);

      ServletHolder agent = new ServletHolder(ServletContainer.class);
      agent.setInitParameter("com.sun.jersey.config.property.resourceConfigClass",
          "com.sun.jersey.api.core.PackagesResourceConfig");
      agent.setInitParameter("com.sun.jersey.config.property.packages",
          "org.apache.ambari.server.agent.rest");
      agent.setInitParameter("com.sun.jersey.api.json.POJOMappingFeature",
          "true");
      agentroot.addServlet(agent, "/agent/v1/*");
      agent.setInitOrder(3);

      ServletHolder cert = new ServletHolder(ServletContainer.class);
      cert.setInitParameter("com.sun.jersey.config.property.resourceConfigClass",
          "com.sun.jersey.api.core.PackagesResourceConfig");
      cert.setInitParameter("com.sun.jersey.config.property.packages",
          "org.apache.ambari.server.security.unsecured.rest");
      agentroot.addServlet(cert, "/*");
      cert.setInitOrder(4);

      ServletHolder resources = new ServletHolder(ServletContainer.class);
      resources.setInitParameter("com.sun.jersey.config.property.resourceConfigClass",
          "com.sun.jersey.api.core.PackagesResourceConfig");
      resources.setInitParameter("com.sun.jersey.config.property.packages",
          "org.apache.ambari.server.resources.api.rest");
      root.addServlet(resources, "/resources/*");
      resources.setInitOrder(6);

      //Set jetty thread pool
      serverForAgent.setThreadPool(new QueuedThreadPool(25));
      server.setThreadPool(new QueuedThreadPool(25));

      /* Configure the API server to use the NIO connectors */
      SelectChannelConnector apiConnector;

      if (configs.getApiSSLAuthentication()) {
        SslSelectChannelConnector sapiConnector = new SslSelectChannelConnector();
        sapiConnector.setPort(CLIENT_SSL_API_PORT);
        sapiConnector.setKeystore(keystore);
        sapiConnector.setTruststore(keystore);
        sapiConnector.setPassword(srvrCrtPass);
        sapiConnector.setKeyPassword(srvrCrtPass);
        sapiConnector.setTrustPassword(srvrCrtPass);
        sapiConnector.setKeystoreType("PKCS12");
        sapiConnector.setTruststoreType("PKCS12");
        apiConnector = sapiConnector;
      } 
      else  {
        apiConnector = new SelectChannelConnector();
        apiConnector.setPort(CLIENT_API_PORT);
      }

      server.addConnector(apiConnector);

      server.setStopAtShutdown(true);
      serverForAgent.setStopAtShutdown(true);
      springAppContext.start();

      LOG.info("********* Initializing Meta Info **********");
      ambariMetaInfo.init();

      String osType = getServerOsType();
      if (osType == null || osType.isEmpty()) {
        throw new RuntimeException(Configuration.OS_VERSION_KEY + " is not "
            + " set in the ambari.properties file");
      }

      //Start action scheduler
      LOG.info("********* Initializing Clusters **********");
      Clusters clusters = injector.getInstance(Clusters.class);
      StringBuilder clusterDump = new StringBuilder();
      clusters.debugDump(clusterDump);
      LOG.info("********* Current Clusters State *********");
      LOG.info(clusterDump.toString());

      LOG.info("********* Initializing ActionManager **********");
      ActionManager manager = injector.getInstance(ActionManager.class);
      LOG.info("********* Initializing Controller **********");
      AmbariManagementController controller = injector.getInstance(
          AmbariManagementController.class);

      clusterController = controller;

      // FIXME need to figure out correct order of starting things to
      // handle restart-recovery correctly

      /*
       * Start the server after controller state is recovered.
       */
      server.start();

      serverForAgent.start();
      LOG.info("********* Started Server **********");

      manager.start();
      LOG.info("********* Started ActionManager **********");

      //TODO: Remove this code when APIs are ready for testing.
      //      RequestInjectorForTest testInjector = new RequestInjectorForTest(controller, clusters);
      //      Thread testInjectorThread = new Thread(testInjector);
      //      testInjectorThread.start();

      server.join();
      LOG.info("Joined the Server");
    } catch(BindException bindException) {
      LOG.error("Could not bind to server port - instance may already be running. " +
          "Terminating this instance.", bindException);
      throw bindException;
    }
  }

  /**
   * Creates default users and roles if in-memory database is used
   */
  @Transactional
  protected void addInMemoryUsers() {
    if (configs.getPersistenceType() == PersistenceType.IN_MEMORY) {
      LOG.info("In-memory database is used - creating default users");
      Users users = injector.getInstance(Users.class);

      users.createDefaultRoles();
      users.createUser("admin", "admin");
      users.createUser("user", "user");
      try {
        users.promoteToAdmin(users.getLocalUser("admin"));
      } catch (AmbariException e) {
        throw new RuntimeException(e);
      }
    }
  }

  public void stop() throws Exception {
    try {
      server.stop();
    } catch (Exception e) {
      LOG.error("Error stopping the server", e);
    }
  }

  /**
   * Static injection replacement to wait Persistence Service start
   */
  public void performStaticInjection() {
    AgentResource.init(injector.getInstance(HeartBeatHandler.class));
    CertificateDownload.init(injector.getInstance(CertificateManager.class));
    CertificateSign.init(injector.getInstance(CertificateManager.class));
    GetResource.init(injector.getInstance(ResourceManager.class));
    PersistKeyValueService.init(injector.getInstance(PersistKeyValueImpl.class));
    KeyService.init(injector.getInstance(PersistKeyValueImpl.class));
    AmbariMetaService.init(injector.getInstance(AmbariMetaInfo.class));
    BootStrapResource.init(injector.getInstance(BootStrapImpl.class));
  }

  public static void main(String[] args) throws Exception {

    Injector injector = Guice.createInjector(new ControllerModule());
    AmbariServer server = null;
    try {
      LOG.info("Getting the controller");
      injector.getInstance(GuiceJpaInitializer.class);
      server = injector.getInstance(AmbariServer.class);
      CertificateManager certMan = injector.getInstance(CertificateManager.class);
      certMan.initRootCert();
      if (server != null) {
        server.run();
      }
    } catch (Throwable t) {
      LOG.error("Failed to run the Ambari Server", t);
      if (server != null) {
        server.stop();
      }
      System.exit(-1);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ClusterRequest.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.Set;

/**
 * Used for create Cluster
 */
public class ClusterRequest {

  private Long clusterId; // for GET

  private String clusterName; // for GET/CREATE/UPDATE

  private String stackVersion; // for CREATE/UPDATE

  Set<String> hostNames; // CREATE/UPDATE

  public ClusterRequest(Long clusterId, String clusterName,
      String stackVersion, Set<String> hostNames) {
    super();
    this.clusterId = clusterId;
    this.clusterName = clusterName;
    this.stackVersion = stackVersion;
    this.hostNames = hostNames;
  }

  /**
   * @return the clusterId
   */
  public Long getClusterId() {
    return clusterId;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @return the stackVersion
   */
  public String getStackVersion() {
    return stackVersion;
  }

  /**
   * @param clusterId the clusterId to set
   */
  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  /**
   * @param clusterName the clusterName to set
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  /**
   * @param stackVersion the stackVersion to set
   */
  public void setStackVersion(String stackVersion) {
    this.stackVersion = stackVersion;
  }

  public Set<String> getHostNames() {
    return hostNames;
  }

  public void setHostNames(Set<String> hostNames) {
    this.hostNames = hostNames;
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("{"
        + " clusterName=" + clusterName
        + ", clusterId=" + clusterId
        + ", hosts=[");
    if (hostNames != null) {
      int i = 0;
      for (String hostName : hostNames) {
        if (i != 0) {
          sb.append(",");
        }
        ++i;
        sb.append(hostName);
      }
    }
    sb.append("] }");
    return sb.toString();
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ClusterResponse.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.Set;

public class ClusterResponse {

  private final Long clusterId;

  private final String clusterName;

  private final Set<String> hostNames;

  private final String desiredStackVersion;

  public ClusterResponse(Long clusterId, String clusterName,
      Set<String> hostNames, String desiredStackVersion) {
    super();
    this.clusterId = clusterId;
    this.clusterName = clusterName;
    this.hostNames = hostNames;
    this.desiredStackVersion = desiredStackVersion;
  }

  /**
   * @return the clusterId
   */
  public Long getClusterId() {
    return clusterId;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @return the host names
   */
  public Set<String> getHostNames() {
    return hostNames;
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("{"
        + " clusterName=" + clusterName
        + ", clusterId=" + clusterId
        + ", desiredStackVersion=" + desiredStackVersion
        + ", hosts=[");
    if (hostNames != null) {
      int i = 0;
      for (String hostName : hostNames) {
        if (i != 0) {
          sb.append(",");
        }
        ++i;
        sb.append(hostName);
      }
    }
    sb.append("] }");
    return sb.toString();
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ClusterResponse that = (ClusterResponse) o;

    if (clusterId != null ?
        !clusterId.equals(that.clusterId) : that.clusterId != null) {
      return false;
    }
    if (clusterName != null ?
        !clusterName.equals(that.clusterName) : that.clusterName != null) {
      return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 71 * result + (clusterName != null ? clusterName.hashCode() : 0);
    return result;
  }

  /**
   * @return the desiredStackVersion
   */
  public String getDesiredStackVersion() {
    return desiredStackVersion;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ConfigurationRequest.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller;

import java.util.Map;

/**
 * This class encapsulates a configuration update request.
 * The configuration properties are grouped at service level. It is assumed that
 * different components of a service don't overload same property name.
 */
public class ConfigurationRequest {

  private String clusterName;

  private String type;

  private String tag;

  private Map<String, String> configs;

  public ConfigurationRequest(String clusterName,
                              String type,
                              String tag,
                              Map<String, String> configs) {
    super();
    this.clusterName = clusterName;
    this.configs = configs;
    this.type = type;
    this.tag = tag;
    this.configs = configs;
  }

  /**
   * @return the type
   */
  public String getType() {
    return type;
  }

  /**
   * @param type the type to set
   */
  public void setType(String type) {
    this.type = type;
  }

  /**
   * @return the versionTag
   */
  public String getVersionTag() {
    return tag;
  }

  /**
   * @param versionTag the versionTag to set
   */
  public void setVersionTag(String versionTag) {
    this.tag = versionTag;
  }

  /**
   * @return the configs
   */
  public Map<String, String> getConfigs() {
    return configs;
  }

  /**
   * @param configs the configs to set
   */
  public void setConfigs(Map<String, String> configs) {
    this.configs = configs;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }


  /**
   * @param clusterName the clusterName to set
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ConfigurationResponse.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller;

import java.util.Map;

/**
 * This class encapsulates a configuration update request.
 * The configuration properties are grouped at service level. It is assumed that
 * different components of a service don't overload same property name.
 */
public class ConfigurationResponse {

  private final String clusterName;

  private final String type;

  private String versionTag;

  private Map<String, String> configs;


  public ConfigurationResponse(String clusterName,
                               String type, String versionTag,
                               Map<String, String> configs) {
    super();
    this.clusterName = clusterName;
    this.configs = configs;
    this.type = type;
    this.versionTag = versionTag;
    this.configs = configs;
  }


  /**
   * @return the versionTag
   */
  public String getVersionTag() {
    return versionTag;
  }

  /**
   * @param versionTag the versionTag to set
   */
  public void setVersionTag(String versionTag) {
    this.versionTag = versionTag;
  }

  /**
   * @return the configs
   */
  public Map<String, String> getConfigs() {
    return configs;
  }

  /**
   * @param configs the configs to set
   */
  public void setConfigs(Map<String, String> configs) {
    this.configs = configs;
  }

  /**
   * @return the type
   */
  public String getType() {
    return type;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ConfigurationResponse that =
        (ConfigurationResponse) o;

    if (clusterName != null ?
        !clusterName.equals(that.clusterName) : that.clusterName != null) {
      return false;
    }
    if (type != null ?
        !type.equals(that.type) : that.type != null) {
      return false;
    }
    if (versionTag != null ?
        !versionTag.equals(that.versionTag) : that.versionTag != null){
      return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterName != null ? clusterName.hashCode() : 0;
    result = 71 * result + (type != null ? type.hashCode() : 0);
    result = 71 * result + (versionTag != null ? versionTag.hashCode():0);
    return result;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ControllerModule.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;
import com.google.gson.Gson;
import com.google.inject.Scopes;
import com.google.inject.assistedinject.FactoryModuleBuilder;
import com.google.inject.matcher.Matchers;
import com.google.inject.persist.Transactional;
import com.google.inject.persist.jpa.JpaPersistModule;
import org.apache.ambari.server.actionmanager.*;
import org.apache.ambari.server.api.services.AmbariMetaInfo;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.ambari.server.orm.PersistenceType;
import org.apache.ambari.server.orm.dao.ClearEntityManagerInterceptor;
import org.apache.ambari.server.state.*;
import org.apache.ambari.server.state.cluster.ClusterFactory;
import org.apache.ambari.server.state.cluster.ClusterImpl;
import org.apache.ambari.server.state.cluster.ClustersImpl;
import org.apache.ambari.server.state.host.HostFactory;
import org.apache.ambari.server.state.host.HostImpl;

import com.google.inject.AbstractModule;
import com.google.inject.name.Names;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostImpl;
import org.springframework.security.crypto.password.PasswordEncoder;
import org.springframework.security.crypto.password.StandardPasswordEncoder;

import java.util.Properties;

/**
 * Used for injection purposes.
 *
 */
public class ControllerModule extends AbstractModule {

  private final Configuration configuration;
  private final AmbariMetaInfo ambariMetaInfo;
  private final HostsMap hostsMap;
  
  public ControllerModule() throws Exception {
    configuration = new Configuration();
    ambariMetaInfo = new AmbariMetaInfo(configuration);
    hostsMap = new HostsMap(configuration);
  }

  public ControllerModule(Properties properties) throws Exception {
    configuration = new Configuration(properties);
    ambariMetaInfo = new AmbariMetaInfo(configuration);
    hostsMap = new HostsMap(configuration);
  }

  @Override
  protected void configure() {
    bindInterceptors();
    installFactories();

    bind(Configuration.class).toInstance(configuration);
    bind(AmbariMetaInfo.class).toInstance(ambariMetaInfo);
    bind(HostsMap.class).toInstance(hostsMap);
    
    bind(PasswordEncoder.class).toInstance(new StandardPasswordEncoder());

    JpaPersistModule jpaPersistModule = new JpaPersistModule(configuration.getPersistenceType().getUnitName());
    if (configuration.getPersistenceType() == PersistenceType.POSTGRES) {
      Properties properties = new Properties();
      properties.setProperty("javax.persistence.jdbc.user", configuration.getDatabaseUser());
      properties.setProperty("javax.persistence.jdbc.password", configuration.getDatabasePassword());
      jpaPersistModule.properties(properties);
    }

    install(jpaPersistModule);


    bind(Gson.class).in(Scopes.SINGLETON);
    bind(Clusters.class).to(ClustersImpl.class);
    bind(ActionDBAccessor.class).to(ActionDBAccessorImpl.class);
    bindConstant().annotatedWith(Names.named("schedulerSleeptime")).to(10000L);
    bindConstant().annotatedWith(Names.named("actionTimeout")).to(300000L);
    bind(AmbariManagementController.class)
        .to(AmbariManagementControllerImpl.class);
  }

  private void installFactories() {
    install(new FactoryModuleBuilder().implement(
        Cluster.class, ClusterImpl.class).build(ClusterFactory.class));
    install(new FactoryModuleBuilder().implement(
        Host.class, HostImpl.class).build(HostFactory.class));
    install(new FactoryModuleBuilder().implement(
        Service.class, ServiceImpl.class).build(ServiceFactory.class));
    install(new FactoryModuleBuilder().implement(
        ServiceComponent.class, ServiceComponentImpl.class).build(
        ServiceComponentFactory.class));
    install(new FactoryModuleBuilder().implement(
        ServiceComponentHost.class, ServiceComponentHostImpl.class).build(
        ServiceComponentHostFactory.class));
    install(new FactoryModuleBuilder().implement(
        Config.class, ConfigImpl.class).build(ConfigFactory.class));
    install(new FactoryModuleBuilder().build(StageFactory.class));
    install(new FactoryModuleBuilder().build(HostRoleCommandFactory.class));
  }

  private void bindInterceptors() {
    ClearEntityManagerInterceptor clearEntityManagerInterceptor = new ClearEntityManagerInterceptor();
    requestInjection(clearEntityManagerInterceptor);
    bindInterceptor(Matchers.any(), Matchers.annotatedWith(Transactional.class), clearEntityManagerInterceptor);

  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/HostRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

public class HostRequest {

  private String hostname;
  private String publicHostname;
  private String clusterName; // CREATE/UPDATE
  private Map<String, String> hostAttributes; // CREATE/UPDATE
  private String rackInfo;

  public HostRequest(String hostname, String clusterName, Map<String, String> hostAttributes) {
    this.hostname = hostname;
    this.clusterName = clusterName;
    this.hostAttributes = hostAttributes;
  }

  public String getHostname() {
    return hostname;
  }

  public void setHostname(String hostname) {
    this.hostname = hostname;
  }

  public String getClusterName() {
    return clusterName;
  }

  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  public Map<String, String> getHostAttributes() {
    return hostAttributes;
  }

  public void setHostAttributes(Map<String, String> hostAttributes) {
    this.hostAttributes = hostAttributes;
  }
  
  public String getRackInfo() {
    return rackInfo;
  }
  
  public void setRackInfo(String info) {
    rackInfo = info;
  }
  
  public String getPublicHostName() {
    return publicHostname;
  }
  
  public void setPublicHostName(String name) {
    publicHostname = name;
  }

  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("{ hostname=").append(hostname).append(", clusterName=").append(clusterName);
    if (hostAttributes != null) {
      sb.append(", hostAttributes=[");
      int i = 0;
      for (Entry<String, String> attr : hostAttributes.entrySet()) {
        if (i != 0) {
          sb.append(",");
        }
        ++i;
        sb.append(attr.getKey() + "=" + attr.getValue());
      }
      sb.append(']');
    }
    sb.append(" }");
    return sb.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/HostResponse.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import org.apache.ambari.server.agent.DiskInfo;
import org.apache.ambari.server.state.AgentVersion;
import org.apache.ambari.server.state.HostHealthStatus;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

public class HostResponse {

  private String hostname;

  private String clusterName;

  /**
   * Host IP if ipv4 interface available
   */
  private String ipv4;

  /**
   * Host IP if ipv6 interface available
   */
  private String ipv6;

  /**
   * Count of cores on Host
   */
  private int cpuCount;

  /**
   * Os Architecture
   */
  private String osArch;

  /**
   * OS Type
   */
  private String osType;

  /**
   * OS Information
   */
  private String osInfo;

  /**
   * Amount of available memory for the Host
   */
  private long availableMemBytes;

  /**
   * Amount of physical memory for the Host
   */
  private long totalMemBytes;

  /**
   * Disks mounted on the Host
   */
  private List<DiskInfo> disksInfo;

  /**
   * Last heartbeat timestamp from the Host
   */
  private long lastHeartbeatTime;

  /**
   * Last registration timestamp for the Host
   */
  private long lastRegistrationTime;

  /**
   * Rack to which the Host belongs to
   */
  private String rackInfo;

  /**
   * Additional Host attributes
   */
  private Map<String, String> hostAttributes;

  /**
   * Version of agent running on the Host
   */
  private AgentVersion agentVersion;

  /**
   * Host Health Status
   */
  private HostHealthStatus healthStatus;
  
  /**
   * Public name.
   */
  private String publicHostname = null;

  /**
   * Host State
   */
  private String hostState;

  public HostResponse(String hostname, String clusterName,
                      String ipv4, String ipv6, int cpuCount, String osArch, String osType,
                      String osInfo, long availableMemBytes, long totalMemBytes,
                      List<DiskInfo> disksInfo, long lastHeartbeatTime,
                      long lastRegistrationTime, String rackInfo,
                      Map<String, String> hostAttributes, AgentVersion agentVersion,
                      HostHealthStatus healthStatus, String hostState) {
    super();
    this.hostname = hostname;
    this.clusterName = clusterName;
    this.ipv4 = ipv4;
    this.ipv6 = ipv6;
    this.cpuCount = cpuCount;
    this.osArch = osArch;
    this.osType = osType;
    this.osInfo = osInfo;
    this.availableMemBytes = availableMemBytes;
    this.totalMemBytes = totalMemBytes;
    this.disksInfo = disksInfo;
    this.lastHeartbeatTime = lastHeartbeatTime;
    this.lastRegistrationTime = lastRegistrationTime;
    this.rackInfo = rackInfo;
    this.hostAttributes = hostAttributes;
    this.agentVersion = agentVersion;
    this.healthStatus = healthStatus;
    this.setHostState(hostState);
  }

  //todo: why are we passing in empty strings for host/cluster name instead of null?
  public HostResponse(String hostname) {
    this(hostname, "", "", "",
        0, "", "",
        "", 0, 0, new ArrayList<DiskInfo>(),
        0, 0, "",
        new HashMap<String, String>(),
        null, null, null);
  }

  /**
   * @return the hostname
   */
  public String getHostname() {
    return hostname;
  }

  /**
   * @param hostname the hostname to set
   */
  public void setHostname(String hostname) {
    this.hostname = hostname;
  }

  /**
   * @return the clusterNames
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @param clusterName the name of the associated cluster
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  /**
   * @return the ipv4
   */
  public String getIpv4() {
    return ipv4;
  }

  /**
   * @param ipv4 the ipv4 to set
   */
  public void setIpv4(String ipv4) {
    this.ipv4 = ipv4;
  }

  /**
   * @return the ipv6
   */
  public String getIpv6() {
    return ipv6;
  }

  /**
   * @param ipv6 the ipv6 to set
   */
  public void setIpv6(String ipv6) {
    this.ipv6 = ipv6;
  }

  /**
   * @return the cpuCount
   */
  public int getCpuCount() {
    return cpuCount;
  }

  /**
   * @param cpuCount the cpuCount to set
   */
  public void setCpuCount(int cpuCount) {
    this.cpuCount = cpuCount;
  }

  /**
   * @return the osArch
   */
  public String getOsArch() {
    return osArch;
  }

  /**
   * @param osArch the osArch to set
   */
  public void setOsArch(String osArch) {
    this.osArch = osArch;
  }

  /**
   * @return the osType
   */
  public String getOsType() {
    return osType;
  }

  /**
   * @param osType the osType to set
   */
  public void setOsType(String osType) {
    this.osType = osType;
  }

  /**
   * @return the osInfo
   */
  public String getOsInfo() {
    return osInfo;
  }

  /**
   * @param osInfo the osInfo to set
   */
  public void setOsInfo(String osInfo) {
    this.osInfo = osInfo;
  }

  /**
   * @return the availableMemBytes
   */
  public long getAvailableMemBytes() {
    return availableMemBytes;
  }

  /**
   * @param availableMemBytes the availableMemBytes to set
   */
  public void setAvailableMemBytes(long availableMemBytes) {
    this.availableMemBytes = availableMemBytes;
  }

  /**
   * @return the totalMemBytes
   */
  public long getTotalMemBytes() {
    return totalMemBytes;
  }

  /**
   * @param totalMemBytes the totalMemBytes to set
   */
  public void setTotalMemBytes(long totalMemBytes) {
    this.totalMemBytes = totalMemBytes;
  }

  /**
   * @return the disksInfo
   */
  public List<DiskInfo> getDisksInfo() {
    return disksInfo;
  }

  /**
   * @param disksInfo the disksInfo to set
   */
  public void setDisksInfo(List<DiskInfo> disksInfo) {
    this.disksInfo = disksInfo;
  }

  /**
   * @return the lastHeartbeatTime
   */
  public long getLastHeartbeatTime() {
    return lastHeartbeatTime;
  }

  /**
   * @param lastHeartbeatTime the lastHeartbeatTime to set
   */
  public void setLastHeartbeatTime(long lastHeartbeatTime) {
    this.lastHeartbeatTime = lastHeartbeatTime;
  }

  /**
   * @return the lastRegistrationTime
   */
  public long getLastRegistrationTime() {
    return lastRegistrationTime;
  }

  /**
   * @param lastRegistrationTime the lastRegistrationTime to set
   */
  public void setLastRegistrationTime(long lastRegistrationTime) {
    this.lastRegistrationTime = lastRegistrationTime;
  }

  /**
   * @return the rackInfo
   */
  public String getRackInfo() {
    return rackInfo;
  }

  /**
   * @param rackInfo the rackInfo to set
   */
  public void setRackInfo(String rackInfo) {
    this.rackInfo = rackInfo;
  }

  /**
   * @return the hostAttributes
   */
  public Map<String, String> getHostAttributes() {
    return hostAttributes;
  }

  /**
   * @param hostAttributes the hostAttributes to set
   */
  public void setHostAttributes(Map<String, String> hostAttributes) {
    this.hostAttributes = hostAttributes;
  }

  /**
   * @return the agentVersion
   */
  public AgentVersion getAgentVersion() {
    return agentVersion;
  }

  /**
   * @param agentVersion the agentVersion to set
   */
  public void setAgentVersion(AgentVersion agentVersion) {
    this.agentVersion = agentVersion;
  }

  /**
   * @return the healthStatus
   */
  public HostHealthStatus getHealthStatus() {
    return healthStatus;
  }

  /**
   * @param healthStatus the healthStatus to set
   */
  public void setHealthStatus(HostHealthStatus healthStatus) {
    this.healthStatus = healthStatus;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostResponse that = (HostResponse) o;

    if (hostname != null ?
        !hostname.equals(that.hostname) : that.hostname != null) {
      return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    int result = hostname != null ? hostname.hashCode() : 0;
    return result;
  }

  public String getPublicHostName() {
    return publicHostname;
  }
  
  public void setPublicHostName(String name) {
    publicHostname = name;
  }

  /**
   * @return the hostState
   */
  public String getHostState() {
    return hostState;
  }

  /**
   * @param hostState the hostState to set
   */
  public void setHostState(String hostState) {
    this.hostState = hostState;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/HostsMap.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStream;
import java.util.Properties;

import org.apache.ambari.server.configuration.Configuration;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Inject;
import com.google.inject.Singleton;

/**
 * Stores the mapping of hostnames to be used in any configuration on 
 * the server.
 *  
 */
@Singleton
public class HostsMap {
  private final static Logger LOG = LoggerFactory
      .getLogger(HostsMap.class);

  private String hostsMapFile;
  private Properties hostsMap;

  @Inject
  public HostsMap(Configuration conf) {
    hostsMapFile = conf.getHostsMapFile();
    setupMap();
  }
  
  public HostsMap(String file) {
    hostsMapFile = file;
  }

  public void setupMap() {
    InputStream inputStream = null;
    LOG.info("Using hostsmap file " + this.hostsMapFile);
    try {
      if (hostsMapFile != null) {
        hostsMap = new Properties();
        inputStream = new FileInputStream(new File(hostsMapFile));
        // load the properties
        hostsMap.load(inputStream);
      }
    } catch (FileNotFoundException fnf) {
      LOG.info("No configuration file " + hostsMapFile + " found in classpath.", fnf);
    } catch (IOException ie) {
      throw new IllegalArgumentException("Can't read configuration file " +
          hostsMapFile, ie);
    } finally {
      if (inputStream != null) {
        try {
          inputStream.close();
        } catch(IOException io) {
          //ignore 
        }
      }
    }
  }

/**
 * Return map of the hostname if available
 * @param hostName hostname map
 * @return 
 */
public String getHostMap(String hostName) {
  if (hostsMapFile == null) 
    return hostName;
  return hostsMap.getProperty(hostName, hostName);
}

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/RequestsByStatusesRequest.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.HashSet;
import java.util.Set;

import org.apache.ambari.server.actionmanager.HostRoleStatus;

public class RequestsByStatusesRequest {
  Set<String> statuses;

  public RequestsByStatusesRequest() {
    statuses = new HashSet<String>();
    statuses.add(HostRoleStatus.PENDING.toString());
    statuses.add(HostRoleStatus.QUEUED.toString());
    statuses.add(HostRoleStatus.IN_PROGRESS.toString());
  }

  public RequestsByStatusesRequest(Set<String> statuses) {
    this.statuses = statuses;
  }

  public Set<String> getStatuses() {
    return statuses;
  }

  public void setStatuses(Set<String> statuses) {
    this.statuses = statuses;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/RequestStatusRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

public class RequestStatusRequest {

  private final Long requestId;
  private final String requestStatus;

  public RequestStatusRequest(Long requestId, String requestStatus) {
    super();
    this.requestId = requestId;
    this.requestStatus = requestStatus;
  }

  /**
   * @return the requestId
   */
  public Long getRequestId() {
    return requestId;
  }

  /**
   * @return the requestStatus
   */
  public String getRequestStatus() {
    return requestStatus;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/RequestStatusResponse.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.List;

public class RequestStatusResponse {

  // Request ID for tracking async operations
  private final Long requestId;

  List<ShortTaskStatus> tasks;

  // TODO how are logs to be sent back?
  private String logs;

  // TODO stage specific information

  public RequestStatusResponse(Long requestId) {
    super();
    this.requestId = requestId;
  }

  /**
   * @return the logs
   */
  public String getLogs() {
    return logs;
  }

  /**
   * @param logs the logs to set
   */
  public void setLogs(String logs) {
    this.logs = logs;
  }

  /**
   * @return the requestId
   */
  public long getRequestId() {
    return requestId;
  }

  public List<ShortTaskStatus> getTasks() {
    return tasks;
  }

  public void setTasks(List<ShortTaskStatus> tasks) {
    this.tasks = tasks;
  }



}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ServiceComponentHostRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.Map;

public class ServiceComponentHostRequest {

  private String clusterName; // REF

  private String serviceName;

  private String componentName;

  private String hostname;

  // Config type -> version mapping
  private Map<String, String> configVersions; // CREATE/UPDATE

  private String desiredState; // CREATE/UPDATE

  public ServiceComponentHostRequest(String clusterName,
                                     String serviceName,
                                     String componentName, String hostname,
                                     Map<String, String> configVersions, String desiredState) {
    super();
    this.clusterName = clusterName;
    this.serviceName = serviceName;
    this.componentName = componentName;
    this.hostname = hostname;
    this.configVersions = configVersions;
    this.desiredState = desiredState;
  }

  /**
   * @return the serviceName
   */
  public String getServiceName() {
    return serviceName;
  }

  /**
   * @param serviceName the serviceName to set
   */
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  /**
   * @return the componentName
   */
  public String getComponentName() {
    return componentName;
  }

  /**
   * @param componentName the componentName to set
   */
  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  /**
   * @return the hostname
   */
  public String getHostname() {
    return hostname;
  }

  /**
   * @param hostname the hostname to set
   */
  public void setHostname(String hostname) {
    this.hostname = hostname;
  }

  /**
   * @return the configVersions
   */
  public Map<String, String> getConfigVersions() {
    return configVersions;
  }

  /**
   * @param configVersions the configVersions to set
   */
  public void setConfigVersions(Map<String, String> configVersions) {
    this.configVersions = configVersions;
  }

  /**
   * @return the desiredState
   */
  public String getDesiredState() {
    return desiredState;
  }

  /**
   * @param desiredState the desiredState to set
   */
  public void setDesiredState(String desiredState) {
    this.desiredState = desiredState;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @param clusterName the clusterName to set
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }


  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("{"
        + " clusterName=" + clusterName
        + ", serviceName=" + serviceName
        + ", componentName=" + componentName
        + ", hostname=" + hostname
        + ", desiredState=" + desiredState
        + "}");
    return sb.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ServiceComponentHostResponse.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.Map;

public class ServiceComponentHostResponse {

  private String clusterName; // REF

  private String serviceName;

  private String componentName;

  private String hostname;

  // Config type -> version mapping
  private Map<String, String> configs;

  private Map<String, String> desiredConfigs;

  private String liveState;

  private String stackVersion;

  private String desiredState;

  public ServiceComponentHostResponse(String clusterName, String serviceName,
                                      String componentName, String hostname,
                                      Map<String, String> configVersions,
                                      Map<String, String> desiredConfigs,
                                      String liveState,
                                      String stackVersion, String desiredState) {
    super();
    this.clusterName = clusterName;
    this.serviceName = serviceName;
    this.componentName = componentName;
    this.hostname = hostname;
    this.configs = configVersions;
    this.desiredConfigs = desiredConfigs;
    this.liveState = liveState;
    this.stackVersion = stackVersion;
    this.desiredState = desiredState;
  }

  /**
   * @return the serviceName
   */
  public String getServiceName() {
    return serviceName;
  }

  /**
   * @param serviceName the serviceName to set
   */
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  /**
   * @return the componentName
   */
  public String getComponentName() {
    return componentName;
  }

  /**
   * @param componentName the componentName to set
   */
  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  /**
   * @return the hostname
   */
  public String getHostname() {
    return hostname;
  }

  /**
   * @param hostname the hostname to set
   */
  public void setHostname(String hostname) {
    this.hostname = hostname;
  }

  /**
   * @return the configVersions
   */
  public Map<String, String> getConfigs() {
    return configs;
  }

  /**
   * @param configVersions the configVersions to set
   */
  public void setConfigs(Map<String, String> configVersions) {
    this.configs = configVersions;
  }

  /**
   * @return the liveState
   */
  public String getLiveState() {
    return liveState;
  }

  /**
   * @param liveState the liveState to set
   */
  public void setLiveState(String liveState) {
    this.liveState = liveState;
  }

  /**
   * @return the stackVersion
   */
  public String getStackVersion() {
    return stackVersion;
  }

  /**
   * @param stackVersion the stackVersion to set
   */
  public void setStackVersion(String stackVersion) {
    this.stackVersion = stackVersion;
  }

  /**
   * @return the desiredState
   */
  public String getDesiredState() {
    return desiredState;
  }

  /**
   * @param desiredState the desiredState to set
   */
  public void setDesiredState(String desiredState) {
    this.desiredState = desiredState;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @param clusterName the clusterName to set
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceComponentHostResponse that =
        (ServiceComponentHostResponse) o;

    if (clusterName != null ?
        !clusterName.equals(that.clusterName) : that.clusterName != null) {
      return false;
    }
    if (serviceName != null ?
        !serviceName.equals(that.serviceName) : that.serviceName != null) {
      return false;
    }
    if (componentName != null ?
        !componentName.equals(that.componentName) : that.componentName != null){
      return false;
    }
    if (hostname != null ?
        !hostname.equals(that.hostname) : that.hostname != null) {
      return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterName != null ? clusterName.hashCode() : 0;
    result = 71 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 71 * result + (componentName != null ? componentName.hashCode():0);
    result = 71 * result + (hostname != null ? hostname.hashCode() : 0);
    return result;
  }

  public Map<String, String> getDesiredConfigs() {
    return desiredConfigs;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ServiceComponentRequest.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.Map;

public class ServiceComponentRequest {

  private String clusterName; // REF

  private String serviceName; // GET/CREATE/UPDATE/DELETE

  private String componentName; // GET/CREATE/UPDATE/DELETE

  // Config type -> version mapping
  private Map<String, String> configVersions; // CREATE/UPDATE

  private String desiredState; // CREATE/UPDATE

  public ServiceComponentRequest(String clusterName,
                                 String serviceName, String componentName,
                                 Map<String, String> configVersions, String desiredState) {
    super();
    this.clusterName = clusterName;
    this.serviceName = serviceName;
    this.componentName = componentName;
    this.configVersions = configVersions;
    this.desiredState = desiredState;
  }

  /**
   * @return the serviceName
   */
  public String getServiceName() {
    return serviceName;
  }

  /**
   * @param serviceName the serviceName to set
   */
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  /**
   * @return the componentName
   */
  public String getComponentName() {
    return componentName;
  }

  /**
   * @param componentName the componentName to set
   */
  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  /**
   * @return the configVersions
   */
  public Map<String, String> getConfigVersions() {
    return configVersions;
  }

  /**
   * @param configVersions the configVersions to set
   */
  public void setConfigVersions(Map<String, String> configVersions) {
    this.configVersions = configVersions;
  }

  /**
   * @return the desiredState
   */
  public String getDesiredState() {
    return desiredState;
  }

  /**
   * @param desiredState the desiredState to set
   */
  public void setDesiredState(String desiredState) {
    this.desiredState = desiredState;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @param clusterName the clusterName to set
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ServiceComponentResponse.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.Map;

public class ServiceComponentResponse {

  private Long clusterId; // REF

  private String clusterName; // REF

  private String serviceName;

  private String componentName;

  // Config type -> version mapping
  private Map<String, String> configVersions;

  private String desiredStackVersion;

  private String desiredState;

  public ServiceComponentResponse(Long clusterId, String clusterName,
                                  String serviceName,
                                  String componentName,
                                  Map<String, String> configVersions,
                                  String desiredStackVersion,
                                  String desiredState) {
    super();
    this.clusterId = clusterId;
    this.clusterName = clusterName;
    this.serviceName = serviceName;
    this.componentName = componentName;
    this.configVersions = configVersions;
    this.desiredStackVersion = desiredStackVersion;
    this.desiredState = desiredState;
  }

  /**
   * @return the serviceName
   */
  public String getServiceName() {
    return serviceName;
  }

  /**
   * @param serviceName the serviceName to set
   */
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  /**
   * @return the componentName
   */
  public String getComponentName() {
    return componentName;
  }

  /**
   * @param componentName the componentName to set
   */
  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  /**
   * @return the configVersions
   */
  public Map<String, String> getConfigVersions() {
    return configVersions;
  }

  /**
   * @param configVersions the configVersions to set
   */
  public void setConfigVersions(Map<String, String> configVersions) {
    this.configVersions = configVersions;
  }

  /**
   * @return the clusterId
   */
  public Long getClusterId() {
    return clusterId;
  }

  /**
   * @param clusterId the clusterId to set
   */
  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @param clusterName the clusterName to set
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  /**
   * @return the desiredState
   */
  public String getDesiredState() {
    return desiredState;
  }

  /**
   * @param desiredState the desiredState to set
   */
  public void setDesiredState(String desiredState) {
    this.desiredState = desiredState;
  }

  /**
   * @return the desiredStackVersion
   */
  public String getDesiredStackVersion() {
    return desiredStackVersion;
  }

  /**
   * @param desiredStackVersion the desiredStackVersion to set
   */
  public void setDesiredStackVersion(String desiredStackVersion) {
    this.desiredStackVersion = desiredStackVersion;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceComponentResponse that =
        (ServiceComponentResponse) o;

    if (clusterName != null ?
        !clusterName.equals(that.clusterName) : that.clusterName != null) {
      return false;
    }
    if (serviceName != null ?
        !serviceName.equals(that.serviceName) : that.serviceName != null) {
      return false;
    }
    if (componentName != null ?
        !componentName.equals(that.componentName) : that.componentName != null){
      return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null? clusterId.intValue() : 0;
    result = 71 * result + (clusterName != null ? clusterName.hashCode() : 0);
    result = 71 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 71 * result + (componentName != null ? componentName.hashCode():0);
    return result;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ServiceRequest.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller;

import java.util.Map;
import java.util.Map.Entry;

public class ServiceRequest {

  private String clusterName; // REF

  private String serviceName; // GET/CREATE/UPDATE/DELETE

  // Config type -> version mapping
  private Map<String, String> configVersions; // CREATE/UPDATE

  private String desiredState; // CREATE/UPDATE

  public ServiceRequest(String clusterName, String serviceName,
                        Map<String, String> configVersions, String desiredState) {
    super();
    this.clusterName = clusterName;
    this.serviceName = serviceName;
    this.configVersions = configVersions;
    this.desiredState = desiredState;
  }

  /**
   * @return the serviceName
   */
  public String getServiceName() {
    return serviceName;
  }

  /**
   * @param serviceName the serviceName to set
   */
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  /**
   * @return the configVersions
   */
  public Map<String, String> getConfigVersions() {
    return configVersions;
  }

  /**
   * @param configVersions the configVersions to set
   */
  public void setConfigVersions(Map<String, String> configVersions) {
    this.configVersions = configVersions;
  }

  /**
   * @return the desiredState
   */
  public String getDesiredState() {
    return desiredState;
  }

  /**
   * @param desiredState the desiredState to set
   */
  public void setDesiredState(String desiredState) {
    this.desiredState = desiredState;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @param clusterName the clusterName to set
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("clusterName=" + clusterName
        + ", serviceName=" + serviceName
        + ", desiredState=" + desiredState
        + ", configs=[ ");
    if (configVersions != null) {
      for (Entry<String, String> entry : configVersions.entrySet()) {
        sb.append("{ type=" + entry.getKey()
            + ", versionTag=" + entry.getValue() + "}, ");
      }
    }
    sb.append(" ]");
    return sb.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ServiceResponse.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import java.util.Map;

public class ServiceResponse {

  private Long clusterId;

  private String clusterName;

  private String serviceName;

  private String desiredStackVersion;

  private String desiredState;

  // Config type -> version mapping
  private Map<String, String> configVersions;

  public ServiceResponse(Long clusterId, String clusterName,
                         String serviceName,
                         Map<String, String> configVersions,
                         String desiredStackVersion, String desiredState) {
    super();
    this.clusterId = clusterId;
    this.clusterName = clusterName;
    this.serviceName = serviceName;
    this.configVersions = configVersions;
    this.setDesiredStackVersion(desiredStackVersion);
    this.setDesiredState(desiredState);
  }

  /**
   * @return the serviceName
   */
  public String getServiceName() {
    return serviceName;
  }

  /**
   * @param serviceName the serviceName to set
   */
  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  /**
   * @return the configVersions
   */
  public Map<String, String> getConfigVersions() {
    return configVersions;
  }

  /**
   * @param configVersions the configVersions to set
   */
  public void setConfigVersions(Map<String, String> configVersions) {
    this.configVersions = configVersions;
  }

  /**
   * @return the clusterId
   */
  public Long getClusterId() {
    return clusterId;
  }

  /**
   * @param clusterId the clusterId to set
   */
  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  /**
   * @return the clusterName
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * @param clusterName the clusterName to set
   */
  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  /**
   * @return the desiredState
   */
  public String getDesiredState() {
    return desiredState;
  }

  /**
   * @param desiredState the desiredState to set
   */
  public void setDesiredState(String desiredState) {
    this.desiredState = desiredState;
  }

  /**
   * @return the desiredStackVersion
   */
  public String getDesiredStackVersion() {
    return desiredStackVersion;
  }

  /**
   * @param desiredStackVersion the desiredStackVersion to set
   */
  public void setDesiredStackVersion(String desiredStackVersion) {
    this.desiredStackVersion = desiredStackVersion;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceResponse that = (ServiceResponse) o;

    if (clusterId != null ?
        !clusterId.equals(that.clusterId) : that.clusterId != null) {
      return false;
    }
    if (clusterName != null ?
        !clusterName.equals(that.clusterName) : that.clusterName != null) {
      return false;
    }
    if (serviceName != null ?
        !serviceName.equals(that.serviceName) : that.serviceName != null) {
      return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null? clusterId.intValue() : 0;
    result = 71 * result + (clusterName != null ? clusterName.hashCode() : 0);
    result = 71 * result + (serviceName != null ? serviceName.hashCode() : 0);
    return result;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ShortTaskStatus.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import org.apache.ambari.server.actionmanager.HostRoleCommand;

public class ShortTaskStatus {
  protected long taskId;
  protected long stageId;
  protected String hostName;
  protected String role;
  protected String command;
  protected String status;

  public ShortTaskStatus() {
  }

  public ShortTaskStatus(int taskId, long stageId, String hostName, String role, String command, String status) {
    this.taskId = taskId;
    this.stageId = stageId;
    this.hostName = hostName;
    this.role = role;
    this.command = command;
    this.status = status;
  }

  public ShortTaskStatus(HostRoleCommand hostRoleCommand) {
    this.taskId = hostRoleCommand.getTaskId();
    this.stageId = hostRoleCommand.getStageId();
    this.command = hostRoleCommand.getRoleCommand().toString();
    this.hostName = hostRoleCommand.getHostName();
    this.role = hostRoleCommand.getRole().toString();
    this.status = hostRoleCommand.getStatus().toString();
  }

  public long getTaskId() {
    return taskId;
  }

  public void setTaskId(long taskId) {
    this.taskId = taskId;
  }

  public long getStageId() {
    return stageId;
  }

  public void setStageId(long stageId) {
    this.stageId = stageId;
  }

  public String getHostName() {
    return hostName;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  public String getRole() {
    return role;
  }

  public void setRole(String role) {
    this.role = role;
  }

  public String getCommand() {
    return command;
  }

  public void setCommand(String command) {
    this.command = command;
  }

  public String getStatus() {
    return status;
  }

  public void setStatus(String status) {
    this.status = status;
  }

  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("ShortTaskStatusDump "
        + ", stageId=" + stageId
        + ", taskId=" + taskId
        + ", hostname=" + hostName
        + ", role=" + role
        + ", command=" + command
        + ", status=" + status);
    return sb.toString();
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/TaskStatusRequest.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

public class TaskStatusRequest {
  protected Long requestId;
  protected Long taskId;

  public TaskStatusRequest() {
  }

  public TaskStatusRequest(Long requestId, Long taskId) {
    this.requestId = requestId;
    this.taskId = taskId;
  }

  public Long getRequestId() {
    return requestId;
  }

  public void setRequestId(Long requestId) {
    this.requestId = requestId;
  }

  public Long getTaskId() {
    return taskId;
  }

  public void setTaskId(Long taskId) {
    this.taskId = taskId;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/TaskStatusResponse.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller;

import org.apache.ambari.server.actionmanager.HostRoleCommand;

public class TaskStatusResponse extends ShortTaskStatus {
  private long requestId;
  private int exitCode;
  private String stderr;
  private String stdout;
  private long startTime;
  private short attemptCount;

  public TaskStatusResponse() {
  }

  public TaskStatusResponse(long requestId,
                            int taskId, long stageId, String hostName, String role, String command, String status,
                            int exitCode, String stderr, String stdout, long startTime, short attemptCount) {
    super(taskId, stageId, hostName, role, command, status);
    this.requestId = requestId;
    this.exitCode = exitCode;
    this.stderr = stderr;
    this.stdout = stdout;
    this.startTime = startTime;
    this.attemptCount = attemptCount;
  }

  public TaskStatusResponse(HostRoleCommand hostRoleCommand) {
    super(hostRoleCommand);
    this.requestId = hostRoleCommand.getRequestId();
    this.exitCode = hostRoleCommand.getExitCode();
    this.stderr = hostRoleCommand.getStderr();
    this.stdout = hostRoleCommand.getStdout();
    this.startTime = hostRoleCommand.getStartTime();
    this.attemptCount = hostRoleCommand.getAttemptCount();
  }

  public long getRequestId() {
    return requestId;
  }

  public void setRequestId(long requestId) {
    this.requestId = requestId;
  }

  public int getExitCode() {
    return exitCode;
  }

  public void setExitCode(int exitCode) {
    this.exitCode = exitCode;
  }

  public String getStderr() {
    return stderr;
  }

  public void setStderr(String stderr) {
    this.stderr = stderr;
  }

  public String getStdout() {
    return stdout;
  }

  public void setStdout(String stdout) {
    this.stdout = stdout;
  }

  public long getStartTime() {
    return startTime;
  }

  public void setStartTime(long startTime) {
    this.startTime = startTime;
  }

  public short getAttemptCount() {
    return attemptCount;
  }

  public void setAttemptCount(short attemptCount) {
    this.attemptCount = attemptCount;
  }
  
  @Override
  public String toString() {
      return super.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/UserRequest.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller;

import java.util.HashSet;
import java.util.Set;

/**
 * Represents a user maintenance request.
 */
public class UserRequest {
  private String userName;
  private String password;
  private String oldPassword;
  private Set<String> roles = new HashSet<String>();

  public UserRequest(String name) {
    this.userName = name;
  }

  public String getUsername() {
    return userName;
  }

  public Set<String> getRoles() {
    return roles;
  }

  public void setRoles(Set<String> userRoles) {
    roles = userRoles;
  }

  public String getPassword() {
    return password;
  }

  public void setPassword(String userPass) {
    password = userPass;
  }

  public String getOldPassword() {
    return oldPassword;
  }

  public void setOldPassword(String oldUserPass) {
    oldPassword = oldUserPass;
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("User"
        + ", username=" + userName
        + ", roles=[ ");
    if (roles != null && !roles.isEmpty()) {
      boolean first = true;
      for (String role : roles) {
        if (!first) {
          sb.append(",");
        }
        first = false;
        sb.append(role);
      }
    }
    sb.append(" ]");
    return sb.toString();
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/UserResponse.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller;

import java.util.Collections;
import java.util.Set;

/**
 * Represents a user maintenance request.
 */
public class UserResponse {

  private Set<String> roles = Collections.emptySet();
  private final String userName;
  private final boolean isLdapUser;

  public UserResponse(String name, boolean isLdapUser) {
    this.userName = name;
    this.isLdapUser = isLdapUser;
  }

  public String getUsername() {
    return userName;
  }

  public Set<String> getRoles() {
    return roles;
  }

  public void setRoles(Set<String> userRoles) {
    roles = userRoles;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    UserResponse that = (UserResponse) o;

    if (userName != null ?
        !userName.equals(that.userName) : that.userName != null) {
      return false;
    }

    return true;
  }

  @Override
  public int hashCode() {
    int result = userName != null ? userName.hashCode() : 0;
    return result;
  }

  /**
   * @return the isLdapUser
   */
  public boolean isLdapUser() {
    return isLdapUser;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ganglia/GangliaComponentPropertyProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.ganglia;

import org.apache.ambari.server.controller.internal.PropertyInfo;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.StreamProvider;

import java.util.Map;

/**
 * Ganglia property provider implementation for component resources.
 */
public class GangliaComponentPropertyProvider extends GangliaPropertyProvider {


  // ----- Constructors ------------------------------------------------------

  public GangliaComponentPropertyProvider(Map<String, Map<String, PropertyInfo>> componentMetrics,
                                          StreamProvider streamProvider,
                                          GangliaHostProvider hostProvider,
                                          String clusterNamePropertyId,
                                          String componentNamePropertyId) {

    super(componentMetrics, streamProvider, hostProvider,
        clusterNamePropertyId, null, componentNamePropertyId);
  }


  // ----- GangliaPropertyProvider -------------------------------------------

  @Override
  protected String getHostName(Resource resource) {
    return "__SummaryInfo__";
  }

  @Override
  protected String getComponentName(Resource resource) {
    return (String) resource.getPropertyValue(getComponentNamePropertyId());
  }

  @Override
  protected String getGangliaClusterName(Resource resource, String clusterName) {
    return GANGLIA_CLUSTER_NAMES.get(getComponentName(resource));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ganglia/GangliaHostComponentPropertyProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.ganglia;

import org.apache.ambari.server.controller.internal.PropertyInfo;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.StreamProvider;

import java.util.Map;

/**
 * Ganglia property provider implementation for host component resources.
 */
public class GangliaHostComponentPropertyProvider extends GangliaPropertyProvider {


  // ----- Constructors ------------------------------------------------------

  public GangliaHostComponentPropertyProvider(Map<String, Map<String, PropertyInfo>> componentPropertyInfoMap,
                                              StreamProvider streamProvider,
                                              GangliaHostProvider hostProvider,
                                              String clusterNamePropertyId,
                                              String hostNamePropertyId,
                                              String componentNamePropertyId) {

    super(componentPropertyInfoMap, streamProvider, hostProvider,
        clusterNamePropertyId, hostNamePropertyId, componentNamePropertyId);
  }


  // ----- GangliaPropertyProvider -------------------------------------------

  @Override
  protected String getHostName(Resource resource) {
    return (String) resource.getPropertyValue(getHostNamePropertyId());
  }

  @Override
  protected String getComponentName(Resource resource) {
    return (String) resource.getPropertyValue(getComponentNamePropertyId());
  }

  @Override
  protected String getGangliaClusterName(Resource resource, String clusterName) {
    return GANGLIA_CLUSTER_NAMES.get(getComponentName(resource));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ganglia/GangliaHostPropertyProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.ganglia;

import org.apache.ambari.server.controller.internal.PropertyInfo;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.StreamProvider;

import java.util.Map;

/**
 * Ganglia property provider implementation for host resources.
 */
public class GangliaHostPropertyProvider extends GangliaPropertyProvider{


  // ----- Constructors ------------------------------------------------------

  public GangliaHostPropertyProvider(Map<String, Map<String, PropertyInfo>> componentPropertyInfoMap,
                                     StreamProvider streamProvider,
                                     GangliaHostProvider hostProvider,
                                     String clusterNamePropertyId,
                                     String hostNamePropertyId) {

    super(componentPropertyInfoMap, streamProvider, hostProvider,
        clusterNamePropertyId, hostNamePropertyId, null);
  }


  // ----- GangliaPropertyProvider -------------------------------------------

  @Override
  protected String getHostName(Resource resource) {
    return (String) resource.getPropertyValue(getHostNamePropertyId());
  }

  @Override
  protected String getComponentName(Resource resource) {
    return "*";
  }

  @Override
  protected String getGangliaClusterName(Resource resource, String clusterName) {
    return "HDPSlaves";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ganglia/GangliaHostProvider.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.ganglia;

import org.apache.ambari.server.controller.spi.SystemException;

/**
 *  Provider of Ganglia host information.
 */
public interface GangliaHostProvider {

  /**
   * Get the Ganglia server host name for the given cluster name.
   *
   * @param clusterName  the cluster name
   *
   * @return the Ganglia server
   *
   * @throws SystemException if unable to get the Ganglia server host name
   */
  public String getGangliaCollectorHostName(String clusterName) throws SystemException;
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ganglia/GangliaMetric.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.ganglia;


/**
 * Data structure for temporal data returned from Ganglia Web.
 */
public class GangliaMetric {

  // Note that the member names correspond to the names in the JSON returned from Ganglia Web.

  /**
   * The name.
   */
  private String ds_name;

  /**
   * The ganglia cluster name.
   */
  private String cluster_name;

  /**
   * The graph type.
   */
  private String graph_type;

  /**
   * The host name.
   */
  private String host_name;

  /**
   * The metric name.
   */
  private String metric_name;

  /**
   * The temporal data points.
   */
  private Number[][] datapoints;


  // ----- GangliaMetric -----------------------------------------------------

  public String getDs_name() {
    return ds_name;
  }

  public void setDs_name(String ds_name) {
    this.ds_name = ds_name;
  }

  public String getCluster_name() {
    return cluster_name;
  }

  public void setCluster_name(String cluster_name) {
    this.cluster_name = cluster_name;
  }

  public String getGraph_type() {
    return graph_type;
  }

  public void setGraph_type(String graph_type) {
    this.graph_type = graph_type;
  }

  public String getHost_name() {
    return host_name;
  }

  public void setHost_name(String host_name) {
    this.host_name = host_name;
  }

  public String getMetric_name() {
    return metric_name;
  }

  public void setMetric_name(String metric_name) {
    this.metric_name = metric_name;
  }

  public Number[][] getDatapoints() {
    return datapoints;
  }

  public void setDatapoints(Number[][] datapoints) {
    this.datapoints = datapoints;
  }


  // ----- Object overrides --------------------------------------------------

  @Override
  public String toString() {
    StringBuilder stringBuilder = new StringBuilder();

    stringBuilder.append("\n");
    stringBuilder.append("name=");
    stringBuilder.append(ds_name);
    stringBuilder.append("\n");
    stringBuilder.append("cluster name=");
    stringBuilder.append(cluster_name);
    stringBuilder.append("\n");
    stringBuilder.append("graph type=");
    stringBuilder.append(graph_type);
    stringBuilder.append("\n");
    stringBuilder.append("host name=");
    stringBuilder.append(host_name);
    stringBuilder.append("\n");
    stringBuilder.append("api name=");
    stringBuilder.append(metric_name);
    stringBuilder.append("\n");

    stringBuilder.append("datapoints (value/timestamp):");
    stringBuilder.append("\n");


    boolean first = true;
    stringBuilder.append("[");
    for (Number[] m : datapoints) {
      if (!first) {
        stringBuilder.append(",");
      }
      stringBuilder.append("[");
      stringBuilder.append(m[0]);
      stringBuilder.append(",");
      stringBuilder.append(m[1].longValue());
      stringBuilder.append("]");
      first = false;
    }
    stringBuilder.append("]");

    return stringBuilder.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ganglia/GangliaPropertyProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.ganglia;

import org.apache.ambari.server.controller.internal.PropertyInfo;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.apache.ambari.server.controller.utilities.StreamProvider;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.type.TypeReference;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

/**
 * Abstract property provider implementation for a Ganglia source.
 */
public abstract class GangliaPropertyProvider implements PropertyProvider {

  /**
   * Set of property ids supported by this provider.
   */
  private final Set<String> propertyIds;

  private final Map<String, Map<String, PropertyInfo>> componentPropertyInfoMap;

  private final StreamProvider streamProvider;

  private final GangliaHostProvider hostProvider;

  private final String clusterNamePropertyId;

  private final String hostNamePropertyId;

  private final String componentNamePropertyId;


  /**
   * Map of Ganglia cluster names keyed by component type.
   */
  public static final Map<String, String> GANGLIA_CLUSTER_NAMES = new HashMap<String, String>();

  static {
    GANGLIA_CLUSTER_NAMES.put("NAMENODE",           "HDPNameNode");
    GANGLIA_CLUSTER_NAMES.put("DATANODE",           "HDPSlaves");
    GANGLIA_CLUSTER_NAMES.put("JOBTRACKER",         "HDPJobTracker");
    GANGLIA_CLUSTER_NAMES.put("TASKTRACKER",        "HDPSlaves");
    GANGLIA_CLUSTER_NAMES.put("HBASE_MASTER",       "HDPHBaseMaster");
    GANGLIA_CLUSTER_NAMES.put("HBASE_CLIENT",       "HDPSlaves");
    GANGLIA_CLUSTER_NAMES.put("HBASE_REGIONSERVER", "HDPSlaves");
  }

  protected final static Logger LOG =
      LoggerFactory.getLogger(GangliaPropertyProvider.class);

  // ----- Constructors ------------------------------------------------------

  public GangliaPropertyProvider(Map<String, Map<String, PropertyInfo>> componentPropertyInfoMap,
                                 StreamProvider streamProvider,
                                 GangliaHostProvider hostProvider,
                                 String clusterNamePropertyId,
                                 String hostNamePropertyId,
                                 String componentNamePropertyId) {
    this.componentPropertyInfoMap = componentPropertyInfoMap;
    this.streamProvider           = streamProvider;
    this.hostProvider             = hostProvider;
    this.clusterNamePropertyId    = clusterNamePropertyId;
    this.hostNamePropertyId       = hostNamePropertyId;
    this.componentNamePropertyId  = componentNamePropertyId;

    propertyIds = new HashSet<String>();
    for (Map.Entry<String, Map<String, PropertyInfo>> entry : componentPropertyInfoMap.entrySet()) {
      propertyIds.addAll(entry.getValue().keySet());
    }
  }


  // ----- PropertyProvider --------------------------------------------------

  @Override
  public Set<Resource> populateResources(Set<Resource> resources, Request request, Predicate predicate)
      throws SystemException {

    Set<String> ids = PropertyHelper.getRequestPropertyIds(propertyIds, request, predicate);
    if (ids.isEmpty()) {
      return resources;
    }

    Set<Resource> keepers = new HashSet<Resource>();

    Map<String, Map<TemporalInfo, RRDRequest>> requestMap = getRRDRequests(resources, request, ids);

    // For each cluster...
    for (Map.Entry<String, Map<TemporalInfo, RRDRequest>> clusterEntry : requestMap.entrySet()) {
      // For each request ...
      for (RRDRequest rrdRequest : clusterEntry.getValue().values() ) {
        keepers.addAll(rrdRequest.populateResources());
      }
    }
    return resources;
  }

  @Override
  public Set<String> getPropertyIds() {
    return propertyIds;
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    if (!this.propertyIds.containsAll(propertyIds)) {
      Set<String> unsupportedPropertyIds = new HashSet<String>(propertyIds);
      unsupportedPropertyIds.removeAll(this.propertyIds);
      return unsupportedPropertyIds;
    }
    return Collections.emptySet();
  }


  // ----- GangliaPropertyProvider -------------------------------------------

  /**
   * Get the host name for the given resource.
   *
   * @param resource  the resource
   *
   * @return the host name
   */
  protected abstract String getHostName(Resource resource);

  /**
   * Get the component name for the given resource.
   *
   * @param resource  the resource
   *
   * @return the component name
   */
  protected abstract String getComponentName(Resource resource);

  /**
   * Get the ganglia cluster name for the given resource.
   *
   * @param resource  the resource
   *
   * @return the ganglia cluster name
   */
  protected abstract String getGangliaClusterName(Resource resource, String clusterName);


  /**
   * Get the component name property id.
   *
   * @return the component name property id
   */
  protected String getComponentNamePropertyId() {
    return componentNamePropertyId;
  }

  /**
   * Get the host name property id.
   *
   * @return the host name property id
   */
  protected String getHostNamePropertyId() {
    return hostNamePropertyId;
  }

  /**
   * Get the stream provider.
   *
   * @return the stream provider
   */
  public StreamProvider getStreamProvider() {
    return streamProvider;
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Get the request objects containing all the information required to
   * make single requests to the Ganglia rrd script.
   * Requests are created per cluster name / temporal information but
   * can span multiple resources and metrics.
   *
   * @param resources  the resources being populated
   * @param request    the request
   * @param ids        the relevant property ids
   *
   * @return a map of maps of rrd requests keyed by cluster name / temporal info
   */
  private Map<String, Map<TemporalInfo, RRDRequest>> getRRDRequests(Set<Resource> resources,
                                                                    Request request,
                                                                    Set<String> ids) {

    Map<String, Map<TemporalInfo, RRDRequest>> requestMap =
        new HashMap<String, Map<TemporalInfo, RRDRequest>>();

    for (Resource resource : resources) {
      String clusterName = (String) resource.getPropertyValue(clusterNamePropertyId);
      Map<TemporalInfo, RRDRequest> requests = requestMap.get(clusterName);
      if (requests == null) {
        requests = new HashMap<TemporalInfo, RRDRequest>();
        requestMap.put(clusterName, requests);
      }

      ResourceKey key =
          new ResourceKey(getHostName(resource), getGangliaClusterName(resource, clusterName));

      Map<String, PropertyInfo> metrics = componentPropertyInfoMap.get(getComponentName(resource));

      if (metrics != null) {
        for (String propertyId : ids) {
          PropertyInfo propertyInfo = metrics.get(propertyId);
          if (propertyInfo != null) {
            TemporalInfo temporalInfo = request.getTemporalInfo(propertyId);

            if ((temporalInfo == null && propertyInfo.isPointInTime()) || (temporalInfo != null && propertyInfo.isTemporal())) {
              RRDRequest rrdRequest = requests.get(temporalInfo);
              if (rrdRequest == null) {
                rrdRequest = new RRDRequest(clusterName, temporalInfo);
                requests.put(temporalInfo, rrdRequest);
              }
              rrdRequest.putResource(key, resource);
              rrdRequest.putPropertyId(propertyInfo.getPropertyId(), propertyId);
            }
          }
        }
      }
    }
    return requestMap;
  }

  /**
   * Get the spec to locate the Ganglia stream from the given
   * request info.
   *
   * @param clusterName   the cluster name
   * @param clusterSet    the set of ganglia cluster names
   * @param hostSet       the set of host names
   * @param metricSet     the set of metric names
   * @param temporalInfo  the temporal information
   *
   * @return the spec
   *
   * @throws SystemException if unable to get the Ganglia Collector host name
   */
  private String getSpec(String clusterName,
                         Set<String> clusterSet,
                         Set<String> hostSet,
                         Set<String> metricSet,
                         TemporalInfo temporalInfo) throws SystemException {

    String clusters = getSetString(clusterSet, -1);
    String hosts    = getSetString(hostSet, -1);
    String metrics  = getSetString(metricSet, 50);

    StringBuilder sb = new StringBuilder();

    sb.append("http://").
        append(hostProvider.getGangliaCollectorHostName(clusterName)).
        append("/cgi-bin/rrd.py?c=").
        append(clusters);

    if (hosts.length() > 0) {
      sb.append("&h=").append(hosts);
    }

    if (metrics.length() > 0) {
      sb.append("&m=").append(metrics);
    }

    if (temporalInfo != null) {
      long startTime = temporalInfo.getStartTime();
      if (startTime != -1) {
        sb.append("&s=").append(startTime);
      }

      long endTime = temporalInfo.getEndTime();
      if (endTime != -1) {
        sb.append("&e=").append(endTime);
      }

      long step = temporalInfo.getStep();
      if (step != -1) {
        sb.append("&r=").append(step);
      }
    }
    else {
      sb.append("&e=now");
    }

    return sb.toString();
  }

  /**
   * Get value from the given metric.
   *
   * @param metric      the metric
   * @param isTemporal  indicates whether or not this a temporal metric
   *
   * @return a range of temporal data or a point in time value if not temporal
   */
  private static Object getValue(GangliaMetric metric, boolean isTemporal) {
    Number[][] dataPoints = metric.getDatapoints();

    if (isTemporal) {
      return dataPoints;
    } else {
      // return the value of the last data point
      int length = dataPoints.length;
      return length > 0 ? dataPoints[length - 1][0] : 0;
    }
  }

  /**
   * Get a comma delimited string from the given set of strings or
   * an empty string if the size of the given set is greater than
   * the given limit.
   *
   * @param set    the set of strings
   * @param limit  the upper size limit for the list
   *
   * @return a comma delimited string of strings
   */
  private static String getSetString(Set<String> set, int limit) {
    StringBuilder sb = new StringBuilder();

    if (limit == -1 || set.size() <= limit) {
      for (String cluster : set) {
        if (sb.length() > 0) {
          sb.append(",");
        }
        sb.append(cluster);
      }
    }
    return sb.toString();
  }


  // ----- inner classes -----------------------------------------------------


  // ----- RRDRequest ----------------------------------------------------

  /**
   * The information required to make a single RRD request.
   */
  private class RRDRequest {
    private final String clusterName;
    private final TemporalInfo temporalInfo;
    private final Map<ResourceKey, Set<Resource>> resources = new HashMap<ResourceKey, Set<Resource>>();
    private final Map<String, Set<String>> metrics = new HashMap<String, Set<String>>();
    private final Set<String> clusterSet = new HashSet<String>();
    private final Set<String> hostSet = new HashSet<String>();


    private RRDRequest(String clusterName, TemporalInfo temporalInfo) {
      this.clusterName  = clusterName;
      this.temporalInfo = temporalInfo;
    }

    public void putResource(ResourceKey key, Resource resource) {
      clusterSet.add(key.getClusterName());
      hostSet.add(key.getHostName());
      Set<Resource> resourceSet = resources.get(key);
      if (resourceSet == null) {
        resourceSet = new HashSet<Resource>();
        resources.put(key, resourceSet);
      }
      resourceSet.add(resource);
    }

    public void putPropertyId(String metric, String id) {
      Set<String> propertyIds = metrics.get(metric);

      if (propertyIds == null) {
        propertyIds = new HashSet<String>();
        metrics.put(metric, propertyIds);
      }
      propertyIds.add(id);
    }

    /**
     * Populate the associated resources by making the rrd request.
     *
     * @return a collection of populated resources
     *
     * @throws SystemException if unable to populate the resources
     */
    public Collection<Resource> populateResources() throws SystemException {

      String spec = getSpec(clusterName, clusterSet, hostSet, metrics.keySet(), temporalInfo);
      Collection<Resource> populatedResources = new HashSet<Resource>();

      try {
        List<GangliaMetric> gangliaMetrics = new ObjectMapper().readValue(getStreamProvider().readFrom(spec),
            new TypeReference<List<GangliaMetric>>() {
            });

        if (gangliaMetrics != null) {
          for (GangliaMetric gangliaMetric : gangliaMetrics) {

            ResourceKey key = new ResourceKey(gangliaMetric.getHost_name(), gangliaMetric.getCluster_name());
            Set<Resource> resourceSet = resources.get(key);
            if (resourceSet != null) {
              for (Resource resource : resourceSet) {
                populateResource(resource, gangliaMetric);
              }
            }
          }
        }
      } catch (IOException e) {
        if (LOG.isDebugEnabled()) {
          LOG.debug("Caught exception getting Ganglia metrics : spec=" + spec, e);
        }
      }
      return populatedResources;
    }

    /**
     * Populate the given resource with the given Ganglia metric.
     *
     * @param resource       the resource
     * @param gangliaMetric  the Ganglia metrics
     */
    private void populateResource(Resource resource, GangliaMetric gangliaMetric) {
      Set<String> propertyIdSet = metrics.get(gangliaMetric.getMetric_name());
      if (propertyIdSet != null) {
        Map<String, PropertyInfo> metricsMap = componentPropertyInfoMap.get(getComponentName(resource));
        if (metricsMap != null) {
          for (String propertyId : propertyIdSet) {
            if (propertyId != null) {
              if (metricsMap.containsKey(propertyId)){
                resource.setProperty(propertyId, getValue(gangliaMetric, temporalInfo != null));
              }
            }
          }
        }
      }
    }
  }


  // ----- ResourceKey ---------------------------------------------------

  /**
   * Key used to associate information from a Ganglia metric to a resource.
   */
  private static class ResourceKey {
    private final String hostName;
    private final String gangliaClusterName;

    private ResourceKey(String hostName, String gangliaClusterName) {
      this.hostName           = hostName;
      this.gangliaClusterName = gangliaClusterName;
    }

    public String getHostName() {
      return hostName;
    }

    public String getClusterName() {
      return gangliaClusterName;
    }

    @Override
    public boolean equals(Object o) {
      if (this == o) return true;
      if (o == null || getClass() != o.getClass()) return false;

      ResourceKey that = (ResourceKey) o;

      return
          !(gangliaClusterName != null ? !gangliaClusterName.equals(that.gangliaClusterName) : that.gangliaClusterName != null) &&
          !(hostName != null ? !hostName.equals(that.hostName) : that.hostName != null);

    }

    @Override
    public int hashCode() {
      int result = hostName != null ? hostName.hashCode() : 0;
      result = 31 * result + (gangliaClusterName != null ? gangliaClusterName.hashCode() : 0);
      return result;
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ganglia/GangliaReportPropertyProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.ganglia;

import org.apache.ambari.server.controller.internal.PropertyInfo;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.apache.ambari.server.controller.utilities.StreamProvider;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.type.TypeReference;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

/**
 * Property provider implementation for a Ganglia source. This provider is specialized
 * to pull metrics from existing Ganglia reports.
 */
public class GangliaReportPropertyProvider implements PropertyProvider {

  /**
   * Set of property ids supported by this provider.
   */
  private final Set<String> propertyIds;

  private final Map<String, PropertyInfo> componentMetrics;

  private final StreamProvider streamProvider;

  private final GangliaHostProvider hostProvider;

  private final String clusterNamePropertyId;


  // ----- Constants --------------------------------------------------------

  protected final static Logger LOG =
      LoggerFactory.getLogger(GangliaReportPropertyProvider.class);

  private static final String GANGLIA_CLUSTER_NAME = "HDPSlaves";


  // ----- Constructors ------------------------------------------------------

  public GangliaReportPropertyProvider(Map<String, PropertyInfo> componentMetrics,
                                       StreamProvider streamProvider,
                                       GangliaHostProvider hostProvider,
                                       String clusterNamePropertyId) {

    this.componentMetrics      = componentMetrics;
    this.streamProvider        = streamProvider;
    this.hostProvider          = hostProvider;
    this.clusterNamePropertyId = clusterNamePropertyId;

    propertyIds = new HashSet<String>(componentMetrics.keySet());
  }


  // ----- PropertyProvider --------------------------------------------------

  @Override
  public Set<Resource> populateResources(Set<Resource> resources, Request request, Predicate predicate)
      throws SystemException {

    Set<Resource> keepers = new HashSet<Resource>();
    for (Resource resource : resources) {
      if (populateResource(resource, request, predicate)) {
        keepers.add(resource);
      }
    }
    return keepers;
  }

  @Override
  public Set<String> getPropertyIds() {
    return propertyIds;
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    if (!this.propertyIds.containsAll(propertyIds)) {
      Set<String> unsupportedPropertyIds = new HashSet<String>(propertyIds);
      unsupportedPropertyIds.removeAll(this.propertyIds);
      return unsupportedPropertyIds;
    }
    return Collections.emptySet();
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Populate a resource by obtaining the requested Ganglia RESOURCE_METRICS.
   *
   * @param resource  the resource to be populated
   * @param request   the request
   * @param predicate the predicate
   *
   * @return true if the resource was successfully populated with the requested properties
   *
   * @throws SystemException if unable to populate the resource
   */
  private boolean populateResource(Resource resource, Request request, Predicate predicate)
      throws SystemException {

    if (propertyIds.isEmpty()) {
      return true;
    }
    String clusterName = (String) resource.getPropertyValue(clusterNamePropertyId);

    if (hostProvider.getGangliaCollectorHostName(clusterName) == null) {
      if (LOG.isWarnEnabled()) {
        LOG.warn("Attempting to get metrics but the Ganglia server is unknown. Resource=" + resource +
            " : Cluster=" + clusterName);
      }
      return true;
    }

    setProperties(resource, clusterName, request,
        PropertyHelper.getRequestPropertyIds(propertyIds, request, predicate));

    return true;
  }

  private boolean setProperties(Resource resource, String clusterName, Request request, Set<String> ids)
      throws SystemException {

    Map<String, Map<String, String>> propertyIdMaps = getPropertyIdMaps(request, ids);

    for (Map.Entry<String, Map<String, String>> entry : propertyIdMaps.entrySet()) {
      Map<String, String>  map = entry.getValue();
      String report = entry.getKey();

      String spec = getSpec(clusterName, report);

      try {
        List<GangliaMetric> gangliaMetrics = new ObjectMapper().readValue(streamProvider.readFrom(spec),
            new TypeReference<List<GangliaMetric>>() {});

        if (gangliaMetrics != null) {
          for (GangliaMetric gangliaMetric : gangliaMetrics) {

            String propertyId = map.get(gangliaMetric.getMetric_name());
            if (propertyId != null) {
              resource.setProperty(propertyId, getValue(gangliaMetric));
            }
          }
        }
      } catch (IOException e) {
        if (LOG.isDebugEnabled()) {
          LOG.debug("Caught exception getting Ganglia metrics : " + e + " : spec=" + spec);
        }
        return false;
      }
    }
    return true;
  }


  private Map<String, Map<String, String>> getPropertyIdMaps(Request request, Set<String> ids) {
    Map<String, Map<String, String>> propertyMap = new HashMap<String, Map<String, String>>();

    for (String propertyId : ids) {
      PropertyInfo propertyInfo = componentMetrics.get(propertyId);

      if (propertyInfo != null) {

        TemporalInfo temporalInfo = request.getTemporalInfo(propertyId);

        if (temporalInfo != null && propertyInfo.isTemporal()) {
          String propertyName = propertyInfo.getPropertyId();
          String report = null;
          // format : report_name.metric_name
          int dotIndex = propertyName.lastIndexOf('.');
          if (dotIndex != -1){
            report = propertyName.substring(0, dotIndex);
            propertyName = propertyName.substring(dotIndex + 1);
          }
          if (report !=  null) {
            Map<String, String> map = propertyMap.get(report);
            if (map == null) {
              map = new HashMap<String, String>();
              propertyMap.put(report, map);
            }
            map.put(propertyName, propertyId);
          }
        }
      }
    }
    return propertyMap;
  }

  /**
   * Get value from the given metric.
   *
   *
   * @param metric     the metric
   */
  private Object getValue(GangliaMetric metric) {
      return metric.getDatapoints();
  }

  /**
   * Get the spec to locate the Ganglia stream from the given
   * request info.
   *
   *
   * @param clusterName     the cluster name
   * @param report          the report
   *
   * @return the spec
   *
   * @throws SystemException if unable to ge the Ganglia Collector host name
   */
  protected String getSpec(String clusterName, String report) throws SystemException {

    StringBuilder sb = new StringBuilder();

    sb.append("http://").
        append(hostProvider.getGangliaCollectorHostName(clusterName)).
        append("/ganglia/graph.php?c=").
        append(GANGLIA_CLUSTER_NAME).
        append("&g=").
        append(report).
        append("&json=1");

    return sb.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/ganglia/MetricsMapping.java,true,"package org.apache.ambari.server.controller.ganglia;

/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 *
 */
public class MetricsMapping {

  private static String[] metrics = new String[] {
      "cpu_nice",
      "cpu_nice",
      "cpu_wio",
      "cpu_wio",
      "cpu_user",
      "cpu_user",
      "cpu_idle",
      "cpu_idle",
      "cpu_system",
      "cpu_system",
      "cpu_aidle",
      "cpu_aidle",
      "dfs.datanode.heartBeats_avg_time",
      "dfs.datanode.heartBeats_avg_time",
      "dfs.datanode.bytes_written",
      "dfs.datanode.bytes_written",
      "dfs.datanode.writes_from_local_client",
      "dfs.datanode.writes_from_local_client",
      "dfs.datanode.blocks_verified",
      "dfs.datanode.blocks_verified",
      "dfs.datanode.heartBeats_num_ops",
      "dfs.datanode.heartBeats_num_ops",
      "dfs.datanode.writeBlockOp_num_ops",
      "dfs.datanode.writeBlockOp_num_ops",
      "dfs.datanode.writeBlockOp_avg_time",
      "dfs.datanode.writeBlockOp_avg_time",
      "dfs.datanode.blockReports_num_ops",
      "dfs.datanode.blockReports_num_ops",
      "dfs.datanode.writes_from_remote_client",
      "dfs.datanode.writes_from_remote_client",
      "dfs.datanode.blockReports_avg_time",
      "dfs.datanode.blockReports_avg_time",
      "dfs.datanode.blocks_written",
      "dfs.datanode.blocks_written",
      "disk_free",
      "disk_free",
      "disk_total",
      "disk_total",
      "part_max_used",
      "part_max_used",
      "hbase.regionserver.deleteRequestLatency_max",
      "hbase.regionserver.deleteRequestLatency_max",
      "hbase.regionserver.putRequestLatency_std_dev",
      "hbase.regionserver.putRequestLatency_std_dev",
      "hbase.regionserver.putRequestLatency_max",
      "hbase.regionserver.putRequestLatency_max",
      "hbase.regionserver.putRequestLatency_num_ops",
      "hbase.regionserver.putRequestLatency_num_ops",
      "hbase.regionserver.requests",
      "hbase.regionserver.requests",
      "hbase.regionserver.fsReadLatencyHistogram_median",
      "hbase.regionserver.fsReadLatencyHistogram_median",
      "hbase.regionserver.deleteRequestLatency_99th_percentile",
      "hbase.regionserver.deleteRequestLatency_99th_percentile",
      "hbase.regionserver.writeRequestsCount",
      "hbase.regionserver.writeRequestsCount",
      "hbase.regionserver.hdfsBlocksLocalityIndex",
      "hbase.regionserver.hdfsBlocksLocalityIndex",
      "hbase.regionserver.compactionQueueSize",
      "hbase.regionserver.compactionQueueSize",
      "hbase.regionserver.deleteRequestLatency_mean",
      "hbase.regionserver.deleteRequestLatency_mean",
      "hbase.regionserver.totalStaticBloomSizeKB",
      "hbase.regionserver.totalStaticBloomSizeKB",
      "hbase.regionserver.flushSize_num_ops",
      "hbase.regionserver.flushSize_num_ops",
      "hbase.regionserver.getRequestLatency_99th_percentile",
      "hbase.regionserver.getRequestLatency_99th_percentile",
      "hbase.regionserver.flushSize_avg_time",
      "hbase.regionserver.flushSize_avg_time",
      "hbase.regionserver.fsWriteLatencyHistogram_95th_percentile",
      "hbase.regionserver.fsWriteLatencyHistogram_95th_percentile",
      "hbase.regionserver.flushTime_num_ops",
      "hbase.regionserver.flushTime_num_ops",
      "hbase.regionserver.deleteRequestLatency_median",
      "hbase.regionserver.deleteRequestLatency_median",
      "hbase.regionserver.blockCacheSize",
      "hbase.regionserver.blockCacheSize",
      "hbase.regionserver.fsSyncLatency_num_ops",
      "hbase.regionserver.fsSyncLatency_num_ops",
      "hbase.regionserver.storefiles",
      "hbase.regionserver.storefiles",
      "hbase.regionserver.getRequestLatency_min",
      "hbase.regionserver.getRequestLatency_min",
      "hbase.regionserver.regions",
      "hbase.regionserver.regions",
      "hbase.regionserver.fsReadLatencyHistogram_max",
      "hbase.regionserver.fsReadLatencyHistogram_max",
      "hbase.regionserver.getRequestLatency_mean",
      "hbase.regionserver.getRequestLatency_mean",
      "hbase.regionserver.fsReadLatency_num_ops",
      "hbase.regionserver.fsReadLatency_num_ops",
      "hbase.regionserver.blockCacheMissCount",
      "hbase.regionserver.blockCacheMissCount",
      "hbase.regionserver.putRequestLatency_75th_percentile",
      "hbase.regionserver.putRequestLatency_75th_percentile",
      "hbase.regionserver.fsReadLatencyHistogram_99th_percentile",
      "hbase.regionserver.fsReadLatencyHistogram_99th_percentile",
      "hbase.regionserver.totalStaticIndexSizeKB",
      "hbase.regionserver.totalStaticIndexSizeKB",
      "hbase.regionserver.compactionTime_avg_time",
      "hbase.regionserver.compactionTime_avg_time",
      "hbase.regionserver.fsWriteLatencyHistogram_min",
      "hbase.regionserver.fsWriteLatencyHistogram_min",
      "hbase.regionserver.fsSyncLatency_avg_time",
      "hbase.regionserver.fsSyncLatency_avg_time",
      "hbase.regionserver.deleteRequestLatency_75th_percentile",
      "hbase.regionserver.deleteRequestLatency_75th_percentile",
      "hbase.regionserver.hlogFileCount",
      "hbase.regionserver.hlogFileCount",
      "hbase.regionserver.getRequestLatency_std_dev",
      "hbase.regionserver.getRequestLatency_std_dev",
      "hbase.regionserver.getRequestLatency_median",
      "hbase.regionserver.getRequestLatency_median",
      "hbase.regionserver.putRequestLatency_median",
      "hbase.regionserver.putRequestLatency_median",
      "hbase.regionserver.rootIndexSizeKB",
      "hbase.regionserver.rootIndexSizeKB",
      "hbase.regionserver.getRequestLatency_num_ops",
      "hbase.regionserver.getRequestLatency_num_ops",
      "hbase.regionserver.getRequestLatency_75th_percentile",
      "hbase.regionserver.getRequestLatency_75th_percentile",
      "hbase.regionserver.putRequestLatency_95th_percentile",
      "hbase.regionserver.putRequestLatency_95th_percentile",
      "hbase.regionserver.fsWriteLatencyHistogram_std_dev",
      "hbase.regionserver.fsWriteLatencyHistogram_std_dev",
      "hbase.regionserver.memstoreSizeMB",
      "hbase.regionserver.memstoreSizeMB",
      "hbase.regionserver.fsWriteLatencyHistogram_num_ops",
      "hbase.regionserver.fsWriteLatencyHistogram_num_ops",
      "hbase.regionserver.deleteRequestLatency_min",
      "hbase.regionserver.deleteRequestLatency_min",
      "hbase.regionserver.fsReadLatencyHistogram_75th_percentile",
      "hbase.regionserver.fsReadLatencyHistogram_75th_percentile",
      "hbase.regionserver.putRequestLatency_min",
      "hbase.regionserver.putRequestLatency_min",
      "hbase.regionserver.fsReadLatencyHistogram_std_dev",
      "hbase.regionserver.fsReadLatencyHistogram_std_dev",
      "hbase.regionserver.deleteRequestLatency_std_dev",
      "hbase.regionserver.deleteRequestLatency_std_dev",
      "hbase.regionserver.fsReadLatency_avg_time",
      "hbase.regionserver.fsReadLatency_avg_time",
      "hbase.regionserver.fsReadLatencyHistogram_num_ops",
      "hbase.regionserver.fsReadLatencyHistogram_num_ops",
      "hbase.regionserver.deleteRequestLatency_num_ops",
      "hbase.regionserver.deleteRequestLatency_num_ops",
      "hbase.regionserver.blockCacheEvictedCount",
      "hbase.regionserver.blockCacheEvictedCount",
      "hbase.regionserver.fsWriteLatencyHistogram_99th_percentile",
      "hbase.regionserver.fsWriteLatencyHistogram_99th_percentile",
      "hbase.regionserver.deleteRequestLatency_95th_percentile",
      "hbase.regionserver.deleteRequestLatency_95th_percentile",
      "hbase.regionserver.getRequestLatency_max",
      "hbase.regionserver.getRequestLatency_max",
      "hbase.regionserver.fsWriteLatencyHistogram_mean",
      "hbase.regionserver.fsWriteLatencyHistogram_mean",
      "hbase.regionserver.storefileIndexSizeMB",
      "hbase.regionserver.storefileIndexSizeMB",
      "hbase.regionserver.compactionSize_avg_time",
      "hbase.regionserver.compactionSize_avg_time",
      "hbase.regionserver.getRequestLatency_95th_percentile",
      "hbase.regionserver.getRequestLatency_95th_percentile",
      "hbase.regionserver.flushQueueSize",
      "hbase.regionserver.flushQueueSize",
      "hbase.regionserver.compactionSize_num_ops",
      "hbase.regionserver.compactionSize_num_ops",
      "hbase.regionserver.putRequestLatency_mean",
      "hbase.regionserver.putRequestLatency_mean",
      "hbase.regionserver.compactionTime_num_ops",
      "hbase.regionserver.compactionTime_num_ops",
      "hbase.regionserver.stores",
      "hbase.regionserver.stores",
      "hbase.regionserver.fsReadLatencyHistogram_min",
      "hbase.regionserver.fsReadLatencyHistogram_min",
      "hbase.regionserver.fsWriteLatency_avg_time",
      "hbase.regionserver.fsWriteLatency_avg_time",
      "hbase.regionserver.fsReadLatencyHistogram_mean",
      "hbase.regionserver.fsReadLatencyHistogram_mean",
      "hbase.regionserver.fsReadLatencyHistogram_95th_percentile",
      "hbase.regionserver.fsReadLatencyHistogram_95th_percentile",
      "hbase.regionserver.flushTime_avg_time",
      "hbase.regionserver.flushTime_avg_time",
      "hbase.regionserver.fsWriteLatencyHistogram_median",
      "hbase.regionserver.fsWriteLatencyHistogram_median",
      "hbase.regionserver.fsWriteLatencyHistogram_max",
      "hbase.regionserver.fsWriteLatencyHistogram_max",
      "hbase.regionserver.blockCacheHitCachingRatio",
      "hbase.regionserver.blockCacheHitCachingRatio",
      "hbase.regionserver.blockCacheHitCount",
      "hbase.regionserver.blockCacheHitCount",
      "hbase.regionserver.blockCacheCount",
      "hbase.regionserver.blockCacheCount",
      "hbase.regionserver.readRequestsCount",
      "hbase.regionserver.readRequestsCount",
      "hbase.regionserver.blockCacheFree",
      "hbase.regionserver.blockCacheFree",
      "hbase.regionserver.putRequestLatency_99th_percentile",
      "hbase.regionserver.putRequestLatency_99th_percentile",
      "hbase.regionserver.fsWriteLatencyHistogram_75th_percentile",
      "hbase.regionserver.fsWriteLatencyHistogram_75th_percentile",
      "hbase.regionserver.blockCacheHitRatio",
      "hbase.regionserver.blockCacheHitRatio",
      "hbase.regionserver.fsWriteLatency_num_ops",
      "hbase.regionserver.fsWriteLatency_num_ops",
      "jvm.metrics.gcCount",
      "jvm.metrics.gcCount",
      "jvm.metrics.threadsTimedWaiting",
      "jvm.metrics.threadsTimedWaiting",
      "jvm.metrics.logWarn",
      "jvm.metrics.logWarn",
      "jvm.metrics.threadsBlocked",
      "jvm.metrics.threadsBlocked",
      "jvm.metrics.logError",
      "jvm.metrics.logError",
      "jvm.metrics.logFatal",
      "jvm.metrics.logFatal",
      "jvm.metrics.threadsNew",
      "jvm.metrics.threadsNew",
      "jvm.metrics.memHeapCommittedM",
      "jvm.metrics.memHeapCommittedM",
      "jvm.metrics.threadsWaiting",
      "jvm.metrics.threadsWaiting",
      "jvm.metrics.memNonHeapCommittedM",
      "jvm.metrics.memNonHeapCommittedM",
      "jvm.metrics.maxMemoryM",
      "jvm.metrics.maxMemoryM",
      "jvm.metrics.threadsTerminated",
      "jvm.metrics.threadsTerminated",
      "jvm.metrics.threadsRunnable",
      "jvm.metrics.threadsRunnable",
      "jvm.metrics.memNonHeapUsedM",
      "jvm.metrics.memNonHeapUsedM",
      "jvm.metrics.gcTimeMillis",
      "jvm.metrics.gcTimeMillis",
      "jvm.metrics.memHeapUsedM",
      "jvm.metrics.memHeapUsedM",
      "jvm.metrics.logInfo",
      "jvm.metrics.logInfo",
      "load_one",
      "load_one",
      "load_five",
      "load_five",
      "load_fifteen",
      "load_fifteen",
      "mapred.shuffleOutput.shuffle_handler_busy_percent",
      "mapred.shuffleOutput.shuffle_handler_busy_percent",
      "mapred.tasktracker.reduces_running",
      "mapred.tasktracker.reduces_running",
      "mapred.tasktracker.reduceTaskSlots",
      "mapred.tasktracker.reduceTaskSlots",
      "mapred.tasktracker.maps_running",
      "mapred.tasktracker.maps_running",
      "mapred.tasktracker.mapTaskSlots",
      "mapred.tasktracker.mapTaskSlots",
      "swap_free",
      "swap_free",
      "mem_cached",
      "mem_cached",
      "mem_free",
      "mem_free",
      "mem_buffers",
      "mem_buffers",
      "mem_shared",
      "mem_shared",
      "metricssystem.MetricsSystem.publish_max_time",
      "metricssystem.MetricsSystem.publish_max_time",
      "metricssystem.MetricsSystem.publish_num_ops",
      "metricssystem.MetricsSystem.publish_num_ops",
      "metricssystem.MetricsSystem.snapshot_stdev_time",
      "metricssystem.MetricsSystem.snapshot_stdev_time",
      "metricssystem.MetricsSystem.snapshot_imax_time",
      "metricssystem.MetricsSystem.snapshot_imax_time",
      "metricssystem.MetricsSystem.num_sinks",
      "metricssystem.MetricsSystem.num_sinks",
      "metricssystem.MetricsSystem.snapshot_min_time",
      "metricssystem.MetricsSystem.snapshot_min_time",
      "metricssystem.MetricsSystem.snapshot_num_ops",
      "metricssystem.MetricsSystem.snapshot_num_ops",
      "metricssystem.MetricsSystem.snapshot_avg_time",
      "metricssystem.MetricsSystem.snapshot_avg_time",
      "metricssystem.MetricsSystem.dropped_pub_all",
      "metricssystem.MetricsSystem.dropped_pub_all",
      "metricssystem.MetricsSystem.sink.ganglia.latency_avg_time",
      "metricssystem.MetricsSystem.sink.ganglia.latency_avg_time",
      "metricssystem.MetricsSystem.publish_stdev_time",
      "metricssystem.MetricsSystem.publish_stdev_time",
      "metricssystem.MetricsSystem.publish_imin_time",
      "metricssystem.MetricsSystem.publish_imin_time",
      "metricssystem.MetricsSystem.num_sources",
      "metricssystem.MetricsSystem.num_sources",
      "metricssystem.MetricsSystem.snapshot_max_time",
      "metricssystem.MetricsSystem.snapshot_max_time",
      "metricssystem.MetricsSystem.sink.ganglia.latency_num_ops",
      "metricssystem.MetricsSystem.sink.ganglia.latency_num_ops",
      "metricssystem.MetricsSystem.publish_imax_time",
      "metricssystem.MetricsSystem.publish_imax_time",
      "metricssystem.MetricsSystem.publish_min_time",
      "metricssystem.MetricsSystem.publish_min_time",
      "metricssystem.MetricsSystem.publish_avg_time",
      "metricssystem.MetricsSystem.publish_avg_time",
      "metricssystem.MetricsSystem.snapshot_imin_time",
      "metricssystem.MetricsSystem.snapshot_imin_time",
      "bytes_out",
      "bytes_out",
      "pkts_in",
      "pkts_in",
      "pkts_out",
      "pkts_out",
      "bytes_in",
      "bytes_in",
      "proc_total",
      "proc_total",
      "proc_run",
      "proc_run",
      "rpc.metrics.getRegionInfo_num_ops",
      "rpc.metrics.getRegionInfo_num_ops",
      "rpc.metrics.isStopped_avg_time",
      "rpc.metrics.isStopped_avg_time",
      "rpc.metrics.RpcQueueTime_avg_time",
      "rpc.metrics.RpcQueueTime_avg_time",
      "rpc.metrics.isMasterRunning_avg_time",
      "rpc.metrics.isMasterRunning_avg_time",
      "rpc.metrics.delete_num_ops",
      "rpc.metrics.delete_num_ops",
      "rpc.metrics.getClusterStatus_avg_time",
      "rpc.metrics.getClusterStatus_avg_time",
      "rpc.metrics.getFromOnlineRegions_num_ops",
      "rpc.metrics.getFromOnlineRegions_num_ops",
      "rpc.metrics.flushRegion_avg_time",
      "rpc.metrics.flushRegion_avg_time",
      "rpc.metrics.getClosestRowBefore_num_ops",
      "rpc.metrics.getClosestRowBefore_num_ops",
      "rpc.metrics.ReceivedBytes",
      "rpc.metrics.ReceivedBytes",
      "rpc.metrics.addToOnlineRegions_avg_time",
      "rpc.metrics.addToOnlineRegions_avg_time",
      "rpc.metrics.splitRegion_avg_time",
      "rpc.metrics.splitRegion_avg_time",
      "rpc.metrics.regionServerReport_num_ops",
      "rpc.metrics.regionServerReport_num_ops",
      "rpc.metrics.getProtocolSignature_num_ops",
      "rpc.metrics.getProtocolSignature_num_ops",
      "rpc.metrics.offline_avg_time",
      "rpc.metrics.offline_avg_time",
      "rpc.metrics.checkAndDelete_num_ops",
      "rpc.metrics.checkAndDelete_num_ops",
      "rpc.metrics.abort_avg_time",
      "rpc.metrics.abort_avg_time",
      "rpc.metrics.openScanner_avg_time",
      "rpc.metrics.openScanner_avg_time",
      "rpc.metrics.removeFromOnlineRegions_num_ops",
      "rpc.metrics.removeFromOnlineRegions_num_ops",
      "rpc.metrics.stop_num_ops",
      "rpc.metrics.stop_num_ops",
      "rpc.metrics.shutdown_num_ops",
      "rpc.metrics.shutdown_num_ops",
      "rpc.metrics.getCatalogTracker_avg_time",
      "rpc.metrics.getCatalogTracker_avg_time",
      "rpc.metrics.regionServerStartup_avg_time",
      "rpc.metrics.regionServerStartup_avg_time",
      "rpc.metrics.disableTable_num_ops",
      "rpc.metrics.disableTable_num_ops",
      "rpc.metrics.getClosestRowBefore_avg_time",
      "rpc.metrics.getClosestRowBefore_avg_time",
      "rpc.metrics.move_num_ops",
      "rpc.metrics.move_num_ops",
      "rpc.metrics.disableTable_avg_time",
      "rpc.metrics.disableTable_avg_time",
      "rpc.metrics.assign_num_ops",
      "rpc.metrics.assign_num_ops",
      "rpc.metrics.balanceSwitch_num_ops",
      "rpc.metrics.balanceSwitch_num_ops",
      "rpc.metrics.getConfiguration_num_ops",
      "rpc.metrics.getConfiguration_num_ops",
      "rpc.metrics.createTable_num_ops",
      "rpc.metrics.createTable_num_ops",
      "rpc.metrics.getHTableDescriptors_num_ops",
      "rpc.metrics.getHTableDescriptors_num_ops",
      "rpc.metrics.exists_avg_time",
      "rpc.metrics.exists_avg_time",
      "rpc.metrics.lockRow_avg_time",
      "rpc.metrics.lockRow_avg_time",
      "rpc.metrics.openRegions_avg_time",
      "rpc.metrics.openRegions_avg_time",
      "rpc.metrics.bulkLoadHFiles_num_ops",
      "rpc.metrics.bulkLoadHFiles_num_ops",
      "rpc.metrics.RpcSlowResponse_avg_time",
      "rpc.metrics.RpcSlowResponse_avg_time",
      "rpc.metrics.incrementColumnValue_avg_time",
      "rpc.metrics.incrementColumnValue_avg_time",
      "rpc.metrics.execCoprocessor_avg_time",
      "rpc.metrics.execCoprocessor_avg_time",
      "rpc.metrics.openRegion_avg_time",
      "rpc.metrics.openRegion_avg_time",
      "rpc.metrics.getOnlineRegions_avg_time",
      "rpc.metrics.getOnlineRegions_avg_time",
      "rpc.metrics.closeRegion_num_ops",
      "rpc.metrics.closeRegion_num_ops",
      "rpc.metrics.enableTable_avg_time",
      "rpc.metrics.enableTable_avg_time",
      "rpc.metrics.replicateLogEntries_avg_time",
      "rpc.metrics.replicateLogEntries_avg_time",
      "rpc.metrics.NumOpenConnections",
      "rpc.metrics.NumOpenConnections",
      "rpc.metrics.getRegionInfo_avg_time",
      "rpc.metrics.getRegionInfo_avg_time",
      "rpc.metrics.exists_num_ops",
      "rpc.metrics.exists_num_ops",
      "rpc.metrics.compactRegion_num_ops",
      "rpc.metrics.compactRegion_num_ops",
      "rpc.metrics.checkAndDelete_avg_time",
      "rpc.metrics.checkAndDelete_avg_time",
      "rpc.metrics.unassign_num_ops",
      "rpc.metrics.unassign_num_ops",
      "rpc.metrics.createTable_avg_time",
      "rpc.metrics.createTable_avg_time",
      "rpc.metrics.getHTableDescriptors_avg_time",
      "rpc.metrics.getHTableDescriptors_avg_time",
      "rpc.metrics.rollHLogWriter_num_ops",
      "rpc.metrics.rollHLogWriter_num_ops",
      "rpc.metrics.closeRegion_avg_time",
      "rpc.metrics.closeRegion_avg_time",
      "rpc.metrics.RpcQueueTime_num_ops",
      "rpc.metrics.RpcQueueTime_num_ops",
      "rpc.metrics.isMasterRunning_num_ops",
      "rpc.metrics.isMasterRunning_num_ops",
      "rpc.metrics.getClusterStatus_num_ops",
      "rpc.metrics.getClusterStatus_num_ops",
      "rpc.metrics.isStopped_num_ops",
      "rpc.metrics.isStopped_num_ops",
      "rpc.metrics.checkAndPut_num_ops",
      "rpc.metrics.checkAndPut_num_ops",
      "rpc.metrics.isAborted_num_ops",
      "rpc.metrics.isAborted_num_ops",
      "rpc.metrics.RpcProcessingTime_num_ops",
      "rpc.metrics.RpcProcessingTime_num_ops",
      "rpc.metrics.rollHLogWriter_avg_time",
      "rpc.metrics.rollHLogWriter_avg_time",
      "rpc.metrics.openRegions_num_ops",
      "rpc.metrics.openRegions_num_ops",
      "rpc.metrics.lockRow_num_ops",
      "rpc.metrics.lockRow_num_ops",
      "rpc.metrics.unlockRow_avg_time",
      "rpc.metrics.unlockRow_avg_time",
      "rpc.metrics.close_num_ops",
      "rpc.metrics.close_num_ops",
      "rpc.metrics.getZooKeeper_avg_time",
      "rpc.metrics.getZooKeeper_avg_time",
      "rpc.metrics.reportRSFatalError_avg_time",
      "rpc.metrics.reportRSFatalError_avg_time",
      "rpc.metrics.unlockRow_num_ops",
      "rpc.metrics.unlockRow_num_ops",
      "rpc.metrics.flushRegion_num_ops",
      "rpc.metrics.flushRegion_num_ops",
      "rpc.metrics.stopMaster_avg_time",
      "rpc.metrics.stopMaster_avg_time",
      "rpc.metrics.getBlockCacheColumnFamilySummaries_num_ops",
      "rpc.metrics.getBlockCacheColumnFamilySummaries_num_ops",
      "rpc.metrics.getServerName_avg_time",
      "rpc.metrics.getServerName_avg_time",
      "rpc.metrics.getHServerInfo_avg_time",
      "rpc.metrics.getHServerInfo_avg_time",
      "rpc.metrics.RpcSlowResponse_num_ops",
      "rpc.metrics.RpcSlowResponse_num_ops",
      "rpc.metrics.increment_avg_time",
      "rpc.metrics.increment_avg_time",
      "rpc.metrics.getFromOnlineRegions_avg_time",
      "rpc.metrics.getFromOnlineRegions_avg_time",
      "rpc.metrics.get_num_ops",
      "rpc.metrics.get_num_ops",
      "rpc.metrics.reportRSFatalError_num_ops",
      "rpc.metrics.reportRSFatalError_num_ops",
      "rpc.metrics.getZooKeeper_num_ops",
      "rpc.metrics.getZooKeeper_num_ops",
      "rpc.metrics.shutdown_avg_time",
      "rpc.metrics.shutdown_avg_time",
      "rpc.metrics.stop_avg_time",
      "rpc.metrics.stop_avg_time",
      "rpc.metrics.splitRegion_num_ops",
      "rpc.metrics.splitRegion_num_ops",
      "rpc.metrics.addToOnlineRegions_num_ops",
      "rpc.metrics.addToOnlineRegions_num_ops",
      "rpc.metrics.bulkLoadHFiles_avg_time",
      "rpc.metrics.bulkLoadHFiles_avg_time",
      "rpc.metrics.deleteTable_num_ops",
      "rpc.metrics.deleteTable_num_ops",
      "rpc.metrics.getProtocolVersion_num_ops",
      "rpc.metrics.getProtocolVersion_num_ops",
      "rpc.metrics.next_num_ops",
      "rpc.metrics.next_num_ops",
      "rpc.metrics.RpcProcessingTime_avg_time",
      "rpc.metrics.RpcProcessingTime_avg_time",
      "rpc.metrics.execCoprocessor_num_ops",
      "rpc.metrics.execCoprocessor_num_ops",
      "rpc.metrics.checkAndPut_avg_time",
      "rpc.metrics.checkAndPut_avg_time",
      "rpc.metrics.isAborted_avg_time",
      "rpc.metrics.isAborted_avg_time",
      "rpc.metrics.incrementColumnValue_num_ops",
      "rpc.metrics.incrementColumnValue_num_ops",
      "rpc.metrics.deleteColumn_num_ops",
      "rpc.metrics.deleteColumn_num_ops",
      "rpc.metrics.getBlockCacheColumnFamilySummaries_avg_time",
      "rpc.metrics.getBlockCacheColumnFamilySummaries_avg_time",
      "rpc.metrics.checkOOME_num_ops",
      "rpc.metrics.checkOOME_num_ops",
      "rpc.metrics.getProtocolVersion_avg_time",
      "rpc.metrics.getProtocolVersion_avg_time",
      "rpc.metrics.deleteTable_avg_time",
      "rpc.metrics.deleteTable_avg_time",
      "rpc.metrics.next_avg_time",
      "rpc.metrics.next_avg_time",
      "rpc.metrics.rpcAuthorizationSuccesses",
      "rpc.metrics.rpcAuthorizationSuccesses",
      "rpc.metrics.addColumn_avg_time",
      "rpc.metrics.addColumn_avg_time",
      "rpc.metrics.getOnlineRegions_num_ops",
      "rpc.metrics.getOnlineRegions_num_ops",
      "rpc.metrics.modifyColumn_avg_time",
      "rpc.metrics.modifyColumn_avg_time",
      "rpc.metrics.getAlterStatus_avg_time",
      "rpc.metrics.getAlterStatus_avg_time",
      "rpc.metrics.openRegion_num_ops",
      "rpc.metrics.openRegion_num_ops",
      "rpc.metrics.multi_avg_time",
      "rpc.metrics.multi_avg_time",
      "rpc.metrics.put_avg_time",
      "rpc.metrics.put_avg_time",
      "rpc.metrics.SentBytes",
      "rpc.metrics.SentBytes",
      "rpc.metrics.stopMaster_num_ops",
      "rpc.metrics.stopMaster_num_ops",
      "rpc.metrics.callQueueLen",
      "rpc.metrics.callQueueLen",
      "rpc.metrics.getProtocolSignature_avg_time",
      "rpc.metrics.getProtocolSignature_avg_time",
      "rpc.metrics.regionServerReport_avg_time",
      "rpc.metrics.regionServerReport_avg_time",
      "rpc.metrics.getConfiguration_avg_time",
      "rpc.metrics.getConfiguration_avg_time",
      "rpc.metrics.offline_num_ops",
      "rpc.metrics.offline_num_ops",
      "rpc.metrics.move_avg_time",
      "rpc.metrics.move_avg_time",
      "rpc.metrics.assign_avg_time",
      "rpc.metrics.assign_avg_time",
      "rpc.metrics.balanceSwitch_avg_time",
      "rpc.metrics.balanceSwitch_avg_time",
      "rpc.metrics.addColumn_num_ops",
      "rpc.metrics.addColumn_num_ops",
      "rpc.metrics.rpcAuthorizationFailures",
      "rpc.metrics.rpcAuthorizationFailures",
      "rpc.metrics.unassign_avg_time",
      "rpc.metrics.unassign_avg_time",
      "rpc.metrics.enableTable_num_ops",
      "rpc.metrics.enableTable_num_ops",
      "rpc.metrics.compactRegion_avg_time",
      "rpc.metrics.compactRegion_avg_time",
      "rpc.metrics.balance_num_ops",
      "rpc.metrics.balance_num_ops",
      "rpc.metrics.modifyTable_num_ops",
      "rpc.metrics.modifyTable_num_ops",
      "rpc.metrics.close_avg_time",
      "rpc.metrics.close_avg_time",
      "rpc.metrics.getHServerInfo_num_ops",
      "rpc.metrics.getHServerInfo_num_ops",
      "rpc.metrics.get_avg_time",
      "rpc.metrics.get_avg_time",
      "rpc.metrics.getServerName_num_ops",
      "rpc.metrics.getServerName_num_ops",
      "rpc.metrics.openScanner_num_ops",
      "rpc.metrics.openScanner_num_ops",
      "rpc.metrics.deleteColumn_avg_time",
      "rpc.metrics.deleteColumn_avg_time",
      "rpc.metrics.checkOOME_avg_time",
      "rpc.metrics.checkOOME_avg_time",
      "rpc.metrics.abort_num_ops",
      "rpc.metrics.abort_num_ops",
      "rpc.metrics.modifyColumn_num_ops",
      "rpc.metrics.modifyColumn_num_ops",
      "rpc.metrics.getAlterStatus_num_ops",
      "rpc.metrics.getAlterStatus_num_ops",
      "rpc.metrics.replicateLogEntries_num_ops",
      "rpc.metrics.replicateLogEntries_num_ops",
      "rpc.metrics.modifyTable_avg_time",
      "rpc.metrics.modifyTable_avg_time",
      "rpc.metrics.balance_avg_time",
      "rpc.metrics.balance_avg_time",
      "rpc.metrics.rpcAuthenticationFailures",
      "rpc.metrics.rpcAuthenticationFailures",
      "rpc.metrics.rpcAuthenticationSuccesses",
      "rpc.metrics.rpcAuthenticationSuccesses",
      "rpc.metrics.delete_avg_time",
      "rpc.metrics.delete_avg_time",
      "rpc.metrics.increment_num_ops",
      "rpc.metrics.increment_num_ops",
      "rpc.metrics.getCatalogTracker_num_ops",
      "rpc.metrics.getCatalogTracker_num_ops",
      "rpc.metrics.regionServerStartup_num_ops",
      "rpc.metrics.regionServerStartup_num_ops",
      "rpc.metrics.removeFromOnlineRegions_avg_time",
      "rpc.metrics.removeFromOnlineRegions_avg_time",
      "rpc.metrics.multi_num_ops",
      "rpc.metrics.multi_num_ops",
      "rpc.metrics.put_num_ops",
      "rpc.metrics.put_num_ops",
      "rpc.metrics.abort.aboveOneSec._num_ops",
      "rpc.metrics.abort.aboveOneSec._num_ops",
      "rpc.metrics.abort.aboveOneSec._avg_time",
      "rpc.metrics.abort.aboveOneSec._avg_time",
      "rpc.metrics.addToOnlineRegions.aboveOneSec._avg_time",
      "rpc.metrics.addToOnlineRegions.aboveOneSec._avg_time",
      "rpc.metrics.addToOnlineRegions.aboveOneSec._num_ops",
      "rpc.metrics.addToOnlineRegions.aboveOneSec._num_ops",
      "rpc.metrics.bulkLoadHFiles.aboveOneSec._avg_time",
      "rpc.metrics.bulkLoadHFiles.aboveOneSec._avg_time",
      "rpc.metrics.bulkLoadHFiles.aboveOneSec._num_ops",
      "rpc.metrics.bulkLoadHFiles.aboveOneSec._num_ops",
      "rpc.metrics.checkAndDelete.aboveOneSec._avg_time",
      "rpc.metrics.checkAndDelete.aboveOneSec._avg_time",
      "rpc.metrics.checkAndDelete.aboveOneSec._num_ops",
      "rpc.metrics.checkAndDelete.aboveOneSec._num_ops",
      "rpc.metrics.checkAndPut.aboveOneSec._avg_time",
      "rpc.metrics.checkAndPut.aboveOneSec._avg_time",
      "rpc.metrics.checkAndPut.aboveOneSec._num_ops",
      "rpc.metrics.checkAndPut.aboveOneSec._num_ops",
      "rpc.metrics.checkOOME.aboveOneSec._num_ops",
      "rpc.metrics.checkOOME.aboveOneSec._num_ops",
      "rpc.metrics.checkOOME.aboveOneSec._avg_time",
      "rpc.metrics.checkOOME.aboveOneSec._avg_time",
      "rpc.metrics.close.aboveOneSec._avg_time",
      "rpc.metrics.close.aboveOneSec._avg_time",
      "rpc.metrics.close.aboveOneSec._num_ops",
      "rpc.metrics.close.aboveOneSec._num_ops",
      "rpc.metrics.closeRegion.aboveOneSec._avg_time",
      "rpc.metrics.closeRegion.aboveOneSec._avg_time",
      "rpc.metrics.closeRegion.aboveOneSec._num_ops",
      "rpc.metrics.closeRegion.aboveOneSec._num_ops",
      "rpc.metrics.compactRegion.aboveOneSec._num_ops",
      "rpc.metrics.compactRegion.aboveOneSec._num_ops",
      "rpc.metrics.compactRegion.aboveOneSec._avg_time",
      "rpc.metrics.compactRegion.aboveOneSec._avg_time",
      "rpc.metrics.delete.aboveOneSec._num_ops",
      "rpc.metrics.delete.aboveOneSec._num_ops",
      "rpc.metrics.delete.aboveOneSec._avg_time",
      "rpc.metrics.delete.aboveOneSec._avg_time",
      "rpc.metrics.execCoprocessor.aboveOneSec._avg_time",
      "rpc.metrics.execCoprocessor.aboveOneSec._avg_time",
      "rpc.metrics.execCoprocessor.aboveOneSec._num_ops",
      "rpc.metrics.execCoprocessor.aboveOneSec._num_ops",
      "rpc.metrics.exists.aboveOneSec._num_ops",
      "rpc.metrics.exists.aboveOneSec._num_ops",
      "rpc.metrics.exists.aboveOneSec._avg_time",
      "rpc.metrics.exists.aboveOneSec._avg_time",
      "rpc.metrics.flushRegion.aboveOneSec._avg_time",
      "rpc.metrics.flushRegion.aboveOneSec._avg_time",
      "rpc.metrics.flushRegion.aboveOneSec._num_ops",
      "rpc.metrics.flushRegion.aboveOneSec._num_ops",
      "rpc.metrics.get.aboveOneSec._avg_time",
      "rpc.metrics.get.aboveOneSec._avg_time",
      "rpc.metrics.get.aboveOneSec._num_ops",
      "rpc.metrics.get.aboveOneSec._num_ops",
      "rpc.metrics.getBlockCacheColumnFamilySummaries.aboveOneSec._num_ops",
      "rpc.metrics.getBlockCacheColumnFamilySummaries.aboveOneSec._num_ops",
      "rpc.metrics.getBlockCacheColumnFamilySummaries.aboveOneSec._avg_time",
      "rpc.metrics.getBlockCacheColumnFamilySummaries.aboveOneSec._avg_time",
      "rpc.metrics.getCatalogTracker.aboveOneSec._avg_time",
      "rpc.metrics.getCatalogTracker.aboveOneSec._avg_time",
      "rpc.metrics.getCatalogTracker.aboveOneSec._num_ops",
      "rpc.metrics.getCatalogTracker.aboveOneSec._num_ops",
      "rpc.metrics.getClosestRowBefore.aboveOneSec._avg_time",
      "rpc.metrics.getClosestRowBefore.aboveOneSec._avg_time",
      "rpc.metrics.getClosestRowBefore.aboveOneSec._num_ops",
      "rpc.metrics.getClosestRowBefore.aboveOneSec._num_ops",
      "rpc.metrics.getConfiguration.aboveOneSec._num_ops",
      "rpc.metrics.getConfiguration.aboveOneSec._num_ops",
      "rpc.metrics.getConfiguration.aboveOneSec._avg_time",
      "rpc.metrics.getConfiguration.aboveOneSec._avg_time",
      "rpc.metrics.getFromOnlineRegions.aboveOneSec._num_ops",
      "rpc.metrics.getFromOnlineRegions.aboveOneSec._num_ops",
      "rpc.metrics.getFromOnlineRegions.aboveOneSec._avg_time",
      "rpc.metrics.getFromOnlineRegions.aboveOneSec._avg_time",
      "rpc.metrics.getHServerInfo.aboveOneSec._num_ops",
      "rpc.metrics.getHServerInfo.aboveOneSec._num_ops",
      "rpc.metrics.getHServerInfo.aboveOneSec._avg_time",
      "rpc.metrics.getHServerInfo.aboveOneSec._avg_time",
      "rpc.metrics.getOnlineRegions.aboveOneSec._avg_time",
      "rpc.metrics.getOnlineRegions.aboveOneSec._avg_time",
      "rpc.metrics.getOnlineRegions.aboveOneSec._num_ops",
      "rpc.metrics.getOnlineRegions.aboveOneSec._num_ops",
      "rpc.metrics.getProtocolSignature.aboveOneSec._avg_time",
      "rpc.metrics.getProtocolSignature.aboveOneSec._avg_time",
      "rpc.metrics.getProtocolSignature.aboveOneSec._num_ops",
      "rpc.metrics.getProtocolSignature.aboveOneSec._num_ops",
      "rpc.metrics.getProtocolVersion.aboveOneSec._num_ops",
      "rpc.metrics.getProtocolVersion.aboveOneSec._num_ops",
      "rpc.metrics.getProtocolVersion.aboveOneSec._avg_time",
      "rpc.metrics.getProtocolVersion.aboveOneSec._avg_time",
      "rpc.metrics.getRegionInfo.aboveOneSec._num_ops",
      "rpc.metrics.getRegionInfo.aboveOneSec._num_ops",
      "rpc.metrics.getRegionInfo.aboveOneSec._avg_time",
      "rpc.metrics.getRegionInfo.aboveOneSec._avg_time",
      "rpc.metrics.getServerName.aboveOneSec._num_ops",
      "rpc.metrics.getServerName.aboveOneSec._num_ops",
      "rpc.metrics.getServerName.aboveOneSec._avg_time",
      "rpc.metrics.getServerName.aboveOneSec._avg_time",
      "rpc.metrics.getZooKeeper.aboveOneSec._num_ops",
      "rpc.metrics.getZooKeeper.aboveOneSec._num_ops",
      "rpc.metrics.getZooKeeper.aboveOneSec._avg_time",
      "rpc.metrics.getZooKeeper.aboveOneSec._avg_time",
      "rpc.metrics.increment.aboveOneSec._num_ops",
      "rpc.metrics.increment.aboveOneSec._num_ops",
      "rpc.metrics.increment.aboveOneSec._avg_time",
      "rpc.metrics.increment.aboveOneSec._avg_time",
      "rpc.metrics.incrementColumnValue.aboveOneSec._avg_time",
      "rpc.metrics.incrementColumnValue.aboveOneSec._avg_time",
      "rpc.metrics.incrementColumnValue.aboveOneSec._num_ops",
      "rpc.metrics.incrementColumnValue.aboveOneSec._num_ops",
      "rpc.metrics.isAborted.aboveOneSec._avg_time",
      "rpc.metrics.isAborted.aboveOneSec._avg_time",
      "rpc.metrics.isAborted.aboveOneSec._num_ops",
      "rpc.metrics.isAborted.aboveOneSec._num_ops",
      "rpc.metrics.isStopped.aboveOneSec._avg_time",
      "rpc.metrics.isStopped.aboveOneSec._avg_time",
      "rpc.metrics.isStopped.aboveOneSec._num_ops",
      "rpc.metrics.isStopped.aboveOneSec._num_ops",
      "rpc.metrics.lockRow.aboveOneSec._num_ops",
      "rpc.metrics.lockRow.aboveOneSec._num_ops",
      "rpc.metrics.lockRow.aboveOneSec._avg_time",
      "rpc.metrics.lockRow.aboveOneSec._avg_time",
      "rpc.metrics.multi.aboveOneSec._num_ops",
      "rpc.metrics.multi.aboveOneSec._num_ops",
      "rpc.metrics.multi.aboveOneSec._avg_time",
      "rpc.metrics.multi.aboveOneSec._avg_time",
      "rpc.metrics.next.aboveOneSec._num_ops",
      "rpc.metrics.next.aboveOneSec._num_ops",
      "rpc.metrics.next.aboveOneSec._avg_time",
      "rpc.metrics.next.aboveOneSec._avg_time",
      "rpc.metrics.openRegion.aboveOneSec._avg_time",
      "rpc.metrics.openRegion.aboveOneSec._avg_time",
      "rpc.metrics.openRegion.aboveOneSec._num_ops",
      "rpc.metrics.openRegion.aboveOneSec._num_ops",
      "rpc.metrics.openRegions.aboveOneSec._num_ops",
      "rpc.metrics.openRegions.aboveOneSec._num_ops",
      "rpc.metrics.openRegions.aboveOneSec._avg_time",
      "rpc.metrics.openRegions.aboveOneSec._avg_time",
      "rpc.metrics.openScanner.aboveOneSec._num_ops",
      "rpc.metrics.openScanner.aboveOneSec._num_ops",
      "rpc.metrics.openScanner.aboveOneSec._avg_time",
      "rpc.metrics.openScanner.aboveOneSec._avg_time",
      "rpc.metrics.put.aboveOneSec._num_ops",
      "rpc.metrics.put.aboveOneSec._num_ops",
      "rpc.metrics.put.aboveOneSec._avg_time",
      "rpc.metrics.put.aboveOneSec._avg_time",
      "rpc.metrics.removeFromOnlineRegions.aboveOneSec._avg_time",
      "rpc.metrics.removeFromOnlineRegions.aboveOneSec._avg_time",
      "rpc.metrics.removeFromOnlineRegions.aboveOneSec._num_ops",
      "rpc.metrics.removeFromOnlineRegions.aboveOneSec._num_ops",
      "rpc.metrics.replicateLogEntries.aboveOneSec._avg_time",
      "rpc.metrics.replicateLogEntries.aboveOneSec._avg_time",
      "rpc.metrics.replicateLogEntries.aboveOneSec._num_ops",
      "rpc.metrics.replicateLogEntries.aboveOneSec._num_ops",
      "rpc.metrics.rollHLogWriter.aboveOneSec._avg_time",
      "rpc.metrics.rollHLogWriter.aboveOneSec._avg_time",
      "rpc.metrics.rollHLogWriter.aboveOneSec._num_ops",
      "rpc.metrics.rollHLogWriter.aboveOneSec._num_ops",
      "rpc.metrics.splitRegion.aboveOneSec._avg_time",
      "rpc.metrics.splitRegion.aboveOneSec._avg_time",
      "rpc.metrics.splitRegion.aboveOneSec._num_ops",
      "rpc.metrics.splitRegion.aboveOneSec._num_ops",
      "rpc.metrics.stop.aboveOneSec._num_ops",
      "rpc.metrics.stop.aboveOneSec._num_ops",
      "rpc.metrics.stop.aboveOneSec._avg_time",
      "rpc.metrics.stop.aboveOneSec._avg_time",
      "rpc.metrics.unlockRow.aboveOneSec._num_ops",
      "rpc.metrics.unlockRow.aboveOneSec._num_ops",
      "rpc.metrics.unlockRow.aboveOneSec._avg_time",
      "rpc.metrics.unlockRow.aboveOneSec._avg_time"
  };
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/ClusterDefinition.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.gsinstaller;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

/**
 * Defines the cluster created by gsInstaller.
 */
public class ClusterDefinition {

  private static final String CLUSTER_DEFINITION_FILE = "gsInstaller-hosts.txt";
  private static final String DEFAULT_CLUSTER_NAME    = "ambari";
  private static final String CLUSTER_NAME_TAG        = "CLUSTER=";

  private final String clusterName;
  private final Set<String> services = new HashSet<String>();
  private final Set<String> hosts = new HashSet<String>();
  private final Map<String, Set<String>> components = new HashMap<String, Set<String>>();
  private final Map<String, Map<String, Set<String>>> hostComponents = new HashMap<String, Map<String, Set<String>>>();


  // ----- Constructors ------------------------------------------------------

  /**
   * Create a cluster definition.
   */
  public ClusterDefinition() {
    this.clusterName = readClusterDefinition();
  }


  // ----- ClusterDefinition -------------------------------------------------

  /**
   * Get the name of the cluster.
   *
   * @return the cluster name
   */
  public String getClusterName() {
    return clusterName;
  }

  /**
   * Get the services for the cluster.
   *
   * @return the set of service names
   */
  public Set<String> getServices() {
    return services;
  }

  /**
   * Get the hosts for the cluster.
   *
   * @return the set of hosts names
   */
  public Set<String> getHosts() {
    return hosts;
  }

  /**
   * Get the components for the given service.
   *
   * @param service  the service name
   *
   * @return the set of component names for the given service name
   */
  public Set<String> getComponents(String service) {
    return components.get(service);
  }

  /**
   * Get the host components for the given service and host.
   *
   * @param service  the service name
   * @param host     the host name
   *
   * @return the set of host component names for the given service and host names
   */
  public Set<String> getHostComponents(String service, String host) {
    Set<String> resultSet = null;
    Map<String, Set<String>> serviceHostComponents = hostComponents.get(service);
    if (serviceHostComponents != null) {
      resultSet = serviceHostComponents.get(host);
    }
    return resultSet == null ? Collections.<String>emptySet() : resultSet;
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Read the gsInstaller cluster definition file.
   *
   * @return the cluster name
   */
  private String readClusterDefinition() {
    String clusterName = DEFAULT_CLUSTER_NAME;

    try {
      InputStream    is = this.getClass().getClassLoader().getResourceAsStream(CLUSTER_DEFINITION_FILE);
      BufferedReader br = new BufferedReader(new InputStreamReader(is));

      String line;
      while ((line = br.readLine()) != null) {
        line = line.trim();
        if (line.startsWith(CLUSTER_NAME_TAG)) {
          clusterName = line.substring(CLUSTER_NAME_TAG.length());
        }
        else {
          String[] parts = line.split("\\s+");
          assert(parts.length == 3);

          String serviceName   = parts[0];
          String componentName = parts[1];
          String hostName      = parts[2];

          services.add(serviceName);
          Set<String> serviceComponents = components.get(serviceName);
          if (serviceComponents == null) {
            serviceComponents = new HashSet<String>();
            components.put(serviceName, serviceComponents);
          }
          serviceComponents.add(componentName);

          Map<String, Set<String>> serviceHostComponents = hostComponents.get(serviceName);
          if (serviceHostComponents == null) {
            serviceHostComponents = new HashMap<String, Set<String>>();
            hostComponents.put(serviceName, serviceHostComponents);
          }

          Set<String> hostHostComponents = serviceHostComponents.get(hostName);
          if (hostHostComponents == null) {
            hostHostComponents = new HashSet<String>();
            serviceHostComponents.put(hostName, hostHostComponents);
          }
          hostHostComponents.add(componentName);
          hosts.add(hostName);
        }
      }
    } catch (IOException e) {
      String msg = "Caught exception reading " + CLUSTER_DEFINITION_FILE + ".";
      throw new IllegalStateException(msg, e);
    }
    return clusterName;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/GSInstallerClusterProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.gsinstaller;

import org.apache.ambari.server.controller.internal.ResourceImpl;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Map;
import java.util.Set;

/**
 * A cluster resource provider for a gsInstaller defined cluster.
 */
public class GSInstallerClusterProvider extends GSInstallerResourceProvider{

  // Clusters
  protected static final String CLUSTER_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("Clusters", "cluster_name");


  // ----- Constructors ------------------------------------------------------

  /**
   * Construct a resource provider based on the given cluster definition.
   *
   * @param clusterDefinition  the cluster definition
   */
  public GSInstallerClusterProvider(ClusterDefinition clusterDefinition) {
    super(clusterDefinition);
    initClusterResources();
  }


  // ----- ResourceProvider --------------------------------------------------

  @Override
  public Set<String> getPropertyIdsForSchema() {
    return PropertyHelper.getPropertyIds(Resource.Type.Cluster);
  }

  @Override
  public Map<Resource.Type, String> getKeyPropertyIds() {
    return PropertyHelper.getKeyPropertyIds(Resource.Type.Cluster);
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Create the resources based on the cluster definition.
   */
  private void initClusterResources() {
    Resource cluster = new ResourceImpl(Resource.Type.Cluster);
    cluster.setProperty(CLUSTER_NAME_PROPERTY_ID, getClusterDefinition().getClusterName());
    addResource(cluster);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/GSInstallerComponentProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.gsinstaller;

import org.apache.ambari.server.controller.internal.ResourceImpl;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Map;
import java.util.Set;

/**
 * A component resource provider for a gsInstaller defined cluster.
 */
public class GSInstallerComponentProvider extends GSInstallerResourceProvider{

  // Components
  protected static final String COMPONENT_CLUSTER_NAME_PROPERTY_ID    = PropertyHelper.getPropertyId("ServiceComponentInfo", "cluster_name");
  protected static final String COMPONENT_SERVICE_NAME_PROPERTY_ID    = PropertyHelper.getPropertyId("ServiceComponentInfo", "service_name");
  protected static final String COMPONENT_COMPONENT_NAME_PROPERTY_ID  = PropertyHelper.getPropertyId("ServiceComponentInfo", "component_name");


  // ----- Constructors ------------------------------------------------------

  /**
   * Construct a resource provider based on the given cluster definition.
   *
   * @param clusterDefinition  the cluster definition
   */
  public GSInstallerComponentProvider(ClusterDefinition clusterDefinition) {
    super(clusterDefinition);
    initComponentResources();
  }


  // ----- ResourceProvider --------------------------------------------------

  @Override
  public Set<String> getPropertyIdsForSchema() {
    return PropertyHelper.getPropertyIds(Resource.Type.Component);
  }

  @Override
  public Map<Resource.Type, String> getKeyPropertyIds() {
    return PropertyHelper.getKeyPropertyIds(Resource.Type.Component);
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Create the resources based on the cluster definition.
   */
  private void initComponentResources() {
    String      clusterName = getClusterDefinition().getClusterName();
    Set<String> services    = getClusterDefinition().getServices();
    for (String serviceName : services) {
      Set<String> components = getClusterDefinition().getComponents(serviceName);
      for (String componentName : components) {
        Resource component = new ResourceImpl(Resource.Type.Component);
        component.setProperty(COMPONENT_CLUSTER_NAME_PROPERTY_ID, clusterName);
        component.setProperty(COMPONENT_SERVICE_NAME_PROPERTY_ID, serviceName);
        component.setProperty(COMPONENT_COMPONENT_NAME_PROPERTY_ID, componentName);
        addResource(component);
      }
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/GSInstallerHostComponentProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.gsinstaller;

import org.apache.ambari.server.controller.internal.ResourceImpl;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Map;
import java.util.Set;

/**
 * A host component resource provider for a gsInstaller defined cluster.
 */
public class GSInstallerHostComponentProvider extends GSInstallerResourceProvider{

  // Host Components
  protected static final String HOST_COMPONENT_CLUSTER_NAME_PROPERTY_ID   = PropertyHelper.getPropertyId("HostRoles", "cluster_name");
  protected static final String HOST_COMPONENT_SERVICE_NAME_PROPERTY_ID   = PropertyHelper.getPropertyId("HostRoles", "service_name");
  protected static final String HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("HostRoles", "component_name");
  protected static final String HOST_COMPONENT_HOST_NAME_PROPERTY_ID      = PropertyHelper.getPropertyId("HostRoles", "host_name");


  // ----- Constructors ------------------------------------------------------

  /**
   * Construct a resource provider based on the given cluster definition.
   *
   * @param clusterDefinition  the cluster definition
   */
  public GSInstallerHostComponentProvider(ClusterDefinition clusterDefinition) {
    super(clusterDefinition);
    initHostComponentResources();
  }


  // ----- ResourceProvider --------------------------------------------------

  @Override
  public Set<String> getPropertyIdsForSchema() {
    return PropertyHelper.getPropertyIds(Resource.Type.HostComponent);
  }

  @Override
  public Map<Resource.Type, String> getKeyPropertyIds() {
    return PropertyHelper.getKeyPropertyIds(Resource.Type.HostComponent);
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Create the resources based on the cluster definition.
   */
  private void initHostComponentResources() {
    String      clusterName = getClusterDefinition().getClusterName();
    Set<String> services    = getClusterDefinition().getServices();
    for (String serviceName : services) {
      Set<String> hosts = getClusterDefinition().getHosts();
      for (String hostName : hosts) {
        Set<String> hostComponents = getClusterDefinition().getHostComponents(serviceName, hostName);
        for (String componentName : hostComponents) {
          Resource hostComponent = new ResourceImpl(Resource.Type.HostComponent);
          hostComponent.setProperty(HOST_COMPONENT_CLUSTER_NAME_PROPERTY_ID, clusterName);
          hostComponent.setProperty(HOST_COMPONENT_SERVICE_NAME_PROPERTY_ID, serviceName);
          hostComponent.setProperty(HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID, componentName);
          hostComponent.setProperty(HOST_COMPONENT_HOST_NAME_PROPERTY_ID, hostName);
          addResource(hostComponent);
        }
      }
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/GSInstallerHostProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.gsinstaller;

import org.apache.ambari.server.controller.internal.ResourceImpl;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Map;
import java.util.Set;

/**
 * A host resource provider for a gsInstaller defined cluster.
 */
public class GSInstallerHostProvider extends GSInstallerResourceProvider{

  // Hosts
  protected static final String HOST_CLUSTER_NAME_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "cluster_name");
  protected static final String HOST_NAME_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "host_name");


  // ----- Constructors ------------------------------------------------------

  /**
   * Construct a resource provider based on the given cluster definition.
   *
   * @param clusterDefinition  the cluster definition
   */
  public GSInstallerHostProvider(ClusterDefinition clusterDefinition) {
    super(clusterDefinition);
    initHostResources();
  }


  // ----- ResourceProvider --------------------------------------------------

  @Override
  public Set<String> getPropertyIdsForSchema() {
    return PropertyHelper.getPropertyIds(Resource.Type.Host);
  }

  @Override
  public Map<Resource.Type, String> getKeyPropertyIds() {
    return PropertyHelper.getKeyPropertyIds(Resource.Type.Host);
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Create the resources based on the cluster definition.
   */
  private void initHostResources() {
    String      clusterName = getClusterDefinition().getClusterName();
    Set<String> hosts       = getClusterDefinition().getHosts();

    for (String hostName : hosts) {
      Resource host = new ResourceImpl(Resource.Type.Host);
      host.setProperty(HOST_CLUSTER_NAME_PROPERTY_ID, clusterName);
      host.setProperty(HOST_NAME_PROPERTY_ID, hostName);
      addResource(host);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/GSInstallerNoOpProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.gsinstaller;

import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Map;
import java.util.Set;

/**
 * A NO-OP resource provider for a gsInstaller defined cluster.
 */
public class GSInstallerNoOpProvider extends GSInstallerResourceProvider{

  private final Resource.Type type;

  // ----- Constructors ------------------------------------------------------

  public GSInstallerNoOpProvider(Resource.Type type, ClusterDefinition clusterDefinition) {
    super(clusterDefinition);
    this.type = type;
  }


  // ----- ResourceProvider --------------------------------------------------

  @Override
  public Set<String> getPropertyIdsForSchema() {
    return PropertyHelper.getPropertyIds(type);
  }

  @Override
  public Map<Resource.Type, String> getKeyPropertyIds() {
    return PropertyHelper.getKeyPropertyIds(type);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/GSInstallerProviderModule.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.gsinstaller;

import org.apache.ambari.server.controller.internal.AbstractProviderModule;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.ResourceProvider;

/**
 * A provider module implementation that uses the GSInstaller resource provider.
 */
public class GSInstallerProviderModule extends AbstractProviderModule {

  private final ClusterDefinition clusterDefinition;

  // ----- Constructors ------------------------------------------------------

  public GSInstallerProviderModule() {
    clusterDefinition = new ClusterDefinition();
  }

  // ----- utility methods ---------------------------------------------------

  @Override
  protected ResourceProvider createResourceProvider(Resource.Type type) {
    return GSInstallerResourceProvider.getResourceProvider(type, clusterDefinition);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/GSInstallerResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.gsinstaller;

import org.apache.ambari.server.controller.internal.ResourceImpl;
import org.apache.ambari.server.controller.spi.NoSuchParentResourceException;
import org.apache.ambari.server.controller.spi.NoSuchResourceException;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.Request;
import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.ResourceAlreadyExistsException;
import org.apache.ambari.server.controller.spi.ResourceProvider;
import org.apache.ambari.server.controller.spi.SystemException;
import org.apache.ambari.server.controller.spi.UnsupportedPropertyException;

import java.util.HashSet;
import java.util.Set;

/**
 * An abstract resource provider for a gsInstaller defined cluster.
 */
public abstract class GSInstallerResourceProvider implements ResourceProvider {

  private final ClusterDefinition clusterDefinition;

  private final Set<Resource> resources = new HashSet<Resource>();


  // ----- Constructors ------------------------------------------------------

  /**
   * Construct a resource provider based on the given cluster definition.
   *
   * @param clusterDefinition  the cluster definition
   */
  public GSInstallerResourceProvider(ClusterDefinition clusterDefinition) {
    this.clusterDefinition = clusterDefinition;
  }


  // ----- ResourceProvider --------------------------------------------------

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException, UnsupportedPropertyException, ResourceAlreadyExistsException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Management operations are not supported");
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    Set<Resource> resultSet = new HashSet<Resource>();

    for (Resource resource : resources) {
      if (predicate == null || predicate.evaluate(resource)) {
        resultSet.add(new ResourceImpl(resource));
      }
    }
    return resultSet;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Management operations are not supported");
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Management operations are not supported");
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    propertyIds = new HashSet<String>(propertyIds);
    propertyIds.removeAll(getPropertyIdsForSchema());
    return propertyIds;
  }


  // ----- accessors ---------------------------------------------------------

  /**
   * Get the configuration provider.
   *
   * @return the configuration provider
   */
  protected ClusterDefinition getClusterDefinition() {
    return clusterDefinition;
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Add a resource to the set of resources provided by this provider.
   *
   * @param resource  the resource to add
   */
  protected void addResource(Resource resource) {
    resources.add(resource);
  }

  /**
   * Factory method for obtaining a resource provider based on a given type.
   *
   * @param type               the resource type
   * @param clusterDefinition  the cluster definition
   *
   * @return a new resource provider
   */
  public static ResourceProvider getResourceProvider(Resource.Type type,
                                                     ClusterDefinition clusterDefinition) {
    switch (type) {
      case Cluster:
        return new GSInstallerClusterProvider(clusterDefinition);
      case Service:
        return new GSInstallerServiceProvider(clusterDefinition);
      case Component:
        return new GSInstallerComponentProvider(clusterDefinition);
      case Host:
        return new GSInstallerHostProvider(clusterDefinition);
      case HostComponent:
        return new GSInstallerHostComponentProvider(clusterDefinition);
      default:
        return new GSInstallerNoOpProvider(type, clusterDefinition);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/gsinstaller/GSInstallerServiceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.gsinstaller;

import org.apache.ambari.server.controller.internal.ResourceImpl;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Map;
import java.util.Set;

/**
 * A service resource provider for a gsInstaller defined cluster.
 */
public class GSInstallerServiceProvider extends GSInstallerResourceProvider{

  // Services
  protected static final String SERVICE_CLUSTER_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("ServiceInfo", "cluster_name");
  protected static final String SERVICE_SERVICE_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("ServiceInfo", "service_name");


  // ----- Constructors ------------------------------------------------------

  /**
   * Construct a resource provider based on the given cluster definition.
   *
   * @param clusterDefinition  the cluster definition
   */
  public GSInstallerServiceProvider(ClusterDefinition clusterDefinition) {
    super(clusterDefinition);
    initServiceResources();
  }


  // ----- ResourceProvider --------------------------------------------------

  @Override
  public Set<String> getPropertyIdsForSchema() {
    return PropertyHelper.getPropertyIds(Resource.Type.Service);
  }

  @Override
  public Map<Resource.Type, String> getKeyPropertyIds() {
    return PropertyHelper.getKeyPropertyIds(Resource.Type.Service);
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Create the resources based on the cluster definition.
   */
  private void initServiceResources() {
    String      clusterName = getClusterDefinition().getClusterName();
    Set<String> services    = getClusterDefinition().getServices();

    for (String serviceName : services) {
      Resource service = new ResourceImpl(Resource.Type.Service);
      service.setProperty(SERVICE_CLUSTER_NAME_PROPERTY_ID, clusterName);
      service.setProperty(SERVICE_SERVICE_NAME_PROPERTY_ID, serviceName);
      addResource(service);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/AbstractProviderModule.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.AmbariServer;
import org.apache.ambari.server.controller.ganglia.GangliaComponentPropertyProvider;
import org.apache.ambari.server.controller.ganglia.GangliaHostComponentPropertyProvider;
import org.apache.ambari.server.controller.ganglia.GangliaHostPropertyProvider;
import org.apache.ambari.server.controller.ganglia.GangliaReportPropertyProvider;
import org.apache.ambari.server.controller.ganglia.GangliaHostProvider;
import org.apache.ambari.server.controller.jmx.JMXHostProvider;
import org.apache.ambari.server.controller.jmx.JMXPropertyProvider;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PredicateBuilder;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.apache.ambari.server.controller.AmbariManagementController;

import com.google.inject.Inject;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Set;

/**
 * An abstract provider module implementation.
 */
public abstract class AbstractProviderModule implements ProviderModule, ResourceProviderObserver, JMXHostProvider, GangliaHostProvider {

  private static final String HOST_CLUSTER_NAME_PROPERTY_ID             = PropertyHelper.getPropertyId("Hosts", "cluster_name");
  private static final String HOST_NAME_PROPERTY_ID                     = PropertyHelper.getPropertyId("Hosts", "host_name");
  private static final String HOST_IP_PROPERTY_ID                       = PropertyHelper.getPropertyId("Hosts", "ip");
  private static final String CLUSTER_NAME_PROPERTY_ID                  = PropertyHelper.getPropertyId("Clusters", "cluster_name");
  private static final String HOST_COMPONENT_CLUSTER_NAME_PROPERTY_ID   = PropertyHelper.getPropertyId("HostRoles", "cluster_name");
  private static final String HOST_COMPONENT_HOST_NAME_PROPERTY_ID      = PropertyHelper.getPropertyId("HostRoles", "host_name");
  private static final String HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("HostRoles", "component_name");
  private static final String GANGLIA_SERVER                            = "GANGLIA_SERVER";
  private static final String GANGLIA_MONITOR                           = "GANGLIA_MONITOR";
  private static final String GANGLIA_SERVER_OLD                        = "GANGLIA_MONITOR_SERVER";

  /**
   * The map of resource providers.
   */
  private final Map<Resource.Type, ResourceProvider> resourceProviders = new HashMap<Resource.Type, ResourceProvider>();

  /**
   * The map of lists of property providers.
   */
  private final Map<Resource.Type,List<PropertyProvider>> propertyProviders = new HashMap<Resource.Type, List<PropertyProvider>>();

  @Inject
  private AmbariManagementController managementController;

  /**
   * The map of hosts.
   */
  private Map<String, Map<String, String>> clusterHostMap;

  private Map<String, Map<String, String>> clusterHostComponentMap;

  /**
   * The host name of the Ganglia collector.
   */
  private Map<String, String> clusterGangliaCollectorMap;

  private volatile boolean initialized = false;

  protected final static Logger LOG =
      LoggerFactory.getLogger(AbstractProviderModule.class);


  // ----- Constructors ------------------------------------------------------

  /**
   * Create a default provider module.
   */
  public AbstractProviderModule() {
    if (managementController == null) {
      managementController = AmbariServer.getController();
    }
  }


  // ----- ProviderModule ----------------------------------------------------

  @Override
  public ResourceProvider getResourceProvider(Resource.Type type) {
    if (!propertyProviders.containsKey(type)) {
      registerResourceProvider(type);
    }
    return resourceProviders.get(type);
  }

  @Override
  public List<PropertyProvider> getPropertyProviders(Resource.Type type) {

    if (!propertyProviders.containsKey(type)) {
      createPropertyProviders(type);
    }
    return propertyProviders.get(type);
  }


  // ----- ResourceProviderObserver ------------------------------------------

  @Override
  public void update(ResourceProviderEvent event) {
    Resource.Type type = event.getResourceType();

    if (type == Resource.Type.Cluster ||
        type == Resource.Type.Host ||
        type == Resource.Type.HostComponent) {
      resetInit();
    }
  }


  // ----- JMXHostProvider ---------------------------------------------------

  @Override
  public String getHostName(String clusterName, String componentName) throws SystemException {
    checkInit();
    return clusterHostComponentMap.get(clusterName).get(componentName);
  }

  @Override
  public Map<String, String> getHostMapping(String clusterName) throws SystemException {
    checkInit();
    return clusterHostMap.get(clusterName);
  }


  // ----- GangliaHostProvider -----------------------------------------------

  @Override
  public String getGangliaCollectorHostName(String clusterName) throws SystemException {
    checkInit();
    return clusterGangliaCollectorMap.get(clusterName);
  }


  // ----- utility methods ---------------------------------------------------

  protected abstract ResourceProvider createResourceProvider(Resource.Type type);

  protected void registerResourceProvider(Resource.Type type) {
    ResourceProvider resourceProvider = createResourceProvider(type);

    if (resourceProvider instanceof ObservableResourceProvider) {
      ((ObservableResourceProvider)resourceProvider).addObserver(this);
    }

    putResourceProvider(type, resourceProvider);
  }

  protected void putResourceProvider(Resource.Type type, ResourceProvider resourceProvider) {
    resourceProviders.put( type , resourceProvider);
  }

  protected void putPropertyProviders(Resource.Type type, List<PropertyProvider> providers) {
    propertyProviders.put(type, providers);
  }

  protected void createPropertyProviders(Resource.Type type) {

    List<PropertyProvider> providers = new LinkedList<PropertyProvider>();

    URLStreamProvider streamProvider = new URLStreamProvider();

    switch (type){
      case Cluster :
        providers.add(new GangliaReportPropertyProvider(
            PropertyHelper.getGangliaPropertyIds(type).get("*"),
            streamProvider,
            this,
            PropertyHelper.getPropertyId("Clusters", "cluster_name")));
        break;
      case Host :
        providers.add(new GangliaHostPropertyProvider(
            PropertyHelper.getGangliaPropertyIds(type),
            streamProvider,
            this,
            PropertyHelper.getPropertyId("Hosts", "cluster_name"),
            PropertyHelper.getPropertyId("Hosts", "host_name")
        ));
        break;
      case Component :
        providers.add(new JMXPropertyProvider(
            PropertyHelper.getJMXPropertyIds(type),
            streamProvider,
            this,
            PropertyHelper.getPropertyId("ServiceComponentInfo", "cluster_name"),
            null,
            PropertyHelper.getPropertyId("ServiceComponentInfo", "component_name")));

        providers.add(new GangliaComponentPropertyProvider(
            PropertyHelper.getGangliaPropertyIds(type),
            streamProvider,
            this,
            PropertyHelper.getPropertyId("ServiceComponentInfo", "cluster_name"),
            PropertyHelper.getPropertyId("ServiceComponentInfo", "component_name")));
        break;
      case HostComponent:
        providers.add(new JMXPropertyProvider(
            PropertyHelper.getJMXPropertyIds(type),
            streamProvider,
            this,
            PropertyHelper.getPropertyId("HostRoles", "cluster_name"),
            PropertyHelper.getPropertyId("HostRoles", "host_name"),
            PropertyHelper.getPropertyId("HostRoles", "component_name")));

        providers.add(new GangliaHostComponentPropertyProvider(
            PropertyHelper.getGangliaPropertyIds(type),
            streamProvider,
            this,
            PropertyHelper.getPropertyId("HostRoles", "cluster_name"),
            PropertyHelper.getPropertyId("HostRoles", "host_name"),
            PropertyHelper.getPropertyId("HostRoles", "component_name")));
        break;
      default :
        break;
    }
    putPropertyProviders(type, providers);
  }

  private void checkInit() throws SystemException{
    if (!initialized) {
      synchronized (this) {
        if (!initialized) {
          initProviderMaps();
          initialized = true;
        }
      }
    }
  }

  private void resetInit() {
    if (initialized) {
      synchronized (this) {
        initialized = false;
      }
    }
  }

  private void initProviderMaps() throws SystemException{
    ResourceProvider provider = getResourceProvider(Resource.Type.Cluster);
    Request          request  = PropertyHelper.getReadRequest(CLUSTER_NAME_PROPERTY_ID);

    try {
      Set<Resource> clusters = provider.getResources(request, null);

      clusterHostMap             = new HashMap<String, Map<String, String>>();
      clusterHostComponentMap    = new HashMap<String, Map<String, String>>();
      clusterGangliaCollectorMap = new HashMap<String, String>();

      for (Resource cluster : clusters) {

        String clusterName = (String) cluster.getPropertyValue(CLUSTER_NAME_PROPERTY_ID);

        // initialize the host map from the known hosts...
        provider = getResourceProvider(Resource.Type.Host);
        request  = PropertyHelper.getReadRequest(HOST_NAME_PROPERTY_ID, HOST_IP_PROPERTY_ID);

        Predicate predicate   = new PredicateBuilder().property(HOST_CLUSTER_NAME_PROPERTY_ID).
            equals(clusterName).toPredicate();

        Set<Resource>       hosts   = provider.getResources(request, predicate);
        Map<String, String> hostMap = clusterHostMap.get(clusterName);

        if (hostMap == null) {
          hostMap = new HashMap<String, String>();
          clusterHostMap.put(clusterName, hostMap);
        }

        for (Resource host : hosts) {
          String hostName = (String) host.getPropertyValue(HOST_NAME_PROPERTY_ID);
          String hostIp   = (String) host.getPropertyValue(HOST_IP_PROPERTY_ID);
          hostMap.put(hostName, hostIp == null ? hostName : hostIp);
        }

        // initialize the host component map and Ganglia server from the known hosts components...
        provider = getResourceProvider(Resource.Type.HostComponent);

        request = PropertyHelper.getReadRequest(HOST_COMPONENT_HOST_NAME_PROPERTY_ID,
            HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID);

        predicate = new PredicateBuilder().property(HOST_COMPONENT_CLUSTER_NAME_PROPERTY_ID).
            equals(clusterName).toPredicate();

        Set<Resource>       hostComponents   = provider.getResources(request, predicate);
        Map<String, String> hostComponentMap = clusterHostComponentMap.get(clusterName);

        if (hostComponentMap == null) {
          hostComponentMap = new HashMap<String, String>();
          clusterHostComponentMap.put(clusterName, hostComponentMap);
        }

        for (Resource hostComponent : hostComponents) {
          String componentName = (String) hostComponent.getPropertyValue(HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID);
          String hostName      = (String) hostComponent.getPropertyValue(HOST_COMPONENT_HOST_NAME_PROPERTY_ID);

          hostComponentMap.put(componentName, hostMap.get(hostName));

          // record the Ganglia server for the current cluster
          if (componentName.equals(GANGLIA_SERVER) || componentName.equals(GANGLIA_MONITOR) ||componentName.equals(GANGLIA_SERVER_OLD)) {
            clusterGangliaCollectorMap.put(clusterName, clusterHostMap.get(clusterName).get(hostName));
          }
        }
      }
    } catch (UnsupportedPropertyException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught UnsupportedPropertyException while trying to get the host mappings.", e);
      }
      throw new SystemException("An exception occurred while initializing the host mappings: " + e, e);
    } catch (NoSuchResourceException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught NoSuchResourceException exception while trying to get the host mappings.", e);
      }
      throw new SystemException("An exception occurred while initializing the host mappings: " + e, e);
    } catch (NoSuchParentResourceException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught NoSuchParentResourceException exception while trying to get the host mappings.", e);
      }
      throw new SystemException("An exception occurred while initializing the host mappings: " + e, e);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ActionResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.ActionRequest;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.RequestStatusResponse;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

/**
 * Resource provider for action resources.
 */
class ActionResourceProvider extends ResourceProviderImpl {

  // ----- Property ID constants ---------------------------------------------

  // Actions
  protected static final String ACTION_CLUSTER_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("Actions", "cluster_name");
  protected static final String ACTION_SERVICE_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("Actions", "service_name");
  protected static final String ACTION_ACTION_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("Actions", "action_name");


  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          ACTION_CLUSTER_NAME_PROPERTY_ID,
          ACTION_SERVICE_NAME_PROPERTY_ID}));

  ActionResourceProvider(Set<String> propertyIds,
                         Map<Resource.Type, String> keyPropertyIds,
                         AmbariManagementController managementController) {

    super(propertyIds, keyPropertyIds, managementController);
  }

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException,
             UnsupportedPropertyException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException {

    final Set<ActionRequest> requests = new HashSet<ActionRequest>();
    for (Map<String, Object> propertyMap : request.getProperties()) {
      requests.add(getRequest(propertyMap));
    }
    return getRequestStatus(createResources(new Command<RequestStatusResponse>() {
      @Override
      public RequestStatusResponse invoke() throws AmbariException {
        return getManagementController().createActions(requests);
      }
    }));
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    propertyIds = super.checkPropertyIds(propertyIds);

    if (propertyIds.isEmpty()) {
      return propertyIds;
    }
    Set<String> unsupportedProperties = new HashSet<String>();

    for (String propertyId : propertyIds) {
      String propertyCategory = PropertyHelper.getPropertyCategory(propertyId);
      if (propertyCategory == null || !propertyCategory.equals("parameters")) {
        unsupportedProperties.add(propertyId);
      }
    }
    return unsupportedProperties;
  }

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  private ActionRequest getRequest(Map<String, Object> properties) {
    Map<String, String> params = new HashMap<String, String>();
    for (Entry<String, Object> entry : properties.entrySet()) {
      String propertyid = entry.getKey();
      if (PropertyHelper.getPropertyCategory(propertyid).equals("parameters")
          && null != entry.getValue()) {
        params.put(PropertyHelper.getPropertyName(propertyid), entry.getValue().toString());
      }
    }
    return new ActionRequest(
        (String)  properties.get(ACTION_CLUSTER_NAME_PROPERTY_ID),
        (String)  properties.get(ACTION_SERVICE_NAME_PROPERTY_ID),
        (String)  properties.get(ACTION_ACTION_NAME_PROPERTY_ID),
        params);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterControllerImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.spi.ProviderModule;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PredicateBuilder;
import org.apache.ambari.server.controller.utilities.PredicateHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Set;

/**
 * Default cluster controller implementation.
 */
public class ClusterControllerImpl implements ClusterController {
  private final static Logger LOG =
      LoggerFactory.getLogger(ClusterControllerImpl.class);
  
  /**
   * Module of providers for this controller.
   */
  private final ProviderModule providerModule;

  /**
   * Map of resource providers keyed by resource type.
   */
  private final Map<Resource.Type, ResourceProvider> resourceProviders =
      new HashMap<Resource.Type, ResourceProvider>();

  /**
   * Map of property provider lists keyed by resource type.
   */
  private final Map<Resource.Type, List<PropertyProvider>> propertyProviders =
      new HashMap<Resource.Type, List<PropertyProvider>>();

  /**
   * Map of schemas keyed by resource type.
   */
  private final Map<Resource.Type, Schema> schemas =
      new HashMap<Resource.Type, Schema>();


  // ----- Constructors ------------------------------------------------------

  public ClusterControllerImpl(ProviderModule providerModule) {
    this.providerModule = providerModule;
  }


  // ----- ClusterController -------------------------------------------------

  @Override
  public Iterable<Resource> getResources(Resource.Type type, Request request, Predicate predicate)
      throws UnsupportedPropertyException,
             SystemException,
             NoSuchParentResourceException,
             NoSuchResourceException {

    ResourceProvider provider = ensureResourceProvider(type);
    ensurePropertyProviders(type);
    Set<Resource> resources;

    if (provider == null) {
      resources = Collections.emptySet();
    } else {
      LOG.info("Using resource provider "
          + provider.getClass().getName()
          + " for request type " + type.toString());

      checkProperties(type, request, predicate);

      resources = provider.getResources(request, predicate);
      resources = populateResources(type, resources, request, predicate);
    }
    
    return new ResourceIterable(resources, predicate);
  }

  @Override
  public Schema getSchema(Resource.Type type) {
    Schema schema;

    synchronized (schemas) {
      schema = schemas.get(type);
      if (schema == null) {
        schema = new SchemaImpl(ensureResourceProvider(type), ensurePropertyProviders(type));
        schemas.put(type, schema);
      }
    }
    return schema;
  }

  @Override
  public RequestStatus createResources(Resource.Type type, Request request)
      throws UnsupportedPropertyException,
             SystemException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException {

    ResourceProvider provider = ensureResourceProvider(type);
    if (provider != null) {

      checkProperties(type, request, null);

      return provider.createResources(request);
    }
    return null;
  }

  @Override
  public RequestStatus updateResources(Resource.Type type, Request request, Predicate predicate)
      throws UnsupportedPropertyException,
             SystemException,
             NoSuchResourceException,
             NoSuchParentResourceException {

    ResourceProvider provider = ensureResourceProvider(type);
    if (provider != null) {

      if (!checkProperties(type, request, predicate)) {
        predicate = resolvePredicate(type, predicate);
        if (predicate == null) {
          return null;
        }
      }
        return provider.updateResources(request, predicate);
    }
    return null;
  }

  @Override
  public RequestStatus deleteResources(Resource.Type type, Predicate predicate)
      throws UnsupportedPropertyException,
             SystemException,
             NoSuchResourceException,
             NoSuchParentResourceException {

    ResourceProvider provider = ensureResourceProvider(type);
    if (provider != null) {
      if (!checkProperties(type, null, predicate)) {
        predicate = resolvePredicate(type, predicate);
        if (predicate == null) {
          return null;
        }
      }
        return provider.deleteResources(predicate);
    }
    return null;
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Check to make sure that all the property ids specified in the given request and
   * predicate are supported by the resource provider or property providers for the
   * given type.
   *
   * @param type       the resource type
   * @param request    the request
   * @param predicate  the predicate
   *
   * @return true if all of the properties specified in the request and predicate are supported by
   *         the resource provider for the given type; false if any of the properties specified in
   *         the request and predicate are not supported by the resource provider but are supported
   *         by a property provider for the given type.
   *
   * @throws UnsupportedPropertyException thrown if any of the properties specified in the request
   *                                      and predicate are not supported by either the resource
   *                                      provider or a property provider for the given type
   */
  private boolean checkProperties(Resource.Type type, Request request, Predicate predicate)
      throws UnsupportedPropertyException {
    Set<String> requestPropertyIds = request == null ? new HashSet<String>() :
        PropertyHelper.getAssociatedPropertyIds(request);

    if (predicate != null) {
      requestPropertyIds.addAll(PredicateHelper.getPropertyIds(predicate));
    }

    if (requestPropertyIds.size() > 0) {
      ResourceProvider provider = ensureResourceProvider(type);
      requestPropertyIds = provider.checkPropertyIds(requestPropertyIds);

      if (requestPropertyIds.size() > 0) {
        List<PropertyProvider> propertyProviders = ensurePropertyProviders(type);
        for (PropertyProvider propertyProvider : propertyProviders) {
          requestPropertyIds = propertyProvider.checkPropertyIds(requestPropertyIds);
          if (requestPropertyIds.size() == 0) {
            return false;
          }
        }
        throw new UnsupportedPropertyException(type, requestPropertyIds);
      }
    }
    return true;
  }

  /**
   * Check to see if any of the property ids specified in the given request and
   * predicate are handled by an associated property provider.  if so, then use
   * the given predicate to obtain a new predicate that can be completely
   * processed by an update or delete operation on a resource provider for
   * the given resource type.  This means that the new predicate should only
   * reference the key property ids for this type.
   *
   * @param type       the resource type
   * @param predicate  the predicate
   *
   * @return the given predicate if a new one is not required; a new predicate if required
   *
   * @throws UnsupportedPropertyException thrown if any of the properties specified in the request
   *                                      and predicate are not supported by either the resource
   *                                      provider or a property provider for the given type
   *
   * @throws SystemException thrown for internal exceptions
   * @throws NoSuchResourceException if the resource that is requested doesn't exist
   * @throws NoSuchParentResourceException if a parent resource of the requested resource doesn't exist
   */
  private Predicate resolvePredicate(Resource.Type type, Predicate predicate)
    throws UnsupportedPropertyException,
        SystemException,
        NoSuchResourceException,
        NoSuchParentResourceException{

    ResourceProvider provider = ensureResourceProvider(type);

    Set<String>  keyPropertyIds = new HashSet<String>(provider.getKeyPropertyIds().values());
    Request      readRequest    = PropertyHelper.getReadRequest(keyPropertyIds);

    Iterable<Resource> resources = getResources(type, readRequest, predicate);

    PredicateBuilder pb = new PredicateBuilder();
    PredicateBuilder.PredicateBuilderWithPredicate pbWithPredicate = null;

    for (Resource resource : resources) {
      if (pbWithPredicate != null) {
        pb = pbWithPredicate.or();
      }

      pb              = pb.begin();
      pbWithPredicate = null;

      for (String keyPropertyId : keyPropertyIds) {
        if (pbWithPredicate != null) {
          pb = pbWithPredicate.and();
        }
        pbWithPredicate =
            pb.property(keyPropertyId).equals((Comparable) resource.getPropertyValue(keyPropertyId));
      }
      if (pbWithPredicate != null) {
        pbWithPredicate = pbWithPredicate.end();
      }
    }
    return pbWithPredicate == null ? null : pbWithPredicate.toPredicate();
  }

  /**
   * Populate the given resources from the associated property providers.  This
   * method may filter the resources based on the predicate and return a subset
   * of the given resources.
   *
   * @param type       the resource type
   * @param resources  the resources to be populated
   * @param request    the request
   * @param predicate  the predicate
   *
   * @return the set of resources that were successfully populated
   *
   * @throws SystemException if unable to populate the resources
   */
  private Set<Resource> populateResources(Resource.Type type,
                                          Set<Resource> resources,
                                          Request request,
                                          Predicate predicate) throws SystemException {
    Set<Resource> keepers = resources;

    for (PropertyProvider propertyProvider : propertyProviders.get(type)) {
      if (providesRequestProperties(propertyProvider, request, predicate)) {
        keepers = propertyProvider.populateResources(keepers, request, predicate);
      }
    }
    return keepers;
  }

  /**
   * Indicates whether or not the given property provider can service the given request.
   *
   * @param provider   the property provider
   * @param request    the request
   * @param predicate  the predicate
   *
   * @return true if the given provider can service the request
   */
  private boolean providesRequestProperties(PropertyProvider provider, Request request, Predicate predicate) {
    Set<String> requestPropertyIds = new HashSet<String>(request.getPropertyIds());

    if (requestPropertyIds.size() == 0) {
      return true;
    }
    requestPropertyIds.addAll(PredicateHelper.getPropertyIds(predicate));

    int size = requestPropertyIds.size();

    return size > provider.checkPropertyIds(requestPropertyIds).size();
  }

  /**
   * Get the resource provider for the given type, creating it if required.
   *
   * @param type  the resource type
   *
   * @return the resource provider
   */
  private ResourceProvider ensureResourceProvider(Resource.Type type) {
    synchronized (resourceProviders) {
      if (!resourceProviders.containsKey(type)) {
        resourceProviders.put(type, providerModule.getResourceProvider(type));
      }
    }
    return resourceProviders.get(type);
  }

  /**
   * Get the list of property providers for the given type.
   *
   * @param type  the resource type
   *
   * @return the list of property providers
   */
  private List<PropertyProvider> ensurePropertyProviders(Resource.Type type) {
    synchronized (propertyProviders) {
      if (!propertyProviders.containsKey(type)) {
        propertyProviders.put(type, providerModule.getPropertyProviders(type));
      }
    }
    return propertyProviders.get(type);
  }


  // ----- ResourceIterable inner class --------------------------------------

  private static class ResourceIterable implements Iterable<Resource> {

    /**
     * The resources to iterate over.
     */
    private final Set<Resource> resources;

    /**
     * The predicate used to filter the set.
     */
    private final Predicate predicate;

    // ----- Constructors ----------------------------------------------------

    /**
     * Create a ResourceIterable.
     *
     * @param resources  the set of resources to iterate over
     * @param predicate  the predicate used to filter the set of resources
     */
    private ResourceIterable(Set<Resource> resources, Predicate predicate) {
      this.resources = resources;
      this.predicate = predicate;
    }

    // ----- Iterable --------------------------------------------------------

    @Override
    public Iterator<Resource> iterator() {
      return new ResourceIterator(resources, predicate);
    }
  }


  // ----- ResourceIterator inner class --------------------------------------

  private static class ResourceIterator implements Iterator<Resource> {

    /**
     * The underlying iterator.
     */
    private final Iterator<Resource> iterator;

    /**
     * The predicate used to filter the resource being iterated over.
     */
    private final Predicate predicate;

    /**
     * The next resource.
     */
    private Resource nextResource;


    // ----- Constructors ----------------------------------------------------

    /**
     * Create a new ResourceIterator.
     *
     * @param resources  the set of resources to iterate over
     * @param predicate  the predicate used to filter the set of resources
     */
    private ResourceIterator(Set<Resource> resources, Predicate predicate) {
      this.iterator     = resources.iterator();
      this.predicate    = predicate;
      this.nextResource = getNextResource();
    }

    // ----- Iterator --------------------------------------------------------

    @Override
    public boolean hasNext() {
      return nextResource != null;
    }

    @Override
    public Resource next() {
      if (nextResource == null) {
        throw new NoSuchElementException("Iterator has no more elements.");
      }

      Resource currentResource = nextResource;
      this.nextResource = getNextResource();

      return currentResource;
    }

    @Override
    public void remove() {
      throw new UnsupportedOperationException("Remove not supported.");
    }

    // ----- helper methods --------------------------------------------------

    /**
     * Get the next resource.
     *
     * @return the next resource.
     */
    private Resource getNextResource() {
      while (iterator.hasNext()) {
        Resource next = iterator.next();
        
        if (predicate == null || predicate.evaluate(next)) {
          return next;
        }
      }
      return null;
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.ClusterRequest;
import org.apache.ambari.server.controller.ClusterResponse;
import org.apache.ambari.server.controller.RequestStatusResponse;
import org.apache.ambari.server.controller.spi.NoSuchParentResourceException;
import org.apache.ambari.server.controller.spi.NoSuchResourceException;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.Request;
import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.ResourceAlreadyExistsException;
import org.apache.ambari.server.controller.spi.SystemException;
import org.apache.ambari.server.controller.spi.UnsupportedPropertyException;
import org.apache.ambari.server.controller.utilities.PredicateHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.Collections;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

/**
 * Resource provider for cluster resources.
 */
class ClusterResourceProvider extends ResourceProviderImpl{

  // ----- Property ID constants ---------------------------------------------

  // Clusters
  protected static final String CLUSTER_ID_PROPERTY_ID      = PropertyHelper.getPropertyId("Clusters", "cluster_id");
  protected static final String CLUSTER_NAME_PROPERTY_ID    = PropertyHelper.getPropertyId("Clusters", "cluster_name");
  protected static final String CLUSTER_VERSION_PROPERTY_ID = PropertyHelper.getPropertyId("Clusters", "version");


  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          CLUSTER_ID_PROPERTY_ID}));

  // ----- Constructors ----------------------------------------------------

  /**
   * Create a  new resource provider for the given management controller.
   *
   * @param propertyIds           the property ids
   * @param keyPropertyIds        the key property ids
   * @param managementController  the management controller
   */
  ClusterResourceProvider(Set<String> propertyIds,
                          Map<Resource.Type, String> keyPropertyIds,
                          AmbariManagementController managementController) {
    super(propertyIds, keyPropertyIds, managementController);
  }

// ----- ResourceProvider ------------------------------------------------

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException,
             UnsupportedPropertyException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException {

    for (final Map<String, Object> properties : request.getProperties()) {
      createResources(new Command<Void>() {
        @Override
        public Void invoke() throws AmbariException {
          getManagementController().createCluster(getRequest(properties));
          return null;
        }
      });
    }
    notifyCreate(Resource.Type.Cluster, request);

    return getRequestStatus(null);
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final ClusterRequest clusterRequest = getRequest(PredicateHelper.getProperties(predicate));
    Set<String> requestedIds = PropertyHelper.getRequestPropertyIds(getPropertyIds(), request, predicate);

    // TODO : handle multiple requests
    Set<ClusterResponse> responses = getResources(new Command<Set<ClusterResponse>>() {
      @Override
      public Set<ClusterResponse> invoke() throws AmbariException {
        return getManagementController().getClusters(Collections.singleton(clusterRequest));
      }
    });

    Set<Resource> resources = new HashSet<Resource>();
    if (LOG.isDebugEnabled()) {
      LOG.debug("Found clusters matching getClusters request"
          + ", clusterResponseCount=" + responses.size());
    }
    for (ClusterResponse response : responses) {
      Resource resource = new ResourceImpl(Resource.Type.Cluster);
      setResourceProperty(resource, CLUSTER_ID_PROPERTY_ID, response.getClusterId(), requestedIds);
      setResourceProperty(resource, CLUSTER_NAME_PROPERTY_ID, response.getClusterName(), requestedIds);

      resource.setProperty(CLUSTER_VERSION_PROPERTY_ID,
          response.getDesiredStackVersion());

      if (LOG.isDebugEnabled()) {
        LOG.debug("Adding ClusterResponse to resource"
            + ", clusterResponse=" + response.toString());
      }

      resources.add(resource);
    }
    return resources;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    for (Map<String, Object> propertyMap : getPropertyMaps(request.getProperties().iterator().next(), predicate)) {
      final ClusterRequest clusterRequest = getRequest(propertyMap);

      modifyResources(new Command<RequestStatusResponse>() {
        @Override
        public RequestStatusResponse invoke() throws AmbariException {
          return getManagementController().updateCluster(clusterRequest);
        }
      });
    }
    notifyUpdate(Resource.Type.Cluster, request, predicate);
    return getRequestStatus(null);
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      final ClusterRequest clusterRequest = getRequest(propertyMap);
      modifyResources(new Command<Void>() {
        @Override
        public Void invoke() throws AmbariException {
          getManagementController().deleteCluster(clusterRequest);
          return null;
        }
      });
    }
    notifyDelete(Resource.Type.Cluster, predicate);
    return getRequestStatus(null);
  }

  // ----- utility methods -------------------------------------------------

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  /**
   * Get a cluster request object from a map of property values.
   *
   * @param properties  the predicate
   *
   * @return the cluster request object
   */
  private ClusterRequest getRequest(Map<String, Object> properties) {
    return new ClusterRequest(
        (Long) properties.get(CLUSTER_ID_PROPERTY_ID),
        (String) properties.get(CLUSTER_NAME_PROPERTY_ID),
        (String) properties.get(CLUSTER_VERSION_PROPERTY_ID),
        null);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ComponentResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.RequestStatusResponse;
import org.apache.ambari.server.controller.ServiceComponentRequest;
import org.apache.ambari.server.controller.ServiceComponentResponse;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

/**
 * Resource provider for component resources.
 */
class ComponentResourceProvider extends ResourceProviderImpl{


  // ----- Property ID constants ---------------------------------------------

  // Components
  protected static final String COMPONENT_CLUSTER_NAME_PROPERTY_ID    = PropertyHelper.getPropertyId("ServiceComponentInfo", "cluster_name");
  protected static final String COMPONENT_SERVICE_NAME_PROPERTY_ID    = PropertyHelper.getPropertyId("ServiceComponentInfo", "service_name");
  protected static final String COMPONENT_COMPONENT_NAME_PROPERTY_ID  = PropertyHelper.getPropertyId("ServiceComponentInfo", "component_name");
  protected static final String COMPONENT_STATE_PROPERTY_ID           = PropertyHelper.getPropertyId("ServiceComponentInfo", "state");
  protected static final String COMPONENT_DESIRED_CONFIGS_PROPERTY_ID = PropertyHelper.getPropertyId("ServiceComponentInfo", "desired_configs");


  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          COMPONENT_CLUSTER_NAME_PROPERTY_ID,
          COMPONENT_SERVICE_NAME_PROPERTY_ID,
          COMPONENT_COMPONENT_NAME_PROPERTY_ID}));

  // ----- Constructors ----------------------------------------------------

  /**
   * Create a  new resource provider for the given management controller.
   *
   * @param propertyIds           the property ids
   * @param keyPropertyIds        the key property ids
   * @param managementController  the management controller
   */
  ComponentResourceProvider(Set<String> propertyIds,
                            Map<Resource.Type, String> keyPropertyIds,
                            AmbariManagementController managementController) {
    super(propertyIds, keyPropertyIds, managementController);
  }

  // ----- ResourceProvider ------------------------------------------------

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException,
             UnsupportedPropertyException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException {

    final Set<ServiceComponentRequest> requests = new HashSet<ServiceComponentRequest>();
    for (Map<String, Object> propertyMap : request.getProperties()) {
      requests.add(getRequest(propertyMap));
    }

    createResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().createComponents(requests);
        return null;
      }
    });

    notifyCreate(Resource.Type.Component, request);

    return getRequestStatus(null);
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<ServiceComponentRequest> requests = new HashSet<ServiceComponentRequest>();

    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      requests.add(getRequest(propertyMap));
    }

    Set<ServiceComponentResponse> responses = getResources(new Command<Set<ServiceComponentResponse>>() {
      @Override
      public Set<ServiceComponentResponse> invoke() throws AmbariException {
        return getManagementController().getComponents(requests);
      }
    });

    Set<String>   requestedIds = PropertyHelper.getRequestPropertyIds(getPropertyIds(), request, predicate);
    Set<Resource> resources    = new HashSet<Resource>();

    for (ServiceComponentResponse response : responses) {
      Resource resource = new ResourceImpl(Resource.Type.Component);
      setResourceProperty(resource, COMPONENT_CLUSTER_NAME_PROPERTY_ID, response.getClusterName(), requestedIds);
      setResourceProperty(resource, COMPONENT_SERVICE_NAME_PROPERTY_ID, response.getServiceName(), requestedIds);
      setResourceProperty(resource, COMPONENT_COMPONENT_NAME_PROPERTY_ID, response.getComponentName(), requestedIds);
      setResourceProperty(resource, COMPONENT_STATE_PROPERTY_ID,
          response.getDesiredState(), requestedIds);
      setResourceProperty(resource, COMPONENT_DESIRED_CONFIGS_PROPERTY_ID,
          response.getConfigVersions(), requestedIds);
      resources.add(resource);
    }
    return resources;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<ServiceComponentRequest> requests = new HashSet<ServiceComponentRequest>();
    for (Map<String, Object> propertyMap : getPropertyMaps(request.getProperties().iterator().next(), predicate)) {
      ServiceComponentRequest compRequest = getRequest(propertyMap);
      Map<String, String>     configMap   = new HashMap<String,String>();

      for (Map.Entry<String,Object> entry : propertyMap.entrySet()) {
        if (PropertyHelper.getPropertyCategory(entry.getKey()).equals("config")) {
          configMap.put(PropertyHelper.getPropertyName(entry.getKey()), (String) entry.getValue());
        }
      }

      if (0 != configMap.size())
        compRequest.setConfigVersions(configMap);

      requests.add(compRequest);
    }

    RequestStatusResponse response = modifyResources(new Command<RequestStatusResponse>() {
      @Override
      public RequestStatusResponse invoke() throws AmbariException {
        return getManagementController().updateComponents(requests);
      }
    });

    notifyUpdate(Resource.Type.Component, request, predicate);

    return getRequestStatus(response);
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<ServiceComponentRequest> requests = new HashSet<ServiceComponentRequest>();
    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      requests.add(getRequest(propertyMap));
    }

    RequestStatusResponse response = modifyResources(new Command<RequestStatusResponse>() {
      @Override
      public RequestStatusResponse invoke() throws AmbariException {
        return getManagementController().deleteComponents(requests);
      }
    });

    notifyDelete(Resource.Type.Component, predicate);
    return getRequestStatus(response);
  }

  // ----- utility methods -------------------------------------------------

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  /**
   * Get a component request object from a map of property values.
   *
   * @param properties  the predicate
   *
   * @return the component request object
   */
  private ServiceComponentRequest getRequest(Map<String, Object> properties) {
    return new ServiceComponentRequest(
        (String) properties.get(COMPONENT_CLUSTER_NAME_PROPERTY_ID),
        (String) properties.get(COMPONENT_SERVICE_NAME_PROPERTY_ID),
        (String) properties.get(COMPONENT_COMPONENT_NAME_PROPERTY_ID),
        null,
        (String) properties.get(COMPONENT_STATE_PROPERTY_ID));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ConfigurationResourceProvider.java,true,"package org.apache.ambari.server.controller.internal;

/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.ConfigurationRequest;
import org.apache.ambari.server.controller.ConfigurationResponse;
import org.apache.ambari.server.controller.ServiceComponentHostRequest;
import org.apache.ambari.server.controller.spi.NoSuchParentResourceException;
import org.apache.ambari.server.controller.spi.NoSuchResourceException;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.Request;
import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.ResourceAlreadyExistsException;
import org.apache.ambari.server.controller.spi.SystemException;
import org.apache.ambari.server.controller.spi.UnsupportedPropertyException;
import org.apache.ambari.server.controller.utilities.PredicateHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;
import java.util.Map.Entry;

/**
 * Resource provider for configuration resources.
 */
class ConfigurationResourceProvider extends ResourceProviderImpl {

  // ----- Property ID constants ---------------------------------------------

  // Configurations (values are part of query strings and body post, so they don't have defined categories)
  protected static final String CONFIGURATION_CLUSTER_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("Config", "cluster_name");
  // TODO : should these be Config/type and Config/tag to be consistent?
  protected static final String CONFIGURATION_CONFIG_TYPE_PROPERTY_ID  = PropertyHelper.getPropertyId(null, "type");
  protected static final String CONFIGURATION_CONFIG_TAG_PROPERTY_ID   = PropertyHelper.getPropertyId(null, "tag");

  private static final String CONFIG_HOST_NAME = PropertyHelper.getPropertyId("Config", "host_name");
  private static final String CONFIG_COMPONENT_NAME = PropertyHelper.getPropertyId("Config", "component_name");


  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          CONFIGURATION_CLUSTER_NAME_PROPERTY_ID,
          CONFIGURATION_CONFIG_TYPE_PROPERTY_ID}));

  ConfigurationResourceProvider(Set<String> propertyIds,
                                Map<Resource.Type, String> keyPropertyIds,
                                AmbariManagementController managementController) {

    super(propertyIds, keyPropertyIds, managementController);

  }

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException,
             UnsupportedPropertyException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException {

    for (Map<String, Object> map : request.getProperties()) {

      String cluster = (String) map.get(CONFIGURATION_CLUSTER_NAME_PROPERTY_ID);
      // TODO : why not CONFIGURATION_CONFIG_TYPE_PROPERTY_ID?
      String type = (String) map.get(PropertyHelper.getPropertyId("", "type"));
      // TODO : why not CONFIGURATION_CONFIG_TAG_PROPERTY_ID?
      String tag = (String) map.get(PropertyHelper.getPropertyId("", "tag"));

      Map<String, String> configMap = new HashMap<String, String>();

      for (Entry<String, Object> entry : map.entrySet()) {
        if (PropertyHelper.getPropertyCategory(entry.getKey()).equals("properties") && null != entry.getValue()) {
          configMap.put(PropertyHelper.getPropertyName(entry.getKey()), entry.getValue().toString());
        }
      }

      final ConfigurationRequest configRequest = new ConfigurationRequest(cluster, type, tag, configMap);

      createResources(new Command<Void>() {
        @Override
        public Void invoke() throws AmbariException {
          getManagementController().createConfiguration(configRequest);
          return null;
        }
      });

    }
    return getRequestStatus(null);
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
    throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    Map<String, Object> map = PredicateHelper.getProperties(predicate);
    
    if (map.containsKey(CONFIG_HOST_NAME) && map.containsKey(CONFIG_COMPONENT_NAME)) {
      final ServiceComponentHostRequest hostComponentRequest = new ServiceComponentHostRequest(
          (String) map.get(CONFIGURATION_CLUSTER_NAME_PROPERTY_ID),
          null,
          (String) map.get(CONFIG_COMPONENT_NAME),
          (String) map.get(CONFIG_HOST_NAME),
          null, null);
      
      Map<String, String> mappints = getResources(new Command<Map<String, String>>() {
        @Override
        public Map<String, String> invoke() throws AmbariException {
          return getManagementController().getHostComponentDesiredConfigMapping(hostComponentRequest);
        }
      });

      Set<Resource> resources = new HashSet<Resource>();
      
      for (Entry<String, String> entry : mappints.entrySet()) {
      
        Resource resource = new ResourceImpl(Resource.Type.Configuration);
        
        resource.setProperty(CONFIGURATION_CLUSTER_NAME_PROPERTY_ID, map.get(CONFIGURATION_CLUSTER_NAME_PROPERTY_ID));
        resource.setProperty(CONFIG_COMPONENT_NAME, map.get(CONFIG_COMPONENT_NAME));
        resource.setProperty(CONFIG_HOST_NAME, map.get(CONFIG_HOST_NAME));

        resource.setProperty(CONFIGURATION_CONFIG_TYPE_PROPERTY_ID, entry.getKey());
        resource.setProperty(CONFIGURATION_CONFIG_TAG_PROPERTY_ID, entry.getValue());
        
        resources.add(resource);
      }


      return resources;
      
    } else {
      // TODO : handle multiple requests
      final ConfigurationRequest configRequest = getRequest(map);
      
      Set<ConfigurationResponse> responses = getResources(new Command<Set<ConfigurationResponse>>() {
        @Override
        public Set<ConfigurationResponse> invoke() throws AmbariException {
          return getManagementController().getConfigurations(Collections.singleton(configRequest));
        }
      });

      Set<Resource> resources = new HashSet<Resource>();
      for (ConfigurationResponse response : responses) {
        Resource resource = new ResourceImpl(Resource.Type.Configuration);
        resource.setProperty(CONFIGURATION_CLUSTER_NAME_PROPERTY_ID, response.getClusterName());
        resource.setProperty(CONFIGURATION_CONFIG_TYPE_PROPERTY_ID, response.getType());
        resource.setProperty(CONFIGURATION_CONFIG_TAG_PROPERTY_ID, response.getVersionTag());
        
        if (null != response.getConfigs() && response.getConfigs().size() > 0) {
          Map<String, String> configs = response.getConfigs();

          for (Entry<String, String> entry : configs.entrySet()) {
            String id = PropertyHelper.getPropertyId("properties", entry.getKey());
            resource.setProperty(id, entry.getValue());
          }
        }

        resources.add(resource);
      }
      
      return resources;
    }
  }

  /**
   * Throws an exception, as Configurations cannot be updated.
   */
  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Cannot update a Configuration resource.");
  }

  /**
   * Throws an exception, as Configurations cannot be deleted.
   */
  @Override
  public RequestStatus deleteResources(Predicate predicate) throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Cannot delete a Configuration resource.");
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    propertyIds = super.checkPropertyIds(propertyIds);

    if (propertyIds.isEmpty()) {
      return propertyIds;
    }
    Set<String> unsupportedProperties = new HashSet<String>();

    for (String propertyId : propertyIds) {

      // TODO : hack to allow for inconsistent property names
      // for example, the tag property can come here as Config/tag, /tag or tag
      if (!propertyId.equals("tag") && !propertyId.equals("type") &&
          !propertyId.equals("/tag") && !propertyId.equals("/type")) {

        String propertyCategory = PropertyHelper.getPropertyCategory(propertyId);

        if (propertyCategory == null || !propertyCategory.equals("properties")) {
          unsupportedProperties.add(propertyId);
        }
      }
    }
    return unsupportedProperties;
  }

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  public static Map<String, String> getConfigPropertyValues(Map<String, Object> propertyMap) {
    Map<String, String> configMap = new HashMap<String, String>();

    for (Map.Entry<String,Object> entry : propertyMap.entrySet()) {
      String propertyId = entry.getKey();
      if (PropertyHelper.getPropertyCategory(propertyId).equals("config")) {
        configMap.put(PropertyHelper.getPropertyName(propertyId), (String) entry.getValue());
      }
    }
    return configMap;
  }

  private ConfigurationRequest getRequest(Map<String, Object> properties) {
    String type = (String) properties.get(CONFIGURATION_CONFIG_TYPE_PROPERTY_ID);

    String tag = (String) properties.get(CONFIGURATION_CONFIG_TAG_PROPERTY_ID);

    return new ConfigurationRequest(
        (String) properties.get(CONFIGURATION_CLUSTER_NAME_PROPERTY_ID),
        type, tag, new HashMap<String, String>());
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/DefaultProviderModule.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import com.google.inject.Inject;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.AmbariServer;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.ResourceProvider;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

/**
 * The default provider module implementation.
 */
public class DefaultProviderModule extends AbstractProviderModule {
  @Inject
  private AmbariManagementController managementController;

  // ----- Constructors ------------------------------------------------------

  /**
   * Create a default provider module.
   */
  public DefaultProviderModule() {
    if (managementController == null) {
      managementController = AmbariServer.getController();
    }
  }


  // ----- utility methods ---------------------------------------------------

  @Override
  protected ResourceProvider createResourceProvider(Resource.Type type) {
    return ResourceProviderImpl.getResourceProvider(type, PropertyHelper.getPropertyIds(type),
            PropertyHelper.getKeyPropertyIds(type), managementController);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/HostComponentResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.RequestStatusResponse;
import org.apache.ambari.server.controller.ServiceComponentHostRequest;
import org.apache.ambari.server.controller.ServiceComponentHostResponse;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;
import java.util.Set;

/**
 * Resource provider for host component resources.
 */
class HostComponentResourceProvider extends ResourceProviderImpl {

  // ----- Property ID constants ---------------------------------------------

  // Host Components
  protected static final String HOST_COMPONENT_CLUSTER_NAME_PROPERTY_ID   = PropertyHelper.getPropertyId("HostRoles", "cluster_name");
  protected static final String HOST_COMPONENT_SERVICE_NAME_PROPERTY_ID   = PropertyHelper.getPropertyId("HostRoles", "service_name");
  protected static final String HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("HostRoles", "component_name");
  protected static final String HOST_COMPONENT_HOST_NAME_PROPERTY_ID      = PropertyHelper.getPropertyId("HostRoles", "host_name");
  protected static final String HOST_COMPONENT_STATE_PROPERTY_ID          = PropertyHelper.getPropertyId("HostRoles", "state");
  protected static final String HOST_COMPONENT_DESIRED_STATE_PROPERTY_ID  = PropertyHelper.getPropertyId("HostRoles", "desired_state");
  protected static final String HOST_COMPONENT_CONFIGS_PROPERTY_ID          = PropertyHelper.getPropertyId("HostRoles", "configs");
  protected static final String HOST_COMPONENT_DESIRED_CONFIGS_PROPERTY_ID  = PropertyHelper.getPropertyId("HostRoles", "desired_configs");

  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          HOST_COMPONENT_CLUSTER_NAME_PROPERTY_ID,
          HOST_COMPONENT_SERVICE_NAME_PROPERTY_ID,
          HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID,
          HOST_COMPONENT_HOST_NAME_PROPERTY_ID}));

  // ----- Constructors ----------------------------------------------------

  /**
   * Create a  new resource provider for the given management controller.
   *
   * @param propertyIds           the property ids
   * @param keyPropertyIds        the key property ids
   * @param managementController  the management controller
   */
  HostComponentResourceProvider(Set<String> propertyIds,
                                Map<Resource.Type, String> keyPropertyIds,
                                AmbariManagementController managementController) {
    super(propertyIds, keyPropertyIds, managementController);
  }

  // ----- ResourceProvider ------------------------------------------------

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException,
             UnsupportedPropertyException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException {

    final Set<ServiceComponentHostRequest> requests = new HashSet<ServiceComponentHostRequest>();
    for (Map<String, Object> propertyMap : request.getProperties()) {
      requests.add(getRequest(propertyMap));
    }

    createResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().createHostComponents(requests);
        return null;
      }
    });

    notifyCreate(Resource.Type.HostComponent, request);

    return getRequestStatus(null);
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<ServiceComponentHostRequest> requests = new HashSet<ServiceComponentHostRequest>();

    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      requests.add(getRequest(propertyMap));
    }

    Set<Resource> resources    = new HashSet<Resource>();
    Set<String>   requestedIds = PropertyHelper.getRequestPropertyIds(getPropertyIds(), request, predicate);

    Set<ServiceComponentHostResponse> responses = getResources(new Command<Set<ServiceComponentHostResponse>>() {
      @Override
      public Set<ServiceComponentHostResponse> invoke() throws AmbariException {
        return getManagementController().getHostComponents(requests);
      }
    });

    for (ServiceComponentHostResponse response : responses) {
      Resource resource = new ResourceImpl(Resource.Type.HostComponent);
      setResourceProperty(resource, HOST_COMPONENT_CLUSTER_NAME_PROPERTY_ID, response.getClusterName(), requestedIds);
      setResourceProperty(resource, HOST_COMPONENT_SERVICE_NAME_PROPERTY_ID, response.getServiceName(), requestedIds);
      setResourceProperty(resource, HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID, response.getComponentName(), requestedIds);
      setResourceProperty(resource, HOST_COMPONENT_HOST_NAME_PROPERTY_ID, response.getHostname(), requestedIds);
      setResourceProperty(resource, HOST_COMPONENT_STATE_PROPERTY_ID, response.getLiveState(), requestedIds);
      setResourceProperty(resource, HOST_COMPONENT_DESIRED_STATE_PROPERTY_ID, response.getDesiredState(), requestedIds);
      setResourceProperty(resource, HOST_COMPONENT_CONFIGS_PROPERTY_ID,
          response.getConfigs(), requestedIds);
      setResourceProperty(resource, HOST_COMPONENT_DESIRED_CONFIGS_PROPERTY_ID,
          response.getDesiredConfigs(), requestedIds);
      resources.add(resource);
    }
    return resources;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
        throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    final Set<ServiceComponentHostRequest> requests = new HashSet<ServiceComponentHostRequest>();
    RequestStatusResponse response = null;

    Iterator<Map<String,Object>> iterator = request.getProperties().iterator();
    if (iterator.hasNext()) {
      for (Map<String, Object> propertyMap : getPropertyMaps(request.getProperties().iterator().next(), predicate)) {
        requests.add(getRequest(propertyMap));
      }
      response = modifyResources(new Command<RequestStatusResponse>() {
        @Override
        public RequestStatusResponse invoke() throws AmbariException {
          return getManagementController().updateHostComponents(requests);
        }
      });

      notifyUpdate(Resource.Type.HostComponent, request, predicate);
    }
    return getRequestStatus(response);
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    final Set<ServiceComponentHostRequest> requests = new HashSet<ServiceComponentHostRequest>();
    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      requests.add(getRequest(propertyMap));
    }
    RequestStatusResponse response = modifyResources(new Command<RequestStatusResponse>() {
      @Override
      public RequestStatusResponse invoke() throws AmbariException {
        return getManagementController().deleteHostComponents(requests);
      }
    });

    notifyDelete(Resource.Type.HostComponent, predicate);

    return getRequestStatus(response);
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    propertyIds = super.checkPropertyIds(propertyIds);

    if (propertyIds.isEmpty()) {
      return propertyIds;
    }
    Set<String> unsupportedProperties = new HashSet<String>();

    for (String propertyId : propertyIds) {
      String propertyCategory = PropertyHelper.getPropertyCategory(propertyId);
      if (propertyCategory == null || !propertyCategory.equals("config")) {
        unsupportedProperties.add(propertyId);
      }
    }
    return unsupportedProperties;
  }


  // ----- utility methods -------------------------------------------------

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  /**
   * Get a component request object from a map of property values.
   *
   * @param properties  the predicate
   *
   * @return the component request object
   */
  private ServiceComponentHostRequest getRequest(Map<String, Object> properties) {
    ServiceComponentHostRequest serviceComponentHostRequest = new ServiceComponentHostRequest(
        (String) properties.get(HOST_COMPONENT_CLUSTER_NAME_PROPERTY_ID),
        (String) properties.get(HOST_COMPONENT_SERVICE_NAME_PROPERTY_ID),
        (String) properties.get(HOST_COMPONENT_COMPONENT_NAME_PROPERTY_ID),
        (String) properties.get(HOST_COMPONENT_HOST_NAME_PROPERTY_ID),
        null,
        (String) properties.get(HOST_COMPONENT_STATE_PROPERTY_ID));

    Map<String, String> configMappings =
        ConfigurationResourceProvider.getConfigPropertyValues(properties);

    if (configMappings.size() > 0) {
      serviceComponentHostRequest.setConfigVersions(configMappings);
    }
    return serviceComponentHostRequest;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/HostResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import java.util.Arrays;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.HostRequest;
import org.apache.ambari.server.controller.HostResponse;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;


/**
 * Resource provider for host resources.
 */
class HostResourceProvider extends ResourceProviderImpl{

  // ----- Property ID constants ---------------------------------------------

  // Hosts
  protected static final String HOST_CLUSTER_NAME_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "cluster_name");
  protected static final String HOST_NAME_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "host_name");
  protected static final String HOST_PUBLIC_NAME_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "public_host_name");
  protected static final String HOST_IP_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "ip");
  protected static final String HOST_TOTAL_MEM_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "total_mem");
  protected static final String HOST_CPU_COUNT_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "cpu_count");
  protected static final String HOST_OS_ARCH_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "os_arch");
  protected static final String HOST_OS_TYPE_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "os_type");
  protected static final String HOST_RACK_INFO_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "rack_info");
  protected static final String HOST_LAST_HEARTBEAT_TIME_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "last_heartbeat_time");
  protected static final String HOST_LAST_REGISTRATION_TIME_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "last_registration_time");
  protected static final String HOST_DISK_INFO_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "disk_info");
  protected static final String HOST_HOST_STATUS_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "host_status");
  protected static final String HOST_HOST_HEALTH_REPORT_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "host_health_report");
  protected static final String HOST_STATE_PROPERTY_ID =
      PropertyHelper.getPropertyId("Hosts", "host_state");

  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          HOST_NAME_PROPERTY_ID}));

  // ----- Constructors ----------------------------------------------------

  /**
   * Create a  new resource provider for the given management controller.
   *
   * @param propertyIds           the property ids
   * @param keyPropertyIds        the key property ids
   * @param managementController  the management controller
   */
  HostResourceProvider(Set<String> propertyIds,
                       Map<Resource.Type, String> keyPropertyIds,
                       AmbariManagementController managementController) {
    super(propertyIds, keyPropertyIds, managementController);
  }

  // ----- ResourceProvider ------------------------------------------------

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException,
          UnsupportedPropertyException,
          ResourceAlreadyExistsException,
          NoSuchParentResourceException {

    final Set<HostRequest> requests = new HashSet<HostRequest>();
    for (Map<String, Object> propertyMap : request.getProperties()) {
      requests.add(getRequest(propertyMap));
    }
    createResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().createHosts(requests);
        return null;
      }
    });

    notifyCreate(Resource.Type.Host, request);

    return getRequestStatus(null);
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<HostRequest> requests = new HashSet<HostRequest>();

    if (predicate == null) {
      requests.add(getRequest(null));
    }
    else {
      for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
        requests.add(getRequest(propertyMap));
      }
    }

    Set<HostResponse> responses = getResources(new Command<Set<HostResponse>>() {
      @Override
      public Set<HostResponse> invoke() throws AmbariException {
        return getManagementController().getHosts(requests);
      }
    });

    Set<String>   requestedIds = PropertyHelper.getRequestPropertyIds(getPropertyIds(), request, predicate);
    Set<Resource> resources    = new HashSet<Resource>();

    for (HostResponse response : responses) {
      Resource resource = new ResourceImpl(Resource.Type.Host);

      // TODO : properly handle more than one cluster
      if (response.getClusterName() != null
          && !response.getClusterName().isEmpty()) {
        setResourceProperty(resource, HOST_CLUSTER_NAME_PROPERTY_ID,
            response.getClusterName(), requestedIds);
      }

      setResourceProperty(resource, HOST_NAME_PROPERTY_ID,
          response.getHostname(), requestedIds);
      setResourceProperty(resource, HOST_PUBLIC_NAME_PROPERTY_ID,
          response.getPublicHostName(), requestedIds);
      setResourceProperty(resource, HOST_IP_PROPERTY_ID,
          response.getIpv4(), requestedIds);
      setResourceProperty(resource, HOST_TOTAL_MEM_PROPERTY_ID,
          response.getTotalMemBytes(), requestedIds);
      setResourceProperty(resource, HOST_CPU_COUNT_PROPERTY_ID,
          (long) response.getCpuCount(), requestedIds);
      setResourceProperty(resource, HOST_OS_ARCH_PROPERTY_ID,
          response.getOsArch(), requestedIds);
      setResourceProperty(resource, HOST_OS_TYPE_PROPERTY_ID,
          response.getOsType(), requestedIds);
      setResourceProperty(resource, HOST_RACK_INFO_PROPERTY_ID,
          response.getRackInfo(), requestedIds);
      setResourceProperty(resource, HOST_LAST_HEARTBEAT_TIME_PROPERTY_ID,
          response.getLastHeartbeatTime(), requestedIds);
      setResourceProperty(resource, HOST_LAST_REGISTRATION_TIME_PROPERTY_ID,
          response.getLastRegistrationTime(), requestedIds);
      setResourceProperty(resource, HOST_HOST_STATUS_PROPERTY_ID,
          response.getHealthStatus().getHealthStatus().toString(),requestedIds);
      setResourceProperty(resource, HOST_HOST_HEALTH_REPORT_PROPERTY_ID,
          response.getHealthStatus().getHealthReport(), requestedIds);
      setResourceProperty(resource, HOST_DISK_INFO_PROPERTY_ID,
          response.getDisksInfo(), requestedIds);
      setResourceProperty(resource, HOST_STATE_PROPERTY_ID,
          response.getHostState(), requestedIds);
      resources.add(resource);
    }
    return resources;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<HostRequest> requests = new HashSet<HostRequest>();
    for (Map<String, Object> propertyMap : getPropertyMaps(request.getProperties().iterator().next(), predicate)) {
      requests.add(getRequest(propertyMap));
    }

    modifyResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().updateHosts(requests);
        return null;
      }
    });

    notifyUpdate(Resource.Type.Host, request, predicate);

    return getRequestStatus(null);
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<HostRequest> requests = new HashSet<HostRequest>();
    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      requests.add(getRequest(propertyMap));
    }

    modifyResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().deleteHosts(requests);
        return null;
      }
    });

    notifyDelete(Resource.Type.Host, predicate);

    return getRequestStatus(null);
  }

  // ----- utility methods -------------------------------------------------

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  /**
   * Get a host request object from a map of property values.
   *
   * @param properties  the predicate
   *
   * @return the component request object
   */
  private HostRequest getRequest(Map<String, Object> properties) {

    if (properties == null) {
      return  new HostRequest(null, null, null);
    }

    HostRequest hostRequest = new HostRequest(
        (String) properties.get(HOST_NAME_PROPERTY_ID),
        (String) properties.get(HOST_CLUSTER_NAME_PROPERTY_ID),
        null);
    hostRequest.setPublicHostName((String) properties.get(HOST_PUBLIC_NAME_PROPERTY_ID));
    hostRequest.setRackInfo((String) properties.get(HOST_RACK_INFO_PROPERTY_ID));

    return hostRequest;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ObservableResourceProvider.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

/**
 * A resource provider that accepts observers that listen for resource provider events.
 */
public interface ObservableResourceProvider {

  /**
   * Update all registered observers with the given event.
   *
   * @param event  the event
   */
  public void updateObservers(ResourceProviderEvent event);

  /**
   * Add an observer.
   *
   * @param observer  the observer
   */
  public void addObserver(ResourceProviderObserver observer);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/PropertyInfo.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

/**
 * Property identifier information.
 */
public class PropertyInfo {
  private final String propertyId;
  private final boolean temporal;
  private final boolean pointInTime;

  public PropertyInfo(String propertyId, boolean temporal, boolean pointInTime) {
    this.propertyId = propertyId;
    this.temporal = temporal;
    this.pointInTime = pointInTime;
  }

  public String getPropertyId() {
    return propertyId;
  }

  public boolean isTemporal() {
    return temporal;
  }

  public boolean isPointInTime() {
    return pointInTime;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/PropertyPredicateVisitor.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.predicate.AlwaysPredicate;
import org.apache.ambari.server.controller.predicate.ArrayPredicate;
import org.apache.ambari.server.controller.predicate.BasePredicate;
import org.apache.ambari.server.controller.predicate.ComparisonPredicate;
import org.apache.ambari.server.controller.predicate.PropertyPredicate;
import org.apache.ambari.server.controller.predicate.PredicateVisitor;
import org.apache.ambari.server.controller.predicate.UnaryPredicate;

import java.util.HashMap;
import java.util.Map;

/**
 * Predicate visitor for extracting property values from the {@link PropertyPredicate}s of a predicate graph.
 */
public class PropertyPredicateVisitor implements PredicateVisitor {
  private final Map<String, Object> properties = new HashMap<String, Object>();

  @Override
  public void acceptComparisonPredicate(ComparisonPredicate predicate) {
    properties.put(predicate.getPropertyId(), predicate.getValue());
  }

  @Override
  public void acceptArrayPredicate(ArrayPredicate predicate) {
    BasePredicate[] predicates = predicate.getPredicates();
    for (BasePredicate predicate1 : predicates) {
      predicate1.accept(this);
    }
  }

  @Override
  public void acceptUnaryPredicate(UnaryPredicate predicate) {
    //Do nothing
  }

  @Override
  public void acceptAlwaysPredicate(AlwaysPredicate predicate) {
    //Do nothing
  }


  // ----- accessors ---------------------------------------------------------

  /**
   * Get the properties.
   *
   * @return the properties
   */
  public Map<String, Object> getProperties() {
    return properties;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RequestImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.spi.Request;
import org.apache.ambari.server.controller.spi.TemporalInfo;

import java.util.*;
import java.util.Map.Entry;

/**
 * Default request implementation.
 */
public class RequestImpl implements Request {

  /**
   * The property ids associated with this request.  Used for requests that
   * get resource values.
   */
  private final Set<String> propertyIds;

  /**
   * The properties associated with this request.  Used for requests that create
   * resources or update resource values.
   */
  private final Set<Map<String, Object>> properties;

  /**
   * Map of property to temporal info.
   */
  private Map<String, TemporalInfo> m_mapTemporalInfo = new HashMap<String, TemporalInfo>();


  // ----- Constructors ------------------------------------------------------

  /**
   * Create a request.
   *
   * @param propertyIds      the property ids associated with the request; may be null
   * @param properties       the properties associated with the request; may be null
   * @param mapTemporalInfo  the temporal info
   */
  public RequestImpl(Set<String> propertyIds, Set<Map<String, Object>> properties,
                     Map<String, TemporalInfo> mapTemporalInfo) {
    this.propertyIds = propertyIds == null ?
        Collections.unmodifiableSet(new HashSet<String>()) :
        Collections.unmodifiableSet(propertyIds);

    this.properties = properties == null ?
        Collections.unmodifiableSet(new HashSet<Map<String, Object>>()) :
        Collections.unmodifiableSet(properties);

    setTemporalInfo(mapTemporalInfo);
  }


  // ----- Request -----------------------------------------------------------

  @Override
  public Set<String> getPropertyIds() {
    return propertyIds;
  }

  @Override
  public Set<Map<String, Object>> getProperties() {
    return properties;
  }

  @Override
  public TemporalInfo getTemporalInfo(String id) {
    return m_mapTemporalInfo.get(id);
  }

  private void setTemporalInfo(Map<String, TemporalInfo> mapTemporalInfo) {
    m_mapTemporalInfo = mapTemporalInfo;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    RequestImpl request = (RequestImpl) o;

    return !(properties == null ? request.properties != null : !properties.equals(request.properties)) &&
        !(propertyIds == null ? request.propertyIds != null : !propertyIds.equals(request.propertyIds));
  }

  @Override
  public int hashCode() {
    int result = propertyIds != null ? propertyIds.hashCode() : 0;
    result = 31 * result + (properties != null ? properties.hashCode() : 0);
    return result;
  }

  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("Request:"
        + ", propertyIds=[");
    for (String pId : propertyIds) {
      sb.append(" { propertyName=").append(pId).append(" }, ");
    }
    sb.append(" ], properties=[ ");
    for (Map<String, Object> map : properties) {
      for (Entry<String, Object> entry : map.entrySet()) {
        sb.append(" { propertyName=").append(entry.getKey()).append(", propertyValue=").
            append(entry.getValue().toString()).append(" }, ");
      }
    }
    sb.append(" ], temporalInfo=[");
    if (m_mapTemporalInfo == null) {
      sb.append("null");
    } else {
      for (Entry<String, TemporalInfo> entry :
        m_mapTemporalInfo.entrySet()) {
        sb.append(" { propertyName=").append(entry.getKey()).append(", temporalInfo=").
            append(entry.getValue().toString());
      }
    }
    sb.append(" ]");
    return sb.toString();
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RequestResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.RequestStatusRequest;
import org.apache.ambari.server.controller.RequestStatusResponse;
import org.apache.ambari.server.controller.spi.NoSuchParentResourceException;
import org.apache.ambari.server.controller.spi.NoSuchResourceException;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.Request;
import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.SystemException;
import org.apache.ambari.server.controller.spi.UnsupportedPropertyException;
import org.apache.ambari.server.controller.utilities.PredicateHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

/**
 * Resource provider for request resources.
 */
class RequestResourceProvider extends ResourceProviderImpl{

  // ----- Property ID constants ---------------------------------------------
  // Requests
  protected static final String REQUEST_CLUSTER_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("Requests", "cluster_name");
  protected static final String REQUEST_ID_PROPERTY_ID           = PropertyHelper.getPropertyId("Requests", "id");
  protected static final String REQUEST_STATUS_PROPERTY_ID       = PropertyHelper.getPropertyId("Requests", "request_status");

  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          REQUEST_ID_PROPERTY_ID}));

  // ----- Constructors ----------------------------------------------------

  /**
   * Create a  new resource provider for the given management controller.
   *
   * @param propertyIds           the property ids
   * @param keyPropertyIds        the key property ids
   * @param managementController  the management controller
   */
  RequestResourceProvider(Set<String> propertyIds,
                          Map<Resource.Type, String> keyPropertyIds,
                          AmbariManagementController managementController) {
    super(propertyIds, keyPropertyIds, managementController);
  }

  // ----- ResourceProvider ------------------------------------------------

  @Override
  public RequestStatus createResources(Request request) {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
    throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    Set<String>         requestedIds         = PropertyHelper.getRequestPropertyIds(getPropertyIds(), request, predicate);
    Map<String, Object> predicateProperties  = PredicateHelper.getProperties(predicate);

    final RequestStatusRequest requestStatusRequest = getRequest(predicateProperties);

    String clusterName = (String) predicateProperties.get(REQUEST_CLUSTER_NAME_PROPERTY_ID);

    Set<RequestStatusResponse> responses = getResources(new Command<Set<RequestStatusResponse>>() {
      @Override
      public Set<RequestStatusResponse> invoke() throws AmbariException {
        return getManagementController().getRequestStatus(requestStatusRequest);
      }
    });


    Set<Resource> resources = new HashSet<Resource>();
    for (RequestStatusResponse response : responses) {
      Resource resource = new ResourceImpl(Resource.Type.Request);
      setResourceProperty(resource, REQUEST_CLUSTER_NAME_PROPERTY_ID, clusterName, requestedIds);
      setResourceProperty(resource, REQUEST_ID_PROPERTY_ID, response.getRequestId(), requestedIds);
      resources.add(resource);
    }
    return resources;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  // ----- utility methods -------------------------------------------------

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  /**
   * Get a component request object from a map of property values.
   *
   * @param properties  the predicate
   *
   * @return the component request object
   */
  private RequestStatusRequest getRequest(Map<String, Object> properties) {
    Long requestId = null;
    if (properties.get(REQUEST_ID_PROPERTY_ID) != null) {
      requestId = Long.valueOf((String) properties
          .get(REQUEST_ID_PROPERTY_ID));
    }
    String requestStatus = null;
    if (properties.get(REQUEST_STATUS_PROPERTY_ID) != null) {
      requestStatus = (String)properties.get(REQUEST_STATUS_PROPERTY_ID);
    }
    return new RequestStatusRequest(requestId, requestStatus);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/RequestStatusImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Collections;
import java.util.Set;

/**
 * Default request status implementation.
 */
public class RequestStatusImpl implements RequestStatus{

  private final Resource requestResource;

  public RequestStatusImpl(Resource requestResource) {
    this.requestResource = requestResource;
  }

  @Override
  public Set<Resource> getAssociatedResources() {
    return Collections.emptySet();  // TODO : handle in M4
  }

  @Override
  public Resource getRequestResource() {
    return requestResource;
  }

  @Override
  public Status getStatus() {

    return requestResource == null ? Status.Complete :
        Status.valueOf((String) requestResource.getPropertyValue(PropertyHelper.getPropertyId("Requests", "status")));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ResourceImpl.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.api.util.TreeNode;
import org.apache.ambari.server.api.util.TreeNodeImpl;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.HashMap;
import java.util.Map;

/**
 * Simple resource implementation.
 */
public class ResourceImpl implements Resource {

  /**
   * The resource type.
   */
  private final Type type;

  /**
   * Tree of categories/properties.
   * Each category is a sub node and each node contains a map of properties(n/v pairs).
   */
  private final TreeNode<Map<String, Object>> m_treeProperties =
      new TreeNodeImpl<Map<String, Object>>(null, new HashMap<String, Object>(), null);


  // ----- Constructors ------------------------------------------------------

  /**
   * Create a resource of the given type.
   *
   * @param type  the resource type
   */
  public ResourceImpl(Type type) {
    this.type = type;
  }

  /**
   * Copy constructor
   *
   * @param resource  the resource to copy
   */
  public ResourceImpl(Resource resource) {
    this.type = resource.getType();

    for (Map.Entry<String, Map<String, Object>> categoryEntry : resource.getPropertiesMap().entrySet()) {
      String category = categoryEntry.getKey();
      Map<String, Object> propertyMap = categoryEntry.getValue();
      if (propertyMap != null) {
        for (Map.Entry<String, Object> propertyEntry : propertyMap.entrySet()) {
          String propertyId    = (category == null ? "" : category + "/") + propertyEntry.getKey();
          Object propertyValue = propertyEntry.getValue();
          setProperty(propertyId, propertyValue);
        }
      }
    }
  }


  // ----- Resource ----------------------------------------------------------

  @Override
  public Type getType() {
    return type;
  }

  @Override
  public TreeNode<Map<String, Object>> getProperties() {
    return m_treeProperties;
  }

  @Override
  public Map<String, Map<String, Object>> getPropertiesMap() {
    Map<String, Map<String, Object>> mapProps = new HashMap<String, Map<String, Object>>();
    addNodeToMap(m_treeProperties, mapProps, null);

    return mapProps;
  }

  @Override
  public void setProperty(String id, Object value) {
    String category = PropertyHelper.getPropertyCategory(id);
    TreeNode<Map<String, Object>> node;
    if (category == null) {
      node = m_treeProperties;
    } else {
      node = m_treeProperties.getChild(category);
      if (node == null) {
        String[] tokens = category.split("/");
        node = m_treeProperties;
        for (String t : tokens) {
          TreeNode<Map<String, Object>> child = node.getChild(t);
          if (child == null) {
            child = node.addChild(new HashMap<String, Object>(), t);
          }
          node = child;
        }
      }
    }
    node.getObject().put(PropertyHelper.getPropertyName(id), value);
  }

  @Override
  public Object getPropertyValue(String id) {
    String category = PropertyHelper.getPropertyCategory(id);
    TreeNode<Map<String, Object>> node = (category == null) ? m_treeProperties :
        m_treeProperties.getChild(category);

    return node == null ? null : node.getObject().get(PropertyHelper.getPropertyName(id));
  }


  // ----- Object overrides --------------------------------------------------

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();

    sb.append("Resource : ").append(type).append("\n");
    sb.append("Properties:\n");

    printPropertyNode(m_treeProperties, sb, null, "  ");

    return sb.toString();
  }


  // ----- class private methods ---------------------------------------------

  /**
   * Recursively prints the properties for a given node and it's children to a StringBuffer.
   *
   * @param node      the node to print properties for
   * @param sb        the SringBuffer to print to
   * @param category  the absolute category name
   * @param indent    the indent to be used
   */
  private void printPropertyNode(TreeNode<Map<String, Object>> node, StringBuilder sb, String category, String indent) {
    if (node.getParent() != null) {
      category = category == null ? node.getName() : category + '/' + node.getName();
      sb.append(indent).append("Category: ").append(category).append('\n');
      indent += "  ";
    }
    for (Map.Entry<String, Object> entry : node.getObject().entrySet()) {
      sb.append(indent).append(entry.getKey()).append('=').append(entry.getValue()).append('\n');
    }

    for (TreeNode<Map<String, Object>> n : node.getChildren()) {
      printPropertyNode(n, sb, category, indent);
    }
  }

  /**
   * Add the node properties to the specified map.
   * Makes recursive calls for each child node.
   *
   * @param node      the node whose properties are to be added
   * @param mapProps  the map that the props are to be added to
   * @param path      the current category hierarchy
   */
  private void addNodeToMap(TreeNode<Map<String, Object>> node, Map<String, Map<String, Object>> mapProps, String path) {
    path = path == null ? node.getName() : path + "/" + node.getName();
    mapProps.put(path, node.getObject());

    for (TreeNode<Map<String, Object>> child : node.getChildren()) {
      addNodeToMap(child, mapProps, path);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ResourceProviderEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.Request;
import org.apache.ambari.server.controller.spi.Resource;

/**
 * Resource provider event used to update resource provider observers.
 */
public class ResourceProviderEvent {
  private final Resource.Type resourceType;
  private final Type type;
  private final Request request;
  private final Predicate predicate;


  // ----- Constructors ------------------------------------------------------

  public ResourceProviderEvent(Resource.Type resourceType, Type type, Request request, Predicate predicate) {
    this.resourceType = resourceType;
    this.type = type;
    this.request = request;
    this.predicate = predicate;
  }

  // ----- ResourceProviderEvent ---------------------------------------------

  /**
   * Get the associated resource type.
   *
   * @return the resource type
   */
  public Resource.Type getResourceType() {
    return resourceType;
  }

  /**
   * Get the event type.
   *
   * @return the event type
   */
  public Type getType() {
    return type;
  }

  /**
   * Get the request object that was used for the operation that generated this event.
   *
   * @return the request object
   */
  public Request getRequest() {
    return request;
  }

  /**
   * Get the predicate object that was used for the operation that generated this event.
   *
   * @return the predicate object
   */
  public Predicate getPredicate() {
    return predicate;
  }


  // ----- event type enumeration --------------------------------------------

  public enum Type {
    Create,
    Update,
    Delete
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ResourceProviderImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.DuplicateResourceException;
import org.apache.ambari.server.ObjectNotFoundException;
import org.apache.ambari.server.ParentObjectNotFoundException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.RequestStatusResponse;
import org.apache.ambari.server.controller.predicate.BasePredicate;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PredicateHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Basic resource provider implementation that maps to a management controller.
 */
public abstract class ResourceProviderImpl implements ResourceProvider, ObservableResourceProvider {

  /**
   * The set of property ids supported by this resource provider.
   */
  private final Set<String> propertyIds;

  /**
   * The management controller to delegate to.
   */
  private final AmbariManagementController managementController;

  /**
   * Key property mapping by resource type.
   */
  private final Map<Resource.Type, String> keyPropertyIds;

  /**
   * Observers of this observable resource provider.
   */
  private final Set<ResourceProviderObserver> observers = new HashSet<ResourceProviderObserver>();


  protected final static Logger LOG =
      LoggerFactory.getLogger(ResourceProviderImpl.class);

    // ----- Constructors ------------------------------------------------------
  /**
   * Create a  new resource provider for the given management controller.
   *
   * @param propertyIds           the property ids
   * @param keyPropertyIds        the key property ids
   * @param managementController  the management controller
   */
  protected ResourceProviderImpl(Set<String> propertyIds,
                               Map<Resource.Type, String> keyPropertyIds,
                               AmbariManagementController managementController) {
    this.propertyIds          = propertyIds;
    this.keyPropertyIds       = keyPropertyIds;
    this.managementController = managementController;
  }


  // ----- ResourceProvider --------------------------------------------------

  @Override
  public Set<String> getPropertyIdsForSchema() {
    return propertyIds;
  }

  @Override
  public Map<Resource.Type, String> getKeyPropertyIds() {
    return keyPropertyIds;
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    if (!this.propertyIds.containsAll(propertyIds)) {
      Set<String> unsupportedPropertyIds = new HashSet<String>(propertyIds);
      unsupportedPropertyIds.removeAll(this.propertyIds);
      return unsupportedPropertyIds;
    }
    return Collections.emptySet();
  }


  // ----- ObservableResourceProvider ----------------------------------------

  @Override
  public void updateObservers(ResourceProviderEvent event) {
    for (ResourceProviderObserver observer : observers) {
      observer.update(event);
    }
  }

  @Override
  public void addObserver(ResourceProviderObserver observer) {
    observers.add(observer);
  }


  // ----- accessors ---------------------------------------------------------

  /**
   * Get the associated property ids.
   *
   * @return the property ids
   */
  protected Set<String> getPropertyIds() {
    return propertyIds;
  }

  /**
   * Get the associated management controller.
   *
   * @return the associated management controller
   */
  protected AmbariManagementController getManagementController() {
    return managementController;
  }


  // ----- utility methods ---------------------------------------------------

  /**
   * Get the set of property ids that uniquely identify the resources
   * of this provider.
   *
   * @return the set of primary key properties
   */
  protected abstract Set<String> getPKPropertyIds();

  /**
   * Notify all listeners of a creation event.
   *
   * @param type     the type of the resources being created
   * @param request  the request used to create the resources
   */
  protected void notifyCreate(Resource.Type type, Request request) {
    updateObservers(new ResourceProviderEvent(type, ResourceProviderEvent.Type.Create, request, null));
  }

  /**
   * Notify all listeners of a update event.
   *
   * @param type       the type of the resources being updated
   * @param request    the request used to update the resources
   * @param predicate  the predicate used to update the resources
   */
  protected void notifyUpdate(Resource.Type type, Request request, Predicate predicate) {
    updateObservers(new ResourceProviderEvent(type, ResourceProviderEvent.Type.Update, request, predicate));
  }

  /**
   * Notify all listeners of a delete event.
   *
   * @param type       the type of the resources being deleted
   * @param predicate  the predicate used to delete the resources
   */
  protected void notifyDelete(Resource.Type type, Predicate predicate) {
    updateObservers(new ResourceProviderEvent(type, ResourceProviderEvent.Type.Delete, null, predicate));
  }

  /**
   * Get a set of properties from the given property map and predicate.
   *
   * @param givenPredicate           the predicate
   *
   * @return the set of properties used to build request objects
   */
  protected Set<Map<String, Object>> getPropertyMaps(Predicate givenPredicate)
    throws UnsupportedPropertyException, SystemException, NoSuchResourceException, NoSuchParentResourceException {

    SimplifyingPredicateVisitor visitor = new SimplifyingPredicateVisitor(propertyIds);
    PredicateHelper.visit(givenPredicate, visitor);
    List<BasePredicate> predicates = visitor.getSimplifiedPredicates();

    Set<Map<String, Object>> propertyMaps = new HashSet<Map<String, Object>>();

    for (BasePredicate predicate : predicates) {
      propertyMaps.add(PredicateHelper.getProperties(predicate));
    }
    return propertyMaps;
  }

  /**
   * Get a set of properties from the given property map and predicate.
   *
   * @param requestPropertyMap  the request properties (for update)
   * @param givenPredicate           the predicate
   *
   * @return the set of properties used to build request objects
   */
  protected Set<Map<String, Object>> getPropertyMaps(Map<String, Object> requestPropertyMap,
                                                         Predicate givenPredicate)
      throws UnsupportedPropertyException, SystemException, NoSuchResourceException, NoSuchParentResourceException {

    Set<Map<String, Object>> propertyMaps = new HashSet<Map<String, Object>>();

    Set<String> pkPropertyIds = getPKPropertyIds();
    if (requestPropertyMap != null && !pkPropertyIds.equals(PredicateHelper.getPropertyIds(givenPredicate))) {

      for (Resource resource : getResources(PropertyHelper.getReadRequest(pkPropertyIds), givenPredicate)) {
        Map<String, Object> propertyMap = new HashMap<String, Object>(PropertyHelper.getProperties(resource));
        propertyMap.putAll(requestPropertyMap);
        propertyMaps.add(propertyMap);
      }
    }
    else {
      Map<String, Object> propertyMap = new HashMap<String, Object>(PredicateHelper.getProperties(givenPredicate));
      propertyMap.putAll(requestPropertyMap);
      propertyMaps.add(propertyMap);
    }

    return propertyMaps;
  }

  /**
   * Get a request status
   *
   * @return the request status
   */
  protected RequestStatus getRequestStatus(RequestStatusResponse response) {

    if (response != null){
      Resource requestResource = new ResourceImpl(Resource.Type.Request);
      requestResource.setProperty(PropertyHelper.getPropertyId("Requests", "id"), response.getRequestId());
      // TODO : how do we tell what a request status is?
      // for now make everything InProgress
      requestResource.setProperty(PropertyHelper.getPropertyId("Requests", "status"), "InProgress");
      return new RequestStatusImpl(requestResource);
    }
    return new RequestStatusImpl(null);
  }

  /**
   * Set a property value on the given resource for the given id and value.
   * Make sure that the id is in the given set of requested ids.
   *
   * @param resource      the resource
   * @param propertyId    the property id
   * @param value         the value to set
   * @param requestedIds  the requested set of property ids
   */
  protected static void setResourceProperty(Resource resource, String propertyId, Object value, Set<String> requestedIds) {
    if (requestedIds.contains(propertyId)) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Setting property for resource"
            + ", resourceType=" + resource.getType()
            + ", propertyId=" + propertyId
            + ", value=" + value);
      }
      resource.setProperty(propertyId, value);
    }
    else {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Skipping property for resource as not in requestedIds"
            + ", resourceType=" + resource.getType()
            + ", propertyId=" + propertyId
            + ", value=" + value);
      }
    }
  }

  /**
   * Factory method for obtaining a resource provider based on a given type and management controller.
   *
   *
   * @param type                  the resource type
   * @param propertyIds           the property ids
   * @param managementController  the management controller
   *
   * @return a new resource provider
   */
  public static ResourceProvider getResourceProvider(Resource.Type type,
                                                     Set<String> propertyIds,
                                                     Map<Resource.Type, String> keyPropertyIds,
                                                     AmbariManagementController managementController) {
    switch (type) {
      case Cluster:
        return new ClusterResourceProvider(propertyIds, keyPropertyIds, managementController);
      case Service:
        return new ServiceResourceProvider(propertyIds, keyPropertyIds, managementController);
      case Component:
        return new ComponentResourceProvider(propertyIds, keyPropertyIds, managementController);
      case Host:
        return new HostResourceProvider(propertyIds, keyPropertyIds, managementController);
      case HostComponent:
        return new HostComponentResourceProvider(propertyIds, keyPropertyIds, managementController);
      case Configuration:
        return new ConfigurationResourceProvider(propertyIds, keyPropertyIds, managementController);
      case Action:
        return new ActionResourceProvider(propertyIds, keyPropertyIds, managementController);
      case Request:
        return new RequestResourceProvider(propertyIds, keyPropertyIds, managementController);
      case Task:
        return new TaskResourceProvider(propertyIds, keyPropertyIds, managementController);
      case User:
        return new UserResourceProvider(propertyIds, keyPropertyIds, managementController);
      default:
        throw new IllegalArgumentException("Unknown type " + type);
    }
  }

  protected <T> T createResources(Command<T> command)
      throws SystemException, ResourceAlreadyExistsException, NoSuchParentResourceException {
    try {
      return command.invoke();
    } catch (ParentObjectNotFoundException e) {
      throw new NoSuchParentResourceException(e.getMessage(), e);
    } catch (DuplicateResourceException e) {
      throw new ResourceAlreadyExistsException(e.getMessage());
    } catch (AmbariException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught AmbariException when creating a resource", e);
      }
      throw new SystemException("An internal system exception occurred: " + e.getMessage(), e);
    }
  }

  protected <T> T getResources (Command<T> command)
      throws SystemException, NoSuchResourceException, NoSuchParentResourceException {
    try {
      return command.invoke();
    } catch (ObjectNotFoundException e) {
      throw new NoSuchResourceException("The requested resource doesn't exist: " + e.getMessage(), e);
    } catch (ParentObjectNotFoundException e) {
      throw new NoSuchParentResourceException(e.getMessage(), e);
    } catch (AmbariException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught AmbariException when getting a resource", e);
      }
      throw new SystemException("An internal system exception occurred: " + e.getMessage(), e);
    }
  }

  protected <T> T modifyResources (Command<T> command)
      throws SystemException, NoSuchResourceException, NoSuchParentResourceException {
    try {
      return command.invoke();
    } catch (ObjectNotFoundException e) {
      throw new NoSuchResourceException("The specified resource doesn't exist: " + e.getMessage(), e);
    } catch (ParentObjectNotFoundException e) {
      throw new NoSuchParentResourceException(e.getMessage(), e);
    } catch (AmbariException e) {
      if (LOG.isErrorEnabled()) {
        LOG.error("Caught AmbariException when modifying a resource", e);
      }
      throw new SystemException("An internal system exception occurred: " + e.getMessage(), e);
    }
  }

  protected interface Command<T> {
    public T invoke() throws AmbariException;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ResourceProviderObserver.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

/**
 * An object that listens for events from a resource provider.
 */
public interface ResourceProviderObserver {
  /**
   * Update this observer with an event from a resource provider.
   *
   * @param event the event
   */
  public void update(ResourceProviderEvent event);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/SchemaImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.spi.PropertyProvider;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.ResourceProvider;
import org.apache.ambari.server.controller.spi.Schema;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

/**
 * Simple schema implementation.
 */
public class SchemaImpl implements Schema {
  /**
   * The associated resource provider.
   */
  private final ResourceProvider resourceProvider;

  /**
   * The list of associated property providers.
   */
  private final List<PropertyProvider> propertyProviders;

  /**
   * The map of categories and properties.
   */
  private final Map<String, Set<String>> categoryProperties;


  // ----- Constructors ------------------------------------------------------

  /**
   * Create a new schema for the given providers.
   *
   * @param resourceProvider   the resource provider
   * @param propertyProviders  the property providers
   */
  public SchemaImpl(ResourceProvider resourceProvider,
                    List<PropertyProvider> propertyProviders) {
    this.resourceProvider   = resourceProvider;
    this.propertyProviders  = propertyProviders;
    this.categoryProperties = initCategoryProperties();
  }


  // ----- Schema ------------------------------------------------------------

  @Override
  public String getKeyPropertyId(Resource.Type type) {
    return resourceProvider.getKeyPropertyIds().get(type);
  }

  @Override
  public Map<String, Set<String>> getCategoryProperties() {
    return categoryProperties;
  }


  // ----- helper methods ----------------------------------------------------

  private Map<String, Set<String>> initCategoryProperties() {
    Map<String, Set<String>> categories = new HashMap<String, Set<String>>();

    for (String propertyId : getPropertyIds()) {
      final String category = PropertyHelper.getPropertyCategory(propertyId);
      Set<String> properties = categories.get(category);
      if (properties == null) {
        properties = new HashSet<String>();
        categories.put(category, properties);
      }
      properties.add(PropertyHelper.getPropertyName(propertyId));
    }
    return categories;
  }

  private Set<String> getPropertyIds() {
    Set<String> propertyIds = new HashSet<String>(resourceProvider.getPropertyIdsForSchema());
    if (propertyProviders != null) {
      for (PropertyProvider propertyProvider : propertyProviders) {
        propertyIds.addAll(propertyProvider.getPropertyIds());
      }
    }
    return propertyIds;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ServiceResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.RequestStatusResponse;
import org.apache.ambari.server.controller.ServiceRequest;
import org.apache.ambari.server.controller.ServiceResponse;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;
import java.util.Set;

/**
 * Resource provider for service resources.
 */
class ServiceResourceProvider extends ResourceProviderImpl {


  // ----- Property ID constants ---------------------------------------------

  // Services
  protected static final String SERVICE_CLUSTER_NAME_PROPERTY_ID    = PropertyHelper.getPropertyId("ServiceInfo", "cluster_name");
  protected static final String SERVICE_SERVICE_NAME_PROPERTY_ID    = PropertyHelper.getPropertyId("ServiceInfo", "service_name");
  protected static final String SERVICE_SERVICE_STATE_PROPERTY_ID   = PropertyHelper.getPropertyId("ServiceInfo", "state");
  protected static final String SERVICE_DESIRED_CONFIGS_PROPERTY_ID = PropertyHelper.getPropertyId("ServiceInfo", "desired_configs");


  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          SERVICE_CLUSTER_NAME_PROPERTY_ID,
          SERVICE_SERVICE_NAME_PROPERTY_ID}));

  // ----- Constructors ----------------------------------------------------

  /**
   * Create a  new resource provider for the given management controller.
   *
   * @param propertyIds           the property ids
   * @param keyPropertyIds        the key property ids
   * @param managementController  the management controller
   */
  ServiceResourceProvider(Set<String> propertyIds,
                          Map<Resource.Type, String> keyPropertyIds,
                          AmbariManagementController managementController) {
    super(propertyIds, keyPropertyIds, managementController);
  }

  // ----- ResourceProvider ------------------------------------------------

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException,
             UnsupportedPropertyException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException {

    final Set<ServiceRequest> requests = new HashSet<ServiceRequest>();
    for (Map<String, Object> propertyMap : request.getProperties()) {
      requests.add(getRequest(propertyMap));
    }
    createResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().createServices(requests);
        return null;
      }
    });
    notifyCreate(Resource.Type.Service, request);

    return getRequestStatus(null);
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate) throws
      SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<ServiceRequest> requests = new HashSet<ServiceRequest>();

    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      requests.add(getRequest(propertyMap));
    }

    Set<ServiceResponse> responses    =  getResources(new Command<Set<ServiceResponse>>() {
      @Override
      public Set<ServiceResponse> invoke() throws AmbariException {
        return getManagementController().getServices(requests);
      }
    });

    Set<String>   requestedIds = PropertyHelper.getRequestPropertyIds(getPropertyIds(), request, predicate);
    Set<Resource> resources    = new HashSet<Resource>();

    for (ServiceResponse response : responses) {
      Resource resource = new ResourceImpl(Resource.Type.Service);
      setResourceProperty(resource, SERVICE_CLUSTER_NAME_PROPERTY_ID,
          response.getClusterName(), requestedIds);
      setResourceProperty(resource, SERVICE_SERVICE_NAME_PROPERTY_ID,
          response.getServiceName(), requestedIds);
      setResourceProperty(resource, SERVICE_DESIRED_CONFIGS_PROPERTY_ID,
          response.getConfigVersions(), requestedIds);
      setResourceProperty(resource, SERVICE_SERVICE_STATE_PROPERTY_ID,
          response.getDesiredState(), requestedIds);
      resources.add(resource);
    }
    return resources;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<ServiceRequest> requests = new HashSet<ServiceRequest>();
    RequestStatusResponse     response = null;

    Iterator<Map<String,Object>> iterator = request.getProperties().iterator();
    if (iterator.hasNext()) {
      for (Map<String, Object> propertyMap : getPropertyMaps(iterator.next(), predicate)) {
        requests.add(getRequest(propertyMap));
      }
      response = modifyResources(new Command<RequestStatusResponse>() {
        @Override
        public RequestStatusResponse invoke() throws AmbariException {
          return getManagementController().updateServices(requests);
        }
      });
    }
    notifyUpdate(Resource.Type.Service, request, predicate);

    return getRequestStatus(response);
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<ServiceRequest> requests = new HashSet<ServiceRequest>();
    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      requests.add(getRequest(propertyMap));
    }
    RequestStatusResponse response = modifyResources(new Command<RequestStatusResponse>() {
      @Override
      public RequestStatusResponse invoke() throws AmbariException {
        return getManagementController().deleteServices(requests);
      }
    });

    notifyDelete(Resource.Type.Service, predicate);
    return getRequestStatus(response);
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    propertyIds = super.checkPropertyIds(propertyIds);

    if (propertyIds.isEmpty()) {
      return propertyIds;
    }
    Set<String> unsupportedProperties = new HashSet<String>();

    for (String propertyId : propertyIds) {
      String propertyCategory = PropertyHelper.getPropertyCategory(propertyId);
      if (propertyCategory == null || !propertyCategory.equals("config")) {
        unsupportedProperties.add(propertyId);
      }
    }
    return unsupportedProperties;
  }


// ----- utility methods -------------------------------------------------

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  /**
   * Get a service request object from a map of property values.
   *
   * @param properties  the predicate
   *
   * @return the service request object
   */
  private ServiceRequest getRequest(Map<String, Object> properties) {
    ServiceRequest svcRequest = new ServiceRequest(
        (String) properties.get(SERVICE_CLUSTER_NAME_PROPERTY_ID),
        (String) properties.get(SERVICE_SERVICE_NAME_PROPERTY_ID),
        null,
        (String) properties.get(SERVICE_SERVICE_STATE_PROPERTY_ID));

    Map<String, String> configMappings =
        ConfigurationResourceProvider.getConfigPropertyValues(properties);

    if (configMappings.size() > 0) {
      svcRequest.setConfigVersions(configMappings);
    }
    return svcRequest;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/SimplifyingPredicateVisitor.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.predicate.AlwaysPredicate;
import org.apache.ambari.server.controller.predicate.AndPredicate;
import org.apache.ambari.server.controller.predicate.ArrayPredicate;
import org.apache.ambari.server.controller.predicate.BasePredicate;
import org.apache.ambari.server.controller.predicate.ComparisonPredicate;
import org.apache.ambari.server.controller.predicate.EqualsPredicate;
import org.apache.ambari.server.controller.predicate.OrPredicate;
import org.apache.ambari.server.controller.predicate.PredicateVisitor;
import org.apache.ambari.server.controller.predicate.UnaryPredicate;

import java.util.Arrays;
import java.util.Collections;
import java.util.LinkedList;
import java.util.List;
import java.util.Set;

/**
 * A predicate visitor used to simplify by doing the following ...
 *
 * 1) distribute across OR (e.g. A && ( B || C ) becomes ( A && B ) || ( A && C )).
 * This is done because an individual back end request object can not handle OR.  Instead
 * we need to break up the predicate to form multiple requests and take the union of all
 * the responses.
 * 2) convert predicates based on unsupported properties to AlwaysPredicate.
 * Unsupported properties are those not returned by the resource provider.  For these
 * properties we need to wait until the property provider that handles the property has
 * been called.
 * 3) convert predicates based on any operator other than == to AlwaysPredicate.
 * The back end requests can not handle any operator other than equals.  The complete predicate
 * will get applied further down the line if necessary.
 *
 * After visiting a predicate, the visitor should be able to supply a list of predicates that can be
 * used to generate requests to the backend, working around the restrictions above.
 *
 * Note that the results acquired using the generated predicates may be a super set of what is actually
 * desired given the original predicate, but the original predicate will be applied at a suitable time
 * down the line if required.
 */
public class SimplifyingPredicateVisitor implements PredicateVisitor {

  private final Set<String> supportedProperties;
  private BasePredicate lastVisited = null;

  public SimplifyingPredicateVisitor(Set<String> supportedProperties) {
    this.supportedProperties = supportedProperties;
  }

  public List<BasePredicate> getSimplifiedPredicates() {
    if (lastVisited == null) {
      return Collections.emptyList();
    }
    if (lastVisited instanceof OrPredicate) {
      return Arrays.asList(((OrPredicate) lastVisited).getPredicates());
    }
    return Collections.singletonList(lastVisited);
  }

  @Override
  public void acceptComparisonPredicate(ComparisonPredicate predicate) {
    if (predicate instanceof EqualsPredicate &&
        supportedProperties.contains(predicate.getPropertyId())) {
      lastVisited = predicate;
    }
    else {
      lastVisited = AlwaysPredicate.INSTANCE;
    }
  }

  @Override
  public void acceptArrayPredicate(ArrayPredicate arrayPredicate) {
    List<BasePredicate> predicateList = new LinkedList<BasePredicate>();
    boolean hasOrs = false;

    BasePredicate[] predicates = arrayPredicate.getPredicates();
    if (predicates.length > 0) {
      for (BasePredicate predicate : predicates) {
        predicate.accept(this);
        predicateList.add(lastVisited);
        if (lastVisited instanceof OrPredicate) {
          hasOrs = true;
        }
      }
    }
    // distribute so that A && ( B || C ) becomes ( A && B ) || ( A && C )
    if (hasOrs && arrayPredicate instanceof AndPredicate) {
      int size = predicateList.size();
      List<BasePredicate> andPredicateList = new LinkedList<BasePredicate>();

      for (int i = 0; i < size; ++i) {
        for (int j = i + 1; j < size; ++j) {
          andPredicateList.addAll(distribute(predicateList.get(i), predicateList.get(j)));
        }
      }
      lastVisited = OrPredicate.instance(andPredicateList.toArray(new BasePredicate[andPredicateList.size()]));
    }
    else {
      lastVisited = arrayPredicate.create(predicateList.toArray(new BasePredicate[predicateList.size()]));
    }
  }

  @Override
  public void acceptUnaryPredicate(UnaryPredicate predicate) {
    lastVisited = predicate;
  }

  @Override
  public void acceptAlwaysPredicate(AlwaysPredicate predicate) {
    lastVisited = predicate;
  }

  private static List<BasePredicate> distribute(BasePredicate left, BasePredicate right) {

    if (left instanceof OrPredicate) {
      return distributeOr((OrPredicate) left, right);
    }

    if (right instanceof OrPredicate) {
      return distributeOr((OrPredicate) right, left);
    }
    return Collections.singletonList(left.equals(right) ?
        left : AndPredicate.instance(left, right));
  }

  private static List<BasePredicate> distributeOr(OrPredicate orPredicate, BasePredicate other) {
    List<BasePredicate> andPredicateList = new LinkedList<BasePredicate>();
    OrPredicate otherOr = null;

    if (other instanceof OrPredicate) {
      otherOr = (OrPredicate) other;
    }

    for (BasePredicate basePredicate : orPredicate.getPredicates()) {

      if (otherOr != null) {
        andPredicateList.addAll(distributeOr(otherOr, basePredicate));
      }
      else {
        andPredicateList.add(basePredicate.equals(other) ?
            basePredicate : AndPredicate.instance(basePredicate, other));
      }
    }
    return andPredicateList;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/TaskResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.TaskStatusRequest;
import org.apache.ambari.server.controller.TaskStatusResponse;
import org.apache.ambari.server.controller.spi.NoSuchParentResourceException;
import org.apache.ambari.server.controller.spi.NoSuchResourceException;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.Request;
import org.apache.ambari.server.controller.spi.RequestStatus;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.SystemException;
import org.apache.ambari.server.controller.spi.UnsupportedPropertyException;
import org.apache.ambari.server.controller.utilities.PredicateHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.Collections;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

/**
 * Resource provider for task resources.
 */
class TaskResourceProvider extends ResourceProviderImpl{

  // ----- Property ID constants ---------------------------------------------

  // Tasks
  protected static final String TASK_CLUSTER_NAME_PROPERTY_ID = PropertyHelper.getPropertyId("Tasks", "cluster_name");
  protected static final String TASK_REQUEST_ID_PROPERTY_ID   = PropertyHelper.getPropertyId("Tasks", "request_id");
  protected static final String TASK_ID_PROPERTY_ID           = PropertyHelper.getPropertyId("Tasks", "id");
  protected static final String TASK_STAGE_ID_PROPERTY_ID     = PropertyHelper.getPropertyId("Tasks", "stage_id");
  protected static final String TASK_HOST_NAME_PROPERTY_ID    = PropertyHelper.getPropertyId("Tasks", "host_name");
  protected static final String TASK_ROLE_PROPERTY_ID         = PropertyHelper.getPropertyId("Tasks", "role");
  protected static final String TASK_COMMAND_PROPERTY_ID      = PropertyHelper.getPropertyId("Tasks", "command");
  protected static final String TASK_STATUS_PROPERTY_ID       = PropertyHelper.getPropertyId("Tasks", "status");
  protected static final String TASK_EXIT_CODE_PROPERTY_ID    = PropertyHelper.getPropertyId("Tasks", "exit_code");
  protected static final String TASK_STDERR_PROPERTY_ID       = PropertyHelper.getPropertyId("Tasks", "stderr");
  protected static final String TASK_STOUT_PROPERTY_ID        = PropertyHelper.getPropertyId("Tasks", "stdout");
  protected static final String TASK_START_TIME_PROPERTY_ID   = PropertyHelper.getPropertyId("Tasks", "start_time");
  protected static final String TASK_ATTEMPT_CNT_PROPERTY_ID  = PropertyHelper.getPropertyId("Tasks", "attempt_cnt");


  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          TASK_ID_PROPERTY_ID}));

  // ----- Constructors ----------------------------------------------------

  /**
   * Create a  new resource provider for the given management controller.
   *
   * @param propertyIds           the property ids
   * @param keyPropertyIds        the key property ids
   * @param managementController  the management controller
   */
  TaskResourceProvider(Set<String> propertyIds,
                       Map<Resource.Type, String> keyPropertyIds,
                       AmbariManagementController managementController) {
    super(propertyIds, keyPropertyIds, managementController);
  }

  // ----- ResourceProvider ------------------------------------------------

  @Override
  public RequestStatus createResources(Request request) {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    Set<String> requestedIds = PropertyHelper.getRequestPropertyIds(getPropertyIds(), request, predicate);
    final Map<String, Object> predicateProperties = PredicateHelper.getProperties(predicate);

    String clusterName = (String) predicateProperties.get(TASK_CLUSTER_NAME_PROPERTY_ID);
    Long   request_id  = new Long((String) predicateProperties.get(TASK_REQUEST_ID_PROPERTY_ID));

    // TODO : handle multiple requests

    Set<TaskStatusResponse> responses = getResources(new Command<Set<TaskStatusResponse>>() {
      @Override
      public Set<TaskStatusResponse> invoke() throws AmbariException {
        return getManagementController().getTaskStatus(Collections.singleton(getRequest(predicateProperties)));
      }
    });
    
    if (LOG.isDebugEnabled()) {
      LOG.debug("Printing size of responses " + responses.size());
      for (TaskStatusResponse response : responses) {
        LOG.debug("Printing response from management controller "
            + response.toString());
      }
    }

    Set<Resource> resources = new HashSet<Resource>();
    for (TaskStatusResponse response : responses) {
      Resource resource = new ResourceImpl(Resource.Type.Task);

      setResourceProperty(resource, TASK_CLUSTER_NAME_PROPERTY_ID, clusterName, requestedIds);
      setResourceProperty(resource, TASK_REQUEST_ID_PROPERTY_ID, request_id, requestedIds);
      setResourceProperty(resource, TASK_ID_PROPERTY_ID, response.getTaskId(), requestedIds);
      setResourceProperty(resource, TASK_STAGE_ID_PROPERTY_ID, response.getStageId(), requestedIds);
      setResourceProperty(resource, TASK_HOST_NAME_PROPERTY_ID, response.getHostName(), requestedIds);
      setResourceProperty(resource, TASK_ROLE_PROPERTY_ID, response.getRole(), requestedIds);
      setResourceProperty(resource, TASK_COMMAND_PROPERTY_ID, response.getCommand(), requestedIds);
      setResourceProperty(resource, TASK_STATUS_PROPERTY_ID, response.getStatus(), requestedIds);
      setResourceProperty(resource, TASK_EXIT_CODE_PROPERTY_ID, response.getExitCode(), requestedIds);
      setResourceProperty(resource, TASK_STDERR_PROPERTY_ID, response.getStderr(), requestedIds);
      setResourceProperty(resource, TASK_STOUT_PROPERTY_ID, response.getStdout(), requestedIds);
      setResourceProperty(resource, TASK_START_TIME_PROPERTY_ID, response.getStartTime(), requestedIds);
      setResourceProperty(resource, TASK_ATTEMPT_CNT_PROPERTY_ID, response.getAttemptCount(), requestedIds);
      resources.add(resource);
    }
    return resources;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    throw new UnsupportedOperationException("Not currently supported.");
  }

  // ----- utility methods -------------------------------------------------

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  /**
   * Get a component request object from a map of property values.
   *
   * @param properties  the predicate
   *
   * @return the component request object
   */
  private TaskStatusRequest getRequest(Map<String, Object> properties) {
    String taskId = (String) properties.get(TASK_ID_PROPERTY_ID);
    Long task_id = (taskId == null? null: Long.valueOf(taskId));
    return new TaskStatusRequest(
        Long.valueOf((String) properties.get(TASK_REQUEST_ID_PROPERTY_ID)),
        task_id);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/TemporalInfoImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.spi.TemporalInfo;

/**
* Temporal query data.
*/
public class TemporalInfoImpl implements TemporalInfo {
  private long m_startTime;
  private long m_endTime;
  private long m_step;

  public TemporalInfoImpl(long startTime, long endTime, long step) {
    m_startTime = startTime;
    m_endTime = endTime;
    m_step = step;
  }

  @Override
  public Long getStartTime() {
    return m_startTime;
  }

  @Override
  public Long getEndTime() {
    return m_endTime;
  }

  @Override
  public Long getStep() {
    return m_step;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    TemporalInfoImpl that = (TemporalInfoImpl) o;
    return m_endTime == that.m_endTime &&
           m_startTime == that.m_startTime &&
           m_step == that.m_step;

  }

  @Override
  public int hashCode() {
    int result = (int) (m_startTime ^ (m_startTime >>> 32));
    result = 31 * result + (int) (m_endTime ^ (m_endTime >>> 32));
    result = 31 * result + (int) (m_step ^ (m_step >>> 32));
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/URLStreamProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.controller.utilities.StreamProvider;

import java.io.IOException;
import java.io.InputStream;
import java.net.URL;
import java.net.URLConnection;

/**
 * URL based implementation of a stream provider.
 */
public class URLStreamProvider implements StreamProvider {
  @Override
  public InputStream readFrom(String spec) throws IOException {
    URLConnection connection = new URL(spec).openConnection();
    connection.setDoOutput(true);
    return connection.getInputStream();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/internal/UserResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.internal;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.AmbariManagementController;
import org.apache.ambari.server.controller.UserRequest;
import org.apache.ambari.server.controller.UserResponse;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

import java.util.Arrays;
import java.util.Collections;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

/**
 * Resource provider for user resources.
 */
class UserResourceProvider extends ResourceProviderImpl{

  // ----- Property ID constants ---------------------------------------------

  // Users
  protected static final String USER_USERNAME_PROPERTY_ID     = PropertyHelper.getPropertyId("Users", "user_name");
  protected static final String USER_ROLES_PROPERTY_ID        = PropertyHelper.getPropertyId("Users", "roles");
  protected static final String USER_PASSWORD_PROPERTY_ID     = PropertyHelper.getPropertyId("Users", "password");
  protected static final String USER_OLD_PASSWORD_PROPERTY_ID = PropertyHelper.getPropertyId("Users", "old_password");
  protected static final String USER_LDAP_USER_PROPERTY_ID    = PropertyHelper.getPropertyId("Users", "ldap_user");

  private static Set<String> pkPropertyIds =
      new HashSet<String>(Arrays.asList(new String[]{
          USER_USERNAME_PROPERTY_ID}));

  /**
   * Create a new resource provider for the given management controller.
   */
  UserResourceProvider(Set<String> propertyIds,
                       Map<Resource.Type, String> keyPropertyIds,
                       AmbariManagementController managementController) {
    super(propertyIds, keyPropertyIds, managementController);
  }

  @Override
  public RequestStatus createResources(Request request)
      throws SystemException,
      UnsupportedPropertyException,
      ResourceAlreadyExistsException,
      NoSuchParentResourceException {
    final Set<UserRequest> requests = new HashSet<UserRequest>();
    for (Map<String, Object> propertyMap : request.getProperties()) {
      requests.add(getRequest(propertyMap));
    }

    createResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().createUsers(requests);
        return null;
      }
    });

    return getRequestStatus(null);
  }

  @Override
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

    final Set<UserRequest> requests = new HashSet<UserRequest>();

    if (predicate == null) {
      requests.add(getRequest(null));
    } else {
      for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
        requests.add(getRequest(propertyMap));
      }
    }

    Set<UserResponse> responses = getResources(new Command<Set<UserResponse>>() {
      @Override
      public Set<UserResponse> invoke() throws AmbariException {
        return getManagementController().getUsers(requests);
      }
    });

    if (LOG.isDebugEnabled()) {
      LOG.debug("Found user responses matching get user request"
          + ", userRequestSize=" + requests.size()
          + ", userResponseSize=" + responses.size());
    }

    Set<String>   requestedIds = PropertyHelper.getRequestPropertyIds(getPropertyIds(), request, predicate);
    Set<Resource> resources    = new HashSet<Resource>();

    for (UserResponse userResponse : responses) {
      ResourceImpl resource = new ResourceImpl(Resource.Type.User);

      setResourceProperty(resource, USER_USERNAME_PROPERTY_ID,
          userResponse.getUsername(), requestedIds);

      setResourceProperty(resource, USER_ROLES_PROPERTY_ID,
          userResponse.getRoles(), requestedIds);

      setResourceProperty(resource, USER_LDAP_USER_PROPERTY_ID,
          userResponse.isLdapUser(), requestedIds);

      resources.add(resource);
    }

    return resources;
  }

  @Override
  public RequestStatus updateResources(Request request, Predicate predicate)
    throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    final Set<UserRequest> requests = new HashSet<UserRequest>();

    for (Map<String, Object> propertyMap : getPropertyMaps(request.getProperties().iterator().next(), predicate)) {
      UserRequest req = getRequest(propertyMap);

      requests.add(req);
    }

    modifyResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().updateUsers(requests);
        return null;
      }
    });

    return getRequestStatus(null);
  }

  @Override
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {
    final Set<UserRequest> requests = new HashSet<UserRequest>();

    for (Map<String, Object> propertyMap : getPropertyMaps(predicate)) {
      UserRequest req = getRequest(propertyMap);

      requests.add(req);
    }

    modifyResources(new Command<Void>() {
      @Override
      public Void invoke() throws AmbariException {
        getManagementController().deleteUsers(requests);
        return null;
      }
    });

    return getRequestStatus(null);
  }

  @Override
  protected Set<String> getPKPropertyIds() {
    return pkPropertyIds;
  }

  private UserRequest getRequest(Map<String, Object> properties) {
    if (properties == null) {
      return new UserRequest(null);
    }

    UserRequest request = new UserRequest ((String) properties.get(USER_USERNAME_PROPERTY_ID));

    request.setPassword((String) properties.get(USER_PASSWORD_PROPERTY_ID));
    request.setOldPassword((String) properties.get(USER_OLD_PASSWORD_PROPERTY_ID));

    // TODO - support array/sets directly out of the request
    if (null != properties.get(USER_ROLES_PROPERTY_ID)) {
      HashSet<String> roles = new HashSet<String>();

      Collections.addAll(roles, ((String) properties.get(USER_ROLES_PROPERTY_ID)).split(","));

      request.setRoles(roles);
    }

    return request;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/jdbc/ConnectionFactory.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.jdbc;

import java.sql.Connection;
import java.sql.SQLException;

/**
 * Simple JDBC connection factory interface.
 */
public interface ConnectionFactory {
  /**
   * Get a connection.
   *
   * @return the connection
   *
   * @throws SQLException thrown if the connection cannot be obtained
   */
  public Connection getConnection() throws SQLException;
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/jdbc/JDBCProviderModule.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.jdbc;

import org.apache.ambari.server.controller.internal.AbstractProviderModule;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.ResourceProvider;
import org.apache.ambari.server.controller.utilities.DBHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

/**
 * A provider module implementation that uses the JDBC resource provider.
 */
public class JDBCProviderModule extends AbstractProviderModule {
  // ----- utility methods ---------------------------------------------------

  @Override
  protected ResourceProvider createResourceProvider(Resource.Type type) {
    return new JDBCResourceProvider(DBHelper.CONNECTION_FACTORY, type,
        PropertyHelper.getPropertyIds(type),
        PropertyHelper.getKeyPropertyIds(type));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/jdbc/JDBCResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.jdbc;

import org.apache.ambari.server.controller.internal.RequestStatusImpl;
import org.apache.ambari.server.controller.internal.ResourceImpl;
import org.apache.ambari.server.controller.predicate.BasePredicate;
import org.apache.ambari.server.controller.predicate.PredicateVisitorAcceptor;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.PredicateHelper;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.sql.Connection;
import java.sql.DatabaseMetaData;
import java.sql.ResultSet;
import java.sql.ResultSetMetaData;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

/**
 * Generic JDBC based resource provider.
 */
public class JDBCResourceProvider implements ResourceProvider {

    private final Resource.Type type;

    private final Set<String> propertyIds;

    private final ConnectionFactory connectionFactory;

    /**
     * The schema for this provider's resource type.
     */
    private final Map<Resource.Type, String> keyPropertyIds;

    /**
     * Key mappings used for joins.
     */
    private final Map<String, Map<String, String>> importedKeys = new HashMap<String, Map<String, String>>();

    protected final static Logger LOG =
            LoggerFactory.getLogger(JDBCResourceProvider.class);

    public JDBCResourceProvider(ConnectionFactory connectionFactory,
                                Resource.Type type,
                                Set<String> propertyIds,
                                Map<Resource.Type, String> keyPropertyIds) {
        this.connectionFactory = connectionFactory;
        this.type = type;
        this.propertyIds = propertyIds;
        this.keyPropertyIds = keyPropertyIds;
    }

    @Override
    public Set<Resource> getResources(Request request, Predicate predicate)
        throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

        Set<Resource> resources = new HashSet<Resource>();
        Set<String> propertyIds = PropertyHelper.getRequestPropertyIds(this.propertyIds, request, predicate);

        // Can't allow these properties with the old schema...
        propertyIds.remove(PropertyHelper.getPropertyId("Clusters", "cluster_id"));
        propertyIds.remove(PropertyHelper.getPropertyId("Hosts", "disk_info"));
        propertyIds.remove(PropertyHelper.getPropertyId("Hosts", "public_host_name"));
        propertyIds.remove(PropertyHelper.getPropertyId("Hosts", "last_registration_time"));
        propertyIds.remove(PropertyHelper.getPropertyId("Hosts", "host_state"));
        propertyIds.remove(PropertyHelper.getPropertyId("Hosts", "last_heartbeat_time"));
        propertyIds.remove(PropertyHelper.getPropertyId("Hosts", "host_health_report"));
        propertyIds.remove(PropertyHelper.getPropertyId("Hosts", "host_status"));
        propertyIds.remove(PropertyHelper.getPropertyId("ServiceInfo", "desired_configs"));
        propertyIds.remove(PropertyHelper.getPropertyId("ServiceComponentInfo", "desired_configs"));
        propertyIds.remove(PropertyHelper.getPropertyId("HostRoles", "configs"));
        propertyIds.remove(PropertyHelper.getPropertyId("HostRoles", "desired_configs"));

        Connection connection = null;
        Statement statement = null;
        ResultSet rs = null;
        try {
            connection = connectionFactory.getConnection();


            for (String table : getTables(propertyIds)) {
                getImportedKeys(connection, table);
            }

            String sql = getSelectSQL(propertyIds, predicate);
            statement = connection.createStatement();

            rs = statement.executeQuery(sql);

            while (rs.next()) {
                ResultSetMetaData metaData = rs.getMetaData();
                int columnCount = metaData.getColumnCount();

                final ResourceImpl resource = new ResourceImpl(type);
                for (int i = 1; i <= columnCount; ++i) {
                    String propertyId = PropertyHelper.getPropertyId(metaData.getTableName(i), metaData.getColumnName(i));
                    if (propertyIds.contains(propertyId)) {
                        resource.setProperty(propertyId, rs.getString(i));
                    }
                }
                resources.add(resource);
            }
            statement.close();

        } catch (SQLException e) {
            if (LOG.isDebugEnabled()) {
                LOG.debug("Caught exception getting resource.", e);
            }
            return Collections.emptySet();
        } finally {
            try {
                if (rs != null) rs.close();
            } catch (SQLException e) {
                LOG.error("Exception while closing ResultSet", e);
            }

            try {
                if (statement != null) statement.close();
            } catch (SQLException e) {
                LOG.error("Exception while closing statment", e);
            }

            try {
                if (connection != null) connection.close();
            } catch (SQLException e) {
                LOG.error("Exception while closing statment", e);
            }

        }


        return resources;
    }

    @Override
    public RequestStatus createResources(Request request)
        throws SystemException,
               UnsupportedPropertyException,
               ResourceAlreadyExistsException,
               NoSuchParentResourceException {

        try {
            Connection connection = connectionFactory.getConnection();

            try {

                Set<Map<String, Object>> propertySet = request.getProperties();

                for (Map<String, Object> properties : propertySet) {
                    String sql = getInsertSQL(properties);

                    Statement statement = connection.createStatement();

                    statement.execute(sql);

                    statement.close();
                }
            } finally {
                connection.close();
            }

        } catch (SQLException e) {
            throw new IllegalStateException("DB error : ", e);
        }

        return getRequestStatus();
    }

    @Override
    public RequestStatus updateResources(Request request, Predicate predicate)
        throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

        try {
            Connection connection = connectionFactory.getConnection();
            try {
                Set<Map<String, Object>> propertySet = request.getProperties();

                Map<String, Object> properties = propertySet.iterator().next();

                String sql = getUpdateSQL(properties, predicate);

                Statement statement = connection.createStatement();

                statement.execute(sql);

                statement.close();
            } finally {
                connection.close();
            }

        } catch (SQLException e) {
            throw new IllegalStateException("DB error : ", e);
        }

        return getRequestStatus();
    }

    @Override
    public RequestStatus deleteResources(Predicate predicate)
        throws SystemException, UnsupportedPropertyException, NoSuchResourceException, NoSuchParentResourceException {

        try {
            Connection connection = connectionFactory.getConnection();
            try {
                String sql = getDeleteSQL(predicate);

                Statement statement = connection.createStatement();
                statement.execute(sql);
                statement.close();
            } finally {
                connection.close();
            }

        } catch (SQLException e) {
            throw new IllegalStateException("DB error : ", e);
        }

        return getRequestStatus();
    }


    private String getInsertSQL(Map<String, Object> properties) {

        StringBuilder columns = new StringBuilder();
        StringBuilder values = new StringBuilder();
        String table = null;


        for (Map.Entry<String, Object> entry : properties.entrySet()) {
            String propertyId = entry.getKey();
            Object propertyValue = entry.getValue();

            table = PropertyHelper.getPropertyCategory(propertyId);


            if (columns.length() > 0) {
                columns.append(", ");
            }
            columns.append(PropertyHelper.getPropertyName(propertyId));

            if (values.length() > 0) {
                values.append(", ");
            }
            values.append("'");
            values.append(propertyValue);
            values.append("'");
        }

        return "insert into " + table + " (" +
                columns + ") values (" + values + ")";
    }

    private String getSelectSQL(Set<String> propertyIds, Predicate predicate) {

        StringBuilder columns = new StringBuilder();
        Set<String> tableSet = new HashSet<String>();

        for (String propertyId : propertyIds) {
            if (columns.length() > 0) {
                columns.append(", ");
            }
          String propertyCategory = PropertyHelper.getPropertyCategory(propertyId);
          columns.append(propertyCategory).append(".").append(PropertyHelper.getPropertyName(propertyId));
            tableSet.add(propertyCategory);
        }


        boolean haveWhereClause = false;
        StringBuilder whereClause = new StringBuilder();
        if (predicate != null &&
                propertyIds.containsAll(PredicateHelper.getPropertyIds(predicate)) &&
                predicate instanceof PredicateVisitorAcceptor) {

            SQLPredicateVisitor visitor = new SQLPredicateVisitor();
            ((PredicateVisitorAcceptor) predicate).accept(visitor);
            whereClause.append(visitor.getSQL());
            haveWhereClause = true;
        }

        StringBuilder joinClause = new StringBuilder();

        if (tableSet.size() > 1) {

            for (String table : tableSet) {
                Map<String, String> joinKeys = importedKeys.get(table);
                if (joinKeys != null) {
                    for (Map.Entry<String, String> entry : joinKeys.entrySet()) {
                        String category1 = PropertyHelper.getPropertyCategory(entry.getKey());
                        String category2 = PropertyHelper.getPropertyCategory(entry.getValue());
                        if (tableSet.contains(category1) && tableSet.contains(category2)) {
                            if (haveWhereClause) {
                                joinClause.append(" AND ");
                            }
                            joinClause.append(category1).append(".").append(PropertyHelper.getPropertyName(entry.getKey()));
                            joinClause.append(" = ");
                            joinClause.append(category2).append(".").append(PropertyHelper.getPropertyName(entry.getValue()));
                            tableSet.add(category1);
                            tableSet.add(category2);

                            haveWhereClause = true;
                        }
                    }
                }
            }
        }

        StringBuilder tables = new StringBuilder();

        for (String table : tableSet) {
            if (tables.length() > 0) {
                tables.append(", ");
            }
            tables.append(table);
        }

        String sql = "select " + columns + " from " + tables;

        if (haveWhereClause) {
            sql = sql + " where " + whereClause + joinClause;
        }

        return sql;
    }

    private String getDeleteSQL(Predicate predicate) {

        StringBuilder whereClause = new StringBuilder();
        if (predicate instanceof BasePredicate) {

            BasePredicate basePredicate = (BasePredicate) predicate;

            SQLPredicateVisitor visitor = new SQLPredicateVisitor();
            basePredicate.accept(visitor);
            whereClause.append(visitor.getSQL());

            String table = PropertyHelper.getPropertyCategory(basePredicate.getPropertyIds().iterator().next());

            return "delete from " + table + " where " + whereClause;
        }
        throw new IllegalStateException("Can't generate SQL.");
    }

    private String getUpdateSQL(Map<String, Object> properties, Predicate predicate) {

        if (predicate instanceof BasePredicate) {

            StringBuilder whereClause = new StringBuilder();

            BasePredicate basePredicate = (BasePredicate) predicate;

            SQLPredicateVisitor visitor = new SQLPredicateVisitor();
            basePredicate.accept(visitor);
            whereClause.append(visitor.getSQL());

            String table = PropertyHelper.getPropertyCategory(basePredicate.getPropertyIds().iterator().next());


            StringBuilder setClause = new StringBuilder();
            for (Map.Entry<String, Object> entry : properties.entrySet()) {

                if (setClause.length() > 0) {
                    setClause.append(", ");
                }
                setClause.append(PropertyHelper.getPropertyName(entry.getKey()));
                setClause.append(" = ");
                setClause.append("'");
                setClause.append(entry.getValue());
                setClause.append("'");
            }

            return "update " + table + " set " + setClause + " where " + whereClause;
        }
        throw new IllegalStateException("Can't generate SQL.");
    }

    @Override
    public Set<String> getPropertyIdsForSchema() {
        return propertyIds;
    }

    @Override
    public Map<Resource.Type, String> getKeyPropertyIds() {
        return keyPropertyIds;
    }

    @Override
    public Set<String> checkPropertyIds(Set<String> propertyIds) {
      if (!this.propertyIds.containsAll(propertyIds)) {
        Set<String> unsupportedPropertyIds = new HashSet<String>(propertyIds);
        unsupportedPropertyIds.removeAll(this.propertyIds);
        return unsupportedPropertyIds;
      }
      return Collections.emptySet();
    }

    /**
     * Lazily populate the imported key mappings for the given table.
     *
     * @param connection the connection to use to obtain the database meta data
     * @param table      the table
     * @throws SQLException thrown if the meta data for the given connection cannot be obtained
     */
    private void getImportedKeys(Connection connection, String table) throws SQLException {
        if (!this.importedKeys.containsKey(table)) {

            Map<String, String> importedKeys = new HashMap<String, String>();
            this.importedKeys.put(table, importedKeys);

            DatabaseMetaData metaData = connection.getMetaData();

            ResultSet rs = metaData.getImportedKeys(connection.getCatalog(), null, table);

            while (rs.next()) {

                String pkPropertyId = PropertyHelper.getPropertyId(
                    rs.getString("PKTABLE_NAME"), rs.getString("PKCOLUMN_NAME"));

                String fkPropertyId = PropertyHelper.getPropertyId(
                    rs.getString("FKTABLE_NAME"), rs.getString("FKCOLUMN_NAME"));

                importedKeys.put(pkPropertyId, fkPropertyId);
            }
        }
    }

    /**
     * Get a request status
     *
     * @return the request status
     */
    private RequestStatus getRequestStatus() {
        return new RequestStatusImpl(null);
    }

    /**
     * Get the set of tables associated with the given property ids.
     *
     * @param propertyIds the property ids
     * @return the set of tables
     */
    private static Set<String> getTables(Set<String> propertyIds) {
        Set<String> tables = new HashSet<String>();
        for (String propertyId : propertyIds) {
            tables.add(PropertyHelper.getPropertyCategory(propertyId));
        }
        return tables;
    }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/jdbc/SQLiteConnectionFactory.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.jdbc;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.SQLException;

/**
 * Connection factory implementation for SQLite.
 */
public class SQLiteConnectionFactory implements ConnectionFactory {

  /**
   * The connection URL minus the db file.
   */
  private static final String CONNECTION_URL = "jdbc:sqlite:";

  /**
   * The filename of the SQLite db file.
   */
  private final String dbFile;


  // ----- Constructors ------------------------------------------------------

  /**
   * Create a connection factory.
   *
   * @param dbFile  the SQLite DB filename
   */
  public SQLiteConnectionFactory(String dbFile) {
    this.dbFile = dbFile;
    try {
      Class.forName("org.sqlite.JDBC");
    } catch (ClassNotFoundException e) {
      throw new IllegalStateException("Can't load SQLite.", e);
    }
  }


  // ----- ConnectionFactory -------------------------------------------------

  @Override
  public Connection getConnection() throws SQLException {
    return DriverManager.getConnection(CONNECTION_URL + dbFile);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/jdbc/SQLPredicateVisitor.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.jdbc;

import org.apache.ambari.server.controller.predicate.AlwaysPredicate;
import org.apache.ambari.server.controller.predicate.ArrayPredicate;
import org.apache.ambari.server.controller.predicate.BasePredicate;
import org.apache.ambari.server.controller.predicate.ComparisonPredicate;
import org.apache.ambari.server.controller.predicate.PredicateVisitor;
import org.apache.ambari.server.controller.predicate.UnaryPredicate;
import org.apache.ambari.server.controller.utilities.PropertyHelper;

/**
 * Predicate visitor used to generate a SQL where clause from a predicate graph.
 */
public class SQLPredicateVisitor implements PredicateVisitor {

  /**
   * The string builder.
   */
  private final StringBuilder stringBuilder = new StringBuilder();


  // ----- PredicateVisitor --------------------------------------------------

  @Override
  public void acceptComparisonPredicate(ComparisonPredicate predicate) {
    String propertyId = predicate.getPropertyId();

    String propertyCategory = PropertyHelper.getPropertyCategory(propertyId);
    if (propertyCategory != null) {
      stringBuilder.append(propertyCategory).append(".");
    }
    stringBuilder.append(PropertyHelper.getPropertyName(propertyId));

    stringBuilder.append(" ").append(predicate.getOperator()).append(" \"");
    stringBuilder.append(predicate.getValue());
    stringBuilder.append("\"");

  }

  @Override
  public void acceptArrayPredicate(ArrayPredicate predicate) {
    BasePredicate[] predicates = predicate.getPredicates();
    if (predicates.length > 0) {

      stringBuilder.append("(");
      for (int i = 0; i < predicates.length; i++) {
        if (i > 0) {
          stringBuilder.append(" ").append(predicate.getOperator()).append(" ");
        }
        predicates[i].accept(this);
      }
      stringBuilder.append(")");
    }
  }

  @Override
  public void acceptUnaryPredicate(UnaryPredicate predicate) {
    stringBuilder.append(predicate.getOperator()).append("(");
    predicate.getPredicate().accept(this);
    stringBuilder.append(")");
  }

  @Override
  public void acceptAlwaysPredicate(AlwaysPredicate predicate) {
    stringBuilder.append("TRUE");
  }


  // ----- SQLPredicateVisitor -----------------------------------------------

  public String getSQL() {
    return stringBuilder.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/jmx/JMXHostProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.jmx;

import org.apache.ambari.server.controller.spi.SystemException;

import java.util.Map;

/**
 * Provider of JMX host information.
 */
public interface JMXHostProvider {

  /**
   * Get the JMX host name for the given cluster name and component name.
   *
   * @param clusterName    the cluster name
   * @param componentName  the component name
   *
   * @return the JMX host name
   *
   * @throws SystemException of unable to ge the JMX host name
   */
  public String getHostName(String clusterName, String componentName) throws SystemException;


  /**
   * Get the host name mappings for the given cluster name.
   *
   * @param clusterName  the cluster name
   *
   * @return the host name mappings
   *
   * @throws SystemException if unable to get the host mappings
   */
  public Map<String, String> getHostMapping(String clusterName) throws SystemException ;
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/jmx/JMXMetricHolder.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.jmx;

import java.util.List;
import java.util.Map;

/**
 *
 */
public class JMXMetricHolder {

  private List<Map<String, Object>> beans;

  public List<Map<String, Object>> getBeans() {
    return beans;
  }

  public void setBeans(List<Map<String, Object>> beans) {
    this.beans = beans;
  }

  @Override
  public String toString() {
    StringBuilder stringBuilder = new StringBuilder();

    for (Map<String, Object> map : beans) {
      for (Map.Entry<String, Object> entry : map.entrySet()) {
        stringBuilder.append("    ").append(entry.toString()).append("\n");
      }
    }
    return stringBuilder.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/jmx/JMXPropertyProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.jmx;

import org.apache.ambari.server.controller.internal.PropertyInfo;
import org.apache.ambari.server.controller.spi.*;
import org.apache.ambari.server.controller.utilities.StreamProvider;
import org.apache.ambari.server.controller.utilities.PropertyHelper;
import org.codehaus.jackson.map.ObjectMapper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Set;

/**
 * Property provider implementation for JMX sources.
 */
public class JMXPropertyProvider implements PropertyProvider {

  private static final String NAME_KEY = "name";
  private static final String PORT_KEY = "tag.port";

  /**
   * Set of property ids supported by this provider.
   */
  private final Set<String> propertyIds;

  private final Map<String, Map<String, PropertyInfo>> componentMetrics;

  private final StreamProvider streamProvider;

  private final JMXHostProvider jmxHostProvider;

  private static final Map<String, String> JMX_PORTS = new HashMap<String, String>();

  private final String clusterNamePropertyId;

  private final String hostNamePropertyId;

  private final String componentNamePropertyId;


  static {
    JMX_PORTS.put("NAMENODE",     "50070");
    JMX_PORTS.put("DATANODE",     "50075");
    JMX_PORTS.put("JOBTRACKER",   "50030");
    JMX_PORTS.put("TASKTRACKER",  "50060");
    JMX_PORTS.put("HBASE_MASTER", "60010");
  }

  protected final static Logger LOG =
      LoggerFactory.getLogger(JMXPropertyProvider.class);


  // ----- Constructors ------------------------------------------------------

  /**
   * Create a JMX property provider.
   *
   * @param componentMetrics         the map of supported metrics
   * @param streamProvider           the stream provider
   * @param jmxHostProvider          the host mapping
   * @param clusterNamePropertyId    the cluster name property id
   * @param hostNamePropertyId       the host name property id
   * @param componentNamePropertyId  the component name property id
   */
  public JMXPropertyProvider(Map<String, Map<String, PropertyInfo>> componentMetrics,
                             StreamProvider streamProvider,
                             JMXHostProvider jmxHostProvider,
                             String clusterNamePropertyId,
                             String hostNamePropertyId,
                             String componentNamePropertyId) {
    this.componentMetrics         = componentMetrics;
    this.streamProvider           = streamProvider;
    this.jmxHostProvider          = jmxHostProvider;
    this.clusterNamePropertyId    = clusterNamePropertyId;
    this.hostNamePropertyId       = hostNamePropertyId;
    this.componentNamePropertyId  = componentNamePropertyId;

    propertyIds = new HashSet<String>();
    for (Map.Entry<String, Map<String, PropertyInfo>> entry : componentMetrics.entrySet()) {
      propertyIds.addAll(entry.getValue().keySet());
    }
  }


  // ----- PropertyProvider --------------------------------------------------

  @Override
  public Set<Resource> populateResources(Set<Resource> resources, Request request, Predicate predicate)
      throws SystemException {


    Set<Resource> keepers = new HashSet<Resource>();
    for (Resource resource : resources) {
      if (populateResource(resource, request, predicate)) {
        keepers.add(resource);
      }
    }
    return keepers;
  }

  @Override
  public Set<String> getPropertyIds() {
    return propertyIds;
  }

  @Override
  public Set<String> checkPropertyIds(Set<String> propertyIds) {
    if (!this.propertyIds.containsAll(propertyIds)) {
      Set<String> unsupportedPropertyIds = new HashSet<String>(propertyIds);
      unsupportedPropertyIds.removeAll(this.propertyIds);
      return unsupportedPropertyIds;
    }
    return Collections.emptySet();
  }


  // ----- helper methods ----------------------------------------------------

  /**
   * Populate a resource by obtaining the requested JMX properties.
   *
   * @param resource  the resource to be populated
   * @param request   the request
   * @param predicate the predicate
   *
   * @return true if the resource was successfully populated with the requested properties
   */
  private boolean populateResource(Resource resource, Request request, Predicate predicate)
      throws SystemException {

    Set<String> ids = PropertyHelper.getRequestPropertyIds(propertyIds, request, predicate);
    if (ids.isEmpty()) {
      return true;
    }

    String clusterName   = (String) resource.getPropertyValue(clusterNamePropertyId);

    // TODO : what should we do if the host mapping is null?
    if (jmxHostProvider.getHostMapping(clusterName) == null) {
      return true;
    }

    String componentName = (String) resource.getPropertyValue(componentNamePropertyId);
    String port          = JMX_PORTS.get(componentName);

    String hostName;
    if (hostNamePropertyId == null) {
      hostName = jmxHostProvider.getHostName(clusterName, componentName);
    }
    else {
      String name = (String) resource.getPropertyValue(hostNamePropertyId);
      hostName = jmxHostProvider.getHostMapping(clusterName).get(name);
    }

    Map<String, PropertyInfo> metrics = componentMetrics.get(componentName);

    if (metrics == null || hostName == null || port == null) {
      return true;
    }

    String spec = getSpec(hostName + ":" + port);

    try {
      JMXMetricHolder metricHolder = new ObjectMapper().readValue(streamProvider.readFrom(spec), JMXMetricHolder.class);

      Map<String, Map<String, Object>> categories = new HashMap<String, Map<String, Object>>();

      for (Map<String, Object> bean : metricHolder.getBeans()) {
        String category = getCategory(bean);
        if (category != null) {
          categories.put(category, bean);
        }
      }

      for (String propertyId : ids) {

        PropertyInfo propertyInfo = metrics.get(propertyId);

        if (propertyInfo != null && propertyInfo.isPointInTime()) {

          String property = propertyInfo.getPropertyId();
          String category = "";

          List<String> keyList = new LinkedList<String>();
          int keyStartIndex = property.indexOf('[', 0);
          int firstKeyIndex = keyStartIndex > -1 ? keyStartIndex : property.length();
          while (keyStartIndex > -1) {
            int keyEndIndex = property.indexOf(']', keyStartIndex);
            if (keyEndIndex > -1 & keyEndIndex > keyStartIndex) {
              keyList.add(property.substring(keyStartIndex + 1, keyEndIndex));
              keyStartIndex = property.indexOf('[', keyEndIndex);
            }
            else {
              keyStartIndex = -1;
            }
          }


          int dotIndex = property.lastIndexOf('.', firstKeyIndex - 1);
          if (dotIndex != -1){
            category = property.substring(0, dotIndex);
            property = property.substring(dotIndex + 1, firstKeyIndex);
          }

          Map<String, Object> properties = categories.get(category);
          if (properties != null && properties.containsKey(property)) {
            Object value = properties.get(property);
            if (keyList.size() > 0 && value instanceof Map) {
              Map map = (Map) value;
              for (String key : keyList) {
                value = map.get(key);
                if (value instanceof Map) {
                  map = (Map) value;
                }
                else {
                  break;
                }
              }
            }
            resource.setProperty(propertyId, value);
          }
        }
      }
    } catch (IOException e) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Caught exception getting JMX metrics : spec=" + spec, e);
      }
    }

    return true;
  }

  private String getCategory(Map<String, Object> bean) {
    if (bean.containsKey(NAME_KEY)) {
      String name = (String) bean.get(NAME_KEY);

      if (bean.containsKey(PORT_KEY)) {
        String port = (String) bean.get(PORT_KEY);
        name = name.replace("ForPort" + port, "");
      }
      return name;
    }
    return null;
  }

  /**
   * Get the spec to locate the JMX stream from the given source
   *
   * @param jmxSource  the source (host and port)
   *
   * @return the spec
   */
  protected String getSpec(String jmxSource) {
//    return "http://" + jmxSource + "/jmx?qry=Hadoop:*";
    return "http://" + jmxSource + "/jmx";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/AlwaysPredicate.java,false,"package org.apache.ambari.server.controller.predicate;

/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import org.apache.ambari.server.controller.spi.Resource;

import java.util.Collections;
import java.util.Set;

/**
 * A predicate that always evaluates to true.
 */
public class AlwaysPredicate implements BasePredicate {
  public static final AlwaysPredicate INSTANCE = new AlwaysPredicate();

  @Override
  public boolean evaluate(Resource resource) {
    return true;
  }

  @Override
  public Set<String> getPropertyIds() {
    return Collections.emptySet();
  }

  @Override
  public void accept(PredicateVisitor visitor) {
    visitor.acceptAlwaysPredicate(this);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/AndPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.Resource;

import java.util.Arrays;
import java.util.LinkedList;
import java.util.List;


/**
 * Predicate which evaluates to true if all of the predicates in a predicate
 * array evaluate to true.
 */
public class AndPredicate extends ArrayPredicate {

  public AndPredicate(BasePredicate... predicates) {
    super(predicates);
  }

  @Override
  public BasePredicate create(BasePredicate... predicates) {
    return instance(predicates);
  }

  public static BasePredicate instance(BasePredicate... predicates) {
    List<BasePredicate> predicateList = new LinkedList<BasePredicate>();

    // Simplify the predicate array
    for (BasePredicate predicate : predicates) {
      if (!(predicate instanceof AlwaysPredicate)) {
        if (predicate instanceof AndPredicate) {
          predicateList.addAll(Arrays.asList(((AndPredicate) predicate).getPredicates()));
        }
        else {
          predicateList.add(predicate);
        }
      }
    }

    return predicateList.size() == 1 ?
        predicateList.get(0) :
        new AndPredicate(predicateList.toArray(new BasePredicate[predicateList.size()]));
  }

  @Override
  public boolean evaluate(Resource resource) {
    Predicate[] predicates = getPredicates();
    for (Predicate predicate : predicates) {
      if (!predicate.evaluate(resource)) {
        return false;
      }
    }
    return true;
  }

  @Override
  public String getOperator() {
    return "AND";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/ArrayPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.predicate;

import java.util.Arrays;
import java.util.HashSet;
import java.util.Set;

/**
 * Predicate which evaluates an array of predicates.
 */
public abstract class ArrayPredicate implements BasePredicate {
  private final BasePredicate[] predicates;
  private final Set<String> propertyIds = new HashSet<String>();

  public ArrayPredicate(BasePredicate... predicates) {
    this.predicates = predicates;
    for (BasePredicate predicate : predicates) {
      propertyIds.addAll(predicate.getPropertyIds());
    }
  }

  /**
   * Factory method.
   *
   * @param predicates  the predicate array
   *
   * @return a new ArrayPredicate
   */
  public abstract BasePredicate create(BasePredicate... predicates);


  public BasePredicate[] getPredicates() {
    return predicates;
  }

  @Override
  public Set<String> getPropertyIds() {
    return propertyIds;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof ArrayPredicate)) return false;

    ArrayPredicate that = (ArrayPredicate) o;

    if (propertyIds != null ? !propertyIds.equals(that.propertyIds) : that.propertyIds != null) return false;

    // don't care about array order
    Set<BasePredicate> setThisPredicates = new HashSet<BasePredicate>(Arrays.asList(predicates));
    Set<BasePredicate> setThatPredicates = new HashSet<BasePredicate>(Arrays.asList(that.predicates));
    return setThisPredicates.equals(setThatPredicates);
  }

  @Override
  public int hashCode() {
    // don't care about array order
    int result = predicates != null ? new HashSet<BasePredicate>(Arrays.asList(predicates)).hashCode() : 0;
    result = 31 * result + (propertyIds != null ? propertyIds.hashCode() : 0);
    return result;
  }

  @Override
  public void accept(PredicateVisitor visitor) {
    visitor.acceptArrayPredicate(this);
  }

  public abstract String getOperator();
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/BasePredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Predicate;

import java.util.Set;

/**
 * An extended predicate interface which allows for the retrieval of any
 * associated property ids.
 */
public interface BasePredicate extends Predicate, PredicateVisitorAcceptor {
  public Set<String> getPropertyIds();
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/ComparisonPredicate.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Resource;

import java.text.NumberFormat;
import java.text.ParsePosition;

/**
 * Predicate that compares a given value to a {@link Resource} property.
 */
public abstract class ComparisonPredicate<T> extends PropertyPredicate implements BasePredicate {
  private final Comparable<T> value;
  private final String stringValue;
  private final Double doubleValue;

  protected ComparisonPredicate(String propertyId, Comparable<T> value) {
    super(propertyId);
    this.value = value;

    if (value instanceof Number) {
      stringValue = null;
      doubleValue = ((Number) value).doubleValue();
    }
    else if (value instanceof String) {
      stringValue = (String) value;
      doubleValue = stringToDouble(stringValue);
    }
    else {
      stringValue = null;
      doubleValue = null;
    }
  }

  public Comparable<T> getValue() {
    return value;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof ComparisonPredicate)) return false;
    if (!super.equals(o)) return false;

    ComparisonPredicate that = (ComparisonPredicate) o;

    return !(value != null ? !value.equals(that.value) : that.value != null);
  }

  @Override
  public int hashCode() {
    int result = super.hashCode();
    result = 31 * result + (value != null ? value.hashCode() : 0);
    return result;
  }

  @Override
  public void accept(PredicateVisitor visitor) {
    visitor.acceptComparisonPredicate(this);
  }

  protected int compareValueTo(Object propertyValue) throws ClassCastException{

    if (doubleValue != null) {
      if (propertyValue instanceof Number ) {
        return (int) (doubleValue - ((Number) propertyValue).doubleValue());
      }
      else if (propertyValue instanceof String) {
        Double doubleFromString = stringToDouble((String) propertyValue);
        if (doubleFromString != null) {
          return (int) (doubleValue - doubleFromString);
        }
      }
    }
    if (stringValue != null) {
      return stringValue.compareTo(propertyValue.toString());
    }

    return getValue().compareTo((T) propertyValue);
  }

  private Double stringToDouble(String stringValue) {
    ParsePosition parsePosition = new ParsePosition(0);
    NumberFormat  numberFormat  = NumberFormat.getInstance();
    Number        parsedNumber  = numberFormat.parse((String) value, parsePosition);

    return parsePosition.getIndex() == stringValue.length() ? parsedNumber.doubleValue() : null;
  }

  public abstract String getOperator();
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/EqualsPredicate.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Resource;

/**
 * Predicate that checks equality of a given value to a {@link Resource} property.
 */
public class EqualsPredicate<T> extends ComparisonPredicate<T> {

  public EqualsPredicate(String propertyId, Comparable<T> value) {
    super(propertyId, value);
  }

  @Override
  public boolean evaluate(Resource resource) {
    Object propertyValue = resource.getPropertyValue(getPropertyId());
    return propertyValue != null && compareValueTo(propertyValue) == 0;
  }

  @Override
  public String getOperator() {
    return "=";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/GreaterEqualsPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Resource;

/**
 * Predicate that checks if a given value is greater than or equal to a {@link Resource} property.
 */
public class GreaterEqualsPredicate<T> extends ComparisonPredicate<T> {

  public GreaterEqualsPredicate(String propertyId, Comparable<T> value) {
    super(propertyId, value);
  }

  @Override
  public boolean evaluate(Resource resource) {
    Object propertyValue = resource.getPropertyValue(getPropertyId());
    return propertyValue != null && compareValueTo(propertyValue) <= 0;
  }

  @Override
  public String getOperator() {
    return ">=";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/GreaterPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Resource;

/**
 * Predicate that checks if a given value is greater than a {@link Resource} property.
 */
public class GreaterPredicate<T> extends ComparisonPredicate<T> {

  public GreaterPredicate(String propertyId, Comparable<T> value) {
    super(propertyId, value);
  }

  @Override
  public boolean evaluate(Resource resource) {
    Object propertyValue = resource.getPropertyValue(getPropertyId());
    return propertyValue != null && compareValueTo(propertyValue) < 0;
  }

  @Override
  public String getOperator() {
    return ">";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/LessEqualsPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Resource;


/**
 * Predicate that checks if a given value is less than or equal to a {@link Resource} property.
 */
public class LessEqualsPredicate<T> extends ComparisonPredicate<T> {

  public LessEqualsPredicate(String propertyId, Comparable<T> value) {
    super(propertyId, value);
  }

  @Override
  public boolean evaluate(Resource resource) {
    Object propertyValue = resource.getPropertyValue(getPropertyId());
    return propertyValue != null && compareValueTo(propertyValue) >= 0;
  }

  @Override
  public String getOperator() {
    return "<=";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/LessPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Resource;

/**
 * Predicate that checks if a given value is less than a {@link Resource} property.
 */
public class LessPredicate<T> extends ComparisonPredicate<T> {

  public LessPredicate(String propertyId, Comparable<T> value) {
    super(propertyId, value);
  }

  @Override
  public boolean evaluate(Resource resource) {
    Object propertyValue = resource.getPropertyValue(getPropertyId());
    return propertyValue != null && compareValueTo(propertyValue) > 0;
  }

  @Override
  public String getOperator() {
    return "<";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/NotPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Resource;

/**
 * Predicate that negates the evaluation of another predicate.
 */
public class NotPredicate extends UnaryPredicate {

  public NotPredicate(BasePredicate predicate) {
    super(predicate);
  }

  @Override
  public boolean evaluate(Resource resource) {
    return !getPredicate().evaluate(resource);
  }

  @Override
  public String getOperator() {
    return "NOT";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/OrPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

import org.apache.ambari.server.controller.spi.Resource;

import java.util.Arrays;
import java.util.LinkedList;
import java.util.List;

/**
 * Predicate which evaluates to true if any of the predicates in a predicate
 * array evaluate to true.
 */
public class OrPredicate extends ArrayPredicate {

  public OrPredicate(BasePredicate... predicates) {
    super(predicates);
  }

  @Override
  public BasePredicate create(BasePredicate... predicates) {
    return instance(predicates);
  }

  public static BasePredicate instance(BasePredicate... predicates) {
    List<BasePredicate> predicateList = new LinkedList<BasePredicate>();

    // Simplify the predicate array
    for (BasePredicate predicate : predicates) {
      if (predicate instanceof AlwaysPredicate) {
        return predicate;
      }
      else if (predicate instanceof OrPredicate) {
        predicateList.addAll(Arrays.asList(((OrPredicate) predicate).getPredicates()));
      }
      else {
        predicateList.add(predicate);
      }
    }
    return predicateList.size() == 1 ?
        predicateList.get(0) :
        new OrPredicate(predicateList.toArray(new BasePredicate[predicateList.size()]));
  }

  @Override
  public boolean evaluate(Resource resource) {
    BasePredicate[] predicates = getPredicates();
    for (BasePredicate predicate : predicates) {
      if (predicate.evaluate(resource)) {
        return true;
      }
    }
    return false;
  }

  @Override
  public String getOperator() {
    return "OR";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/PredicateVisitor.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

/**
 * A visitor of predicates.
 */
public interface PredicateVisitor {

  public void acceptComparisonPredicate(ComparisonPredicate predicate);

  public void acceptArrayPredicate(ArrayPredicate predicate);

  public void acceptUnaryPredicate(UnaryPredicate predicate);

  public void acceptAlwaysPredicate(AlwaysPredicate predicate);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/PredicateVisitorAcceptor.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

/**
 * An acceptor of predicate visitors.
 */
public interface PredicateVisitorAcceptor {

  public void accept(PredicateVisitor visitor);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/PropertyPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

import java.util.Collections;
import java.util.Set;

/**
 * Predicate that is associated with a resource property.
 */
public abstract class PropertyPredicate implements BasePredicate {
  private final String propertyId;

  public PropertyPredicate(String propertyId) {
    assert (propertyId != null);
    this.propertyId = propertyId;
  }

  @Override
  public Set<String> getPropertyIds() {
    return Collections.singleton(propertyId);
  }

  public String getPropertyId() {
    return propertyId;
  }

  @Override
  public boolean equals(Object o) {

    if (this == o) {
      return true;
    }

    if (!(o instanceof PropertyPredicate)) {
      return false;
    }

    PropertyPredicate that = (PropertyPredicate) o;

    return propertyId == null ? that.propertyId == null : propertyId.equals(that.propertyId);
  }

  @Override
  public int hashCode() {
    return propertyId != null ? propertyId.hashCode() : 0;
  }
}

"
ambari-server/src/main/java/org/apache/ambari/server/controller/predicate/UnaryPredicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.predicate;

import java.util.Set;

/**
 * Predicate that operates on one other predicate.
 */
public abstract class UnaryPredicate implements BasePredicate {
  private final BasePredicate predicate;

  public UnaryPredicate(BasePredicate predicate) {
    assert(predicate != null);
    this.predicate = predicate;
  }

  public BasePredicate getPredicate() {
    return predicate;
  }

  @Override
  public Set<String> getPropertyIds() {
    return predicate.getPropertyIds();
  }

  @Override
  public void accept(PredicateVisitor visitor) {
    visitor.acceptUnaryPredicate(this);
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof UnaryPredicate)) return false;

    UnaryPredicate that = (UnaryPredicate) o;

    return predicate.equals(that.predicate);
  }

  @Override
  public int hashCode() {
    return predicate.hashCode();
  }

  public abstract String getOperator();
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/ClusterController.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.spi;


/**
 * The cluster controller is the main access point for accessing resources
 * from the backend sources.  A cluster controller maintains a mapping of
 * resource providers keyed by resource types.
 */
public interface ClusterController {

  // ----- Monitoring ------------------------------------------------------

  /**
   * Get the resources of the given type filtered by the given request and
   * predicate objects.
   *
   * @param type      the type of the requested resources
   * @param request   the request object which defines the desired set of properties
   * @param predicate the predicate object which filters which resources are returned
   *
   * @return an iterable object of the requested resources
   *
   * @throws UnsupportedPropertyException thrown if the request or predicate contain
   *                                      unsupported property ids
   * @throws SystemException an internal exception occurred
   * @throws NoSuchResourceException no matching resource(s) found
   * @throws NoSuchParentResourceException a specified parent resource doesn't exist
   */
  public Iterable<Resource> getResources(Resource.Type type,
                                         Request request,
                                         Predicate predicate)
      throws UnsupportedPropertyException,
             SystemException,
             NoSuchResourceException,
             NoSuchParentResourceException;

  /**
   * Get the {@link Schema schema} for the given resource type.  The schema
   * for a given resource type describes the properties and categories provided
   * by that type of resource.
   *
   * @param type the resource type
   * @return the schema object for the given resource
   */
  public Schema getSchema(Resource.Type type);


  // ----- Management -------------------------------------------------------

  /**
   * Create the resources defined by the properties in the given request object.
   *
   * @param type     the type of the resources
   * @param request  the request object which defines the set of properties
   *                 for the resources to be created
   *
   * @throws UnsupportedPropertyException thrown if the request contains
   *                                      unsupported property ids
   * @throws SystemException an internal exception occurred
   * @throws ResourceAlreadyExistsException attempted to create a resource that already exists
   * @throws NoSuchParentResourceException a specified parent resource doesn't exist
   */
  public RequestStatus createResources(Resource.Type type, Request request)
      throws UnsupportedPropertyException,
             SystemException,
             ResourceAlreadyExistsException,
             NoSuchParentResourceException;

  /**
   * Update the resources selected by the given predicate with the properties
   * from the given request object.
   *
   *
   * @param type       the type of the resources
   * @param request    the request object which defines the set of properties
   *                   for the resources to be updated
   * @param predicate  the predicate object which can be used to filter which
   *                   resources are updated
   *
   * @throws UnsupportedPropertyException thrown if the request or predicate
   *                                      contain unsupported property ids
   * @throws SystemException an internal exception occurred
   * @throws NoSuchResourceException no matching resource(s) found
   * @throws NoSuchParentResourceException a specified parent resource doesn't exist
   */
  public RequestStatus updateResources(Resource.Type type,
                                       Request request,
                                       Predicate predicate)
      throws UnsupportedPropertyException,
             SystemException,
             NoSuchResourceException,
             NoSuchParentResourceException;

  /**
   * Delete the resources selected by the given predicate.
   *
   * @param type      the type of the resources
   * @param predicate the predicate object which can be used to filter which
   *                  resources are deleted
   *
   * @throws UnsupportedPropertyException thrown if the predicate contains
   *                                      unsupported property ids
   * @throws SystemException an internal exception occurred
   * @throws NoSuchResourceException no matching resource(s) found
   * @throws NoSuchParentResourceException a specified parent resource doesn't exist
   */
  public RequestStatus deleteResources(Resource.Type type, Predicate predicate)
      throws UnsupportedPropertyException,
             SystemException,
             NoSuchResourceException,
             NoSuchParentResourceException ;
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/NoSuchParentResourceException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.spi;

/**
 * Indicates that a parent of a resource doesn't exist.
 */
public class NoSuchParentResourceException extends Exception {

  /**
   * Constructor.
   *
   * @param msg        the message
   * @param throwable  the root exception
   */
  public NoSuchParentResourceException(String msg, Throwable throwable) {
    super(msg, throwable);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/NoSuchResourceException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.spi;

/**
 * Indicates that a resource doesn't exist.
 */
public class NoSuchResourceException extends Exception {

  /**
   * Constructor.
   *
   * @param msg        message
   * @param throwable  root exception
   */
  public NoSuchResourceException(String msg, Throwable throwable) {
    super(msg, throwable);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/Predicate.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.spi;

/**
 * The predicate is used to filter the resources returned from the cluster
 * controller.  The predicate can examine a resource object and determine
 * whether or not it should be included in the returned results.
 */
public interface Predicate {
  /**
   * Evaluate the predicate for the given resource.
   *
   * @param resource the resource to evaluate the predicate against
   * @return the result of applying the predicate to the given resource
   */
  public boolean evaluate(Resource resource);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/PropertyProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.spi;

import org.apache.ambari.server.AmbariException;

import java.util.Set;

/**
 * The property provider is used to plug in various property sources into a
 * resource provider.  The property provider is able to populate, or partially
 * populate a given resource object with property values.
 */
public interface PropertyProvider {

  /**
   * Populate the given set of resource with any properties that this property
   * provider can provide and return a populated set of resources.  The provider
   * may drop resources from the original set if it determines that the don't
   * meet the conditions of the predicate.
   *
   * @param resources  the resources to be populated
   * @param request    the request object which defines the desired set of properties
   * @param predicate  the predicate object which filters which resources are returned
   *
   * @return the populated set of resources
   *
   * @throws SystemException thrown if resources cannot be populated
   */
  public Set<Resource> populateResources(Set<Resource> resources, Request request, Predicate predicate)
      throws SystemException;

  /**
   * Get the set of property ids for the properties that this provider can provide.
   *
   * @return the set of property ids for the properties that this provider can provide
   */
  // TODO : remove this
  public Set<String> getPropertyIds();

  /**
   * Check whether the set of given property ids is supported by this resource
   * provider.
   *
   * @return a subset of the given property id set containing any property ids not
   *         supported by this resource provider.  An empty return set indicates
   *         that all of the given property ids are supported.
   */
  public Set<String> checkPropertyIds(Set<String> propertyIds);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/ProviderModule.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.spi;

import java.util.List;

/**
 *  Interface to allow the plugging in of resource adapters.
 */
public interface ProviderModule {
  /**
   * Get a resource adapter for the given resource type.
   *
   * @param type  the resource type
   *
   * @return the resource adapter
   */
  public ResourceProvider getResourceProvider(Resource.Type type);

  /**
   * Get the list of property providers for the given resource type.
   *
   * @param type  the resource type
   *
   * @return the list of property providers
   */
  public List<PropertyProvider> getPropertyProviders(Resource.Type type);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/Request.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.spi;

import java.util.Map;
import java.util.Set;

/**
 * The request object carries the properties or property ids required to
 * satisfy a resource request.  The request object also contains any
 * temporal (date range) information, if any, for each requested property.
 */
public interface Request {

  /**
   * Get the set of property ids being requested.  Used for requests to get
   * resources.  An empty set signifies that all supported properties should
   * be returned (i.e. select * ).
   *
   * @return the set of property ids being requested
   */
  public Set<String> getPropertyIds();

  /**
   * Get the set of maps of properties being requested.  Used
   * for requests to update or create resources.  Each value
   * in the set is a map of properties for a resource being
   * created/updated.  Each map contains property values keyed
   * by property ids.
   *
   * @return the set of properties being requested
   */
  public Set<Map<String, Object>> getProperties();

  /**
   * Get the {@link TemporalInfo temporal information} for the given property
   * id for this request, if any.
   *
   * @param id the property id
   * @return the temporal information for the given property id; null if noe exists
   */
  public TemporalInfo getTemporalInfo(String id);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/RequestStatus.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.spi;

import java.util.Set;

/**
 * A RequestStatus represents the result of an asynchronous operation on resources. Methods are
 * provided to check the status of the operation and to retrieve the set of resources involved
 * in the operation.
 */
public interface RequestStatus {

  /**
   * Get the resources involved in the operation initiated by the request.
   *
   * @return the set of resources
   */
  public Set<Resource> getAssociatedResources();

  /**
   * Get the resource of type request for the asynchronous request.
   *
   * @return the request resource
   */
  public Resource getRequestResource();

  /**
   * Get the status of the operation initiated by the request.
   *
   * @return the status
   */
  public Status getStatus();

  /**
   * Request status.
   */
  public enum Status {
    Accepted,
    InProgress,
    Complete
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/Resource.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.spi;


import org.apache.ambari.server.api.util.TreeNode;

import java.util.Map;

/**
 * The resource object represents a requested resource.  The resource
 * contains a collection of values for the requested properties.
 */
public interface Resource {
  /**
   * Get the resource type.
   *
   * @return the resource type
   */
  public Type getType();

  /**
   * Get the properties contained by this resource.
   * Each category is contained in a sub-node.
   *
   * @return resource properties tree
   */
  public TreeNode<Map<String, Object>> getProperties();

  /**
   * Obtain the properties contained by this group in a map structure.
   * The category/property hierarchy is flattened into a map where
   * each key is the absolute category name and the corresponding
   * value is a map of properties(name/value pairs) for that category.
   *
   * @return  resource properties map
   */
  public Map<String, Map<String, Object>> getPropertiesMap();

  /**
   * Set a property value for the given property id on this resource.
   *
   * @param id    the property id
   * @param value the value
   */
  public void setProperty(String id, Object value);

  /**
   * Get a property value for the given property id from this resource.
   *
   * @param id the property id
   * @return the property value
   */
  public Object getPropertyValue(String id);

  /**
   * Resource types.
   */
  public enum Type {
    Cluster,
    Service,
    Host,
    Component,
    HostComponent,
    Configuration,
    Action,
    Request,
    Task,
    User
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/ResourceAlreadyExistsException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.spi;

/**
 * Indicates that a resource already exists.
 */
public class ResourceAlreadyExistsException extends Exception {
  /**
   * Constructor.
   *
   * @param msg  msg
   */
  public ResourceAlreadyExistsException(String msg) {
    super(msg);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/ResourceProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.spi;

import java.util.Map;
import java.util.Set;

/**
 * The resource provider allows for the plugging in of a back end data store
 * for a resource type.  The resource provider is associated with a specific
 * resource type and can be queried for a list of resources of that type.
 * The resource provider plugs into and is used by the
 * {@link ClusterController cluster controller} to obtain a list of resources
 * for a given request.
 */
public interface ResourceProvider {

  /**
   * Create the resources defined by the properties in the given request object.
   *
   *
   * @param request  the request object which defines the set of properties
   *                 for the resources to be created
   *
   * @return the request status
   *
   * @throws SystemException an internal system exception occurred
   * @throws UnsupportedPropertyException the request contains unsupported property ids
   * @throws ResourceAlreadyExistsException attempted to create a resource which already exists
   * @throws NoSuchParentResourceException a parent resource of the resource to create doesn't exist
   */
  public RequestStatus createResources(Request request)
      throws SystemException,
      UnsupportedPropertyException,
      ResourceAlreadyExistsException,
      NoSuchParentResourceException;

  /**
   * Get a set of {@link Resource resources} based on the given request and predicate
   * information.
   * </p>
   * Note that it is not required for this resource provider to completely filter
   * the set of resources based on the given predicate.  It may not be possible
   * since some of the properties involved may be provided by another
   * {@link PropertyProvider provider}.  This partial filtering is allowed because
   * the predicate will always be applied by the calling cluster controller.  The
   * predicate is made available at this level so that some pre-filtering can be done
   * as an optimization.
   * </p>
   * A simple implementation of a resource provider may choose to just return all of
   * the resources of a given type and allow the calling cluster controller to filter
   * based on the predicate.
   *
   *
   * @param request    the request object which defines the desired set of properties
   * @param predicate  the predicate object which can be used to filter which
   *                   resources are returned
   * @return a set of resources based on the given request and predicate information
   *
   * @throws SystemException an internal system exception occurred
   * @throws UnsupportedPropertyException the request contains unsupported property ids
   * @throws NoSuchResourceException the requested resource instance doesn't exist
   * @throws NoSuchParentResourceException a parent resource of the requested resource doesn't exist
   */
  public Set<Resource> getResources(Request request, Predicate predicate)
      throws SystemException,
      UnsupportedPropertyException,
      NoSuchResourceException,
      NoSuchParentResourceException;

  /**
   * Update the resources selected by the given predicate with the properties
   * from the given request object.
   *
   *
   *
   * @param request    the request object which defines the set of properties
   *                   for the resources to be updated
   * @param predicate  the predicate object which can be used to filter which
   *                   resources are updated
   *
   * @return the request status
   *
   * @throws SystemException an internal system exception occurred
   * @throws UnsupportedPropertyException the request contains unsupported property ids
   * @throws NoSuchResourceException the resource instance to be updated doesn't exist
   * @throws NoSuchParentResourceException a parent resource of the resource doesn't exist
   */
  public RequestStatus updateResources(Request request, Predicate predicate)
      throws SystemException,
      UnsupportedPropertyException,
      NoSuchResourceException,
      NoSuchParentResourceException;

  /**
   * Delete the resources selected by the given predicate.
   *
   *
   *
   * @param predicate the predicate object which can be used to filter which
   *                  resources are deleted
   *
   * @return the request status
   *
   * @throws SystemException an internal system exception occurred
   * @throws UnsupportedPropertyException the request contains unsupported property ids
   * @throws NoSuchResourceException the resource instance to be deleted doesn't exist
   * @throws NoSuchParentResourceException a parent resource of the resource doesn't exist
   */
  public RequestStatus deleteResources(Predicate predicate)
      throws SystemException,
      UnsupportedPropertyException,
      NoSuchResourceException,
      NoSuchParentResourceException;

  /**
   * Get the set of property ids for the properties that this provider can provide.
   *
   * @return the set of property ids for the properties that this provider can provide
   */
  // TODO : remove this
  public Set<String> getPropertyIdsForSchema();

  /**
   * Get the key property ids for the resource type associated with this resource
   * providers.  The key properties are those that uniquely identify the resource.
   *
   * @return a map of key property ids
   */
  public Map<Resource.Type, String> getKeyPropertyIds();

  /**
   * Check whether the set of given property ids is supported by this resource
   * provider.
   *
   * @return a subset of the given property id set containing any property ids not
   *         supported by this resource provider.  An empty return set indicates
   *         that all of the given property ids are supported.
   */
  public Set<String> checkPropertyIds(Set<String> propertyIds);
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/Schema.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.spi;

import java.util.Map;
import java.util.Set;

/**
 * The schema is used to describe all of the properties that a resource type
 * supports.
 */
public interface Schema {

  /**
   * Get the property id for the property that uniquely identifies
   * the given resource type for the resource described by this schema.
   * </p>
   * For example, the resource 'HostComponent' is uniquely identified by
   * its associated 'Cluster', 'Host' and 'Component' resources.  Passing
   * the 'Host' resource type to
   * {@link Schema#getKeyPropertyId(org.apache.ambari.server.controller.spi.Resource.Type)}
   * on a schema object of a 'HostComponent' resource will return the id of the
   * property of the foreign key reference from the 'HostComponent' to the 'Host'.
   *
   * @param type the resource type
   * @return the key property id for the given resource type
   */
  public String getKeyPropertyId(Resource.Type type);

  /**
   * Get this schema's map of category and property names.  The map
   * is keyed by category name and contains sets of property names
   * for each category.
   *
   * @return the map of category and property names
   */
  public Map<String, Set<String>> getCategoryProperties();
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/SystemException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.spi;

/**
 * Indicates that a system exception occurred.
 */
public class SystemException extends Exception {
  /**
   * Constructor.
   *
   * @param msg        message
   * @param throwable  root exception
   */
  public SystemException(String msg, Throwable throwable) {
    super(msg, throwable);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/TemporalInfo.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.spi;

/**
 * Temporal query data.
 */
public interface TemporalInfo {
  /**
   * Get the start of the requested time range.  The time is given in
   * seconds since the Unix epoch.
   *
   * @return the start time in seconds
   */
  Long getStartTime();

  /**
   * Get the end of the requested time range.  The time is given in
   * seconds since the Unix epoch.
   *
   * @return the end time in seconds
   */
  Long getEndTime();

  /**
   * Get the requested time between each data point of the temporal
   * data.  The time is given in seconds.
   *
   * @return the step time in seconds
   */
  Long getStep();
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/spi/UnsupportedPropertyException.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.spi;

import java.util.Set;

/**
 * Thrown to indicate that the requested properties are not supported for the
 * associated resource type.
 */
public class UnsupportedPropertyException extends Exception {
  /**
   * The resource type.
   */
  private final Resource.Type type;

  /**
   * The unsupported property ids.
   */
  private final Set<String> propertyIds;

  /**
   * Construct an UnsupportedPropertyException.
   *
   * @param type         the resource type
   * @param propertyIds  the unsupported property ids
   */
  public UnsupportedPropertyException(Resource.Type type, Set<String> propertyIds) {
    super("The properties " + propertyIds +
        " specified in the request or predicate are not supported for the resource type " +
        type + ".");
    this.type = type;
    this.propertyIds = propertyIds;
  }

  /**
   * Get the resource type.
   *
   * @return the resource type
   */
  public Resource.Type getType() {
    return type;
  }

  /**
   * Get the unsupported property ids.
   *
   * @return the unsupported property ids
   */
  public Set<String> getPropertyIds() {
    return propertyIds;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/utilities/ClusterControllerHelper.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.utilities;

import org.apache.ambari.server.controller.spi.ProviderModule;
import org.apache.ambari.server.controller.internal.ClusterControllerImpl;
import org.apache.ambari.server.controller.spi.ClusterController;

/**
 * Temporary class to bootstrap a cluster controller.  TODO : Replace this global state with injection.
 */
public class ClusterControllerHelper {

  private static String PROVIDER_MODULE_CLASS = System.getProperty("provider.module.class",
      "org.apache.ambari.server.controller.internal.DefaultProviderModule");

  private static ClusterController controller;

  public static synchronized ClusterController getClusterController() {
    if (controller == null) {
      try {
        Class<?> implClass = Class.forName(PROVIDER_MODULE_CLASS);
        ProviderModule providerModule = (ProviderModule) implClass.newInstance();
        controller = new ClusterControllerImpl(providerModule);

      } catch (Exception e) {
        throw new IllegalStateException("Can't create provider module " + PROVIDER_MODULE_CLASS, e);
      }
    }
    return controller;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/utilities/DBHelper.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.utilities;

import org.apache.ambari.server.controller.jdbc.ConnectionFactory;
import org.apache.ambari.server.controller.jdbc.SQLiteConnectionFactory;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.type.TypeReference;

import java.io.IOException;
import java.sql.Connection;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.HashMap;
import java.util.Map;

/**
 *
 */
public class DBHelper {
  private static String DB_FILE_NAME = System.getProperty("ambariapi.dbfile", "src/test/resources/data.db");

  public static final ConnectionFactory CONNECTION_FACTORY = new SQLiteConnectionFactory(DB_FILE_NAME);

  private static final Map<String, String> HOSTS = readHosts();

  public static Map<String, String> getHosts() {
    return HOSTS;
  }

  private static Map<String, String> readHosts() {
    Map<String, String> hosts = new HashMap<String, String>();

    try {
      Connection connection = CONNECTION_FACTORY.getConnection();

      try {
        String sql = "select attributes from hosts";

        Statement statement = connection.createStatement();

        ResultSet rs = statement.executeQuery(sql);

        ObjectMapper mapper = new ObjectMapper();

        while (rs.next()) {
          String attributes = rs.getString(1);

          if (!attributes.startsWith("[]")) {
            try {
              Map<String, String> attributeMap = mapper.readValue(attributes, new TypeReference<Map<String, String>>() {
              });
              hosts.put(attributeMap.get("privateFQDN"), attributeMap.get("publicFQDN"));
            } catch (IOException e) {
              throw new IllegalStateException("Can't read hosts " + attributes, e);
            }
          }
        }

        statement.close();
      } finally {
        connection.close();
      }

    } catch (SQLException e) {
      throw new IllegalStateException("Can't access DB.", e);
    }

    return hosts;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/utilities/PredicateBuilder.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.utilities;

import org.apache.ambari.server.controller.predicate.AndPredicate;
import org.apache.ambari.server.controller.predicate.BasePredicate;
import org.apache.ambari.server.controller.predicate.EqualsPredicate;
import org.apache.ambari.server.controller.predicate.GreaterEqualsPredicate;
import org.apache.ambari.server.controller.predicate.GreaterPredicate;
import org.apache.ambari.server.controller.predicate.LessEqualsPredicate;
import org.apache.ambari.server.controller.predicate.LessPredicate;
import org.apache.ambari.server.controller.predicate.NotPredicate;
import org.apache.ambari.server.controller.predicate.OrPredicate;

import java.util.LinkedList;
import java.util.List;

/**
 * Builder for predicates.
 */
public class PredicateBuilder {

  private String propertyId;
  private List<BasePredicate> predicates = new LinkedList<BasePredicate>();
  private Operator operator = null;
  private final PredicateBuilder outer;
  private boolean done = false;
  private boolean not = false;

  public PredicateBuilder() {
    this.outer = null;
  }

  private PredicateBuilder(PredicateBuilder outer) {
    this.outer = outer;
  }

  private enum Operator {
    And,
    Or
  }

  public PredicateBuilderWithProperty property(String id) {
    checkDone();
    propertyId = id;
    return new PredicateBuilderWithProperty();
  }

  public PredicateBuilder not() {
    not = true;
    return this;
  }

  public PredicateBuilder begin() {
    checkDone();
    return new PredicateBuilder(this);
  }

  public BasePredicate toPredicate() {
    return getPredicate();
  }

  private void checkDone() {
    if (done) {
      throw new IllegalStateException("Can't reuse a predicate builder.");
    }
  }

  private PredicateBuilderWithPredicate getPredicateBuilderWithPredicate() {
    return new PredicateBuilderWithPredicate();
  }

  private void addPredicate(BasePredicate predicate) {
    predicates.add(predicate);
  }

  private void handleComparator() {
    if (operator == null) {
      return;
    }

    if (predicates.size() == 0) {
      throw new IllegalStateException("No left operand.");
    }
    BasePredicate predicate;

    switch (operator) {
      case And:
        predicate = new AndPredicate(predicates.toArray(new BasePredicate[predicates.size()]));
        break;
      case Or:
        predicate = new OrPredicate(predicates.toArray(new BasePredicate[predicates.size()]));
        break;
      default:
        throw new IllegalStateException("Unknown operator " + this.operator);
    }
    predicates.clear();
    addPredicate(predicate);
  }

  private BasePredicate getPredicate() {
    handleComparator();

    if (predicates.size() == 1) {
      BasePredicate predicate = predicates.get(0);
      if (not) {
        predicate = new NotPredicate(predicate);
        not = false;
      }
      return predicate;
    }
    throw new IllegalStateException("Can't return a predicate.");
  }

  public class PredicateBuilderWithProperty {

    // ----- Equals -----
    public <T>PredicateBuilderWithPredicate equals(Comparable<T> value) {
      if (propertyId == null) {
        throw new IllegalStateException("No property.");
      }
      addPredicate(new EqualsPredicate<T>(propertyId, value));

      return new PredicateBuilderWithPredicate();
    }

    // ----- Greater than -----
    public <T>PredicateBuilderWithPredicate greaterThan(Comparable<T> value) {
      if (propertyId == null) {
        throw new IllegalStateException("No property.");
      }
      addPredicate(new GreaterPredicate<T>(propertyId, value));

      return new PredicateBuilderWithPredicate();
    }

    // ----- Greater than equal to -----
    public <T>PredicateBuilderWithPredicate greaterThanEqualTo(Comparable<T> value) {
      if (propertyId == null) {
        throw new IllegalStateException("No property.");
      }
      addPredicate(new GreaterEqualsPredicate<T>(propertyId, value));

      return new PredicateBuilderWithPredicate();
    }

    // ----- Less than -----
    public <T>PredicateBuilderWithPredicate lessThan(Comparable<T> value) {
      if (propertyId == null) {
        throw new IllegalStateException("No property.");
      }
      addPredicate(new LessPredicate<T>(propertyId, value));

      return new PredicateBuilderWithPredicate();
    }

    // ----- Less than equal to -----
    public <T>PredicateBuilderWithPredicate lessThanEqualTo(Comparable<T> value) {
      if (propertyId == null) {
        throw new IllegalStateException("No property.");
      }
      addPredicate(new LessEqualsPredicate<T>(propertyId, value));

      return new PredicateBuilderWithPredicate();
    }
  }

  public class PredicateBuilderWithPredicate {
    public PredicateBuilder and() {

      if (operator != Operator.And) {
        handleComparator();
        operator = Operator.And;
      }
      return PredicateBuilder.this;
    }

    public PredicateBuilder or() {

      if (operator != Operator.Or) {
        handleComparator();
        operator = Operator.Or;
      }
      return PredicateBuilder.this;
    }

    public BasePredicate toPredicate() {
      if (outer != null) {
        throw new IllegalStateException("Unbalanced block - missing end.");
      }
      done = true;
      return getPredicate();
    }

    public PredicateBuilderWithPredicate end() {
      if (outer == null) {
        throw new IllegalStateException("Unbalanced block - missing begin.");
      }
      outer.addPredicate(getPredicate());
      return outer.getPredicateBuilderWithPredicate();
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/utilities/PredicateHelper.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.utilities;

import org.apache.ambari.server.controller.internal.PropertyPredicateVisitor;
import org.apache.ambari.server.controller.predicate.BasePredicate;
import org.apache.ambari.server.controller.predicate.PredicateVisitor;
import org.apache.ambari.server.controller.predicate.PredicateVisitorAcceptor;
import org.apache.ambari.server.controller.spi.Predicate;

import java.util.Collections;
import java.util.Map;
import java.util.Set;

/**
 *
 */
public class PredicateHelper {

  public static Set<String> getPropertyIds(Predicate predicate) {
    if (predicate instanceof BasePredicate) {
      return ((BasePredicate) predicate).getPropertyIds();
    }
    return Collections.emptySet();
  }

  public static void visit(Predicate predicate, PredicateVisitor visitor) {
    if (predicate instanceof PredicateVisitorAcceptor) {
      ((PredicateVisitorAcceptor) predicate).accept(visitor);
    }
  }

  /**
   * Get a map of property values from a given predicate.
   *
   * @param predicate  the predicate
   *
   * @return the map of properties
   */
  public static Map<String, Object> getProperties(Predicate predicate) {
    if (predicate == null) {
      return Collections.emptyMap();
    }
    PropertyPredicateVisitor visitor = new PropertyPredicateVisitor();
    visit(predicate, visitor);
    return visitor.getProperties();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/utilities/PropertyHelper.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.controller.utilities;

import org.apache.ambari.server.controller.internal.PropertyInfo;
import org.apache.ambari.server.controller.internal.RequestImpl;
import org.apache.ambari.server.controller.spi.Predicate;
import org.apache.ambari.server.controller.spi.Request;
import org.apache.ambari.server.controller.spi.Resource;
import org.apache.ambari.server.controller.spi.TemporalInfo;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.type.TypeReference;

import java.io.IOException;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

/**
 *
 */
public class PropertyHelper {

  private static final String PROPERTIES_FILE = "properties.json";
  private static final String GANGLIA_PROPERTIES_FILE = "ganglia_properties.json";
  private static final String JMX_PROPERTIES_FILE = "jmx_properties.json";
  private static final String KEY_PROPERTIES_FILE = "key_properties.json";
  private static final char EXTERNAL_PATH_SEP = '/';

  private static final Map<Resource.Type, Set<String>> PROPERTY_IDS = readPropertyIds(PROPERTIES_FILE);
  private static final Map<Resource.Type, Map<String, Map<String, PropertyInfo>>> JMX_PROPERTY_IDS = readPropertyProviderIds(JMX_PROPERTIES_FILE);
  private static final Map<Resource.Type, Map<String, Map<String, PropertyInfo>>> GANGLIA_PROPERTY_IDS = readPropertyProviderIds(GANGLIA_PROPERTIES_FILE);
  private static final Map<Resource.Type, Map<Resource.Type, String>> KEY_PROPERTY_IDS = readKeyPropertyIds(KEY_PROPERTIES_FILE);

  public static String getPropertyId(String category, String name) {
    return category == null ? name : category + EXTERNAL_PATH_SEP + name;
  }

  public static Set<String> getPropertyIds(Resource.Type resourceType) {
    Set<String> propertyIds = PROPERTY_IDS.get(resourceType);
    return propertyIds == null ? Collections.<String>emptySet() : propertyIds;
  }

  public static Map<String, Map<String, PropertyInfo>> getGangliaPropertyIds(Resource.Type resourceType) {
    return GANGLIA_PROPERTY_IDS.get(resourceType);
  }

  public static Map<String, Map<String, PropertyInfo>> getJMXPropertyIds(Resource.Type resourceType) {
    return JMX_PROPERTY_IDS.get(resourceType);
  }

  public static Map<Resource.Type, String> getKeyPropertyIds(Resource.Type resourceType) {
    return KEY_PROPERTY_IDS.get(resourceType);
  }

  /**
   * Helper to get a property name from a string.
   *
   * @param absProperty  the fully qualified property
   *
   * @return the property name
   */
  public static String getPropertyName(String absProperty) {
    int lastPathSep = absProperty.lastIndexOf(EXTERNAL_PATH_SEP);

    return lastPathSep == -1 ? absProperty : absProperty.substring(lastPathSep + 1);
  }

  /**
   * Helper to get a property category from a string.
   *
   * @param absProperty  the fully qualified property
   *
   * @return the property category; null if there is no category
   */
  public static String getPropertyCategory(String absProperty) {
    int lastPathSep = absProperty.lastIndexOf(EXTERNAL_PATH_SEP);
    return lastPathSep == -1 ? null : absProperty.substring(0, lastPathSep);
  }

  /**
   * Get all of the property ids associated with the given request.
   *
   * @param request  the request
   *
   * @return the associated properties
   */
  public static Set<String> getAssociatedPropertyIds(Request request) {
    Set<String> ids = request.getPropertyIds();

    if (ids != null) {
      ids = new HashSet<String>(ids);
    } else {
      ids = new HashSet<String>();
    }

    Set<Map<String, Object>> properties = request.getProperties();
    if (properties != null) {
      for (Map<String, Object> propertyMap : properties) {
        ids.addAll(propertyMap.keySet());
      }
    }
    return ids;
  }

  /**
   * Get a map of all the property values keyed by property id for the given resource.
   *
   * @param resource  the resource
   *
   * @return the map of properties for the given resource
   */
  public static Map<String, Object> getProperties(Resource resource) {
    Map<String, Object> properties = new HashMap<String, Object>();

    Map<String, Map<String, Object>> categories = resource.getPropertiesMap();

    for (Map.Entry<String, Map<String, Object>> categoryEntry : categories.entrySet()) {
      for (Map.Entry<String, Object>  propertyEntry : categoryEntry.getValue().entrySet()) {
        properties.put(getPropertyId(categoryEntry.getKey(), propertyEntry.getKey()), propertyEntry.getValue());
      }
    }
    return properties;
  }

  /**
   * Get the set of property ids required to satisfy the given request.
   *
   * @param providerPropertyIds  the provider property ids
   * @param request              the request
   * @param predicate            the predicate
   *
   * @return the set of property ids needed to satisfy the request
   */
  public static Set<String> getRequestPropertyIds(Set<String> providerPropertyIds,
                                                      Request request,
                                                      Predicate predicate) {
    Set<String> propertyIds  = request.getPropertyIds();

    // if no properties are specified, then return them all
    if (propertyIds == null || propertyIds.isEmpty()) {
      providerPropertyIds = new HashSet<String>(providerPropertyIds);

//      // strip out the temporal properties, they must be asked for explicitly
//      Iterator<String> iter = providerPropertyIds.iterator();
//      while (iter.hasNext()) {
//        String propertyId = iter.next();
//        if (propertyId.isTemporal()) {
//          iter.remove();
//        }
//      }
      return providerPropertyIds;
    }

    propertyIds = new HashSet<String>(propertyIds);

    if (predicate != null) {
      propertyIds.addAll(PredicateHelper.getPropertyIds(predicate));
    }
    propertyIds.retainAll(providerPropertyIds);
    return propertyIds;
  }

  /**
   * Factory method to create a create request from the given set of property maps.
   * Each map contains the properties to be used to create a resource.  Multiple maps in the
   * set should result in multiple creates.
   *
   * @param properties   the properties associated with the request; may be null
   */
  public static Request getCreateRequest(Set<Map<String, Object>> properties) {
    return new RequestImpl(null,  properties, null);
  }

  /**
   * Factory method to create a read request from the given set of property ids.  The set of
   * property ids represents the properties of interest for the query.
   *
   * @param propertyIds  the property ids associated with the request; may be null
   */
  public static Request getReadRequest(Set<String> propertyIds) {
    return new RequestImpl(propertyIds,  null, null);
  }

  /**
   * Factory method to create a read request from the given set of property ids.  The set of
   * property ids represents the properties of interest for the query.
   *
   * @param propertyIds      the property ids associated with the request; may be null
   * @param mapTemporalInfo  the temporal info
   */
  public static Request getReadRequest(Set<String> propertyIds, Map<String,
      TemporalInfo> mapTemporalInfo) {
    return new RequestImpl(propertyIds,  null, mapTemporalInfo);
  }

  /**
   * Factory method to create a read request from the given set of property ids.  The set of
   * property ids represents the properties of interest for the query.
   *
   * @param propertyIds  the property ids associated with the request; may be null
   */
  public static Request getReadRequest(String ... propertyIds) {
    return new RequestImpl(new HashSet<String>(Arrays.asList(propertyIds)),  null, null);
  }

  /**
   * Factory method to create an update request from the given map of properties.
   * The properties values in the given map are used to update the resource.
   *
   * @param properties   the properties associated with the request; may be null
   */
  public static Request getUpdateRequest(Map<String, Object> properties) {
    return new RequestImpl(null,  Collections.singleton(properties), null);
  }

  private static Map<Resource.Type, Map<String, Map<String, PropertyInfo>>> readPropertyProviderIds(String filename) {
    ObjectMapper mapper = new ObjectMapper();

    try {
      Map<Resource.Type, Map<String, Map<String, Metric>>> resourceMetricMap =
          mapper.readValue(ClassLoader.getSystemResourceAsStream(filename),
              new TypeReference<Map<Resource.Type, Map<String, Map<String, Metric>>>>() {});

      Map<Resource.Type, Map<String, Map<String, PropertyInfo>>> resourceMetrics =
          new HashMap<Resource.Type, Map<String, Map<String, PropertyInfo>>>();

      for (Map.Entry<Resource.Type, Map<String, Map<String, Metric>>> resourceEntry : resourceMetricMap.entrySet()) {
        Map<String, Map<String, PropertyInfo>> componentMetrics = new HashMap<String, Map<String, PropertyInfo>>();

        for (Map.Entry<String, Map<String, Metric>> componentEntry : resourceEntry.getValue().entrySet()) {
          Map<String, PropertyInfo> metrics = new HashMap<String, PropertyInfo>();

          for (Map.Entry<String, Metric> metricEntry : componentEntry.getValue().entrySet()) {
            String property = metricEntry.getKey();
            Metric metric   = metricEntry.getValue();

            metrics.put(property, new PropertyInfo(metric.getMetric(), metric.isTemporal(), metric.isPointInTime()));
          }
          componentMetrics.put(componentEntry.getKey(), metrics);
        }
        resourceMetrics.put(resourceEntry.getKey(), componentMetrics);
      }
      return resourceMetrics;
    } catch (IOException e) {
      throw new IllegalStateException("Can't read properties file " + filename, e);
    }
  }

  private static Map<Resource.Type, Set<String>> readPropertyIds(String filename) {
    ObjectMapper mapper = new ObjectMapper();

    try {
      return mapper.readValue(ClassLoader.getSystemResourceAsStream(filename), new TypeReference<Map<Resource.Type, Set<String>>>() {
      });
    } catch (IOException e) {
      throw new IllegalStateException("Can't read properties file " + filename, e);
    }
  }

  private static Map<Resource.Type, Map<Resource.Type, String>> readKeyPropertyIds(String filename) {
    ObjectMapper mapper = new ObjectMapper();

    try {
      return mapper.readValue(ClassLoader.getSystemResourceAsStream(filename), new TypeReference<Map<Resource.Type, Map<Resource.Type, String>>>() {
      });
    } catch (IOException e) {
      throw new IllegalStateException("Can't read properties file " + filename, e);
    }
  }

  protected static class Metric {
    private String metric;
    private boolean pointInTime;
    private boolean temporal;

    private Metric() {
    }

    protected Metric(String metric, boolean pointInTime, boolean temporal) {
      this.metric = metric;
      this.pointInTime = pointInTime;
      this.temporal = temporal;
    }

    public String getMetric() {
      return metric;
    }

    public void setMetric(String metric) {
      this.metric = metric;
    }

    public boolean isPointInTime() {
      return pointInTime;
    }

    public void setPointInTime(boolean pointInTime) {
      this.pointInTime = pointInTime;
    }

    public boolean isTemporal() {
      return temporal;
    }

    public void setTemporal(boolean temporal) {
      this.temporal = temporal;
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/controller/utilities/StreamProvider.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.controller.utilities;

import java.io.IOException;
import java.io.InputStream;

/**
 * A provider of input stream from a property source.
 */
public interface StreamProvider {
  public InputStream readFrom(String spec) throws IOException;
}
"
ambari-server/src/main/java/org/apache/ambari/server/metadata/ActionMetadata.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.metadata;

import com.google.inject.Singleton;
import org.apache.ambari.server.Role;

import java.util.*;

/**
 * Contains metadata about actions supported by services
 */
@Singleton
public class ActionMetadata {
  private final Map<String, List<String>> serviceActions = new HashMap<String, List<String>>();
  private final Map<String, String> serviceClients = new HashMap<String, String>();
  private final Map<String, String> serviceCheckActions =
      new HashMap<String, String>();

  public ActionMetadata() {
    fillServiceActions();
    fillServiceClients();
    fillServiceCheckActions();
  }

  private void fillServiceClients() {
    serviceClients.put("hdfs"       , Role.HDFS_CLIENT.toString());
    serviceClients.put("hbase"      , Role.HBASE_CLIENT.toString());
    serviceClients.put("mapreduce"  , Role.MAPREDUCE_CLIENT.toString());
    serviceClients.put("zookeeper"  , Role.ZOOKEEPER_CLIENT.toString());
    serviceClients.put("hive"       , Role.HIVE_CLIENT.toString());
    serviceClients.put("hcat"       , Role.HCAT.toString());
    serviceClients.put("oozie"      , Role.OOZIE_CLIENT.toString());
    serviceClients.put("pig"        , Role.PIG.toString());
    serviceClients.put("sqoop"      , Role.SQOOP.toString());
  }

  private void fillServiceActions() {
    serviceActions.put("hdfs"       , Arrays.asList(Role.HDFS_SERVICE_CHECK.toString()));
    serviceActions.put("hbase"      , Arrays.asList(Role.HBASE_SERVICE_CHECK.toString()));
    serviceActions.put("mapreduce"  , Arrays.asList(Role.MAPREDUCE_SERVICE_CHECK.toString()));
    serviceActions.put("zookeeper"  , Arrays.asList(Role.ZOOKEEPER_QUORUM_SERVICE_CHECK.toString()));
    serviceActions.put("hive"       , Arrays.asList(Role.HIVE_SERVICE_CHECK.toString()));
    serviceActions.put("hcat"       , Arrays.asList(Role.HCAT_SERVICE_CHECK.toString()));
    serviceActions.put("oozie"      , Arrays.asList(Role.OOZIE_SERVICE_CHECK.toString()));
    serviceActions.put("pig"        , Arrays.asList(Role.PIG_SERVICE_CHECK.toString()));
    serviceActions.put("sqoop"      , Arrays.asList(Role.SQOOP_SERVICE_CHECK.toString()));
    serviceActions.put("webhcat"  , Arrays.asList(Role.WEBHCAT_SERVICE_CHECK.toString()));
  }

  private void fillServiceCheckActions() {
    serviceCheckActions.put("hdfs", Role.HDFS_SERVICE_CHECK.toString());
    serviceCheckActions.put("hbase", Role.HBASE_SERVICE_CHECK.toString());
    serviceCheckActions.put("mapreduce",
        Role.MAPREDUCE_SERVICE_CHECK.toString());
    serviceCheckActions.put("zookeeper",
        Role.ZOOKEEPER_QUORUM_SERVICE_CHECK.toString());
    serviceCheckActions.put("hive", Role.HIVE_SERVICE_CHECK.toString());
    serviceCheckActions.put("hcat", Role.HCAT_SERVICE_CHECK.toString());
    serviceCheckActions.put("oozie", Role.OOZIE_SERVICE_CHECK.toString());
    serviceCheckActions.put("pig", Role.PIG_SERVICE_CHECK.toString());
    serviceCheckActions.put("sqoop", Role.SQOOP_SERVICE_CHECK.toString());
    serviceCheckActions.put("webhcat",
        Role.WEBHCAT_SERVICE_CHECK.toString());
  }

  public List<String> getActions(String serviceName) {
    List<String> result = serviceActions.get(serviceName.toLowerCase());
    if (result != null) {
      return result;
    } else {
      return Collections.emptyList();
    }
  }

  public String getClient(String serviceName) {
    return serviceClients.get(serviceName.toLowerCase());
  }

  public String getServiceCheckAction(String serviceName) {
    return serviceCheckActions.get(serviceName.toLowerCase());
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/metadata/RoleCommandOrder.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.metadata;

import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.RoleCommand;
import org.apache.ambari.server.stageplanner.RoleGraphNode;

/**
 * This class is used to establish the order between two roles. This class
 * should not be used to determine the dependencies.
 */
public class RoleCommandOrder {

  private static class RoleCommandPair {
    Role role;
    RoleCommand cmd;

    public RoleCommandPair(Role _role, RoleCommand _cmd) {
      if (_role == null || _cmd == null) {
        throw new IllegalArgumentException("role = "+_role+", cmd = "+_cmd);
      }
      this.role = _role;
      this.cmd = _cmd;
    }

    @Override
    public int hashCode() {
      return (role.toString() + cmd.toString()).hashCode();
    }

    @Override
    public boolean equals(Object other) {
      if (other != null && (other instanceof RoleCommandPair)
          && ((RoleCommandPair) other).role.equals(role)
          && ((RoleCommandPair) other).cmd.equals(cmd)) {
        return true;
      }
      return false;
    }
  }

  /**
   * key -> blocked role command value -> set of blocker role commands.
   */
  private static Map<RoleCommandPair, Set<RoleCommandPair>> dependencies = new HashMap<RoleCommandPair, Set<RoleCommandPair>>();

  private static void addDependency(Role blockedRole,
      RoleCommand blockedCommand, Role blockerRole, RoleCommand blockerCommand) {
    RoleCommandPair rcp1 = new RoleCommandPair(blockedRole, blockedCommand);
    RoleCommandPair rcp2 = new RoleCommandPair(blockerRole, blockerCommand);
    if (dependencies.get(rcp1) == null) {
      dependencies.put(rcp1, new HashSet<RoleCommandPair>());
    }
    dependencies.get(rcp1).add(rcp2);
  }

  public static void initialize() {
    addDependency(Role.SECONDARY_NAMENODE, RoleCommand.START, Role.NAMENODE,
        RoleCommand.START);
    addDependency(Role.HBASE_MASTER, RoleCommand.START, Role.ZOOKEEPER_SERVER,
        RoleCommand.START);
    addDependency(Role.HBASE_MASTER, RoleCommand.START, Role.NAMENODE,
        RoleCommand.START);
    addDependency(Role.HBASE_MASTER, RoleCommand.START, Role.DATANODE,
        RoleCommand.START);
    addDependency(Role.HBASE_REGIONSERVER, RoleCommand.START,
        Role.HBASE_MASTER, RoleCommand.START);
    addDependency(Role.JOBTRACKER, RoleCommand.START, Role.NAMENODE,
        RoleCommand.START);
    addDependency(Role.JOBTRACKER, RoleCommand.START, Role.DATANODE,
        RoleCommand.START);
    addDependency(Role.TASKTRACKER, RoleCommand.START, Role.NAMENODE,
        RoleCommand.START);
    addDependency(Role.TASKTRACKER, RoleCommand.START, Role.DATANODE,
        RoleCommand.START);
    addDependency(Role.OOZIE_SERVER, RoleCommand.START, Role.JOBTRACKER,
        RoleCommand.START);
    addDependency(Role.OOZIE_SERVER, RoleCommand.START, Role.TASKTRACKER,
        RoleCommand.START);
    addDependency(Role.HIVE_SERVER, RoleCommand.START, Role.TASKTRACKER,
        RoleCommand.START);
    addDependency(Role.HIVE_SERVER, RoleCommand.START, Role.DATANODE,
        RoleCommand.START);
    addDependency(Role.WEBHCAT_SERVER, RoleCommand.START, Role.TASKTRACKER,
        RoleCommand.START);
    addDependency(Role.WEBHCAT_SERVER, RoleCommand.START, Role.DATANODE,
        RoleCommand.START);
    addDependency(Role.WEBHCAT_SERVER, RoleCommand.START, Role.HIVE_SERVER,
        RoleCommand.START);
    addDependency(Role.HIVE_METASTORE, RoleCommand.START, Role.MYSQL_SERVER,
        RoleCommand.START);
    addDependency(Role.HIVE_SERVER, RoleCommand.START, Role.MYSQL_SERVER,
        RoleCommand.START);

    // Service checks
    addDependency(Role.HDFS_SERVICE_CHECK, RoleCommand.EXECUTE, Role.NAMENODE,
        RoleCommand.START);
    addDependency(Role.HDFS_SERVICE_CHECK, RoleCommand.EXECUTE, Role.DATANODE,
        RoleCommand.START);
    addDependency(Role.MAPREDUCE_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.JOBTRACKER, RoleCommand.START);
    addDependency(Role.MAPREDUCE_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.TASKTRACKER, RoleCommand.START);
    addDependency(Role.OOZIE_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.OOZIE_SERVER, RoleCommand.START);
    addDependency(Role.WEBHCAT_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.WEBHCAT_SERVER, RoleCommand.START);
    addDependency(Role.HBASE_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.HBASE_MASTER, RoleCommand.START);
    addDependency(Role.HBASE_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.HBASE_REGIONSERVER, RoleCommand.START);
    addDependency(Role.HIVE_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.HIVE_SERVER, RoleCommand.START);
    addDependency(Role.HIVE_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.HIVE_METASTORE, RoleCommand.START);
    addDependency(Role.HCAT_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.HIVE_SERVER, RoleCommand.START);
    addDependency(Role.PIG_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.JOBTRACKER, RoleCommand.START);
    addDependency(Role.PIG_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.TASKTRACKER, RoleCommand.START);
    addDependency(Role.SQOOP_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.JOBTRACKER, RoleCommand.START);
    addDependency(Role.SQOOP_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.TASKTRACKER, RoleCommand.START);
    addDependency(Role.ZOOKEEPER_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.ZOOKEEPER_SERVER, RoleCommand.START);
    addDependency(Role.ZOOKEEPER_QUORUM_SERVICE_CHECK, RoleCommand.EXECUTE,
        Role.ZOOKEEPER_SERVER, RoleCommand.START);
    
    addDependency(Role.ZOOKEEPER_SERVER, RoleCommand.STOP,
        Role.HBASE_MASTER, RoleCommand.STOP);
    addDependency(Role.ZOOKEEPER_SERVER, RoleCommand.STOP,
        Role.HBASE_REGIONSERVER, RoleCommand.STOP);
    addDependency(Role.NAMENODE, RoleCommand.STOP,
        Role.HBASE_MASTER, RoleCommand.STOP);
    addDependency(Role.DATANODE, RoleCommand.STOP,
        Role.HBASE_MASTER, RoleCommand.STOP);
    addDependency(Role.HBASE_MASTER, RoleCommand.STOP,
        Role.HBASE_REGIONSERVER, RoleCommand.STOP);
    addDependency(Role.NAMENODE, RoleCommand.STOP,
        Role.JOBTRACKER, RoleCommand.STOP);
    addDependency(Role.NAMENODE, RoleCommand.STOP,
        Role.TASKTRACKER, RoleCommand.STOP);
    addDependency(Role.DATANODE, RoleCommand.STOP,
        Role.JOBTRACKER, RoleCommand.STOP);
    addDependency(Role.DATANODE, RoleCommand.STOP,
        Role.TASKTRACKER, RoleCommand.STOP);
  }

  /**
   * Returns the dependency order. -1 => rgn1 before rgn2, 0 => they can be
   * parallel 1 => rgn2 before rgn1
   * 
   * @param roleGraphNode
   * @param roleGraphNode2
   */
  public int order(RoleGraphNode rgn1, RoleGraphNode rgn2) {
    RoleCommandPair rcp1 = new RoleCommandPair(rgn1.getRole(),
        rgn1.getCommand());
    RoleCommandPair rcp2 = new RoleCommandPair(rgn2.getRole(),
        rgn2.getCommand());
    if ((dependencies.get(rcp1) != null)
        && (dependencies.get(rcp1).contains(rcp2))) {
      return 1;
    } else if ((dependencies.get(rcp2) != null)
        && (dependencies.get(rcp2).contains(rcp1))) {
      return -1;
    } else if (!rgn2.getCommand().equals(rgn1.getCommand())) {
      return compareCommands(rgn1, rgn2);
    }
    return 0;
  }

  private int compareCommands(RoleGraphNode rgn1, RoleGraphNode rgn2) {
    RoleCommand rc1 = rgn1.getCommand();
    RoleCommand rc2 = rgn2.getCommand();
    if (rc1.equals(rc2)) {
      //If its coming here means roles have no dependencies.
      return 0;
    }
   
    if ((rc1.equals(RoleCommand.START) && rc2.equals(RoleCommand.EXECUTE)) ||
        (rc2.equals(RoleCommand.START) && rc1.equals(RoleCommand.EXECUTE))) {
      //START and execute are independent, role order matters
      return 0;
    }
    
    if (rc1.equals(RoleCommand.INSTALL)) {
      return -1;
    } else if (rc2.equals(RoleCommand.INSTALL)) {
      return 1;
    } else if (rc1.equals(RoleCommand.START) || rc1.equals(RoleCommand.EXECUTE)) {
      return -1;
    } else if (rc2.equals(RoleCommand.START) || rc2.equals(RoleCommand.EXECUTE)) {
      return 1;
    } else if (rc1.equals(RoleCommand.STOP)) {
      return -1;
    } else if (rc2.equals(RoleCommand.STOP)) {
      return 1;
    }
    return 0;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/GuiceJpaInitializer.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm;

import com.google.inject.Inject;
import com.google.inject.persist.PersistService;

/**
 * This class needs to be instantiated with guice to initialize Guice-persist
 */
public class GuiceJpaInitializer {

  @Inject
  public GuiceJpaInitializer(PersistService service) {
    service.start();
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/PersistenceType.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm;

public enum PersistenceType {
  IN_MEMORY("ambari-javadb"),
  POSTGRES("ambari-postgres");

  String unitName;

  PersistenceType(String unitName) {
    this.unitName = unitName;
  }

  public String getUnitName() {
    return unitName;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ClearEntityManagerInterceptor.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import org.aopalliance.intercept.MethodInterceptor;
import org.aopalliance.intercept.MethodInvocation;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.persistence.EntityManager;

/**
 * Interceptors clears EntityManager before method call
 */
public class ClearEntityManagerInterceptor implements MethodInterceptor {
  private static final Logger log = LoggerFactory.getLogger(ClearEntityManagerInterceptor.class);

  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Override
  public Object invoke(MethodInvocation methodInvocation) throws Throwable {
    try {
      return methodInvocation.proceed();
    } finally {
      if (!entityManagerProvider.get().getTransaction().isActive()) {
        log.debug("Transaction is not active any more - clearing Entity Manager");
        entityManagerProvider.get().clear();
      }
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ClusterDAO.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import java.util.List;

import javax.persistence.EntityManager;
import javax.persistence.NoResultException;
import javax.persistence.TypedQuery;

import org.apache.ambari.server.orm.entities.ClusterConfigEntity;
import org.apache.ambari.server.orm.entities.ClusterEntity;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;

public class ClusterDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;

  /**
   * Looks for Cluster by ID
   * @param id ID of Cluster
   * @return Found entity or NULL
   */
  @Transactional
  public ClusterEntity findById(long id) {
    return entityManagerProvider.get().find(ClusterEntity.class, id);
  }

  @Transactional
  public ClusterEntity findByName(String clusterName) {
    TypedQuery<ClusterEntity> query = entityManagerProvider.get().createNamedQuery("clusterByName", ClusterEntity.class);
    query.setParameter("clusterName", clusterName);
    try {
      return query.getSingleResult();
    } catch (NoResultException ignored) {
      return null;
    }
  }

  @Transactional
  public List<ClusterEntity> findAll() {
    TypedQuery<ClusterEntity> query = entityManagerProvider.get().createNamedQuery("allClusters", ClusterEntity.class);
    try {
      return query.getResultList();
    } catch (NoResultException ignored) {
    }
    return null;
  }

  /**
   * Create Cluster entity in Database
   * @param clusterEntity entity to create
   */
  @Transactional
  public void create(ClusterEntity clusterEntity) {
    entityManagerProvider.get().persist(clusterEntity);
  }

  /**
   * Creates a cluster configuration in the DB.
   */
  @Transactional
  public void createConfig(ClusterConfigEntity entity) {
    entityManagerProvider.get().persist(entity);
  }

  /**
   * Retrieve entity data from DB
   * @param clusterEntity entity to refresh
   */
  @Transactional
  public void refresh(ClusterEntity clusterEntity) {
    entityManagerProvider.get().refresh(clusterEntity);
  }

  @Transactional
  public ClusterEntity merge(ClusterEntity clusterEntity) {
    return entityManagerProvider.get().merge(clusterEntity);
  }

  @Transactional
  public void remove(ClusterEntity clusterEntity) {
    entityManagerProvider.get().remove(merge(clusterEntity));
  }

  @Transactional
  public void removeByName(String clusterName) {
    remove(findByName(clusterName));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ClusterServiceDAO.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.ClusterServiceEntity;
import org.apache.ambari.server.orm.entities.ClusterServiceEntityPK;

import javax.persistence.EntityManager;
import javax.persistence.NoResultException;
import javax.persistence.TypedQuery;

public class ClusterServiceDAO {
  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public ClusterServiceEntity findByPK(ClusterServiceEntityPK clusterServiceEntityPK) {
    return entityManagerProvider.get().find(ClusterServiceEntity.class, clusterServiceEntityPK);
  }

  @Transactional
  public ClusterServiceEntity findByClusterAndServiceNames(String  clusterName, String serviceName) {
    TypedQuery<ClusterServiceEntity> query = entityManagerProvider.get()
            .createNamedQuery("clusterServiceByClusterAndServiceNames", ClusterServiceEntity.class);
    query.setParameter("clusterName", clusterName);
    query.setParameter("serviceName", serviceName);

    try {
      return query.getSingleResult();
    } catch (NoResultException ignored) {
      return null;
    }
  }

  @Transactional
  public void refresh(ClusterServiceEntity clusterServiceEntity) {
    entityManagerProvider.get().refresh(clusterServiceEntity);
  }

  @Transactional
  public void create(ClusterServiceEntity clusterServiceEntity) {
    entityManagerProvider.get().persist(clusterServiceEntity);
  }

  @Transactional
  public ClusterServiceEntity merge(ClusterServiceEntity clusterServiceEntity) {
    return entityManagerProvider.get().merge(clusterServiceEntity);
  }

  @Transactional
  public void remove(ClusterServiceEntity clusterServiceEntity) {
    entityManagerProvider.get().remove(merge(clusterServiceEntity));
  }

  @Transactional
  public void removeByPK(ClusterServiceEntityPK clusterServiceEntityPK) {
    remove(findByPK(clusterServiceEntityPK));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ClusterStateDAO.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.ClusterStateEntity;

import javax.persistence.EntityManager;

public class ClusterStateDAO {
  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public ClusterStateEntity findByPK(String clusterName) {
    return entityManagerProvider.get().find(ClusterStateEntity.class, clusterName);
  }

  @Transactional
  public void refresh(ClusterStateEntity clusterStateEntity) {
    entityManagerProvider.get().refresh(clusterStateEntity);
  }

  @Transactional
  public void create(ClusterStateEntity clusterStateEntity) {
    entityManagerProvider.get().persist(clusterStateEntity);
  }

  @Transactional
  public ClusterStateEntity merge(ClusterStateEntity clusterStateEntity) {
    return entityManagerProvider.get().merge(clusterStateEntity);
  }

  @Transactional
  public void remove(ClusterStateEntity clusterStateEntity) {
    entityManagerProvider.get().remove(merge(clusterStateEntity));
  }

  @Transactional
  public void removeByPK(String clusterName) {
    remove(findByPK(clusterName));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ComponentConfigMappingDAO.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import java.util.Collection;
import java.util.Collections;
import java.util.List;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;

import javax.persistence.EntityManager;
import javax.persistence.TypedQuery;

import org.apache.ambari.server.orm.entities.ComponentConfigMappingEntity;

public class ComponentConfigMappingDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;
  @Inject
  DaoUtils daoUtils;

  @Transactional
  public List<ComponentConfigMappingEntity> findByType(
      Collection<String> configTypes) {
    TypedQuery<ComponentConfigMappingEntity> query =
        entityManagerProvider.get().createQuery(
            "SELECT config FROM ComponentConfigMappingEntity config"
            + " WHERE config.configType IN ?1",
        ComponentConfigMappingEntity.class);
    return daoUtils.selectList(query, configTypes);
  }

  public List<ComponentConfigMappingEntity> findByComponentAndType(long clusterId, String serviceName, String componentName,
                                                                   Collection<String> configTypes) {
    if (configTypes.isEmpty()) {
      return Collections.emptyList();
    }
    TypedQuery<ComponentConfigMappingEntity> query = entityManagerProvider.get().createQuery("SELECT config " +
        "FROM ComponentConfigMappingEntity config " +
        "WHERE " +
        "config.clusterId = ?1 " +
        "AND config.serviceName = ?2 " +
        "AND config.componentName = ?3 " +
        "AND config.configType IN ?4",
        ComponentConfigMappingEntity.class);
    return daoUtils.selectList(query, clusterId, serviceName, componentName, configTypes);
  }

  @Transactional
  public void refresh(
      ComponentConfigMappingEntity componentConfigMappingEntity) {
    entityManagerProvider.get().refresh(componentConfigMappingEntity);
  }

  @Transactional
  public ComponentConfigMappingEntity merge(
      ComponentConfigMappingEntity componentConfigMappingEntity) {
    return entityManagerProvider.get().merge(
        componentConfigMappingEntity);
  }

  @Transactional
  public void remove(
      ComponentConfigMappingEntity componentConfigMappingEntity) {
    entityManagerProvider.get().remove(merge(componentConfigMappingEntity));
  }

  @Transactional
  public void removeByType(Collection<String> configTypes) {
    for (ComponentConfigMappingEntity entity : findByType(configTypes)) {
      remove(entity);
    }
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/DaoUtils.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Singleton;

import javax.persistence.NoResultException;
import javax.persistence.Query;
import javax.persistence.TypedQuery;
import java.util.Collections;
import java.util.List;

@Singleton
public class DaoUtils {

  public <T> List<T> selectList(TypedQuery<T> query, Object... parameters) {
    setParameters(query, parameters);
    try {
      return query.getResultList();
    } catch (NoResultException ignored) {
      return Collections.emptyList();
    }
  }

  public <T> T selectSingle(TypedQuery<T> query, Object... parameters) {
    setParameters(query, parameters);
    try {
      return query.getSingleResult();
    } catch (NoResultException ignored) {
      return null;
    }
  }

  public int executeUpdate(Query query, Object... parameters) {
    setParameters(query, parameters);
    return query.executeUpdate();
  }

  public void setParameters(Query query, Object... parameters) {
    for (int i = 0; i < parameters.length; i++) {
      query.setParameter(i+1, parameters[i]);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ExecutionCommandDAO.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.ExecutionCommandEntity;

import javax.persistence.EntityManager;

public class ExecutionCommandDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public ExecutionCommandEntity findByPK(long taskId) {
    return entityManagerProvider.get().find(ExecutionCommandEntity.class, taskId);
  }

  @Transactional
  public void create(ExecutionCommandEntity stageEntity) {
    entityManagerProvider.get().persist(stageEntity);
  }

  @Transactional
  public ExecutionCommandEntity merge(ExecutionCommandEntity stageEntity) {
    return entityManagerProvider.get().merge(stageEntity);
  }

  @Transactional
  public void remove(ExecutionCommandEntity stageEntity) {
    entityManagerProvider.get().remove(merge(stageEntity));
  }

  @Transactional
  public void removeByPK(int taskId) {
    remove(findByPK(taskId));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostComponentConfigMappingDAO.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import java.util.ArrayList;
import java.util.Collection;
import java.util.List;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;

import javax.persistence.EntityManager;
import javax.persistence.TypedQuery;

import org.apache.ambari.server.orm.entities.HostComponentConfigMappingEntity;

public class HostComponentConfigMappingDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;
  @Inject
  DaoUtils daoUtils;

  @Transactional
  public List<HostComponentConfigMappingEntity> findByType(
      Collection<String> configTypes) {
    TypedQuery<HostComponentConfigMappingEntity> query =
        entityManagerProvider.get().createQuery(
            "SELECT config FROM HostComponentConfigMappingEntity config"
            + " WHERE config.configType IN ?1",
        HostComponentConfigMappingEntity.class);
    return daoUtils.selectList(query, configTypes);
  }

  @Transactional
  public void refresh(
      HostComponentConfigMappingEntity componentConfigMappingEntity) {
    entityManagerProvider.get().refresh(componentConfigMappingEntity);
  }

  @Transactional
  public HostComponentConfigMappingEntity merge(
      HostComponentConfigMappingEntity componentConfigMappingEntity) {
    return entityManagerProvider.get().merge(
        componentConfigMappingEntity);
  }

  @Transactional
  public void remove(
      HostComponentConfigMappingEntity componentConfigMappingEntity) {
    entityManagerProvider.get().remove(merge(componentConfigMappingEntity));
  }

  @Transactional
  public void removeByType(Collection<String> configTypes) {
    for (HostComponentConfigMappingEntity entity : findByType(configTypes)) {
      remove(entity);
    }
  }

  @Transactional
  public List<HostComponentConfigMappingEntity> findByHostComponentAndType(
      long clusterId, String serviceName, String componentName,
      String hostname,
      Collection<String> configTypes) {
    if (configTypes.isEmpty()) {
      return new ArrayList<HostComponentConfigMappingEntity>();
    }    
    TypedQuery<HostComponentConfigMappingEntity> query =
        entityManagerProvider.get().createQuery(
            "SELECT config FROM HostComponentConfigMappingEntity config"
            + " WHERE "
            + " config.clusterId = ?1"
            + " AND config.serviceName = ?2"
            + " AND config.componentName = ?3"
            + " AND config.hostName = ?4"
            + " AND config.configType IN ?5",
        HostComponentConfigMappingEntity.class);
    return daoUtils.selectList(query, clusterId, serviceName,
        componentName, hostname, configTypes);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostComponentDesiredConfigMappingDAO.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import java.util.ArrayList;
import java.util.Collection;
import java.util.List;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;

import javax.persistence.EntityManager;
import javax.persistence.TypedQuery;

import org.apache.ambari.server.orm.entities.HostComponentDesiredConfigMappingEntity;

public class HostComponentDesiredConfigMappingDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;
  @Inject
  DaoUtils daoUtils;

  @Transactional
  public List<HostComponentDesiredConfigMappingEntity> findByType(
      Collection<String> configTypes) {
    TypedQuery<HostComponentDesiredConfigMappingEntity> query =
        entityManagerProvider.get().createQuery(
            "SELECT config FROM HostComponentDesiredConfigMappingEntity config"
            + " WHERE config.configType IN ?1",
        HostComponentDesiredConfigMappingEntity.class);
    return daoUtils.selectList(query, configTypes);
  }

  @Transactional
  public List<HostComponentDesiredConfigMappingEntity> findByHostComponentAndType(
      long clusterId, String serviceName, String componentName,
      String hostname,
      Collection<String> configTypes) {
    if (configTypes.isEmpty()) {
      return new ArrayList<HostComponentDesiredConfigMappingEntity>();
    }
    TypedQuery<HostComponentDesiredConfigMappingEntity> query =
        entityManagerProvider.get().createQuery(
            "SELECT config FROM HostComponentDesiredConfigMappingEntity config"
                + " WHERE "
                + " config.clusterId = ?1"
                + " AND config.serviceName = ?2"
                + " AND config.componentName = ?3"
                + " AND config.hostName = ?4"
                + " AND config.configType IN ?5",
            HostComponentDesiredConfigMappingEntity.class);
    return daoUtils.selectList(query, clusterId, serviceName,
        componentName, hostname, configTypes);
  }

  @Transactional
  public void refresh(
      HostComponentDesiredConfigMappingEntity componentConfigMappingEntity) {
    entityManagerProvider.get().refresh(componentConfigMappingEntity);
  }

  @Transactional
  public HostComponentDesiredConfigMappingEntity merge(
      HostComponentDesiredConfigMappingEntity componentConfigMappingEntity) {
    return entityManagerProvider.get().merge(
        componentConfigMappingEntity);
  }

  @Transactional
  public void remove(
      HostComponentDesiredConfigMappingEntity componentConfigMappingEntity) {
    entityManagerProvider.get().remove(merge(componentConfigMappingEntity));
  }

  @Transactional
  public void removeByType(Collection<String> configTypes) {
    for (HostComponentDesiredConfigMappingEntity entity : findByType(configTypes)) {
      remove(entity);
    }
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostComponentDesiredStateDAO.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.HostComponentDesiredStateEntity;
import org.apache.ambari.server.orm.entities.HostComponentDesiredStateEntityPK;

import javax.persistence.EntityManager;

public class HostComponentDesiredStateDAO {
  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public HostComponentDesiredStateEntity findByPK(HostComponentDesiredStateEntityPK primaryKey) {
    return entityManagerProvider.get().find(HostComponentDesiredStateEntity.class, primaryKey);
  }

  @Transactional
  public void refresh(HostComponentDesiredStateEntity hostComponentDesiredStateEntity) {
    entityManagerProvider.get().refresh(hostComponentDesiredStateEntity);
  }

  @Transactional
  public void create(HostComponentDesiredStateEntity hostComponentDesiredStateEntity) {
    entityManagerProvider.get().persist(hostComponentDesiredStateEntity);
  }

  @Transactional
  public HostComponentDesiredStateEntity merge(HostComponentDesiredStateEntity hostComponentDesiredStateEntity) {
    return entityManagerProvider.get().merge(hostComponentDesiredStateEntity);
  }

  @Transactional
  public void remove(HostComponentDesiredStateEntity hostComponentDesiredStateEntity) {
    entityManagerProvider.get().remove(merge(hostComponentDesiredStateEntity));
  }

  @Transactional
  public void removeByPK(HostComponentDesiredStateEntityPK primaryKey) {
    remove(findByPK(primaryKey));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostComponentStateDAO.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.HostComponentStateEntity;
import org.apache.ambari.server.orm.entities.HostComponentStateEntityPK;

import javax.persistence.EntityManager;

public class HostComponentStateDAO {
  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public HostComponentStateEntity findByPK(HostComponentStateEntityPK primaryKey) {
    return entityManagerProvider.get().find(HostComponentStateEntity.class, primaryKey);
  }

  @Transactional
  public void refresh(HostComponentStateEntity hostComponentStateEntity) {
    entityManagerProvider.get().refresh(hostComponentStateEntity);
  }

  @Transactional
  public void create(HostComponentStateEntity hostComponentStateEntity) {
    entityManagerProvider.get().persist(hostComponentStateEntity);
  }

  @Transactional
  public HostComponentStateEntity merge(HostComponentStateEntity hostComponentStateEntity) {
    return entityManagerProvider.get().merge(hostComponentStateEntity);
  }

  @Transactional
  public void remove(HostComponentStateEntity hostComponentStateEntity) {
    entityManagerProvider.get().remove(merge(hostComponentStateEntity));
  }

  @Transactional
  public void removeByPK(HostComponentStateEntityPK primaryKey) {
    remove(findByPK(primaryKey));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostDAO.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.HostEntity;
import org.apache.ambari.server.orm.entities.StageEntity;

import javax.persistence.EntityManager;
import javax.persistence.NoResultException;
import javax.persistence.TypedQuery;
import java.util.Collections;
import java.util.List;

public class HostDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public HostEntity findByName(String hostName) {
    return entityManagerProvider.get().find(HostEntity.class, hostName);
  }

  @Transactional
  public List<HostEntity> findAll() {
    TypedQuery<HostEntity> query = entityManagerProvider.get().createQuery("SELECT host FROM HostEntity host", HostEntity.class);
    try {
      return query.getResultList();
    } catch (NoResultException e) {
      return Collections.emptyList();
    }
  }

  @Transactional
  public List<HostEntity> findByStage(StageEntity stageEntity) {
    TypedQuery<HostEntity> query = entityManagerProvider.get().createQuery(
        "SELECT DISTINCT host FROM HostEntity host JOIN host.hostRoleCommandEntities command JOIN command.stage stage " +
            "WHERE stage=:stageEntity", HostEntity.class);
    query.setParameter("stageEntity", stageEntity);
    try {
      return query.getResultList();
    } catch (NoResultException e) {
      return Collections.emptyList();
    }
  }

  /**
   * Refreshes entity state from database
   * @param hostEntity entity to refresh
   */
  @Transactional
  public void refresh(HostEntity hostEntity) {
    entityManagerProvider.get().refresh(hostEntity);
  }

  @Transactional
  public void create(HostEntity hostEntity) {
    entityManagerProvider.get().persist(hostEntity);
  }

  @Transactional
  public HostEntity merge(HostEntity hostEntity) {
    return entityManagerProvider.get().merge(hostEntity);
  }

  @Transactional
  public void remove(HostEntity hostEntity) {
    entityManagerProvider.get().remove(merge(hostEntity));
  }

  @Transactional
  public void removeByName(String hostName) {
    remove(findByName(hostName));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostRoleCommandDAO.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.Role;
import org.apache.ambari.server.actionmanager.HostRoleStatus;
import org.apache.ambari.server.orm.entities.HostEntity;
import org.apache.ambari.server.orm.entities.HostRoleCommandEntity;
import org.apache.ambari.server.orm.entities.StageEntity;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.persistence.EntityManager;
import javax.persistence.Query;
import javax.persistence.TypedQuery;

import java.util.Collection;
import java.util.List;

public class HostRoleCommandDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;
  @Inject
  DaoUtils daoUtils;
  private static Logger LOG = LoggerFactory.getLogger(HostRoleCommandDAO.class);

  @Transactional
  public HostRoleCommandEntity findByPK(long taskId) {
    return entityManagerProvider.get().find(HostRoleCommandEntity.class, taskId);
  }

  @Transactional
  public List<HostRoleCommandEntity> findByPKs(Collection<Long> taskIds) {
    TypedQuery<HostRoleCommandEntity> query = entityManagerProvider.get().createQuery(
        "SELECT task FROM HostRoleCommandEntity task WHERE task.taskId IN ?1 " +
            "ORDER BY task.taskId",
        HostRoleCommandEntity.class);
    return daoUtils.selectList(query, taskIds);
  }

  @Transactional
  public List<HostRoleCommandEntity> findByRequestIds(Collection<Long> requestIds) {
    TypedQuery<HostRoleCommandEntity> query = entityManagerProvider.get().createQuery(
        "SELECT task FROM HostRoleCommandEntity task " +
            "WHERE task.requestId IN ?1 " +
            "ORDER BY task.taskId", HostRoleCommandEntity.class);
    return daoUtils.selectList(query, requestIds);
  }

  @Transactional
  public List<HostRoleCommandEntity> findByRequestAndTaskIds(Collection<Long> requestIds, Collection<Long> taskIds) {
    TypedQuery<HostRoleCommandEntity> query = entityManagerProvider.get().createQuery(
        "SELECT DISTINCT task FROM HostRoleCommandEntity task " +
            "WHERE task.requestId IN ?1 OR task.taskId IN ?2 " +
            "ORDER BY task.taskId", HostRoleCommandEntity.class
    );
    return daoUtils.selectList(query, requestIds, taskIds);
  }

  @Transactional
  public List<HostRoleCommandEntity> findSortedCommandsByStageAndHost(StageEntity stageEntity, HostEntity hostEntity) {
    TypedQuery<HostRoleCommandEntity> query = entityManagerProvider.get().createQuery("SELECT hostRoleCommand " +
        "FROM HostRoleCommandEntity hostRoleCommand " +
        "WHERE hostRoleCommand.stage=?1 AND hostRoleCommand.host=?2 " +
        "ORDER BY hostRoleCommand.taskId", HostRoleCommandEntity.class);
    return daoUtils.selectList(query, stageEntity, hostEntity);
  }

  @Transactional
  public List<HostRoleCommandEntity> findByHostRole(String hostName, long requestId, long stageId, Role role) {
    TypedQuery<HostRoleCommandEntity> query = entityManagerProvider.get().createQuery("SELECT command " +
        "FROM HostRoleCommandEntity command " +
        "WHERE command.hostName=?1 AND command.requestId=?2 " +
        "AND command.stageId=?3 AND command.role=?4 " +
        "ORDER BY command.taskId", HostRoleCommandEntity.class);

    return daoUtils.selectList(query, hostName, requestId, stageId, role);
  }

  @Transactional
  public List<Long> getRequests() {
    String queryStr = "SELECT DISTINCT command.requestId " +
        "FROM HostRoleCommandEntity command ORDER BY command.requestId DESC";
    TypedQuery<Long> query = entityManagerProvider.get().createQuery(queryStr,
        Long.class);
    query.setMaxResults(20);
    return daoUtils.selectList(query);
  }

  @Transactional
  public int updateStatusByRequestId(long requestId, HostRoleStatus target, Collection<HostRoleStatus> sources) {
    Query query = entityManagerProvider.get().createQuery("UPDATE HostRoleCommandEntity command " +
        "SET command.status=?1 " +
        "WHERE command.requestId=?2 AND command.status IN ?3");

    return daoUtils.executeUpdate(query, target, requestId, sources);
  }

  @Transactional
  public List<HostRoleCommandEntity> findByRequest(long requestId) {
    TypedQuery<HostRoleCommandEntity> query = entityManagerProvider.get().createQuery("SELECT command " +
        "FROM HostRoleCommandEntity command " +
        "WHERE command.requestId=?1 ORDER BY command.taskId", HostRoleCommandEntity.class);
    return daoUtils.selectList(query, requestId);
  }

  @Transactional
  public void create(HostRoleCommandEntity stageEntity) {
    entityManagerProvider.get().persist(stageEntity);
  }

  @Transactional
  public HostRoleCommandEntity merge(HostRoleCommandEntity stageEntity) {
    HostRoleCommandEntity entity = entityManagerProvider.get().merge(stageEntity);
    return entity;

  }

  @Transactional
  public void remove(HostRoleCommandEntity stageEntity) {
    entityManagerProvider.get().remove(merge(stageEntity));
  }

  @Transactional
  public void removeByPK(int taskId) {
    remove(findByPK(taskId));
  }

  @Transactional
  public List<Long> getRequestsByTaskStatus(
      Collection<HostRoleStatus> statuses, boolean match) {
    String queryStr = "SELECT DISTINCT command.requestId "
        + " FROM HostRoleCommandEntity command WHERE "
        + " command.status";
    if (!match) {
      queryStr += " NOT";
    }
    queryStr += " IN ?1"
        + " ORDER BY command.requestId DESC";
    TypedQuery<Long> query = entityManagerProvider.get().createQuery(queryStr,
        Long.class);
    return daoUtils.selectList(query, statuses);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/HostStateDAO.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.HostStateEntity;

import javax.persistence.EntityManager;

public class HostStateDAO {
  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public HostStateEntity findByHostName(String hostName) {
    return entityManagerProvider.get().find(HostStateEntity.class, hostName);
  }

  @Transactional
  public void refresh(HostStateEntity hostStateEntity) {
    entityManagerProvider.get().refresh(hostStateEntity);
  }

  @Transactional
  public void create(HostStateEntity hostStateEntity) {
    entityManagerProvider.get().persist(hostStateEntity);
  }

  @Transactional
  public HostStateEntity merge(HostStateEntity hostStateEntity) {
    return entityManagerProvider.get().merge(hostStateEntity);
  }

  @Transactional
  public void remove(HostStateEntity hostStateEntity) {
    entityManagerProvider.get().remove(merge(hostStateEntity));
  }

  @Transactional
  public void removeByHostName(String hostName) {
    remove(findByHostName(hostName));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/KeyValueDAO.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.KeyValueEntity;

import javax.persistence.EntityManager;
import javax.persistence.TypedQuery;
import java.util.Collection;

public class KeyValueDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;
  @Inject
  DaoUtils daoUtils;

  @Transactional
  public KeyValueEntity findByKey(String key) {
    return entityManagerProvider.get().find(KeyValueEntity.class, key);
  }

  public Collection<KeyValueEntity> findAll() {
    TypedQuery<KeyValueEntity> query =
        entityManagerProvider.get().createQuery("SELECT keyValue FROM KeyValueEntity keyValue", KeyValueEntity.class);
    return daoUtils.selectList(query);
  }

  @Transactional
  public void refresh(KeyValueEntity keyValueEntity) {
    entityManagerProvider.get().refresh(keyValueEntity);
  }

  @Transactional
  public void create(KeyValueEntity keyValueEntity) {
    entityManagerProvider.get().persist(keyValueEntity);
  }

  @Transactional
  public KeyValueEntity merge(KeyValueEntity keyValueEntity) {
    return entityManagerProvider.get().merge(keyValueEntity);
  }

  @Transactional
  public void remove(KeyValueEntity keyValueEntity) {
    entityManagerProvider.get().remove(merge(keyValueEntity));
  }

  @Transactional
  public void removeByHostName(String key) {
    remove(findByKey(key));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/RoleDAO.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.RoleEntity;

import javax.persistence.EntityManager;

public class RoleDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public RoleEntity findByName(String roleName) {
    return entityManagerProvider.get().find(RoleEntity.class, roleName.toLowerCase());
  }

  @Transactional
  public void create(RoleEntity role) {
    role.setRoleName(role.getRoleName().toLowerCase());
    entityManagerProvider.get().persist(role);
  }

  @Transactional
  public RoleEntity merge(RoleEntity role) {
    return entityManagerProvider.get().merge(role);
  }

  @Transactional
  public void remove(RoleEntity role) {
    entityManagerProvider.get().remove(merge(role));
  }

  @Transactional
  public void removeByName(String roleName) {
    remove(findByName(roleName));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/RoleSuccessCriteriaDAO.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.RoleSuccessCriteriaEntity;
import org.apache.ambari.server.orm.entities.RoleSuccessCriteriaEntityPK;

import javax.persistence.EntityManager;

public class RoleSuccessCriteriaDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public RoleSuccessCriteriaEntity findByPK(RoleSuccessCriteriaEntityPK roleSuccessCriteriaEntityPK) {
    entityManagerProvider.get().clear();
    return entityManagerProvider.get().find(RoleSuccessCriteriaEntity.class, roleSuccessCriteriaEntityPK);
  }

  @Transactional
  public void create(RoleSuccessCriteriaEntity stageEntity) {
    entityManagerProvider.get().persist(stageEntity);
  }

  @Transactional
  public RoleSuccessCriteriaEntity merge(RoleSuccessCriteriaEntity stageEntity) {
    return entityManagerProvider.get().merge(stageEntity);
  }

  @Transactional
  public void remove(RoleSuccessCriteriaEntity stageEntity) {
    entityManagerProvider.get().remove(merge(stageEntity));
  }

  @Transactional
  public void removeByPK(RoleSuccessCriteriaEntityPK roleSuccessCriteriaEntityPK) {
    remove(findByPK(roleSuccessCriteriaEntityPK));
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ServiceComponentDesiredStateDAO.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.ServiceComponentDesiredStateEntityPK;
import org.apache.ambari.server.orm.entities.ServiceComponentDesiredStateEntity;

import javax.persistence.EntityManager;

public class ServiceComponentDesiredStateDAO {
  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public ServiceComponentDesiredStateEntity findByPK(ServiceComponentDesiredStateEntityPK primaryKey) {
    return entityManagerProvider.get().find(ServiceComponentDesiredStateEntity.class, primaryKey);
  }

  @Transactional
  public void refresh(ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity) {
    entityManagerProvider.get().refresh(serviceComponentDesiredStateEntity);
  }

  @Transactional
  public void create(ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity) {
    entityManagerProvider.get().persist(serviceComponentDesiredStateEntity);
  }

  @Transactional
  public ServiceComponentDesiredStateEntity merge(ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity) {
    return entityManagerProvider.get().merge(serviceComponentDesiredStateEntity);
  }

  @Transactional
  public void remove(ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity) {
    entityManagerProvider.get().remove(merge(serviceComponentDesiredStateEntity));
  }

  @Transactional
  public void removeByPK(ServiceComponentDesiredStateEntityPK primaryKey) {
    remove(findByPK(primaryKey));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ServiceConfigMappingDAO.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.ServiceConfigMappingEntity;

import javax.persistence.EntityManager;
import javax.persistence.TypedQuery;
import java.util.Collection;
import java.util.Collections;
import java.util.List;

public class ServiceConfigMappingDAO {
  @Inject
  Provider<EntityManager> entityManagerProvider;
  @Inject
  DaoUtils daoUtils;

  @Transactional
  public List<ServiceConfigMappingEntity> findByType(
      Collection<String> configTypes) {
    TypedQuery<ServiceConfigMappingEntity> query =
        entityManagerProvider.get().createQuery(
            "SELECT config FROM ServiceConfigMappingEntity config"
                + " WHERE config.configType IN ?1",
            ServiceConfigMappingEntity.class);
    return daoUtils.selectList(query, configTypes);
  }

  @Transactional
  public List<ServiceConfigMappingEntity> findByServiceAndType(
      long clusterId, String serviceName,
      Collection<String> configTypes) {
    if (configTypes.isEmpty()) {
      return Collections.emptyList();
    }
    TypedQuery<ServiceConfigMappingEntity> query =
        entityManagerProvider.get().createQuery(
            "SELECT config FROM ServiceConfigMappingEntity config"
                + " WHERE "
                + " config.clusterId = ?1"
                + " AND config.serviceName = ?2"
                + " AND config.configType IN ?3",
            ServiceConfigMappingEntity.class);
    return daoUtils.selectList(query, clusterId, serviceName, configTypes);
  }

  @Transactional
  public void refresh(
      ServiceConfigMappingEntity serviceConfigMappingEntity) {
    entityManagerProvider.get().refresh(serviceConfigMappingEntity);
  }

  @Transactional
  public ServiceConfigMappingEntity merge(
      ServiceConfigMappingEntity serviceConfigMappingEntity) {
    return entityManagerProvider.get().merge(
        serviceConfigMappingEntity);
  }

  @Transactional
  public void remove(
      ServiceConfigMappingEntity serviceConfigMappingEntity) {
    entityManagerProvider.get().remove(merge(serviceConfigMappingEntity));
  }

  @Transactional
  public void removeByType(Collection<String> configTypes) {
    for (ServiceConfigMappingEntity entity : findByType(configTypes)) {
      remove(entity);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/ServiceDesiredStateDAO.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.ServiceDesiredStateEntity;
import org.apache.ambari.server.orm.entities.ServiceDesiredStateEntityPK;

import javax.persistence.EntityManager;

public class ServiceDesiredStateDAO {
  @Inject
  Provider<EntityManager> entityManagerProvider;

  @Transactional
  public ServiceDesiredStateEntity findByPK(ServiceDesiredStateEntityPK primaryKey) {
    return entityManagerProvider.get().find(ServiceDesiredStateEntity.class, primaryKey);
  }

  @Transactional
  public void refresh(ServiceDesiredStateEntity serviceDesiredStateEntity) {
    entityManagerProvider.get().refresh(serviceDesiredStateEntity);
  }

  @Transactional
  public void create(ServiceDesiredStateEntity serviceDesiredStateEntity) {
    entityManagerProvider.get().persist(serviceDesiredStateEntity);
  }

  @Transactional
  public ServiceDesiredStateEntity merge(ServiceDesiredStateEntity serviceDesiredStateEntity) {
    return entityManagerProvider.get().merge(serviceDesiredStateEntity);
  }

  @Transactional
  public void remove(ServiceDesiredStateEntity serviceDesiredStateEntity) {
    entityManagerProvider.get().remove(merge(serviceDesiredStateEntity));
  }

  @Transactional
  public void removeByPK(ServiceDesiredStateEntityPK primaryKey) {
    remove(findByPK(primaryKey));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/StageDAO.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.actionmanager.HostRoleStatus;
import org.apache.ambari.server.orm.entities.StageEntity;
import org.apache.ambari.server.orm.entities.StageEntityPK;
import org.apache.ambari.server.utils.StageUtils;

import javax.persistence.EntityManager;
import javax.persistence.TypedQuery;
import java.util.Collection;
import java.util.List;

public class StageDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;
  @Inject
  DaoUtils daoUtils;

  @Transactional
  public StageEntity findByPK(StageEntityPK stageEntityPK) {
    return entityManagerProvider.get().find(StageEntity.class, stageEntityPK);
  }

  public long getLastRequestId() {
    TypedQuery<Long> query = entityManagerProvider.get().createQuery("SELECT max(stage.requestId) FROM StageEntity stage", Long.class);
    Long result = daoUtils.selectSingle(query);
    if (result != null) {
      return result;
    } else {
      return 0;
    }
  }

  @Transactional
  public StageEntity findByActionId(String actionId) {
    long[] ids = StageUtils.getRequestStage(actionId);
    StageEntityPK pk = new StageEntityPK();
    pk.setRequestId(ids[0]);
    pk.setStageId(ids[1]);
    return findByPK(pk);
  }

  @Transactional
  public List<StageEntity> findByRequestId(long requestId) {
    TypedQuery<StageEntity> query = entityManagerProvider.get().createQuery("SELECT stage " +
        "FROM StageEntity stage " +
        "WHERE stage.requestId=?1 " +
        "ORDER BY stage.stageId", StageEntity.class);
    return daoUtils.selectList(query, requestId);
  }

  @Transactional
  public List<StageEntity> findByCommandStatuses(Collection<HostRoleStatus> statuses) {
//    TypedQuery<StageEntity> query = entityManagerProvider.get().createQuery("SELECT stage " +
//        "FROM StageEntity stage JOIN stage.hostRoleCommands command " +
//        "WHERE command.status IN ?1 " +
//        "ORDER BY stage.requestId, stage.stageId", StageEntity.class);
    TypedQuery<StageEntity> query = entityManagerProvider.get().createQuery("SELECT stage " +
          "FROM StageEntity stage WHERE stage.stageId IN (SELECT hrce.stageId FROM " +
          "HostRoleCommandEntity hrce WHERE stage.requestId = hrce.requestId and hrce.status IN ?1 ) " +
          "ORDER BY stage.requestId, stage.stageId", StageEntity.class);
    return daoUtils.selectList(query, statuses);
  }

  @Transactional
  public void create(StageEntity stageEntity) {
    entityManagerProvider.get().persist(stageEntity);
  }

  @Transactional
  public StageEntity merge(StageEntity stageEntity) {
    return entityManagerProvider.get().merge(stageEntity);
  }

  @Transactional
  public void remove(StageEntity stageEntity) {
    entityManagerProvider.get().remove(merge(stageEntity));
  }

  @Transactional
  public void removeByPK(StageEntityPK stageEntityPK) {
    remove(findByPK(stageEntityPK));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/dao/UserDAO.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.dao;

import com.google.inject.Inject;
import com.google.inject.Provider;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.orm.entities.UserEntity;

import javax.persistence.EntityManager;
import javax.persistence.NoResultException;
import javax.persistence.TypedQuery;
import java.util.List;

public class UserDAO {

  @Inject
  Provider<EntityManager> entityManagerProvider;
  @Inject
  DaoUtils daoUtils;

  @Transactional
  public UserEntity findByPK(Integer userPK) {
    return entityManagerProvider.get().find(UserEntity.class, userPK);
  }

  @Transactional
  public List<UserEntity> findAll() {
    TypedQuery<UserEntity> query = entityManagerProvider.get().createQuery("SELECT user FROM UserEntity user", UserEntity.class);
    return daoUtils.selectList(query);
  }

  @Transactional
  public UserEntity findLocalUserByName(String userName) {
    TypedQuery<UserEntity> query = entityManagerProvider.get().createNamedQuery("localUserByName", UserEntity.class);
    query.setParameter("username", userName.toLowerCase());
    try {
      return query.getSingleResult();
    } catch (NoResultException e) {
      return null;
    }
  }

  @Transactional
  public UserEntity findLdapUserByName(String userName) {
    TypedQuery<UserEntity> query = entityManagerProvider.get().createNamedQuery("ldapUserByName", UserEntity.class);
    query.setParameter("username", userName.toLowerCase());
    try {
      return query.getSingleResult();
    } catch (NoResultException e) {
      return null;
    }
  }

  @Transactional
  public void create(UserEntity user) {
    user.setUserName(user.getUserName().toLowerCase());
    entityManagerProvider.get().persist(user);
  }

  @Transactional
  public UserEntity merge(UserEntity user) {
    user.setUserName(user.getUserName().toLowerCase());
    return entityManagerProvider.get().merge(user);
  }

  @Transactional
  public void remove(UserEntity user) {
    entityManagerProvider.get().remove(merge(user));
  }

  @Transactional
  public void removeByPK(Integer userPK) {
    remove(findByPK(userPK));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ClusterConfigEntity.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.*;
import java.util.Collection;

@IdClass(ClusterConfigEntityPK.class)
@Table(name = "clusterconfig", schema = "ambari", catalog = "")
@Entity
public class ClusterConfigEntity {
  private Long clusterId;
  private String configJson;
  private String type;
  private String tag;
  private long timestamp;
  private Collection<HostComponentConfigMappingEntity> hostComponentConfigMappingEntities;
  private Collection<ServiceConfigMappingEntity> serviceConfigMappingEntities;
  private Collection<HostComponentDesiredConfigMappingEntity> hostComponentDesiredConfigMappingEntities;
  private Collection<ComponentConfigMappingEntity> componentConfigMappingEntities;
  
  @Column(name = "cluster_id", nullable = false, insertable = false, updatable = false, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }
  
  @Column(name = "type_name")
  @Id
  public String getType() {
    return type;
  }
  
  public void setType(String typeName) {
    type = typeName;
  }
  
  @Column(name = "version_tag")
  @Id
  public String getTag() {
    return tag;
  }
  
  public void setTag(String versionTag) {
    tag = versionTag;
  }

  @Column(name = "config_data", nullable = false, insertable = true, updatable = false, length=32000)
  @Basic(fetch=FetchType.LAZY)
  public String getData() {
    return configJson;
  }

  public void setData(String data) {
    this.configJson = data;
  }
  
  @Column(name = "create_timestamp", nullable=false, insertable=true, updatable=false)
  public long getTimestamp() {
    return timestamp;
  }
  
  public void setTimestamp(long stamp) {
    timestamp = stamp;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ClusterConfigEntity that = (ClusterConfigEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (configJson != null ? !configJson.equals(that.configJson) : that.configJson != null)
      return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (configJson != null ? configJson.hashCode() : 0);
    return result;
  }

  private ClusterEntity clusterEntity;

  @ManyToOne
  @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false)
  public ClusterEntity getClusterEntity() {
    return clusterEntity;
  }

  public void setClusterEntity(ClusterEntity clusterEntity) {
    this.clusterEntity = clusterEntity;
  }

  @OneToMany(mappedBy = "clusterConfigEntity")
  public Collection<HostComponentConfigMappingEntity> getHostComponentConfigMappingEntities() {
    return hostComponentConfigMappingEntities;
  }

  public void setHostComponentConfigMappingEntities(Collection<HostComponentConfigMappingEntity> hostComponentConfigMappingEntities) {
    this.hostComponentConfigMappingEntities = hostComponentConfigMappingEntities;
  }

  @OneToMany(mappedBy = "clusterConfigEntity")
  public Collection<ServiceConfigMappingEntity> getServiceConfigMappingEntities() {
    return serviceConfigMappingEntities;
  }

  public void setServiceConfigMappingEntities(Collection<ServiceConfigMappingEntity> serviceConfigMappingEntities) {
    this.serviceConfigMappingEntities = serviceConfigMappingEntities;
  }

  @OneToMany(mappedBy = "clusterConfigEntity")
  public Collection<HostComponentDesiredConfigMappingEntity> getHostComponentDesiredConfigMappingEntities() {
    return hostComponentDesiredConfigMappingEntities;
  }

  public void setHostComponentDesiredConfigMappingEntities(Collection<HostComponentDesiredConfigMappingEntity> hostComponentDesiredConfigMappingEntities) {
    this.hostComponentDesiredConfigMappingEntities = hostComponentDesiredConfigMappingEntities;
  }

  @OneToMany(mappedBy = "clusterConfigEntity")
  public Collection<ComponentConfigMappingEntity> getComponentConfigMappingEntities() {
    return componentConfigMappingEntities;
  }

  public void setComponentConfigMappingEntities(Collection<ComponentConfigMappingEntity> componentConfigMappingEntities) {
    this.componentConfigMappingEntities = componentConfigMappingEntities;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ClusterConfigEntityPK.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class ClusterConfigEntityPK implements Serializable {
  private Long clusterId;

  @Id
  @Column(name = "cluster_id", nullable = false, insertable = true, updatable = true, length = 10)
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String type;
  @Id
  @Column(name = "type_name", nullable = false, insertable = true, updatable = false)
  public String getType() {
    return type;
  }

  public void setType(String typeName) {
    type = typeName;
  }

  private String tag;
  @Id
  @Column(name="version_tag", nullable = false, insertable = true, updatable = false)
  public String getTag() {
    return tag;
  }

  public void setTag(String configTag) {
    tag = configTag;
  }


  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ClusterConfigEntityPK that = (ClusterConfigEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (type != null ? !type.equals(that.type) : that.type != null) return false;
    if (tag != null ? !tag.equals(that.tag) : that.tag != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (type != null ? type.hashCode() : 0);
    result = 31 * result + (tag != null ? tag.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ClusterEntity.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.*;
import java.util.Collection;

@javax.persistence.Table(name = "clusters", schema = "ambari", catalog = "")
@NamedQueries({
    @NamedQuery(name = "clusterByName", query =
        "SELECT cluster " +
            "FROM ClusterEntity cluster " +
            "WHERE cluster.clusterName=:clusterName"),
    @NamedQuery(name = "allClusters", query =
        "SELECT clusters " +
            "FROM ClusterEntity clusters")
})
@Entity
@SequenceGenerator(name = "ambari.clusters_cluster_id_seq", allocationSize = 1)
public class ClusterEntity {
  private Long clusterId;

  @javax.persistence.Column(name = "cluster_id", nullable = false, insertable = true, updatable = true)
  @Id
  @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "ambari.clusters_cluster_id_seq")
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String clusterName;

  @javax.persistence.Column(name = "cluster_name", nullable = false, insertable = true,
          updatable = true, unique = true, length = 100)
  @Basic
  public String getClusterName() {
    return clusterName;
  }

  public void setClusterName(String clusterName) {
    this.clusterName = clusterName;
  }

  private String desiredClusterState = "";

  @javax.persistence.Column(name = "desired_cluster_state", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getDesiredClusterState() {
    return desiredClusterState;
  }

  public void setDesiredClusterState(String desiredClusterState) {
    this.desiredClusterState = desiredClusterState;
  }

  private String clusterInfo = "";

  @javax.persistence.Column(name = "cluster_info", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getClusterInfo() {
    return clusterInfo;
  }

  public void setClusterInfo(String clusterInfo) {
    this.clusterInfo = clusterInfo;
  }

  private String desiredStackVersion = "";

  @javax.persistence.Column(name = "desired_stack_version", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getDesiredStackVersion() {
    return desiredStackVersion;
  }

  public void setDesiredStackVersion(String desiredStackVersion) {
    this.desiredStackVersion = desiredStackVersion;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ClusterEntity that = (ClusterEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (clusterInfo != null ? !clusterInfo.equals(that.clusterInfo) : that.clusterInfo != null) return false;
    if (clusterName != null ? !clusterName.equals(that.clusterName) : that.clusterName != null) return false;
    if (desiredClusterState != null ? !desiredClusterState.equals(that.desiredClusterState) : that.desiredClusterState != null)
      return false;
    if (desiredStackVersion != null ? !desiredStackVersion.equals(that.desiredStackVersion) : that.desiredStackVersion != null)
      return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (clusterName != null ? clusterName.hashCode() : 0);
    result = 31 * result + (desiredClusterState != null ? desiredClusterState.hashCode() : 0);
    result = 31 * result + (clusterInfo != null ? clusterInfo.hashCode() : 0);
    result = 31 * result + (desiredStackVersion != null ? desiredStackVersion.hashCode() : 0);
    return result;
  }

  private Collection<ClusterServiceEntity> clusterServiceEntities;

  @OneToMany(mappedBy = "clusterEntity")
  public Collection<ClusterServiceEntity> getClusterServiceEntities() {
    return clusterServiceEntities;
  }

  public void setClusterServiceEntities(Collection<ClusterServiceEntity> clusterServiceEntities) {
    this.clusterServiceEntities = clusterServiceEntities;
  }

  private ClusterStateEntity clusterStateEntity;

  @OneToOne(mappedBy = "clusterEntity")
  public ClusterStateEntity getClusterStateEntity() {
    return clusterStateEntity;
  }

  public void setClusterStateEntity(ClusterStateEntity clusterStateEntity) {
    this.clusterStateEntity = clusterStateEntity;
  }

  private Collection<HostEntity> hostEntities;

  @ManyToMany(mappedBy = "clusterEntities")
  public Collection<HostEntity> getHostEntities() {
    return hostEntities;
  }

  public void setHostEntities(Collection<HostEntity> hostEntities) {
    this.hostEntities = hostEntities;
  }

  private Collection<StageEntity> stages;

  @OneToMany(mappedBy = "cluster")
  public Collection<StageEntity> getStages() {
    return stages;
  }

  public void setStages(Collection<StageEntity> stages) {
    this.stages = stages;
  }
  
  private Collection<ClusterConfigEntity> configEntities;
  @OneToMany(mappedBy = "clusterEntity")
  public Collection<ClusterConfigEntity> getClusterConfigEntities() {
    return configEntities;
  }
  
  public void setClusterConfigEntities(Collection<ClusterConfigEntity> entities) {
    configEntities = entities;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ClusterServiceEntity.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.*;
import java.util.Collection;

@javax.persistence.IdClass(ClusterServiceEntityPK.class)
@javax.persistence.Table(name = "clusterservices", schema = "ambari", catalog = "")
@NamedQueries({
        @NamedQuery(name = "clusterServiceByClusterAndServiceNames", query =
                "SELECT clusterService " +
                        "FROM ClusterServiceEntity clusterService " +
                        "JOIN clusterService.clusterEntity cluster " +
                        "WHERE clusterService.serviceName=:serviceName AND cluster.clusterName=:clusterName")
})
@Entity
public class ClusterServiceEntity {
  private Long clusterId;

  @javax.persistence.Column(name = "cluster_id", nullable = false, insertable = false, updatable = false, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @javax.persistence.Column(name = "service_name", nullable = false, insertable = true, updatable = true)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  private Integer serviceEnabled = 0;

  @javax.persistence.Column(name = "service_enabled", nullable = false, insertable = true, updatable = true, length = 10)
  @Basic
  public int getServiceEnabled() {
    return serviceEnabled;
  }

  public void setServiceEnabled(int serviceEnabled) {
    this.serviceEnabled = serviceEnabled;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ClusterServiceEntity that = (ClusterServiceEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (serviceEnabled != null ? !serviceEnabled.equals(that.serviceEnabled) : that.serviceEnabled != null)
      return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + serviceEnabled;
    return result;
  }

  private ClusterEntity clusterEntity;

  @ManyToOne
  @javax.persistence.JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false)
  public ClusterEntity getClusterEntity() {
    return clusterEntity;
  }

  public void setClusterEntity(ClusterEntity clusterEntity) {
    this.clusterEntity = clusterEntity;
  }

  private ServiceDesiredStateEntity serviceDesiredStateEntity;

  @OneToOne(mappedBy = "clusterServiceEntity")
  public ServiceDesiredStateEntity getServiceDesiredStateEntity() {
    return serviceDesiredStateEntity;
  }

  public void setServiceDesiredStateEntity(ServiceDesiredStateEntity serviceDesiredStateEntity) {
    this.serviceDesiredStateEntity = serviceDesiredStateEntity;
  }

  private Collection<ServiceComponentDesiredStateEntity> serviceComponentDesiredStateEntities;

  @OneToMany(mappedBy = "clusterServiceEntity")
  public Collection<ServiceComponentDesiredStateEntity> getServiceComponentDesiredStateEntities() {
    return serviceComponentDesiredStateEntities;
  }

  public void setServiceComponentDesiredStateEntities(Collection<ServiceComponentDesiredStateEntity> serviceComponentDesiredStateEntities) {
    this.serviceComponentDesiredStateEntities = serviceComponentDesiredStateEntities;
  }

  private Collection<ServiceConfigMappingEntity> serviceConfigMappings;
  @OneToMany(mappedBy = "serviceEntity", cascade = CascadeType.ALL)
  public Collection<ServiceConfigMappingEntity> getServiceConfigMappings() {
    return serviceConfigMappings;
  }

  public void setServiceConfigMappings(Collection<ServiceConfigMappingEntity> entities) {
    serviceConfigMappings = entities;
  }



}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ClusterServiceEntityPK.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class ClusterServiceEntityPK implements Serializable {
  private Long clusterId;

  @Id
  @Column(name = "cluster_id", nullable = false, insertable = true, updatable = true, length = 10)
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @Id
  @Column(name = "service_name", nullable = false, insertable = true, updatable = true)
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ClusterServiceEntityPK that = (ClusterServiceEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ClusterStateEntity.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.Basic;
import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.OneToOne;

@javax.persistence.Table(name = "clusterstate", schema = "ambari", catalog = "")
@Entity
public class ClusterStateEntity {
  private Long clusterId;

  @javax.persistence.Column(name = "cluster_id", nullable = false, insertable = false, updatable = false, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String currentClusterState = "";

  @javax.persistence.Column(name = "current_cluster_state", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getCurrentClusterState() {
    return currentClusterState;
  }

  public void setCurrentClusterState(String currentClusterState) {
    this.currentClusterState = currentClusterState;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ClusterStateEntity that = (ClusterStateEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (currentClusterState != null ? !currentClusterState.equals(that.currentClusterState) : that.currentClusterState != null)
      return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (currentClusterState != null ? currentClusterState.hashCode() : 0);
    return result;
  }

  private ClusterEntity clusterEntity;

  @OneToOne
  @javax.persistence.JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false)
  public ClusterEntity getClusterEntity() {
    return clusterEntity;
  }

  public void setClusterEntity(ClusterEntity clusterEntity) {
    this.clusterEntity = clusterEntity;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ComponentConfigMappingEntity.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.IdClass;
import javax.persistence.JoinColumn;
import javax.persistence.JoinColumns;
import javax.persistence.ManyToOne;
import javax.persistence.Table;

@IdClass(ComponentConfigMappingEntityPK.class)
@Entity
@Table(name = "componentconfigmapping", schema = "ambari", catalog = "")
public class ComponentConfigMappingEntity {
  private Long clusterId;
  private String serviceName;
  private String componentName;
  private String configType;
  private String configTag;
  private Long timestamp;
  private ServiceComponentDesiredStateEntity componentEntity;
  private ClusterConfigEntity clusterConfigEntity;

  @Column(name = "cluster_id", insertable = false, updatable = false, nullable = false)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long id) {
    clusterId = id;
  }

  @Column(name = "service_name", insertable = false, updatable = false, nullable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String name) {
    serviceName = name;
  }

  @Column(name = "component_name", insertable = false, updatable = false, nullable = false)
  @Id
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String name) {
    componentName = name;
  }

  @Column(name = "config_type", insertable = true, updatable = false, nullable = false)
  @Id
  public String getConfigType() {
    return configType;
  }

  public void setConfigType(String type) {
    configType = type;
  }

  @Column(name = "config_tag", nullable = false, insertable = true, updatable = true)
  public String getVersionTag() {
    return configTag;
  }

  public void setVersionTag(String tag) {
    configTag = tag;
  }

  @Column(name="timestamp", nullable = false, insertable = true, updatable = true)
  public Long getTimestamp() {
    return timestamp;
  }

  public void setTimestamp(Long stamp) {
    timestamp = stamp;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ComponentConfigMappingEntity that = (ComponentConfigMappingEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (configType != null ? !configType.equals(that.configType) : that.configType != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    result = 31 * result + (configType != null ? configType.hashCode() : 0);
    return result;
  }


  @ManyToOne
  @JoinColumns({
    @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false),
    @JoinColumn(name = "service_name", referencedColumnName = "service_name", nullable = false),
    @JoinColumn(name = "component_name", referencedColumnName = "component_name", nullable = false)
  })
  public ServiceComponentDesiredStateEntity getServiceComponentDesiredStateEntity() {
    return componentEntity;
  }

  public void setServiceComponentDesiredStateEntity(ServiceComponentDesiredStateEntity entity) {
    componentEntity = entity;
  }

  @ManyToOne
  @JoinColumns({
      @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false, insertable = false, updatable = false),
      @JoinColumn(name = "config_type", referencedColumnName = "type_name", nullable = false, insertable = false, updatable = false),
      @JoinColumn(name = "config_tag", referencedColumnName = "version_tag", nullable = false, insertable = false, updatable = false)
  })
  public ClusterConfigEntity getClusterConfigEntity() {
    return clusterConfigEntity;
  }

  public void setClusterConfigEntity(ClusterConfigEntity clusterConfigEntity) {
    this.clusterConfigEntity = clusterConfigEntity;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ComponentConfigMappingEntityPK.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import java.io.Serializable;

import javax.persistence.Column;
import javax.persistence.Id;

/**
 * @author ncole
 *
 */
@SuppressWarnings("serial")
public class ComponentConfigMappingEntityPK implements Serializable {
  private Long clusterId;
  private String serviceName;
  private String componentName;
  private String configType;

  @Id
  @Column(name = "cluster_id", insertable = true, updatable = true, nullable = false, length = 10)
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  @Id
  @Column(name = "service_name", insertable = true, updatable = true, nullable = false)
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  @Column(name = "component_name", insertable = true, updatable = true, nullable = false)
  @Id
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String name) {
    componentName = name;
  }

  @Column(name = "config_type", insertable = true, updatable = false, nullable = false)
  @Id
  public String getConfigType() {
    return configType;
  }

  public void setConfigType(String type) {
    configType = type;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ComponentConfigMappingEntityPK that = (ComponentConfigMappingEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    return result;
  }





}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ExecutionCommandEntity.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.*;

@Table(name = "execution_command", schema = "ambari", catalog = "")
@Entity
public class ExecutionCommandEntity {
  private Long taskId;

  @Column(name = "task_id", insertable = false, updatable = false, nullable = false)
  @Id
  public Long getTaskId() {
    return taskId;
  }

  public void setTaskId(Long taskId) {
    this.taskId = taskId;
  }

  private byte[] command;

  @Column(name = "command")
  @Lob
  @Basic
  public byte[] getCommand() {
    return command;
  }

  public void setCommand(byte[] command) {
    this.command = command;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ExecutionCommandEntity that = (ExecutionCommandEntity) o;

    if (command != null ? !command.equals(that.command) : that.command != null) return false;
    if (taskId != null ? !taskId.equals(that.taskId) : that.taskId != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = taskId != null ? taskId.hashCode() : 0;
    result = 31 * result + (command != null ? command.hashCode() : 0);
    return result;
  }

  private HostRoleCommandEntity hostRoleCommand;

  @OneToOne
  @JoinColumn(name = "task_id", referencedColumnName = "task_id", nullable = false)
  public HostRoleCommandEntity getHostRoleCommand() {
    return hostRoleCommand;
  }

  public void setHostRoleCommand(HostRoleCommandEntity hostRoleCommandByTaskId) {
    this.hostRoleCommand = hostRoleCommandByTaskId;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentConfigMappingEntity.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.IdClass;
import javax.persistence.JoinColumn;
import javax.persistence.JoinColumns;
import javax.persistence.ManyToOne;
import javax.persistence.Table;

@IdClass(HostComponentConfigMappingEntityPK.class)
@Table(name = "hostcomponentconfigmapping", schema = "ambari", catalog = "")
@Entity
public class HostComponentConfigMappingEntity {
  private Long clusterId;
  private String serviceName;
  private String componentName;
  private String hostName;
  private String configType;
  private String configTag;
  private Long timestamp;
  private HostComponentStateEntity hostComponentStateEntity;
  private ClusterConfigEntity clusterConfigEntity;

  @Column(name = "cluster_id", insertable = false, updatable = false, nullable = false)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long id) {
    clusterId = id;
  }

  @Column(name = "service_name", insertable = false, updatable = false, nullable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String name) {
    serviceName = name;
  }

  @Column(name = "component_name", insertable = false, updatable = false, nullable = false)
  @Id
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String name) {
    componentName = name;
  }

  @Column(name = "host_name", insertable = false, updatable = false, nullable = false)
  @Id
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String name) {
    hostName = name;
  }

  @Column(name = "config_type", insertable = true, updatable = false, nullable = false)
  @Id
  public String getConfigType() {
    return configType;
  }

  public void setConfigType(String type) {
    configType = type;
  }

  @Column(name = "config_tag", nullable = false, insertable = true, updatable = true)
  public String getVersionTag() {
    return configTag;
  }

  public void setVersionTag(String tag) {
    configTag = tag;
  }

  @Column(name="timestamp", nullable = false, insertable = true, updatable = true)
  public Long getTimestamp() {
    return timestamp;
  }

  public void setTimestamp(Long stamp) {
    timestamp = stamp;
  }

  @ManyToOne
  @JoinColumns({
    @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false),
    @JoinColumn(name = "service_name", referencedColumnName = "service_name", nullable = false),
    @JoinColumn(name = "component_name", referencedColumnName = "component_name", nullable = false),
    @JoinColumn(name = "host_name", referencedColumnName = "host_name", nullable = false) })
  public HostComponentStateEntity getHostComponentStateEntity() {
    return hostComponentStateEntity;
  }

  public void setHostComponentStateEntity(HostComponentStateEntity entity) {
    hostComponentStateEntity = entity;
  }

  @ManyToOne
  @JoinColumns({
      @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false, insertable = false, updatable = false),
      @JoinColumn(name = "config_type", referencedColumnName = "type_name", nullable = false, insertable = false, updatable = false),
      @JoinColumn(name = "config_tag", referencedColumnName = "version_tag", nullable = false, insertable = false, updatable = false)
  })
  public ClusterConfigEntity getClusterConfigEntity() {
    return clusterConfigEntity;
  }

  public void setClusterConfigEntity(ClusterConfigEntity clusterConfigEntity) {
    this.clusterConfigEntity = clusterConfigEntity;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostComponentConfigMappingEntity that = (HostComponentConfigMappingEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;
    if (configType != null ? !configType.equals(that.configType) : that.configType != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (configType != null ? configType.hashCode() : 0);
    return result;
  }


}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentConfigMappingEntityPK.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

public class HostComponentConfigMappingEntityPK implements Serializable {
  private Long clusterId;
  private String serviceName;
  private String componentName;
  private String hostName;
  private String configType;

  @Id
  @Column(name = "cluster_id", insertable = true, updatable = true, nullable = false, length = 10)
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  @Id
  @Column(name = "service_name", insertable = true, updatable = true, nullable = false)
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  @Column(name = "component_name", insertable = true, updatable = true, nullable = false)
  @Id
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String name) {
    componentName = name;
  }

  @Column(name = "host_name", insertable = true, updatable = true, nullable = false)
  @Id
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String name) {
    hostName = name;
  }

  @Column(name = "config_type", insertable = true, updatable = false, nullable = false)
  @Id
  public String getConfigType() {
    return configType;
  }

  public void setConfigType(String configType) {
    this.configType = configType;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostComponentConfigMappingEntityPK that = (HostComponentConfigMappingEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;
    if (configType != null ? !configType.equals(that.configType) : that.configType != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (configType != null ? configType.hashCode() : 0);
    return result;
  }


}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentDesiredConfigMappingEntity.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.IdClass;
import javax.persistence.JoinColumn;
import javax.persistence.JoinColumns;
import javax.persistence.ManyToOne;
import javax.persistence.Table;

@IdClass(HostComponentDesiredConfigMappingEntityPK.class)
@Table(name = "hostcomponentdesiredconfigmapping", schema = "ambari", catalog = "")
@Entity
public class HostComponentDesiredConfigMappingEntity {
  private Long clusterId;
  private String serviceName;
  private String componentName;
  private String hostName;
  private String configType;
  private String configTag;
  private Long timestamp;
  private HostComponentDesiredStateEntity hostComponentEntity;
  private ClusterConfigEntity clusterConfigEntity;

  @Column(name = "cluster_id", insertable = false, updatable = false, nullable = false)
  @Id
  public Long getClusterId() {
    return clusterId;
  }
  
  public void setClusterId(Long id) {
    clusterId = id;
  }
  
  @Column(name = "service_name", insertable = false, updatable = false, nullable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }
  
  public void setServiceName(String name) {
    serviceName = name;
  }
  
  @Column(name = "component_name", insertable = false, updatable = false, nullable = false)
  @Id
  public String getComponentName() {
    return componentName;
  }
  
  public void setComponentName(String name) {
    componentName = name;
  }
  
  @Column(name = "host_name", insertable = false, updatable = false, nullable = false)
  @Id
  public String getHostName() {
    return hostName;
  }
  
  public void setHostName(String name) {
    hostName = name;
  }

  @Column(name = "config_type", insertable = true, updatable = false, nullable = false)
  @Id
  public String getConfigType() {
    return configType;
  }
  
  public void setConfigType(String type) {
    configType = type;
  }
  
  @Column(name = "config_tag", nullable = false, insertable = true, updatable = true)
  public String getVersionTag() {
    return configTag;
  }
  
  public void setVersionTag(String tag) {
    configTag = tag;
  }
  
  @Column(name="timestamp", nullable = false, insertable = true, updatable = true)
  public Long getTimestamp() {
    return timestamp;
  }
  
  public void setTimestamp(Long stamp) {
    timestamp = stamp;
  }
  
  @ManyToOne
  @JoinColumns({
    @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false),
    @JoinColumn(name = "service_name", referencedColumnName = "service_name", nullable = false),
    @JoinColumn(name = "component_name", referencedColumnName = "component_name", nullable = false),
    @JoinColumn(name = "host_name", referencedColumnName = "host_name", nullable = false) })
  public HostComponentDesiredStateEntity getHostComponentDesiredStateEntity() {
    return hostComponentEntity;
  }
  
  public void setHostComponentDesiredStateEntity(HostComponentDesiredStateEntity entity) {
    hostComponentEntity = entity;
  }

  @ManyToOne
  @JoinColumns({
      @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false, insertable = false, updatable = false),
      @JoinColumn(name = "config_type", referencedColumnName = "type_name", nullable = false, insertable = false, updatable = false),
      @JoinColumn(name = "config_tag", referencedColumnName = "version_tag", nullable = false, insertable = false, updatable = false)
  })
  public ClusterConfigEntity getClusterConfigEntity() {
    return clusterConfigEntity;
  }

  public void setClusterConfigEntity(ClusterConfigEntity clusterConfigEntity) {
    this.clusterConfigEntity = clusterConfigEntity;
  }


  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostComponentDesiredConfigMappingEntity that = (HostComponentDesiredConfigMappingEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;
    if (configType != null ? !configType.equals(that.configType) : that.configType != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (configType != null ? configType.hashCode() : 0);
    return result;
  }  
  
  
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentDesiredConfigMappingEntityPK.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

public class HostComponentDesiredConfigMappingEntityPK implements Serializable {
  private Long clusterId;
  private String serviceName;
  private String componentName;
  private String hostName;
  private String configType;

  @Id
  @Column(name = "cluster_id", insertable = true, updatable = true, nullable = false, length = 10)
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  @Id
  @Column(name = "service_name", insertable = true, updatable = true, nullable = false)
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  @Column(name = "component_name", insertable = true, updatable = true, nullable = false)
  @Id
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String name) {
    componentName = name;
  }

  @Column(name = "host_name", insertable = true, updatable = true, nullable = false)
  @Id
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String name) {
    hostName = name;
  }

  @Column(name = "config_type", insertable = true, updatable = false, nullable = false)
  @Id
  public String getConfigType() {
    return configType;
  }

  public void setConfigType(String configType) {
    this.configType = configType;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostComponentDesiredConfigMappingEntityPK that = (HostComponentDesiredConfigMappingEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;
    if (configType != null ? !configType.equals(that.configType) : that.configType != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (configType != null ? configType.hashCode() : 0);
    return result;
  }


}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentDesiredStateEntity.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import java.util.Collection;

import javax.persistence.*;

import org.apache.ambari.server.state.State;

@javax.persistence.IdClass(HostComponentDesiredStateEntityPK.class)
@javax.persistence.Table(name = "hostcomponentdesiredstate", schema = "ambari", catalog = "")
@Entity
public class HostComponentDesiredStateEntity {
  private Long clusterId;

  @javax.persistence.Column(name = "cluster_id", nullable = false, insertable = false, updatable = false, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @javax.persistence.Column(name = "service_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  private String hostName = "";

  @javax.persistence.Column(name = "host_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  private String componentName = "";

  @javax.persistence.Column(name = "component_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  private State desiredState = State.INIT;

  @javax.persistence.Column(name = "desired_state", nullable = false, insertable = true, updatable = true)
  @Enumerated(value = EnumType.STRING)
  @Basic
  public State getDesiredState() {
    return desiredState;
  }

  public void setDesiredState(State desiredState) {
    this.desiredState = desiredState;
  }

  private String desiredStackVersion = "";

  @javax.persistence.Column(name = "desired_stack_version", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getDesiredStackVersion() {
    return desiredStackVersion;
  }

  public void setDesiredStackVersion(String desiredStackVersion) {
    this.desiredStackVersion = desiredStackVersion;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostComponentDesiredStateEntity that = (HostComponentDesiredStateEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (desiredStackVersion != null ? !desiredStackVersion.equals(that.desiredStackVersion) : that.desiredStackVersion != null)
      return false;
    if (desiredState != null ? !desiredState.equals(that.desiredState) : that.desiredState != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    result = 31 * result + (desiredState != null ? desiredState.hashCode() : 0);
    result = 31 * result + (desiredStackVersion != null ? desiredStackVersion.hashCode() : 0);
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    return result;
  }

  private ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity;

  @ManyToOne
  @JoinColumns({
      @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false),
      @JoinColumn(name = "service_name", referencedColumnName = "service_name", nullable = false),
      @JoinColumn(name = "component_name", referencedColumnName = "component_name", nullable = false)})
  public ServiceComponentDesiredStateEntity getServiceComponentDesiredStateEntity() {
    return serviceComponentDesiredStateEntity;
  }

  public void setServiceComponentDesiredStateEntity(ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity) {
    this.serviceComponentDesiredStateEntity = serviceComponentDesiredStateEntity;
  }

  private HostEntity hostEntity;

  @ManyToOne
  @javax.persistence.JoinColumn(name = "host_name", referencedColumnName = "host_name", nullable = false)
  public HostEntity getHostEntity() {
    return hostEntity;
  }

  public void setHostEntity(HostEntity hostEntity) {
    this.hostEntity = hostEntity;
  }

  private Collection<HostComponentDesiredConfigMappingEntity> desiredConfigMappingEntities;
  @OneToMany(mappedBy = "hostComponentDesiredStateEntity", cascade = CascadeType.ALL)
  public Collection<HostComponentDesiredConfigMappingEntity> getHostComponentDesiredConfigMappingEntities() {
    return desiredConfigMappingEntities;
  }

  public void setHostComponentDesiredConfigMappingEntities(Collection<HostComponentDesiredConfigMappingEntity> entities) {
    desiredConfigMappingEntities = entities;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentDesiredStateEntityPK.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class HostComponentDesiredStateEntityPK implements Serializable {
  private Long clusterId;

  @Id
  @Column(name = "cluster_id", nullable = false, insertable = true, updatable = true, length = 10)
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @Id
  @Column(name = "service_name", nullable = false, insertable = true, updatable = true)
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  private String hostName;

  @Id
  @Column(name = "host_name", nullable = false, insertable = true, updatable = true)
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  private String componentName;

  @Id
  @Column(name = "component_name", nullable = false, insertable = true, updatable = true)
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostComponentDesiredStateEntityPK that = (HostComponentDesiredStateEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentStateEntity.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import java.util.Collection;

import org.apache.ambari.server.state.State;

import javax.persistence.*;

@javax.persistence.IdClass(HostComponentStateEntityPK.class)
@javax.persistence.Table(name = "hostcomponentstate", schema = "ambari", catalog = "")
@Entity
public class HostComponentStateEntity {
  private Long clusterId;

  @javax.persistence.Column(name = "cluster_id", nullable = false, insertable = false, updatable = false, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @javax.persistence.Column(name = "service_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  private String hostName = "";

  @javax.persistence.Column(name = "host_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  private String componentName;

  @javax.persistence.Column(name = "component_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  private State currentState = State.INIT;

  @javax.persistence.Column(name = "current_state", nullable = false, insertable = true, updatable = true)
  @Enumerated(value = EnumType.STRING)
  public State getCurrentState() {
    return currentState;
  }

  public void setCurrentState(State currentState) {
    this.currentState = currentState;
  }

  private String currentStackVersion;

  @javax.persistence.Column(name = "current_stack_version", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getCurrentStackVersion() {
    return currentStackVersion;
  }

  public void setCurrentStackVersion(String currentStackVersion) {
    this.currentStackVersion = currentStackVersion;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostComponentStateEntity that = (HostComponentStateEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (currentStackVersion != null ? !currentStackVersion.equals(that.currentStackVersion) : that.currentStackVersion != null)
      return false;
    if (currentState != null ? !currentState.equals(that.currentState) : that.currentState != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    result = 31 * result + (currentState != null ? currentState.hashCode() : 0);
    result = 31 * result + (currentStackVersion != null ? currentStackVersion.hashCode() : 0);
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    return result;
  }

  private ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity;

  @ManyToOne
  @JoinColumns({
      @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false),
      @JoinColumn(name = "service_name", referencedColumnName = "service_name", nullable = false),
      @JoinColumn(name = "component_name", referencedColumnName = "component_name", nullable = false)})
  public ServiceComponentDesiredStateEntity getServiceComponentDesiredStateEntity() {
    return serviceComponentDesiredStateEntity;
  }

  public void setServiceComponentDesiredStateEntity(ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity) {
    this.serviceComponentDesiredStateEntity = serviceComponentDesiredStateEntity;
  }

  private HostEntity hostEntity;

  @ManyToOne
  @JoinColumn(name = "host_name", referencedColumnName = "host_name", nullable = false)
  public HostEntity getHostEntity() {
    return hostEntity;
  }

  public void setHostEntity(HostEntity hostEntity) {
    this.hostEntity = hostEntity;
  }

  private Collection<HostComponentConfigMappingEntity> configMappingEntities;
  @OneToMany(mappedBy = "hostComponentStateEntity", cascade = CascadeType.ALL)
  public Collection<HostComponentConfigMappingEntity> getHostComponentConfigMappingEntities() {
    return configMappingEntities;
  }

  public void setHostComponentConfigMappingEntities(Collection<HostComponentConfigMappingEntity> entities) {
    configMappingEntities = entities;
  }



}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostComponentStateEntityPK.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class HostComponentStateEntityPK implements Serializable {
  private Long clusterId;

  @Id
  @Column(name = "cluster_id", nullable = false, insertable = true, updatable = true, length = 10)
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @Id
  @Column(name = "service_name", nullable = false, insertable = true, updatable = true)
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  private String hostName;

  @Id
  @Column(name = "host_name", nullable = false, insertable = true, updatable = true)
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  private String componentName;

  @Id
  @Column(name = "component_name", nullable = false, insertable = true, updatable = true)
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostComponentStateEntityPK that = (HostComponentStateEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostEntity.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.*;
import java.util.Collection;

@javax.persistence.Table(name = "hosts", schema = "ambari", catalog = "")
@Entity
public class HostEntity {
  private String hostName;

  @javax.persistence.Column(name = "host_name", nullable = false, insertable = true, updatable = true)
  @Id
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  private String ipv4;

  @javax.persistence.Column(name = "ipv4", nullable = true, insertable = true, updatable = true)
  @Basic
  public String getIpv4() {
    return ipv4;
  }

  public void setIpv4(String ipv4) {
    this.ipv4 = ipv4;
  }

  private String ipv6;

  @javax.persistence.Column(name = "ipv6", nullable = true, insertable = true, updatable = true)
  @Basic
  public String getIpv6() {
    return ipv6;
  }

  public void setIpv6(String ipv6) {
    this.ipv6 = ipv6;
  }
  
  private String publicHostName;
  @Column(name="public_host_name", nullable = true, insertable = true, updatable = true)
  @Basic
  public String getPublicHostName() {
    return publicHostName;
  }
  
  public void setPublicHostName(String name) {
    publicHostName = name;
  }

  private Long totalMem = 0L;

  @javax.persistence.Column(name = "total_mem", nullable = false, insertable = true, updatable = true, length = 10)
  @Basic
  public Long getTotalMem() {
    return totalMem;
  }

  public void setTotalMem(Long totalMem) {
    this.totalMem = totalMem;
  }

  private Integer cpuCount = 0;

  @javax.persistence.Column(name = "cpu_count", nullable = false, insertable = true, updatable = true, length = 10)
  @Basic
  public Integer getCpuCount() {
    return cpuCount;
  }

  public void setCpuCount(Integer cpuCount) {
    this.cpuCount = cpuCount;
  }

  private String cpuInfo = "";

  @javax.persistence.Column(name = "cpu_info", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getCpuInfo() {
    return cpuInfo;
  }

  public void setCpuInfo(String cpuInfo) {
    this.cpuInfo = cpuInfo;
  }

  private String osArch = "";

  @javax.persistence.Column(name = "os_arch", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getOsArch() {
    return osArch;
  }

  public void setOsArch(String osArch) {
    this.osArch = osArch;
  }

  private String disksInfo = "";

  @javax.persistence.Column(name = "disks_info", nullable = false, insertable = true,
		  updatable = true, length = 2000)
  @Basic
  public String getDisksInfo() {
    return disksInfo;
  }

  public void setDisksInfo(String disksInfo) {
    this.disksInfo = disksInfo;
  }

  private String osInfo = "";

  @javax.persistence.Column(name = "os_info", nullable = false, insertable = true, updatable = true,
      length = 1000)
  @Basic
  public String getOsInfo() {
    return osInfo;
  }

  public void setOsInfo(String osInfo) {
    this.osInfo = osInfo;
  }

  private String osType = "";

  @javax.persistence.Column(name = "os_type", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getOsType() {
    return osType;
  }

  public void setOsType(String osType) {
    this.osType = osType;
  }

  private String discoveryStatus = "";

  @javax.persistence.Column(name = "discovery_status", nullable = false, insertable = true, updatable = true,
      length = 2000)
  @Basic
  public String getDiscoveryStatus() {
    return discoveryStatus;
  }

  public void setDiscoveryStatus(String discoveryStatus) {
    this.discoveryStatus = discoveryStatus;
  }

  private Long lastRegistrationTime = 0L;

  @javax.persistence.Column(name = "last_registration_time", nullable = false, insertable = true, updatable = true, length = 10)
  @Basic
  public Long getLastRegistrationTime() {
    return lastRegistrationTime;
  }

  public void setLastRegistrationTime(Long lastRegistrationTime) {
    this.lastRegistrationTime = lastRegistrationTime;
  }

  private String rackInfo = "/default-rack";

  @javax.persistence.Column(name = "rack_info", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getRackInfo() {
    return rackInfo;
  }

  public void setRackInfo(String rackInfo) {
    this.rackInfo = rackInfo;
  }

  private String hostAttributes = "";

  @javax.persistence.Column(name = "host_attributes", nullable = false, insertable = true, updatable = true,
      length = 20000)
  @Basic
  public String getHostAttributes() {
    return hostAttributes;
  }

  public void setHostAttributes(String hostAttributes) {
    this.hostAttributes = hostAttributes;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostEntity that = (HostEntity) o;

    if (cpuCount != null ? !cpuCount.equals(that.cpuCount) : that.cpuCount != null) return false;
    if (lastRegistrationTime != null ? !lastRegistrationTime.equals(that.lastRegistrationTime) : that.lastRegistrationTime != null) return false;
    if (totalMem != null ? !totalMem.equals(that.totalMem) : that.totalMem != null) return false;
    if (cpuInfo != null ? !cpuInfo.equals(that.cpuInfo) : that.cpuInfo != null) return false;
    if (discoveryStatus != null ? !discoveryStatus.equals(that.discoveryStatus) : that.discoveryStatus != null)
      return false;
    if (disksInfo != null ? !disksInfo.equals(that.disksInfo) : that.disksInfo != null) return false;
    if (hostAttributes != null ? !hostAttributes.equals(that.hostAttributes) : that.hostAttributes != null)
      return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;
    if (ipv4 != null ? !ipv4.equals(that.ipv4) : that.ipv4 != null) return false;
    if (osArch != null ? !osArch.equals(that.osArch) : that.osArch != null) return false;
    if (osInfo != null ? !osInfo.equals(that.osInfo) : that.osInfo != null) return false;
    if (osType != null ? !osType.equals(that.osType) : that.osType != null) return false;
    if (rackInfo != null ? !rackInfo.equals(that.rackInfo) : that.rackInfo != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = hostName != null ? hostName.hashCode() : 0;
    result = 31 * result + (ipv4 != null ? ipv4.hashCode() : 0);
    result = 31 * result + (totalMem != null ? totalMem.intValue() : 0);
    result = 31 * result + cpuCount;
    result = 31 * result + (cpuInfo != null ? cpuInfo.hashCode() : 0);
    result = 31 * result + (osArch != null ? osArch.hashCode() : 0);
    result = 31 * result + (disksInfo != null ? disksInfo.hashCode() : 0);
    result = 31 * result + (osInfo != null ? osInfo.hashCode() : 0);
    result = 31 * result + (osType != null ? osType.hashCode() : 0);
    result = 31 * result + (discoveryStatus != null ? discoveryStatus.hashCode() : 0);
    result = 31 * result + (lastRegistrationTime != null ? lastRegistrationTime.intValue() : 0);
    result = 31 * result + (rackInfo != null ? rackInfo.hashCode() : 0);
    result = 31 * result + (hostAttributes != null ? hostAttributes.hashCode() : 0);
    return result;
  }

  private Collection<HostComponentDesiredStateEntity> hostComponentDesiredStateEntities;

  @OneToMany(mappedBy = "hostEntity")
  public Collection<HostComponentDesiredStateEntity> getHostComponentDesiredStateEntities() {
    return hostComponentDesiredStateEntities;
  }

  public void setHostComponentDesiredStateEntities(Collection<HostComponentDesiredStateEntity> hostComponentDesiredStateEntities) {
    this.hostComponentDesiredStateEntities = hostComponentDesiredStateEntities;
  }

  private Collection<HostComponentStateEntity> hostComponentStateEntities;

  @OneToMany(mappedBy = "hostEntity")
  public Collection<HostComponentStateEntity> getHostComponentStateEntities() {
    return hostComponentStateEntities;
  }

  public void setHostComponentStateEntities(Collection<HostComponentStateEntity> hostComponentStateEntities) {
    this.hostComponentStateEntities = hostComponentStateEntities;
  }

  private Collection<ClusterEntity> clusterEntities;

  @ManyToMany
//  @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id")
  @JoinTable(name = "ClusterHostMapping", catalog = "", schema = "ambari",
          joinColumns = {@JoinColumn(name = "host_name", referencedColumnName = "host_name")},
          inverseJoinColumns = {@JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id")}

  )
  public Collection<ClusterEntity> getClusterEntities() {
    return clusterEntities;
  }

  public void setClusterEntities(Collection<ClusterEntity> clusterEntities) {
    this.clusterEntities = clusterEntities;
  }

  private HostStateEntity hostStateEntity;

  @OneToOne(mappedBy = "hostEntity")
  public HostStateEntity getHostStateEntity() {
    return hostStateEntity;
  }

  public void setHostStateEntity(HostStateEntity hostStateEntity) {
    this.hostStateEntity = hostStateEntity;
  }

  private Collection<HostRoleCommandEntity> hostRoleCommandEntities;

  @OneToMany(mappedBy = "host")
  public Collection<HostRoleCommandEntity> getHostRoleCommandEntities() {
    return hostRoleCommandEntities;
  }

  public void setHostRoleCommandEntities(Collection<HostRoleCommandEntity> hostRoleCommandEntities) {
    this.hostRoleCommandEntities = hostRoleCommandEntities;
  }

  //  private Collection<ServiceComponentStateEntity> serviceComponentStateEntities;
//
//  @OneToMany(mappedBy = "hostEntity")
//  public Collection<ServiceComponentStateEntity> getServiceComponentStateEntities() {
//    return serviceComponentStateEntities;
//  }
//
//  public void setServiceComponentStateEntities(Collection<ServiceComponentStateEntity> serviceComponentStateEntities) {
//    this.serviceComponentStateEntities = serviceComponentStateEntities;
//  }

//  private Collection<ServiceStateEntity> serviceStateEntities;
//
//  @OneToMany(mappedBy = "hostEntity")
//  public Collection<ServiceStateEntity> getServiceStateEntities() {
//    return serviceStateEntities;
//  }
//
//  public void setServiceStateEntities(Collection<ServiceStateEntity> serviceStateEntities) {
//    this.serviceStateEntities = serviceStateEntities;
//  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostRoleCommandEntity.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.RoleCommand;
import org.apache.ambari.server.actionmanager.HostRoleStatus;

import javax.persistence.*;

@Table(name = "host_role_command", schema = "ambari", catalog = "")
@Entity
@Cacheable(false)
@SequenceGenerator(name = "ambari.host_role_command_task_id_seq", allocationSize = 1)
public class HostRoleCommandEntity {
  private Long taskId;

  @Column(name = "task_id")
  @Id
  @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "ambari.host_role_command_task_id_seq")
  public Long getTaskId() {
    return taskId;
  }

  public void setTaskId(Long taskId) {
    this.taskId = taskId;
  }

  private Long requestId;

  @Column(name = "request_id", insertable = false, updatable = false, nullable = false)
  @Basic
  public Long getRequestId() {
    return requestId;
  }

  public void setRequestId(Long requestId) {
    this.requestId = requestId;
  }

  private Long stageId;

  @Column(name = "stage_id", insertable = false, updatable = false, nullable = false)
  @Basic
  public Long getStageId() {
    return stageId;
  }

  public void setStageId(Long stageId) {
    this.stageId = stageId;
  }

  private String hostName;

  @Column(name = "host_name", insertable = false, updatable = false, nullable = false)
  @Basic
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  private Role role;

  @Column(name = "role")
  @Enumerated(EnumType.STRING)
  public Role getRole() {
    return role;
  }

  public void setRole(Role role) {
    this.role = role;
  }

  private String event = "";

  @Column(name = "event", nullable = false, length = 32000)
  @Basic
  public String getEvent() {
    return event;
  }

  public void setEvent(String event) {
    this.event = event;
  }

  private Integer exitcode = 0;

  @Column(name = "exitcode", nullable = false)
  @Basic
  public Integer getExitcode() {
    return exitcode;
  }

  public void setExitcode(Integer exitcode) {
    this.exitcode = exitcode;
  }

  private HostRoleStatus status;

  @Column(name = "status")
  @Enumerated(EnumType.STRING)
  public HostRoleStatus getStatus() {
    return status;
  }

  public void setStatus(HostRoleStatus status) {
    this.status = status;
  }

  private byte[] stdError = new byte[0];

  @Column(name = "std_error", nullable = false)
  @Lob
  @Basic
  public byte[] getStdError() {
    return stdError;
  }

  public void setStdError(byte[] stdError) {
    this.stdError = stdError;
  }

  private byte[] stdOut = new byte[0];

  @Column(name = "std_out", nullable = false)
  @Lob
  @Basic
  public byte[] getStdOut() {
    return stdOut;
  }

  public void setStdOut(byte[] stdOut) {
    this.stdOut = stdOut;
  }

  private Long startTime = -1L;

  @Column(name = "start_time", nullable = false)
  @Basic
  public Long getStartTime() {
    return startTime;
  }

  public void setStartTime(Long startTime) {
    this.startTime = startTime;
  }

  private Long lastAttemptTime = -1L;

  @Column(name = "last_attempt_time", nullable = false)
  @Basic
  public Long getLastAttemptTime() {
    return lastAttemptTime;
  }

  public void setLastAttemptTime(Long lastAttemptTime) {
    this.lastAttemptTime = lastAttemptTime;
  }

  private Short attemptCount = 0;

  @Column(name = "attempt_count", nullable = false)
  @Basic
  public Short getAttemptCount() {
    return attemptCount;
  }

  public void setAttemptCount(Short attemptCount) {
    this.attemptCount = attemptCount;
  }

  private RoleCommand roleCommand;

  @Column(name = "role_command")
  @Enumerated(EnumType.STRING)
  public RoleCommand getRoleCommand() {
    return roleCommand;
  }

  public void setRoleCommand(RoleCommand roleCommand) {
    this.roleCommand = roleCommand;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostRoleCommandEntity that = (HostRoleCommandEntity) o;

    if (attemptCount != null ? !attemptCount.equals(that.attemptCount) : that.attemptCount != null) return false;
    if (event != null ? !event.equals(that.event) : that.event != null) return false;
    if (exitcode != null ? !exitcode.equals(that.exitcode) : that.exitcode != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;
    if (lastAttemptTime != null ? !lastAttemptTime.equals(that.lastAttemptTime) : that.lastAttemptTime != null)
      return false;
    if (requestId != null ? !requestId.equals(that.requestId) : that.requestId != null) return false;
    if (role != null ? !role.equals(that.role) : that.role != null) return false;
    if (stageId != null ? !stageId.equals(that.stageId) : that.stageId != null) return false;
    if (startTime != null ? !startTime.equals(that.startTime) : that.startTime != null) return false;
    if (status != null ? !status.equals(that.status) : that.status != null) return false;
    if (stdError != null ? !stdError.equals(that.stdError) : that.stdError != null) return false;
    if (stdOut != null ? !stdOut.equals(that.stdOut) : that.stdOut != null) return false;
    if (taskId != null ? !taskId.equals(that.taskId) : that.taskId != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = taskId != null ? taskId.hashCode() : 0;
    result = 31 * result + (requestId != null ? requestId.hashCode() : 0);
    result = 31 * result + (stageId != null ? stageId.hashCode() : 0);
    result = 31 * result + (hostName != null ? hostName.hashCode() : 0);
    result = 31 * result + (role != null ? role.hashCode() : 0);
    result = 31 * result + (event != null ? event.hashCode() : 0);
    result = 31 * result + (exitcode != null ? exitcode.hashCode() : 0);
    result = 31 * result + (status != null ? status.hashCode() : 0);
    result = 31 * result + (stdError != null ? stdError.hashCode() : 0);
    result = 31 * result + (stdOut != null ? stdOut.hashCode() : 0);
    result = 31 * result + (startTime != null ? startTime.hashCode() : 0);
    result = 31 * result + (lastAttemptTime != null ? lastAttemptTime.hashCode() : 0);
    result = 31 * result + (attemptCount != null ? attemptCount.hashCode() : 0);
    return result;
  }

  private ExecutionCommandEntity executionCommand;

  @OneToOne(mappedBy = "hostRoleCommand")
  public ExecutionCommandEntity getExecutionCommand() {
    return executionCommand;
  }

  public void setExecutionCommand(ExecutionCommandEntity executionCommandsByTaskId) {
    this.executionCommand = executionCommandsByTaskId;
  }

  private StageEntity stage;

  @ManyToOne
  @JoinColumns({@JoinColumn(name = "request_id", referencedColumnName = "request_id", nullable = false), @JoinColumn(name = "stage_id", referencedColumnName = "stage_id", nullable = false)})
  public StageEntity getStage() {
    return stage;
  }

  public void setStage(StageEntity stage) {
    this.stage = stage;
  }

  private HostEntity host;

  @ManyToOne
  @JoinColumn(name = "host_name", referencedColumnName = "host_name", nullable = false)
  public HostEntity getHost() {
    return host;
  }

  public void setHost(HostEntity host) {
    this.host = host;
  }
}"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/HostStateEntity.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import org.apache.ambari.server.state.HostState;

import javax.persistence.*;

@javax.persistence.Table(name = "hoststate", schema = "ambari", catalog = "")
@Entity
public class HostStateEntity {
  private String hostName;

  @javax.persistence.Column(name = "host_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getHostName() {
    return hostName;
  }

  public void setHostName(String hostName) {
    this.hostName = hostName;
  }

  private Long availableMem = 0L;

  @Column(name = "available_mem", nullable = false, insertable = true, updatable = true)
  @Basic
  public Long getAvailableMem() {
    return availableMem;
  }

  public void setAvailableMem(Long availableMem) {
    this.availableMem = availableMem;
  }

  private Long timeInState = 0L;

  @javax.persistence.Column(name = "time_in_state", nullable = false, insertable = true, updatable = true, length = 10)
  @Basic
  public Long getTimeInState() {
    return timeInState;
  }

  public void setTimeInState(Long timeInState) {
    this.timeInState = timeInState;
  }

  private String healthStatus;

  @Column(name = "health_status", insertable = true, updatable = true)
  @Basic
  public String getHealthStatus() {
    return healthStatus;
  }

  public void setHealthStatus(String healthStatus) {
    this.healthStatus = healthStatus;
  }

  private String agentVersion = "";

  @javax.persistence.Column(name = "agent_version", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getAgentVersion() {
    return agentVersion;
  }

  public void setAgentVersion(String agentVersion) {
    this.agentVersion = agentVersion;
  }

  private HostState currentState = HostState.INIT;

  @javax.persistence.Column(name = "current_state", nullable = false, insertable = true, updatable = true)
  @Enumerated(value = EnumType.STRING)
  public HostState getCurrentState() {
    return currentState;
  }

  public void setCurrentState(HostState currentState) {
    this.currentState = currentState;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    HostStateEntity that = (HostStateEntity) o;

    if (availableMem != null ? !availableMem.equals(that.availableMem) : that.availableMem != null) return false;
    if (timeInState != null ? !timeInState.equals(that.timeInState) : that.timeInState!= null) return false;
    if (agentVersion != null ? !agentVersion.equals(that.agentVersion) : that.agentVersion != null) return false;
    if (currentState != null ? !currentState.equals(that.currentState) : that.currentState != null) return false;
    if (hostName != null ? !hostName.equals(that.hostName) : that.hostName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = hostName != null ? hostName.hashCode() : 0;
    result = 31 * result + (availableMem != null ? availableMem.intValue() : 0);
    result = 31 * result + (timeInState != null ? timeInState.intValue() : 0);
    result = 31 * result + (agentVersion != null ? agentVersion.hashCode() : 0);
    result = 31 * result + (currentState != null ? currentState.hashCode() : 0);
    return result;
  }

//  private ClusterEntity clusterEntity;
//
//  @ManyToOne
//  @javax.persistence.JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id")
//  public ClusterEntity getClusterEntity() {
//    return clusterEntity;
//  }
//
//  public void setClusterEntity(ClusterEntity clusterEntity) {
//    this.clusterEntity = clusterEntity;
//  }

  private HostEntity hostEntity;

  @OneToOne
  @JoinColumn(name = "host_name", referencedColumnName = "host_name", nullable = false)
  public HostEntity getHostEntity() {
    return hostEntity;
  }

  public void setHostEntity(HostEntity hostEntity) {
    this.hostEntity = hostEntity;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/KeyValueEntity.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;


import javax.persistence.Column;
import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.Table;

@Table(name = "key_value_store", schema = "ambari", catalog = "")
@Entity
public class KeyValueEntity {

  private String key;
  private String value;

  @Column(name = "\"key\"", length = 255)
  @Id
  public String getKey() {
    return key;
  }

  public void setKey(String key) {
    this.key = key;
  }

  @Column(name = "\"value\"", length = 32000)
  public String getValue() {
    return value;
  }

  public void setValue(String value) {
    this.value = value;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    KeyValueEntity that = (KeyValueEntity) o;

    if (key != null ? !key.equals(that.key) : that.key != null) return false;
    if (value != null ? !value.equals(that.value) : that.value != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = key != null ? key.hashCode() : 0;
    result = 31 * result + (value != null ? value.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/RoleEntity.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.CascadeType;
import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.JoinColumn;
import javax.persistence.JoinTable;
import javax.persistence.ManyToMany;
import java.util.Set;

@javax.persistence.Table(name = "roles", schema = "ambari", catalog = "")
@Entity
public class RoleEntity {

  private String roleName;

  @javax.persistence.Column(name = "role_name")
  @Id
  public String getRoleName() {
    return roleName;
  }

  public void setRoleName(String roleName) {
    this.roleName = roleName;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    RoleEntity that = (RoleEntity) o;

    if (roleName != null ? !roleName.equals(that.roleName) : that.roleName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    return roleName != null ? roleName.hashCode() : 0;
  }

  private Set<org.apache.ambari.server.orm.entities.UserEntity> userEntities;

  @JoinTable(name = "user_roles", catalog = "", schema = "ambari",
      joinColumns = {@JoinColumn(name = "role_name", referencedColumnName = "role_name")},
      inverseJoinColumns = {@JoinColumn(name = "user_id", referencedColumnName = "user_id")})
  @ManyToMany(cascade = CascadeType.ALL)
  public Set<org.apache.ambari.server.orm.entities.UserEntity> getUserEntities() {
    return userEntities;
  }

  public void setUserEntities(Set<org.apache.ambari.server.orm.entities.UserEntity> userEntities) {
    this.userEntities = userEntities;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/RoleSuccessCriteriaEntity.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import org.apache.ambari.server.Role;

import javax.persistence.*;

@IdClass(org.apache.ambari.server.orm.entities.RoleSuccessCriteriaEntityPK.class)
@Table(name = "role_success_criteria", schema = "ambari", catalog = "")
@Entity
public class RoleSuccessCriteriaEntity {
  private Long requestId;

  @Column(name = "request_id", insertable = false, updatable = false, nullable = false)
  @Id
  public Long getRequestId() {
    return requestId;
  }

  public void setRequestId(Long requestId) {
    this.requestId = requestId;
  }

  private Long stageId;

  @Column(name = "stage_id", insertable = false, updatable = false, nullable = false)
  @Id
  public Long getStageId() {
    return stageId;
  }

  public void setStageId(Long stageId) {
    this.stageId = stageId;
  }

  private Role role;

  @Column(name = "role")
  @Enumerated(EnumType.STRING)
  @Id
  public Role getRole() {
    return role;
  }

  public void setRole(Role role) {
    this.role = role;
  }

  private Double successFactor = 1d;

  @Column(name = "success_factor", nullable = false)
  @Basic
  public Double getSuccessFactor() {
    return successFactor;
  }

  public void setSuccessFactor(Double successFactor) {
    this.successFactor = successFactor;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    RoleSuccessCriteriaEntity that = (RoleSuccessCriteriaEntity) o;

    if (requestId != null ? !requestId.equals(that.requestId) : that.requestId != null) return false;
    if (role != null ? !role.equals(that.role) : that.role != null) return false;
    if (stageId != null ? !stageId.equals(that.stageId) : that.stageId != null) return false;
    if (successFactor != null ? !successFactor.equals(that.successFactor) : that.successFactor != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = requestId != null ? requestId.hashCode() : 0;
    result = 31 * result + (stageId != null ? stageId.hashCode() : 0);
    result = 31 * result + (role != null ? role.hashCode() : 0);
    result = 31 * result + (successFactor != null ? successFactor.hashCode() : 0);
    return result;
  }

  private StageEntity stage;

  @ManyToOne
  @JoinColumns({@JoinColumn(name = "request_id", referencedColumnName = "request_id", nullable = false), @JoinColumn(name = "stage_id", referencedColumnName = "stage_id", nullable = false)})
  public StageEntity getStage() {
    return stage;
  }

  public void setStage(StageEntity stage) {
    this.stage = stage;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/RoleSuccessCriteriaEntityPK.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import org.apache.ambari.server.Role;

import javax.persistence.Column;
import javax.persistence.EnumType;
import javax.persistence.Enumerated;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class RoleSuccessCriteriaEntityPK implements Serializable {
  private Long requestId;

  @Id
  @Column(name = "request_id")
  public Long getRequestId() {
    return requestId;
  }

  public void setRequestId(Long requestId) {
    this.requestId = requestId;
  }

  private Long stageId;

  @Id
  @Column(name = "stage_id")
  public Long getStageId() {
    return stageId;
  }

  public void setStageId(Long stageId) {
    this.stageId = stageId;
  }

  private Role role;

  @Column(name = "role")
  @Enumerated(EnumType.STRING)
  @Id
  public Role getRole() {
    return role;
  }

  public void setRole(Role role) {
    this.role = role;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    RoleSuccessCriteriaEntityPK that = (RoleSuccessCriteriaEntityPK) o;

    if (requestId != null ? !requestId.equals(that.requestId) : that.requestId != null) return false;
    if (role != null ? !role.equals(that.role) : that.role != null) return false;
    if (stageId != null ? !stageId.equals(that.stageId) : that.stageId != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = requestId != null ? requestId.hashCode() : 0;
    result = 31 * result + (stageId != null ? stageId.hashCode() : 0);
    result = 31 * result + (role != null ? role.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ServiceComponentDesiredStateEntity.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import org.apache.ambari.server.state.State;

import javax.persistence.*;
import java.util.Collection;

@javax.persistence.IdClass(ServiceComponentDesiredStateEntityPK.class)
@javax.persistence.Table(name = "servicecomponentdesiredstate", schema = "ambari", catalog = "")
@Entity
public class ServiceComponentDesiredStateEntity {
  private Long clusterId;

  @javax.persistence.Column(name = "cluster_id", nullable = false, insertable = false, updatable = false, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @javax.persistence.Column(name = "service_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  private String componentName;

  @javax.persistence.Column(name = "component_name", nullable = false, insertable = true, updatable = true)
  @Id
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  private State desiredState = State.INIT;

  @javax.persistence.Column(name = "desired_state", nullable = false, insertable = true, updatable = true)
  @Enumerated(EnumType.STRING)
  public State getDesiredState() {
    return desiredState;
  }

  public void setDesiredState(State desiredState) {
    this.desiredState = desiredState;
  }

  private String desiredStackVersion = "";

  @javax.persistence.Column(name = "desired_stack_version", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getDesiredStackVersion() {
    return desiredStackVersion;
  }

  public void setDesiredStackVersion(String desiredStackVersion) {
    this.desiredStackVersion = desiredStackVersion;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceComponentDesiredStateEntity that = (ServiceComponentDesiredStateEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (desiredState != null ? !desiredState.equals(that.desiredState) : that.desiredState != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;
    if (desiredStackVersion != null ? !desiredStackVersion.equals(that.desiredStackVersion) : that.desiredStackVersion != null)
      return false;
    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    result = 31 * result + (desiredState != null ? desiredState.hashCode() : 0);
    result = 31 * result + (desiredStackVersion != null ? desiredStackVersion.hashCode() : 0);

    return result;
  }

  private ClusterServiceEntity clusterServiceEntity;

  @ManyToOne
  @javax.persistence.JoinColumns({@javax.persistence.JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false), @javax.persistence.JoinColumn(name = "service_name", referencedColumnName = "service_name", nullable = false)})
  public ClusterServiceEntity getClusterServiceEntity() {
    return clusterServiceEntity;
  }

  public void setClusterServiceEntity(ClusterServiceEntity clusterServiceEntity) {
    this.clusterServiceEntity = clusterServiceEntity;
  }

  private Collection<HostComponentStateEntity> hostComponentStateEntities;

  @OneToMany(mappedBy = "serviceComponentDesiredStateEntity")
  public Collection<HostComponentStateEntity> getHostComponentStateEntities() {
    return hostComponentStateEntities;
  }

  public void setHostComponentStateEntities(Collection<HostComponentStateEntity> hostComponentStateEntities) {
    this.hostComponentStateEntities = hostComponentStateEntities;
  }

  private Collection<HostComponentDesiredStateEntity> hostComponentDesiredStateEntities;

  @OneToMany(mappedBy = "serviceComponentDesiredStateEntity")
  public Collection<HostComponentDesiredStateEntity> getHostComponentDesiredStateEntities() {
    return hostComponentDesiredStateEntities;
  }

  public void setHostComponentDesiredStateEntities(Collection<HostComponentDesiredStateEntity> hostComponentDesiredStateEntities) {
    this.hostComponentDesiredStateEntities = hostComponentDesiredStateEntities;
  }

  private Collection<ComponentConfigMappingEntity> configMappingEntities;
  @OneToMany(mappedBy = "serviceComponentDesiredStateEntity", cascade = CascadeType.ALL)
  public Collection<ComponentConfigMappingEntity> getComponentConfigMappingEntities() {
    return configMappingEntities;
  }
  
  public void setComponentConfigMappingEntities(Collection<ComponentConfigMappingEntity> entities) {
    configMappingEntities = entities;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ServiceComponentDesiredStateEntityPK.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class ServiceComponentDesiredStateEntityPK implements Serializable {
  private Long clusterId;

  @Column(name = "cluster_id", nullable = false, insertable = true, updatable = true, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @javax.persistence.Column(name = "service_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  private String componentName;

  @Id
  @Column(name = "component_name", nullable = false, insertable = true, updatable = true)
  public String getComponentName() {
    return componentName;
  }

  public void setComponentName(String componentName) {
    this.componentName = componentName;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceComponentDesiredStateEntityPK that = (ServiceComponentDesiredStateEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (componentName != null ? !componentName.equals(that.componentName) : that.componentName != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (componentName != null ? componentName.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ServiceConfigMappingEntity.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Entity;
import javax.persistence.Id;
import javax.persistence.IdClass;
import javax.persistence.JoinColumn;
import javax.persistence.JoinColumns;
import javax.persistence.ManyToOne;
import javax.persistence.Table;

@IdClass(ServiceConfigMappingEntityPK.class)
@Entity
@Table(name="serviceconfigmapping", schema="ambari", catalog="")
public class ServiceConfigMappingEntity {
  private Long clusterId;
  private String serviceName;
  private String configType;
  private String configVersion;
  private Long timestamp;
  private ClusterServiceEntity serviceEntity;
  private ClusterConfigEntity clusterConfigEntity;

  @Column(name = "cluster_id", nullable = false, insertable = false, updatable = false)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long id) {
    clusterId = id;
  }

  @Column(name = "service_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String name) {
    serviceName = name;
  }

  @Column(name = "config_type", nullable = false, insertable = true, updatable = false)
  @Id
  public String getConfigType() {
    return configType;
  }

  public void setConfigType(String type) {
    configType = type;
  }

  @Column(name = "config_tag", nullable = false, insertable = true, updatable = true)
  public String getVersionTag() {
    return configVersion;
  }

  public void setVersionTag(String tag) {
    configVersion = tag;
  }

  @Column(name = "timestamp", nullable = false, insertable = true, updatable = true)
  public Long getTimestamp() {
    return timestamp;
  }

  public void setTimestamp(Long stamp) {
    timestamp = stamp;
  }

  @ManyToOne
  @JoinColumns({
      @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false),
      @JoinColumn(name = "service_name", referencedColumnName = "service_name", nullable = false) })
  public ClusterServiceEntity getServiceEntity() {
    return serviceEntity;
  }

  public void setServiceEntity(ClusterServiceEntity entity) {
    serviceEntity = entity;
  }

  @ManyToOne
  @JoinColumns({
      @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false, insertable = false, updatable = false),
      @JoinColumn(name = "config_type", referencedColumnName = "type_name", nullable = false, insertable = false, updatable = false),
      @JoinColumn(name = "config_tag", referencedColumnName = "version_tag", nullable = false, insertable = false, updatable = false)
  })
  public ClusterConfigEntity getClusterConfigEntity() {
    return clusterConfigEntity;
  }

  public void setClusterConfigEntity(ClusterConfigEntity clusterConfigEntity) {
    this.clusterConfigEntity = clusterConfigEntity;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceConfigMappingEntity that = (ServiceConfigMappingEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;
    if (configType != null ? !configType.equals(that.configType) : that.configType != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (configType != null ? configType.hashCode() : 0);
    return result;
  }




}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ServiceConfigMappingEntityPK.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class ServiceConfigMappingEntityPK implements Serializable {
  private Long clusterId;
  private String serviceName;
  private String configType;

  @Id
  @Column(name = "cluster_id", nullable = false, insertable = true, updatable = true, length = 10)
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  @Id
  @Column(name = "service_name", nullable = false, insertable = true, updatable = true)
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  @Id
  @Column(name = "config_type", nullable = false, insertable = true, updatable = false)
  public String getConfigType() {
    return configType;
  }

  public void setConfigType(String type) {
    configType = type;
  }


  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceConfigMappingEntityPK that = (ServiceConfigMappingEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId !=null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ServiceDesiredStateEntity.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import org.apache.ambari.server.state.State;

import javax.persistence.*;

@javax.persistence.IdClass(ServiceDesiredStateEntityPK.class)
@javax.persistence.Table(name = "servicedesiredstate", schema = "ambari", catalog = "")
@Entity
public class ServiceDesiredStateEntity {
  private Long clusterId;

  @javax.persistence.Column(name = "cluster_id", nullable = false, insertable = false, updatable = false, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @javax.persistence.Column(name = "service_name", nullable = false, insertable = false, updatable = false)
  @Id
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  private State desiredState = State.INIT;

  @javax.persistence.Column(name = "desired_state", nullable = false, insertable = true, updatable = true)
  @Enumerated(value = EnumType.STRING)
  public State getDesiredState() {
    return desiredState;
  }

  public void setDesiredState(State desiredState) {
    this.desiredState = desiredState;
  }

  private int desiredHostRoleMapping = 0;

  @javax.persistence.Column(name = "desired_host_role_mapping", nullable = false, insertable = true, updatable = true, length = 10)
  @Basic
  public int getDesiredHostRoleMapping() {
    return desiredHostRoleMapping;
  }

  public void setDesiredHostRoleMapping(int desiredHostRoleMapping) {
    this.desiredHostRoleMapping = desiredHostRoleMapping;
  }

  private String desiredStackVersion = "";

  @javax.persistence.Column(name = "desired_stack_version", nullable = false, insertable = true, updatable = true)
  @Basic
  public String getDesiredStackVersion() {
    return desiredStackVersion;
  }

  public void setDesiredStackVersion(String desiredStackVersion) {
    this.desiredStackVersion = desiredStackVersion;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceDesiredStateEntity that = (ServiceDesiredStateEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (desiredState != null ? !desiredState.equals(that.desiredState) : that.desiredState != null) return false;
    if (desiredHostRoleMapping != that.desiredHostRoleMapping) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;
    if (desiredStackVersion != null ? !desiredStackVersion.equals(that.desiredStackVersion) : that.desiredStackVersion != null)
      return false;
    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    result = 31 * result + (desiredState != null ? desiredState.hashCode() : 0);
    result = 31 * result + desiredHostRoleMapping;
    result = 31 * result + (desiredStackVersion != null ? desiredStackVersion.hashCode() : 0);
    return result;
  }

  private ClusterServiceEntity clusterServiceEntity;

  @OneToOne
  @javax.persistence.JoinColumns({@javax.persistence.JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id", nullable = false), @javax.persistence.JoinColumn(name = "service_name", referencedColumnName = "service_name", nullable = false)})
  public ClusterServiceEntity getClusterServiceEntity() {
    return clusterServiceEntity;
  }

  public void setClusterServiceEntity(ClusterServiceEntity clusterServiceEntity) {
    this.clusterServiceEntity = clusterServiceEntity;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/ServiceDesiredStateEntityPK.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class ServiceDesiredStateEntityPK implements Serializable {
  private Long clusterId;

  @javax.persistence.Column(name = "cluster_id", nullable = false, insertable = true, updatable = true, length = 10)
  @Id
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private String serviceName;

  @Id
  @Column(name = "service_name", nullable = false, insertable = true, updatable = true, length = 2147483647, precision = 0)
  public String getServiceName() {
    return serviceName;
  }

  public void setServiceName(String serviceName) {
    this.serviceName = serviceName;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    ServiceDesiredStateEntityPK that = (ServiceDesiredStateEntityPK) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (serviceName != null ? !serviceName.equals(that.serviceName) : that.serviceName != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.intValue() : 0;
    result = 31 * result + (serviceName != null ? serviceName.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/StageEntity.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.*;
import java.util.Collection;

@IdClass(org.apache.ambari.server.orm.entities.StageEntityPK.class)
@Table(name = "stage", schema = "ambari", catalog = "")
@Entity
public class StageEntity {
  private Long clusterId;

  @Column(name = "cluster_id", insertable = false, updatable = false, nullable = false)
  @Basic
  public Long getClusterId() {
    return clusterId;
  }

  public void setClusterId(Long clusterId) {
    this.clusterId = clusterId;
  }

  private Long requestId;

  @Column(name = "request_id")
  @Id
  public Long getRequestId() {
    return requestId;
  }

  public void setRequestId(Long requestId) {
    this.requestId = requestId;
  }

  private Long stageId = 0L;

  @Column(name = "stage_id", nullable = false)
  @Id
  public Long getStageId() {
    return stageId;
  }

  public void setStageId(Long stageId) {
    this.stageId = stageId;
  }

  private String logInfo = "";

  @Column(name = "log_info", nullable = false)
  @Basic
  public String getLogInfo() {
    return logInfo;
  }

  public void setLogInfo(String logInfo) {
    this.logInfo = logInfo;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    StageEntity that = (StageEntity) o;

    if (clusterId != null ? !clusterId.equals(that.clusterId) : that.clusterId != null) return false;
    if (logInfo != null ? !logInfo.equals(that.logInfo) : that.logInfo != null) return false;
    if (requestId != null ? !requestId.equals(that.requestId) : that.requestId != null) return false;
    if (stageId != null ? !stageId.equals(that.stageId) : that.stageId != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = clusterId != null ? clusterId.hashCode() : 0;
    result = 31 * result + (requestId != null ? requestId.hashCode() : 0);
    result = 31 * result + (stageId != null ? stageId.hashCode() : 0);
    result = 31 * result + (logInfo != null ? logInfo.hashCode() : 0);
    return result;
  }

  private ClusterEntity cluster;

  @ManyToOne
  @JoinColumn(name = "cluster_id", referencedColumnName = "cluster_id")
  public ClusterEntity getCluster() {
    return cluster;
  }

  public void setCluster(ClusterEntity cluster) {
    this.cluster = cluster;
  }

  private Collection<HostRoleCommandEntity> hostRoleCommands;

  @OneToMany(mappedBy = "stage")
  public Collection<HostRoleCommandEntity> getHostRoleCommands() {
    return hostRoleCommands;
  }

  public void setHostRoleCommands(Collection<HostRoleCommandEntity> hostRoleCommands) {
    this.hostRoleCommands = hostRoleCommands;
  }

  private Collection<RoleSuccessCriteriaEntity> roleSuccessCriterias;

  @OneToMany(mappedBy = "stage")
  public Collection<RoleSuccessCriteriaEntity> getRoleSuccessCriterias() {
    return roleSuccessCriterias;
  }

  public void setRoleSuccessCriterias(Collection<RoleSuccessCriteriaEntity> roleSuccessCriterias) {
    this.roleSuccessCriterias = roleSuccessCriterias;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/StageEntityPK.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.orm.entities;

import javax.persistence.Column;
import javax.persistence.Id;
import java.io.Serializable;

@SuppressWarnings("serial")
public class StageEntityPK implements Serializable {
  private Long requestId;

  @Id
  @Column(name = "request_id")
  public Long getRequestId() {
    return requestId;
  }

  public void setRequestId(Long requestId) {
    this.requestId = requestId;
  }

  private Long stageId;

  @Id
  @Column(name = "stage_id")
  public Long getStageId() {
    return stageId;
  }

  public void setStageId(Long stageId) {
    this.stageId = stageId;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    StageEntityPK that = (StageEntityPK) o;

    if (requestId != null ? !requestId.equals(that.requestId) : that.requestId != null) return false;
    if (stageId != null ? !stageId.equals(that.stageId) : that.stageId != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = requestId != null ? requestId.hashCode() : 0;
    result = 31 * result + (stageId != null ? stageId.hashCode() : 0);
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/orm/entities/UserEntity.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.orm.entities;

import javax.persistence.*;

import java.util.Date;
import java.util.Set;

@Table(name = "users", schema = "ambari", catalog = "", uniqueConstraints = {@UniqueConstraint(columnNames = {"user_name", "ldap_user"})})
@Entity
@NamedQueries({
    @NamedQuery(name = "localUserByName", query = "SELECT user FROM UserEntity user where lower(user.userName)=:username AND user.ldapUser=false"),
    @NamedQuery(name = "ldapUserByName", query = "SELECT user FROM UserEntity user where lower(user.userName)=:username AND user.ldapUser=true")
})
@SequenceGenerator(name = "ambari.users_user_id_seq", allocationSize = 1)
public class UserEntity {

  private Integer userId;

  @Id
  @Column(name = "user_id")
  @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "ambari.users_user_id_seq")
  public Integer getUserId() {
    return userId;
  }

  public void setUserId(Integer userId) {
    this.userId = userId;
  }

  private String userName;

  @Column(name = "user_name")
  public String getUserName() {
    return userName;
  }

  public void setUserName(String userName) {
    this.userName = userName;
  }

  private Boolean ldapUser = false;

  @Column(name = "ldap_user")
  public Boolean getLdapUser() {
    return ldapUser;
  }

  public void setLdapUser(Boolean ldapUser) {
    this.ldapUser = ldapUser;
  }

  private String userPassword;

  @Column(name = "user_password")
  @Basic
  public String getUserPassword() {
    return userPassword;
  }

  public void setUserPassword(String userPassword) {
    this.userPassword = userPassword;
  }

  private Date createTime = new Date();

  @Column(name = "create_time")
  @Basic
  @Temporal(value = TemporalType.TIMESTAMP)
  public Date getCreateTime() {
    return createTime;
  }

  public void setCreateTime(Date createTime) {
    this.createTime = createTime;
  }

  @Override
  public boolean equals(Object o) {
    if (this == o) return true;
    if (o == null || getClass() != o.getClass()) return false;

    UserEntity that = (UserEntity) o;

    if (userId != null ? !userId.equals(that.userId) : that.userId != null) return false;
    if (createTime != null ? !createTime.equals(that.createTime) : that.createTime != null) return false;
    if (ldapUser != null ? !ldapUser.equals(that.ldapUser) : that.ldapUser != null) return false;
    if (userName != null ? !userName.equals(that.userName) : that.userName != null) return false;
    if (userPassword != null ? !userPassword.equals(that.userPassword) : that.userPassword != null) return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = userId != null ? userId.hashCode() : 0;
    result = 31 * result + (userName != null ? userName.hashCode() : 0);
    result = 31 * result + (userPassword != null ? userPassword.hashCode() : 0);
    result = 31 * result + (ldapUser != null ? ldapUser.hashCode() : 0);
    result = 31 * result + (createTime != null ? createTime.hashCode() : 0);
    return result;
  }

  private Set<RoleEntity> roleEntities;

  @ManyToMany(mappedBy = "userEntities")
  public Set<RoleEntity> getRoleEntities() {
    return roleEntities;
  }

  public void setRoleEntities(Set<RoleEntity> roleEntities) {
    this.roleEntities = roleEntities;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/resources/ResourceManager.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.resources;

import java.io.File;

import org.apache.ambari.server.configuration.Configuration;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;
import com.google.inject.Singleton;

/**
 * Resource manager.
 */
@Singleton
public class ResourceManager {
  private static Log LOG = LogFactory.getLog(ResourceManager.class);
	
  @Inject Configuration configs;
  /**
  * Returns resource file.
  * @param resourcePath relational path to file
  * @return resource file
  */
  public File getResource(String resourcePath) {
    String resDir = configs.getConfigsMap().get(Configuration.RESOURCES_DIR_KEY);
    String resourcePathIndep = resourcePath.replaceAll("/", File.separator);
    File resourceFile = new File(resDir + File.separator + resourcePathIndep);
    if (LOG.isDebugEnabled()) {
      LOG.debug("Resource requested from ResourceManager"
          + ", resourceDir=" + resDir
          + ", resourcePath=" + resourcePathIndep
          + ", fileExists=" + resourceFile.exists());
    }
    return resourceFile;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/resources/api/rest/GetResource.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.resources.api.rest;


import java.io.File;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import javax.ws.rs.Consumes;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;

import org.apache.ambari.server.resources.ResourceManager;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;

/**
 * Resource api.
 */
@Path("/")
public class GetResource {
  private static Log LOG = LogFactory.getLog(GetResource.class);

  private static ResourceManager resourceManager;

  @Inject
  public static void init(ResourceManager instance) {
	  resourceManager = instance;
  }


  @GET
  @Path("{resourcePath:.*}")
  @Consumes(MediaType.TEXT_PLAIN)
  @Produces(MediaType.APPLICATION_OCTET_STREAM)
  public Response getResource(@PathParam("resourcePath") String resourcePath,
      @Context HttpServletRequest req) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Received a resource request from agent"
          + ", resourcePath=" + resourcePath);
    }
    File resourceFile = resourceManager.getResource(resourcePath);

    if (!resourceFile.exists()) {
    	return Response.status(HttpServletResponse.SC_NOT_FOUND).build();
    }

    return Response.ok(resourceFile).build();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/AmbariEntryPoint.java,false,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security;

import org.springframework.security.core.AuthenticationException;
import org.springframework.security.web.AuthenticationEntryPoint;

import javax.servlet.ServletException;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;

public class AmbariEntryPoint implements AuthenticationEntryPoint {
  @Override
  public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException {
    response.sendError(HttpServletResponse.SC_FORBIDDEN, authException.getMessage());
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/CertificateManager.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security;

import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;
import java.io.InputStreamReader;
import java.nio.charset.Charset;
import java.text.MessageFormat;
import java.util.Map;

import org.apache.ambari.server.utils.ShellCommandUtil;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.commons.io.FileUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;
import com.google.inject.Singleton;

/**
 * Ambari security.
 * Manages server and agent certificates
 */
@Singleton
public class CertificateManager {

  @Inject Configuration configs;

  private static final Log LOG = LogFactory.getLog(CertificateManager.class);


  private static final String GEN_SRVR_KEY = "openssl genrsa -des3 " +
      "-passout pass:{0} -out {1}/{2} 4096 ";
  private static final String GEN_SRVR_REQ = "openssl req -passin pass:{0} " +
      "-new -key {1}/{2} -out {1}/{3} -batch";
  private static final String SIGN_SRVR_CRT = "openssl x509 " +
      "-passin pass:{0} -req -days 365 -in {1}/{3} -signkey {1}/{2} " +
      "-out {1}/{3} \n";
  private static final String EXPRT_KSTR = "openssl pkcs12 -export" +
      " -in {1}/{3} -inkey {1}/{2} -certfile {1}/{3} -out {1}/{4} " +
      "-password pass:{0} -passin pass:{0} \n";
  private static final String SIGN_AGENT_CRT = "openssl ca -config " +
      "{0}/ca.config -in {0}/{1} -out {0}/{2} -batch -passin pass:{3} " +
      "-keyfile {0}/{4} -cert {0}/{5}"; /**
       * Verify that root certificate exists, generate it otherwise.
       */
  public void initRootCert() {
    LOG.info("Initialization of root certificate");

    boolean certExists = isCertExists();

    LOG.info("Certificate exists:" + certExists);

    if (!certExists) {
      generateServerCertificate();
    }
  }

  /**
   * Checks root certificate state.
   * @return "true" if certificate exists
   */
  private boolean isCertExists() {

    Map<String, String> configsMap = configs.getConfigsMap();
    String srvrKstrDir = configsMap.get(Configuration.SRVR_KSTR_DIR_KEY);
    String srvrCrtName = configsMap.get(Configuration.SRVR_CRT_NAME_KEY);
    File certFile = new File(srvrKstrDir + File.separator + srvrCrtName);
    LOG.debug("srvrKstrDir = " + srvrKstrDir);
    LOG.debug("srvrCrtName = " + srvrCrtName);
    LOG.debug("certFile = " + certFile.getAbsolutePath());

    return certFile.exists();
  }


  /**
   * Runs os command
   *
   * @return command execution exit code
   */
  private int runCommand(String command) {
    String line = null;
    Process process = null;
    BufferedReader br= null;
    try {
      process = Runtime.getRuntime().exec(command);
      br = new BufferedReader(new InputStreamReader(
          process.getInputStream(), Charset.forName("UTF8")));

      while ((line = br.readLine()) != null) {
        LOG.info(line);
      }

      try {
        process.waitFor();
        ShellCommandUtil.logOpenSslExitCode(command, process.exitValue());
        return process.exitValue(); //command is executed
      } catch (InterruptedException e) {
        e.printStackTrace();
      }
    } catch (IOException e) {
      e.printStackTrace();
    } finally {
      if (br != null) {
        try {
          br.close();
        } catch (IOException ioe) {
          ioe.printStackTrace();
        }
      }
    }

    return -1;//some exception occurred

  }

  private void generateServerCertificate() {
    LOG.info("Generation of server certificate");

    Map<String, String> configsMap = configs.getConfigsMap();
    String srvrKstrDir = configsMap.get(Configuration.SRVR_KSTR_DIR_KEY);
    String srvrCrtName = configsMap.get(Configuration.SRVR_CRT_NAME_KEY);
    String srvrKeyName = configsMap.get(Configuration.SRVR_KEY_NAME_KEY);
    String kstrName = configsMap.get(Configuration.KSTR_NAME_KEY);
    String srvrCrtPass = configsMap.get(Configuration.SRVR_CRT_PASS_KEY);

    Object[] scriptArgs = {srvrCrtPass, srvrKstrDir, srvrKeyName,
        srvrCrtName, kstrName};

    String command = MessageFormat.format(GEN_SRVR_KEY,scriptArgs);
    runCommand(command);

    command = MessageFormat.format(GEN_SRVR_REQ,scriptArgs);
    runCommand(command);

    command = MessageFormat.format(SIGN_SRVR_CRT,scriptArgs);
    runCommand(command);

    command = MessageFormat.format(EXPRT_KSTR,scriptArgs);
    runCommand(command);

  }

  /**
   * Returns server certificate content
   * @return string with server certificate content
   */
  public String getServerCert() {
    Map<String, String> configsMap = configs.getConfigsMap();
    File certFile = new File(configsMap.get(Configuration.SRVR_KSTR_DIR_KEY) +
        File.separator + configsMap.get(Configuration.SRVR_CRT_NAME_KEY));
    String srvrCrtContent = null;
    try {
      srvrCrtContent = FileUtils.readFileToString(certFile);
    } catch (IOException e) {
      LOG.error(e.getMessage());
    }
    return srvrCrtContent;
  }

  /**
   * Signs agent certificate
   * Adds agent certificate to server keystore
   * @return string with agent signed certificate content
   */
  public synchronized SignCertResponse signAgentCrt(String agentHostname, String agentCrtReqContent, String passphraseAgent) {
    SignCertResponse response = new SignCertResponse();
    LOG.info("Signing of agent certificate");
    LOG.info("Verifying passphrase");



    String passphraseSrvr = configs.getConfigsMap().get(Configuration.
        PASSPHRASE_KEY).trim();

    LOG.info("Pass phrase Server " + passphraseSrvr);
    LOG.info("Pass phrase Agent " + passphraseAgent);

    if (!passphraseSrvr.equals(passphraseAgent.trim())) {
      LOG.warn("Incorrect passphrase from the agent");
      response.setResult(SignCertResponse.ERROR_STATUS);
      response.setMessage("Incorrect passphrase from the agent");
      return response;
    }

    Map<String, String> configsMap = configs.getConfigsMap();
    String srvrKstrDir = configsMap.get(Configuration.SRVR_KSTR_DIR_KEY);
    String srvrCrtPass = configsMap.get(Configuration.SRVR_CRT_PASS_KEY);
    String srvrCrtName = configsMap.get(Configuration.SRVR_CRT_NAME_KEY);
    String srvrKeyName = configsMap.get(Configuration.SRVR_KEY_NAME_KEY);
    String agentCrtReqName = agentHostname + ".csr";
    String agentCrtName = agentHostname + ".crt";


    File agentCrtReqFile = new File(srvrKstrDir + File.separator +
        agentCrtReqName);
    try {
      FileUtils.writeStringToFile(agentCrtReqFile, agentCrtReqContent);
    } catch (IOException e1) {
      // TODO Auto-generated catch block
      e1.printStackTrace();
    }
    Object[] scriptArgs = {srvrKstrDir,agentCrtReqName,agentCrtName,
        srvrCrtPass,srvrKeyName,srvrCrtName};

    String command = MessageFormat.format(SIGN_AGENT_CRT,scriptArgs);

    LOG.debug(command);

    int commandExitCode = runCommand(command); // ssl command execution
    if(commandExitCode != 0) {
      response.setResult(SignCertResponse.ERROR_STATUS);
      response.setMessage(ShellCommandUtil.getOpenSslCommandResult(command, commandExitCode));
      //LOG.warn(ShellCommandUtil.getOpenSslCommandResult(command, commandExitCode));
      return response;
    }

    File agentCrtFile = new File(srvrKstrDir + File.separator + agentCrtName);
    String agentCrtContent = "";
    try {
      agentCrtContent = FileUtils.readFileToString(agentCrtFile);
    } catch (IOException e) {
      e.printStackTrace();
      LOG.error("Error reading signed agent certificate");
      response.setResult(SignCertResponse.ERROR_STATUS);
      response.setMessage("Error reading signed agent certificate");
      return response;
    }
    response.setResult(SignCertResponse.OK_STATUS);
    response.setSignedCa(agentCrtContent);
    //LOG.info(ShellCommandUtil.getOpenSslCommandResult(command, commandExitCode));
    return response;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/ClientSecurityType.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security;

public enum ClientSecurityType {
  LOCAL("local"),
  LDAP("ldap");

  private String value;
  ClientSecurityType(String value) {
    this.value = value;
  }

  /**
   * Constructs enum object from string representation
   * @param value string representation of client security type
   * @return ClientSecurityType (defaults to LOCAL if not recognized)
   */
  public static ClientSecurityType fromString(String value) {
    for (ClientSecurityType securityType : ClientSecurityType.values()) {
      if (securityType.toString().equalsIgnoreCase(value)) {
        return securityType;
      }
    }
    return LOCAL;
  }


  @Override
  public String toString() {
    return value;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/SecurityFilter.java,true,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.security;

import java.io.IOException;
import java.util.regex.Pattern;

import javax.servlet.Filter;
import javax.servlet.FilterChain;
import javax.servlet.FilterConfig;
import javax.servlet.ServletException;
import javax.servlet.ServletRequest;
import javax.servlet.ServletResponse;
import javax.servlet.http.HttpServletRequest;

import org.apache.ambari.server.controller.AmbariServer;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

public class SecurityFilter implements Filter {
	
  //Allowed pathes for one way auth https
  private static String CA = "/ca";
  private final static Log LOG = LogFactory.getLog(SecurityFilter.class);

  @Override
  public void destroy() {
  }

  @Override
  public void doFilter(ServletRequest serReq, ServletResponse serResp,
		FilterChain filtCh) throws IOException, ServletException {

    HttpServletRequest req = (HttpServletRequest) serReq;
    String reqUrl = req.getRequestURL().toString();
	
    if (serReq.getLocalPort() == AmbariServer.AGENT_ONE_WAY_AUTH) {
      if (isRequestAllowed(reqUrl)) {
        filtCh.doFilter(serReq, serResp);
      }
      else {
        LOG.warn("This request is not allowed on this port");
      }

	}
	else
      filtCh.doFilter(serReq, serResp);
  }

  @Override
  public void init(FilterConfig arg0) throws ServletException {
  }

  private boolean isRequestAllowed(String reqUrl) {
	try {

      boolean isMatch = Pattern.matches("https://[A-z]*:[0-9]*/cert/ca[/]*", reqUrl);
		
      if (isMatch)
    	  return true;
		
		 isMatch = Pattern.matches("https://[A-z]*:[0-9]*/certs/[A-z0-9-.]*", reqUrl);
		
		 if (isMatch)
			 return true;
		
		 isMatch = Pattern.matches("https://[A-z]*:[0-9]*/resources/.*", reqUrl);
		
		 if (isMatch)
			 return true;
		
	} catch (Exception e) {
	}
  LOG.warn("Request " + reqUrl + " doesn't match any pattern.");
	return false;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/SignCertResponse.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.security;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlElement;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlType;

/**
 *
 * Sign certificate response data model.
 *
 */
@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
@XmlType(name = "", propOrder = {})
public class SignCertResponse {
	
  public static final String ERROR_STATUS = "ERROR";
  public static final String OK_STATUS = "OK";

  @XmlElement
  private String result;
  @XmlElement
  private String signedCa;
  @XmlElement
  private String message;

  public String getResult() {
    return result;
  }
  public void setResult(String result) {
    this.result = result;
  }
  public String getSignedCa() {
    return signedCa;
  }
  public void setSignedCa(String signedCa) {
    this.signedCa = signedCa;
  }

  public String getMessage() {
    return message;
  }
  public void setMessage(String message) {
    this.message = message;
  }
}

"
ambari-server/src/main/java/org/apache/ambari/server/security/SignMessage.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.security;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlElement;
import javax.xml.bind.annotation.XmlRootElement;
import javax.xml.bind.annotation.XmlType;

/**
 *
 * Sign certificate request data model.
 *
 */
@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
@XmlType(name = "", propOrder = {})
public class SignMessage {

  @XmlElement
  private String csr;
  @XmlElement
  private String passphrase;
  public String getCsr() {
    return csr;
  }
  public void setCsr(String csr) {
    this.csr = csr;
  }
  public String getPassphrase() {
    return passphrase;
  }
  public void setPassphrase(String passphrase) {
    this.passphrase = passphrase;
  }
}

"
ambari-server/src/main/java/org/apache/ambari/server/security/authorization/AmbariLdapAuthenticationProvider.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.authorization;

import com.google.inject.Inject;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.ambari.server.security.ClientSecurityType;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.security.authentication.AuthenticationProvider;
import org.springframework.security.authentication.UsernamePasswordAuthenticationToken;
import org.springframework.security.core.Authentication;
import org.springframework.security.core.AuthenticationException;
import org.springframework.security.core.userdetails.UsernameNotFoundException;
import org.springframework.security.ldap.DefaultSpringSecurityContextSource;
import org.springframework.security.ldap.authentication.BindAuthenticator;
import org.springframework.security.ldap.authentication.LdapAuthenticationProvider;
import org.springframework.security.ldap.search.FilterBasedLdapUserSearch;


/**
 * Provides LDAP user authorization logic for Ambari Server
 */
public class AmbariLdapAuthenticationProvider implements AuthenticationProvider {
  private static final Logger log = LoggerFactory.getLogger(AmbariLdapAuthenticationProvider.class);

  Configuration configuration;

  private AmbariLdapAuthoritiesPopulator authoritiesPopulator;

  private ThreadLocal<LdapServerProperties> ldapServerProperties = new ThreadLocal<LdapServerProperties>();
  private ThreadLocal<LdapAuthenticationProvider> providerThreadLocal = new ThreadLocal<LdapAuthenticationProvider>();

  @Inject
  public AmbariLdapAuthenticationProvider(Configuration configuration, AmbariLdapAuthoritiesPopulator authoritiesPopulator) {
    this.configuration = configuration;
    this.authoritiesPopulator = authoritiesPopulator;
  }

  @Override
  public Authentication authenticate(Authentication authentication) throws AuthenticationException {

    if (isLdapEnabled()) {

      return loadLdapAuthenticationProvider().authenticate(authentication);

    } else {
      return null;
    }

  }

  @Override
  public boolean supports(Class<?> authentication) {
    return UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication);
  }

  /**
   * Reloads LDAP Context Source and depending objects if properties were changed
   * @return corresponding LDAP authentication provider
   */
  private LdapAuthenticationProvider loadLdapAuthenticationProvider() {
    if (reloadLdapServerProperties()) {
      log.info("LDAP Properties changed - rebuilding Context");
      DefaultSpringSecurityContextSource springSecurityContextSource =
              new DefaultSpringSecurityContextSource(ldapServerProperties.get().getLdapUrls(), ldapServerProperties.get().getBaseDN());

      if (!ldapServerProperties.get().isAnonymousBind()) {
        springSecurityContextSource.setUserDn(ldapServerProperties.get().getManagerDn());
        springSecurityContextSource.setPassword(ldapServerProperties.get().getManagerPassword());
      }

      try {
        springSecurityContextSource.afterPropertiesSet();
      } catch (Exception e) {
        log.error("LDAP Context Source not loaded ", e);
        throw new UsernameNotFoundException("LDAP Context Source not loaded", e);
      }

      //TODO change properties
      String userSearchBase = ldapServerProperties.get().getUserSearchBase();
      String userSearchFilter = ldapServerProperties.get().getUserSearchFilter();

      FilterBasedLdapUserSearch userSearch = new FilterBasedLdapUserSearch(userSearchBase, userSearchFilter, springSecurityContextSource);

      BindAuthenticator bindAuthenticator = new BindAuthenticator(springSecurityContextSource);
      bindAuthenticator.setUserSearch(userSearch);

      LdapAuthenticationProvider authenticationProvider = new LdapAuthenticationProvider(bindAuthenticator, authoritiesPopulator);

      providerThreadLocal.set(authenticationProvider);
    }

    return providerThreadLocal.get();
  }


  /**
   * Check if LDAP authentication is enabled in server properties
   * @return true if enabled
   */
  private boolean isLdapEnabled() {
    return configuration.getClientSecurityType() == ClientSecurityType.LDAP;
  }

  /**
   * Reloads LDAP Server properties from configuration
   *
   * @return true if properties were reloaded
   */
  private boolean reloadLdapServerProperties() {
    LdapServerProperties properties = configuration.getLdapServerProperties();
    if (!properties.equals(ldapServerProperties.get())) {
      log.info("Reloading properties");
      ldapServerProperties.set(properties);
      return true;
    }
    return false;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/authorization/AmbariLdapAuthoritiesPopulator.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.authorization;

import com.google.inject.Inject;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.ambari.server.orm.dao.RoleDAO;
import org.apache.ambari.server.orm.dao.UserDAO;
import org.apache.ambari.server.orm.entities.RoleEntity;
import org.apache.ambari.server.orm.entities.UserEntity;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.ldap.core.DirContextOperations;
import org.springframework.security.core.GrantedAuthority;
import org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator;

import java.util.Collection;

/**
 * Provides authorities population for LDAP user from local DB
 */
public class AmbariLdapAuthoritiesPopulator implements LdapAuthoritiesPopulator {
  private static final Logger log = LoggerFactory.getLogger(AmbariLdapAuthoritiesPopulator.class);

  Configuration configuration;
  private AuthorizationHelper authorizationHelper;
  UserDAO userDAO;
  RoleDAO roleDAO;

  @Inject
  public AmbariLdapAuthoritiesPopulator(Configuration configuration, AuthorizationHelper authorizationHelper,
                                        UserDAO userDAO, RoleDAO roleDAO) {
    this.configuration = configuration;
    this.authorizationHelper = authorizationHelper;
    this.userDAO = userDAO;
    this.roleDAO = roleDAO;
  }

  @Override
  @Transactional
  public Collection<? extends GrantedAuthority> getGrantedAuthorities(DirContextOperations userData, String username) {
    log.info("Get roles for user " + username + " from local DB");

    UserEntity user = null;

    user = userDAO.findLdapUserByName(username);

    if (user == null) {
      log.info("User " + username + " not present in local DB - creating");

      UserEntity newUser = new UserEntity();
      newUser.setLdapUser(true);
      newUser.setUserName(username);

      String roleName = (configuration.getConfigsMap().get(Configuration.USER_ROLE_NAME_KEY));
      log.info("Using default role name " + roleName);

      RoleEntity role = roleDAO.findByName(roleName);

      if (role == null) {
        log.info("Role " + roleName + " not present in local DB - creating");
        role = new RoleEntity();
        role.setRoleName(roleName);
        roleDAO.create(role);
        role = roleDAO.findByName(role.getRoleName());
      }

      userDAO.create(newUser);

      user = userDAO.findLdapUserByName(newUser.getUserName());

      user.getRoleEntities().add(role);
      role.getUserEntities().add(user);
      roleDAO.merge(role);
      userDAO.merge(user);
    }

    return authorizationHelper.convertRolesToAuthorities(user.getRoleEntities());
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/authorization/AmbariLocalUserDetailsService.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.authorization;

import com.google.inject.Inject;
import com.google.inject.Injector;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.ambari.server.orm.dao.RoleDAO;
import org.apache.ambari.server.orm.dao.UserDAO;
import org.apache.ambari.server.orm.entities.UserEntity;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.security.core.userdetails.User;
import org.springframework.security.core.userdetails.UserDetails;
import org.springframework.security.core.userdetails.UserDetailsService;
import org.springframework.security.core.userdetails.UsernameNotFoundException;


public class AmbariLocalUserDetailsService implements UserDetailsService {
  private static final Logger log = LoggerFactory.getLogger(AmbariLocalUserDetailsService.class);

  Injector injector;
  Configuration configuration;
  private AuthorizationHelper authorizationHelper;
  UserDAO userDAO;
  RoleDAO roleDAO;

  @Inject
  public AmbariLocalUserDetailsService(Injector injector, Configuration configuration,
                                       AuthorizationHelper authorizationHelper, UserDAO userDAO, RoleDAO roleDAO) {
    this.injector = injector;
    this.configuration = configuration;
    this.authorizationHelper = authorizationHelper;
    this.userDAO = userDAO;
    this.roleDAO = roleDAO;
  }

  /**
   * Loads Spring Security UserDetails from identity storage according to Configuration
   *
   * @param username username
   * @return UserDetails
   * @throws UsernameNotFoundException when user not found or have empty roles
   */
  @Override
  public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
    log.info("Loading user by name: " + username);

    UserEntity user = userDAO.findLocalUserByName(username);

    if (user == null) {
      log.info("user not found ");
      throw new UsernameNotFoundException("Username " + username + " not found");
    }else if (user.getRoleEntities().isEmpty()) {
      log.info("No authorities for user");
      throw new UsernameNotFoundException("Username " + username + " has no roles");
    }

    return new User(user.getUserName(), user.getUserPassword(),
            authorizationHelper.convertRolesToAuthorities(user.getRoleEntities()));
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/security/authorization/AuthorizationHelper.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.authorization;

import com.google.inject.Singleton;
import org.apache.ambari.server.orm.entities.RoleEntity;
import org.springframework.security.core.GrantedAuthority;
import org.springframework.security.core.authority.SimpleGrantedAuthority;

import java.util.ArrayList;
import java.util.Collection;
import java.util.List;

@Singleton
/**
 * Provides utility methods for authentication functionality
 */
public class AuthorizationHelper {

  /**
   * Converts collection of RoleEntities to collection of GrantedAuthorities
   */
  public Collection<GrantedAuthority> convertRolesToAuthorities(Collection<RoleEntity> roleEntities) {
    List<GrantedAuthority> authorities = new ArrayList<GrantedAuthority>(roleEntities.size());

    for (RoleEntity roleEntity : roleEntities) {
      authorities.add(new SimpleGrantedAuthority(roleEntity.getRoleName().toUpperCase()));
    }

    return authorities;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/authorization/LdapServerProperties.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.authorization;

import org.apache.commons.lang.StringUtils;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

/**
 * Describes LDAP Server connection parameters
 */
public class LdapServerProperties {

  private String primaryUrl;
  private String secondaryUrl;
  private boolean useSsl;
  private boolean anonymousBind;
  private String managerDn;
  private String managerPassword;
  private String baseDN;
  private String userSearchBase = "";
  private String usernameAttribute;

  private static final String userSearchFilter = "({attribute}={0})";

  public List<String> getLdapUrls() {
    String protocol = useSsl ? "ldaps://" : "ldap://";

    if (StringUtils.isEmpty(primaryUrl)) {
      return Collections.emptyList();
    } else {
      List<String> list = new ArrayList<String>();
      list.add(protocol + primaryUrl);
      if (!StringUtils.isEmpty(secondaryUrl)) {
        list.add(protocol + secondaryUrl);
      }
      return list;
    }
  }

  public String getPrimaryUrl() {
    return primaryUrl;
  }

  public void setPrimaryUrl(String primaryUrl) {
    this.primaryUrl = primaryUrl;
  }

  public String getSecondaryUrl() {
    return secondaryUrl;
  }

  public void setSecondaryUrl(String secondaryUrl) {
    this.secondaryUrl = secondaryUrl;
  }

  public boolean isUseSsl() {
    return useSsl;
  }

  public void setUseSsl(boolean useSsl) {
    this.useSsl = useSsl;
  }

  public boolean isAnonymousBind() {
    return anonymousBind;
  }

  public void setAnonymousBind(boolean anonymousBind) {
    this.anonymousBind = anonymousBind;
  }

  public String getManagerDn() {
    return managerDn;
  }

  public void setManagerDn(String managerDn) {
    this.managerDn = managerDn;
  }

  public String getManagerPassword() {
    return managerPassword;
  }

  public void setManagerPassword(String managerPassword) {
    this.managerPassword = managerPassword;
  }

  public String getBaseDN() {
    return baseDN;
  }

  public void setBaseDN(String baseDN) {
    this.baseDN = baseDN;
  }

  public String getUserSearchBase() {
    return userSearchBase;
  }

  public void setUserSearchBase(String userSearchBase) {
    this.userSearchBase = userSearchBase;
  }

  public String getUserSearchFilter() {
    return userSearchFilter.replace("{attribute}", usernameAttribute);
  }

  public String getUsernameAttribute() {
    return usernameAttribute;
  }

  public void setUsernameAttribute(String usernameAttribute) {
    this.usernameAttribute = usernameAttribute;
  }

  @Override
  public boolean equals(Object obj) {
    if (this == obj) return true;
    if (obj == null || getClass() != obj.getClass()) return false;

    LdapServerProperties that = (LdapServerProperties) obj;

    if (primaryUrl != null ? !primaryUrl.equals(that.primaryUrl) : that.primaryUrl != null) return false;
    if (secondaryUrl != null ? !secondaryUrl.equals(that.secondaryUrl) : that.secondaryUrl != null) return false;
    if (useSsl!=that.useSsl) return false;
    if (anonymousBind!=that.anonymousBind) return false;
    if (managerDn != null ? !managerDn.equals(that.managerDn) : that.managerDn != null) return false;
    if (managerPassword != null ? !managerPassword.equals(that.managerPassword) : that.managerPassword != null)
      return false;
    if (baseDN != null ? !baseDN.equals(that.baseDN) : that.baseDN != null) return false;
    if (userSearchBase != null ? !userSearchBase.equals(that.userSearchBase) : that.userSearchBase != null)
      return false;
    if (usernameAttribute != null ? !usernameAttribute.equals(that.usernameAttribute) : that.usernameAttribute != null)
      return false;

    return true;
  }

  @Override
  public int hashCode() {
    int result = primaryUrl != null ? primaryUrl.hashCode() : 0;
    result = 31 * result + (secondaryUrl != null ? secondaryUrl.hashCode() : 0);
    result = 31 * result + (useSsl ? 1 : 0);
    result = 31 * result + (anonymousBind ? 1 : 0);
    result = 31 * result + (managerDn != null ? managerDn.hashCode() : 0);
    result = 31 * result + (managerPassword != null ? managerPassword.hashCode() : 0);
    result = 31 * result + (baseDN != null ? baseDN.hashCode() : 0);
    result = 31 * result + (userSearchBase != null ? userSearchBase.hashCode() : 0);
    result = 31 * result + (usernameAttribute != null ? usernameAttribute.hashCode() : 0);
    return result;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/security/authorization/User.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.authorization;

import org.apache.ambari.server.orm.entities.RoleEntity;
import org.apache.ambari.server.orm.entities.UserEntity;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Date;

/**
 * Describes user of web-services
 */
public class User {
  final int userId;
  final String userName;
  final boolean ldapUser;
  final Date createTime;
  final Collection<String> roles = new ArrayList<String>();

  User(UserEntity userEntity) {
    userId = userEntity.getUserId();
    userName = userEntity.getUserName();
    createTime = userEntity.getCreateTime();
    ldapUser = userEntity.getLdapUser();
    for (RoleEntity roleEntity : userEntity.getRoleEntities()) {
      roles.add(roleEntity.getRoleName());
    }
  }

  public int getUserId() {
    return userId;
  }

  public String getUserName() {
    return userName;
  }

  public boolean isLdapUser() {
    return ldapUser;
  }

  public Date getCreateTime() {
    return createTime;
  }

  public Collection<String> getRoles() {
    return roles;
  }

  @Override
  public String toString() {
    return (ldapUser ? "[LDAP]" : "[LOCAL]") + userName;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/authorization/Users.java,true,"/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.authorization;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.configuration.Configuration;
import org.apache.ambari.server.orm.dao.RoleDAO;
import org.apache.ambari.server.orm.dao.UserDAO;
import org.apache.ambari.server.orm.entities.RoleEntity;
import org.apache.ambari.server.orm.entities.UserEntity;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.security.crypto.password.PasswordEncoder;

import com.google.inject.Inject;
import com.google.inject.Singleton;
import com.google.inject.persist.Transactional;

/**
 * Provides high-level access to Users and Roles in database
 */
@Singleton
public class Users {

  private final static Logger LOG = LoggerFactory.getLogger(Users.class);

  @Inject
  protected UserDAO userDAO;
  @Inject
  protected RoleDAO roleDAO;
  @Inject
  protected PasswordEncoder passwordEncoder;
  @Inject
  protected Configuration configuration;


  public List<User> getAllUsers() {
    List<UserEntity> userEntities = userDAO.findAll();
    List<User> users = new ArrayList<User>(userEntities.size());

    for (UserEntity userEntity : userEntities) {
      users.add(new User(userEntity));
    }

    return users;
  }

  public User getUser(int userId) throws AmbariException {
    UserEntity userEntity = userDAO.findByPK(userId);
    if (userEntity != null) {
      return new User(userEntity);
    } else {
      throw new AmbariException("User with id '" + userId + " not found");
    }
  }

  public User getAnyUser(String userName) {
    UserEntity userEntity = userDAO.findLdapUserByName(userName);
    if (null == userEntity) {
      userEntity = userDAO.findLocalUserByName(userName);
    }

    return (null == userEntity) ? null : new User(userEntity);
  }

  public User getLocalUser(String userName) throws AmbariException{
    UserEntity userEntity = userDAO.findLocalUserByName(userName);
    if (userEntity == null) {
      throw new AmbariException("User doesn't exist");
    }
    return new User(userEntity);
  }

  public User getLdapUser(String userName) throws AmbariException{
    UserEntity userEntity = userDAO.findLdapUserByName(userName);
    if (userEntity == null) {
      throw new AmbariException("User doesn't exist");
    }
    return new User(userEntity);
  }

  /**
   * Modifies password of local user
   * @throws AmbariException
   */
  public synchronized void modifyPassword(String userName, String oldPassword, String newPassword) throws AmbariException {
    UserEntity userEntity = userDAO.findLocalUserByName(userName);
    if (userEntity != null) {
      if (passwordEncoder.matches(oldPassword, userEntity.getUserPassword())) {
        userEntity.setUserPassword(passwordEncoder.encode(newPassword));
        userDAO.merge(userEntity);
      } else {
        throw new AmbariException("Wrong password provided");
      }

    } else {
      userEntity = userDAO.findLdapUserByName(userName);
      if (userEntity != null) {
        throw new AmbariException("Password of LDAP user cannot be modified");
      } else {
        throw new AmbariException("User " + userName + " not found");
      }
    }
  }

  /**
   * Creates new local user with provided userName and password
   */
  @Transactional
  public synchronized void createUser(String userName, String password) {
    UserEntity userEntity = new UserEntity();
    userEntity.setUserName(userName);
    userEntity.setUserPassword(passwordEncoder.encode(password));
    userEntity.setRoleEntities(new HashSet<RoleEntity>());

    RoleEntity roleEntity = roleDAO.findByName(getUserRole());
    if (roleEntity == null) {
      createRole(getUserRole());
    }
    roleEntity = roleDAO.findByName(getUserRole());

    userEntity.getRoleEntities().add(roleEntity);
    userDAO.create(userEntity);

    roleEntity.getUserEntities().add(userEntity);
    roleDAO.merge(roleEntity);
  }

  @Transactional
  public synchronized void removeUser(User user) throws AmbariException {
    UserEntity userEntity = userDAO.findByPK(user.getUserId());
    if (userEntity != null) {
      userDAO.remove(userEntity);
    } else {
      throw new AmbariException("User " + user + " doesn't exist");
    }
  }

  /**
   * Grants ADMIN role to provided user
   * @throws AmbariException
   */
  public synchronized void promoteToAdmin(User user) throws AmbariException{
    addRoleToUser(user, getAdminRole());
  }

  /**
   * Removes ADMIN role form provided user
   * @throws AmbariException
   */
  public synchronized void demoteAdmin(User user) throws AmbariException {
    removeRoleFromUser(user, getAdminRole());
  }

  @Transactional
  public synchronized void addRoleToUser(User user, String role)
      throws AmbariException {

    UserEntity userEntity = userDAO.findByPK(user.getUserId());
    if (userEntity == null) {
      throw new AmbariException("User " + user + " doesn't exist");
    }

    RoleEntity roleEntity = roleDAO.findByName(role);
    if (roleEntity == null) {
      LOG.warn("Trying to add user to non-existent role"
          + ", user=" + user.getUserName()
          + ", role=" + role);
      throw new AmbariException("Role " + role + " doesn't exist");
    }

    if (!userEntity.getRoleEntities().contains(roleEntity)) {
      userEntity.getRoleEntities().add(roleEntity);
      roleEntity.getUserEntities().add(userEntity);
      userDAO.merge(userEntity);
      roleDAO.merge(roleEntity);
    } else {
      throw new AmbariException("User " + user + " already owns role " + role);
    }

  }

  @Transactional
  public synchronized void removeRoleFromUser(User user, String role)
      throws AmbariException {
    UserEntity userEntity = userDAO.findByPK(user.getUserId());
    if (userEntity == null) {
      throw new AmbariException("User " + user + " doesn't exist");
    }

    RoleEntity roleEntity = roleDAO.findByName(role);
    if (roleEntity == null) {
      throw new AmbariException("Role " + role + " doesn't exist");
    }

    if (userEntity.getRoleEntities().contains(roleEntity)) {
      userEntity.getRoleEntities().remove(roleEntity);
      roleEntity.getUserEntities().remove(userEntity);
      userDAO.merge(userEntity);
      roleDAO.merge(roleEntity);
    } else {
      throw new AmbariException("User " + user + " doesn't own role " + role);
    }

  }

  public String getUserRole() {
    return configuration.getConfigsMap().get(Configuration.USER_ROLE_NAME_KEY);
  }

  public String getAdminRole() {
    return configuration.getConfigsMap().get(Configuration.ADMIN_ROLE_NAME_KEY);
  }

  /**
   * Creates new role
   */
  public void createRole(String role) {
    RoleEntity roleEntity = new RoleEntity();
    roleEntity.setRoleName(role);
    roleDAO.create(roleEntity);
  }

  /**
   * Creates ADMIN adn USER roles if not present
   */
  public synchronized void createDefaultRoles() {
    if (roleDAO.findByName(getUserRole()) == null) {
      createRole(getUserRole());
    }
    if (roleDAO.findByName(getAdminRole()) == null) {
      createRole(getAdminRole());
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/security/unsecured/rest/CertificateDownload.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.unsecured.rest;


import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.apache.ambari.server.security.CertificateManager;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;

@Path("/cert/ca")
public class CertificateDownload {
  private static Log LOG = LogFactory.getLog(CertificateDownload.class);
  private static CertificateManager certMan;

  @Inject
  public static void init(CertificateManager instance) {
    certMan = instance;
  }

  @GET
  @Produces({MediaType.TEXT_PLAIN})
  public String downloadSrvrCrt() {
    return certMan.getServerCert();
  }


}
"
ambari-server/src/main/java/org/apache/ambari/server/security/unsecured/rest/CertificateSign.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.security.unsecured.rest;


import javax.servlet.http.HttpServletRequest;
import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import javax.ws.rs.Produces;
import javax.ws.rs.core.Context;
import javax.ws.rs.core.MediaType;

import org.apache.ambari.server.security.CertificateManager;
import org.apache.ambari.server.security.SignCertResponse;
import org.apache.ambari.server.security.SignMessage;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import com.google.inject.Inject;
@Path("/certs")
public class CertificateSign {
  private static Log LOG = LogFactory.getLog(CertificateSign.class);
  private static CertificateManager certMan;

  @Inject
  public static void init(CertificateManager instance) {
    certMan = instance;
  }

  /**
   * Signs agent certificate
   * @response.representation.200.doc This API is invoked by Ambari agent running
   *  on a cluster to register with the server.
   * @response.representation.200.mediaType application/json
   * @response.representation.406.doc Error in register message format
   * @response.representation.408.doc Request Timed out
   * @param message Register message
   * @throws Exception
   */
  @Path("{hostName}")
  @POST
  @Consumes(MediaType.APPLICATION_JSON)
  @Produces({MediaType.APPLICATION_JSON, MediaType.APPLICATION_XML})
  public SignCertResponse signAgentCrt(@PathParam("hostName") String hostname,
                                       SignMessage message, @Context HttpServletRequest req) {
    return certMan.signAgentCrt(hostname, message.getCsr(), message.getPassphrase());
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/serveraction/kerberos/KerberosCredential.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.serveraction.kerberos;

import com.google.gson.Gson;
import com.google.gson.JsonSyntaxException;
import org.apache.ambari.server.AmbariException;
import org.apache.commons.codec.binary.Base64;

import javax.crypto.BadPaddingException;
import javax.crypto.Cipher;
import javax.crypto.IllegalBlockSizeException;
import javax.crypto.NoSuchPaddingException;
import javax.crypto.spec.SecretKeySpec;
import java.security.InvalidKeyException;
import java.security.NoSuchAlgorithmException;
import java.util.Arrays;
import java.util.Map;

/**
 * KerberosCredential encapsulates data needed to authenticate an identity to a KDC.
 * <p/>
 * This class has the ability to encrypt and decrypt itself using the AES encryption algorithm.
 */
public class KerberosCredential {

  /**
   * A property name used to hold the KDC administrator's principal value.
   */
  public static final String KEY_NAME_PRINCIPAL = "principal";
  /**
   * A property name used to hold the KDC administrator's password value.
   */
  public static final String KEY_NAME_PASSWORD = "password";
  /**
   * A property name used to hold the KDC administrator's (base64-encoded) keytab
   * value.
   */
  public static final String KEY_NAME_KEYTAB = "keytab";

  /**
   * This principal value
   */
  private String principal = null;

  /**
   * The plaintext password value
   */
  private String password = null;

  /**
   * A base64-encoded keytab
   */
  private String keytab = null;

  /**
   * Given a Map of attributes, attempts to safely retrieve the data needed to create a
   * KerberosCredential representing a KDC administrator.
   * <p/>
   * It is expected that the following properties exist in the Map:
   * <ul>
   * <li>principal</li>
   * <li>password (optional)</li>
   * <li>keytab (optional)</li>
   * </ul>
   * <p/>
   * Each of these properties may be prefixed with some prefix value to generate a relevant key value.
   * If prefix was "kerberos_admin/", then the key representing the principal would be computed
   * to be "kerberos_admin/principal".
   *
   * @param map    a Map of attributes containing the values needed to create a new KerberosCredential
   * @param prefix a String containing the prefix to used along with the base key name (principal, etc...)
   *               to create the relevant key name ([prefix]base_key. etc...)
   * @return a KerberosCredential or null if commandParameters is null
   */
  public static KerberosCredential fromMap(Map<String, Object> map, String prefix) {
    KerberosCredential credential = null;

    if (map != null) {
      Object attribute;
      String principal;
      String password;
      String keytab;

      if (prefix == null) {
        prefix = "";
      }

      attribute = map.get(prefix + KEY_NAME_PRINCIPAL);
      principal = (attribute == null) ? null : attribute.toString();

      attribute = map.get(prefix + KEY_NAME_PASSWORD);
      password = (attribute == null) ? null : attribute.toString();

      attribute = map.get(prefix + KEY_NAME_KEYTAB);
      keytab = (attribute == null) ? null : attribute.toString();

      if (((principal != null) && !principal.isEmpty()) ||
          ((password != null) && !password.isEmpty()) ||
          ((keytab != null) && !keytab.isEmpty())) {
        credential = new KerberosCredential(principal, password, keytab);
      }
    }

    return credential;
  }

  /**
   * Decrypts a String containing base64-encoded encrypted data into a new KerberosCredential.
   * <p/>
   * Given a key and a base64-encoded set of bytes containing encrypted data (ideally obtained from
   * {@link #encrypt(KerberosCredential, byte[])} or {@link #encrypt(byte[])}, decodes and decrypts
   * into a new KerberosCredential.
   *
   * @param cipherText a String containing base64-encoded encrypted data
   * @param key        an array of bytes used to decrypt the encrypted data
   * @return a new KerberosCredential
   * @throws AmbariException if an error occurs while decrypting the data
   */
  public static KerberosCredential decrypt(String cipherText, byte[] key) throws AmbariException {
    if (cipherText == null) {
      return null;
    } else {
      try {
        SecretKeySpec secretKey = new SecretKeySpec(Arrays.copyOf(key, 16), "AES");
        Cipher cipher = Cipher.getInstance("AES/ECB/PKCS5Padding");
        cipher.init(Cipher.DECRYPT_MODE, secretKey);
        byte[] plaintext = cipher.doFinal(Base64.decodeBase64(cipherText));
        return new Gson().fromJson(new String(plaintext), KerberosCredential.class);
      } catch (NoSuchAlgorithmException e) {
        throw new AmbariException("Failed to decrypt cipher text due to invalid encryption algorithm", e);
      } catch (NoSuchPaddingException e) {
        throw new AmbariException("Failed to decrypt cipher text due to invalid padding scheme algorithm", e);
      } catch (IllegalBlockSizeException e) {
        throw new AmbariException("Failed to decrypt cipher text due to invalid block size", e);
      } catch (BadPaddingException e) {
        throw new AmbariException("Failed to decrypt cipher text due to invalid padding", e);
      } catch (InvalidKeyException e) {
        throw new AmbariException("Failed to decrypt cipher text due to invalid key", e);
      } catch (JsonSyntaxException e) {
        throw new AmbariException("Failed to decrypt cipher, cannot parse data into a KerberosCredential", e);
      }
    }
  }

  /**
   * Encrypts a KerberosCredential into a base64-encoded set of bytes.
   * <p/>
   * Given a KerberosCredential and a key, serializes the data into a JSON-formatted string and
   * encrypts it.
   *
   * @param kerberosCredential the KerberosCredential to encrypt
   * @param key                an array of bytes used to decrypt the encrypted data
   * @return a String containing base64-encoded encrypted data
   * @throws AmbariException if an error occurs while encrypting the KerberosCredential
   */
  public static String encrypt(KerberosCredential kerberosCredential, byte[] key) throws AmbariException {
    if (kerberosCredential == null) {
      return null;
    } else {
      try {
        SecretKeySpec secretKey = new SecretKeySpec(Arrays.copyOf(key, 16), "AES");
        Cipher cipher = Cipher.getInstance("AES/ECB/PKCS5Padding");
        cipher.init(Cipher.ENCRYPT_MODE, secretKey);
        String plaintext = new Gson().toJson(kerberosCredential);
        return Base64.encodeBase64String(cipher.doFinal(plaintext.getBytes()));
      } catch (NoSuchAlgorithmException e) {
        throw new AmbariException("Failed to encrypt plaintext due to invalid encryption algorithm", e);
      } catch (NoSuchPaddingException e) {
        throw new AmbariException("Failed to encrypt plaintext due to invalid padding scheme algorithm", e);
      } catch (IllegalBlockSizeException e) {
        throw new AmbariException("Failed to encrypt plaintext due to invalid key", e);
      } catch (BadPaddingException e) {
        throw new AmbariException("Failed to encrypt plaintext due to unexpected reasons", e);
      } catch (InvalidKeyException e) {
        throw new AmbariException("Failed to encrypt plaintext due to invalid key", e);
      }
    }
  }

  /**
   * Creates an empty KerberosCredential
   */
  public KerberosCredential() {
    principal = null;
    password = null;
    keytab = null;
  }

  /**
   * Creates a new KerberosCredential
   *
   * @param principal a String containing the principal name for this Kerberos credential
   * @param password  a String containing the password for this Kerberos credential
   * @param keytab    a String containing the base64 encoded keytab for this Kerberos credential
   */
  public KerberosCredential(String principal, String password, String keytab) {
    this.principal = principal;
    this.password = password;
    this.keytab = keytab;
  }

  /**
   * @return a String containing the principal name for this Kerberos credential
   */
  public String getPrincipal() {
    return principal;
  }

  /**
   * @param principal a String containing the principal name for this Kerberos credential
   */
  public void setPrincipal(String principal) {
    this.principal = principal;
  }

  /**
   * @return a String containing the password for this Kerberos credential
   */
  public String getPassword() {
    return password;
  }

  /**
   * @param password a String containing the password for this Kerberos credential
   */
  public void setPassword(String password) {
    this.password = password;
  }

  /**
   * @return a String containing the base64 encoded keytab for this Kerberos credential
   */
  public String getKeytab() {
    return keytab;
  }

  /**
   * @param keytab a String containing the base64 encoded keytab for this Kerberos credential
   */
  public void setKeytab(String keytab) {
    this.keytab = keytab;
  }

  /**
   * Encrypts this KerberosCredential into a base64-encoded set of bytes.
   * <p/>
   * Serializes this KerberosCredential into a JSON-formatted string and
   * encrypts it using the supplied key.
   *
   * @param key an array of bytes used to decrypt the encrypted data
   * @return a String containing base64-encoded encrypted data
   * @throws AmbariException if an error occurs while encrypting the KerberosCredential
   */
  public String encrypt(byte[] key) throws AmbariException {
    return encrypt(this, key);
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/stageplanner/RoleGraph.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.stageplanner;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.TreeMap;

import org.apache.ambari.server.actionmanager.HostRoleCommand;
import org.apache.ambari.server.actionmanager.Stage;
import org.apache.ambari.server.metadata.RoleCommandOrder;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

public class RoleGraph {

  private static Log LOG = LogFactory.getLog(RoleGraph.class);

  Map<String, RoleGraphNode> graph = null;
  private RoleCommandOrder roleDependencies;
  private Stage initialStage = null;
  private boolean sameHostOptimization = true;

  public RoleGraph(RoleCommandOrder rd) {
    this.roleDependencies = rd;
  }

  /**
   * Given a stage builds a DAG of all execution commands within the stage.
   */
  public void build(Stage stage) {
    if (stage == null) {
      throw new IllegalArgumentException("Null stage");
    }
    graph = new TreeMap<String, RoleGraphNode>();
    initialStage = stage;

    Map<String, Map<String, HostRoleCommand>> hostRoleCommands = stage.getHostRoleCommands();
    for (String host : hostRoleCommands.keySet()) {
      for (String role : hostRoleCommands.get(host).keySet()) {
        HostRoleCommand hostRoleCommand = hostRoleCommands.get(host).get(role);
        RoleGraphNode rgn;
        if (graph.get(role) == null) {
          rgn = new RoleGraphNode(hostRoleCommand.getRole(),
              hostRoleCommand.getRoleCommand());
          graph.put(role, rgn);
        }
        rgn = graph.get(role);
        rgn.addHost(host);
      }
    }

    //Add edges
    for (String roleI : graph.keySet()) {
      for (String roleJ : graph.keySet()) {
        if (roleI.equals(roleJ)) {
          continue;
        } else {
          RoleGraphNode rgnI = graph.get(roleI);
          RoleGraphNode rgnJ = graph.get(roleJ);
          int order = roleDependencies.order(rgnI, rgnJ);
          if (order == -1) {
            rgnI.addEdge(rgnJ);
          } else if (order == 1) {
            rgnJ.addEdge(rgnI);
          }
        }
      }
    }
  }

  /**
   * Returns a list of stages that need to be executed one after another
   * to execute the DAG generated in the last {@link #build(Stage)} call.
   */
  public List<Stage> getStages() {
    long initialStageId = initialStage.getStageId();
    List<Stage> stageList = new ArrayList<Stage>();
    List<RoleGraphNode> firstStageNodes = new ArrayList<RoleGraphNode>();
    while (!graph.isEmpty()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(this.stringifyGraph());
      }

      for (String role: graph.keySet()) {
        RoleGraphNode rgn = graph.get(role);
        if (rgn.getInDegree() == 0) {
          firstStageNodes.add(rgn);
        }
      }
      Stage aStage = getStageFromGraphNodes(initialStage, firstStageNodes);
      aStage.setStageId(++initialStageId);
      stageList.add(aStage);
      //Remove first stage nodes from the graph, we know that none of
      //these nodes have an incoming edges.
      for (RoleGraphNode rgn : firstStageNodes) {
        if (this.sameHostOptimization) {
          //Perform optimization
        }
        removeZeroInDegreeNode(rgn.getRole().toString());
      }
      firstStageNodes.clear();
    }
    return stageList;
  }

  /**
   * Assumes there are no incoming edges.
   */
  private synchronized void removeZeroInDegreeNode(String role) {
    RoleGraphNode nodeToRemove = graph.remove(role);
    for (RoleGraphNode edgeNode: nodeToRemove.getEdges()) {
      edgeNode.decrementInDegree();
    }
  }

  private Stage getStageFromGraphNodes(Stage origStage,
      List<RoleGraphNode> stageGraphNodes) {
    Stage newStage = new Stage(origStage.getRequestId(),
        origStage.getLogDir(), origStage.getClusterName());
    newStage.setSuccessFactors(origStage.getSuccessFactors());
    for (RoleGraphNode rgn : stageGraphNodes) {
      for (String host : rgn.getHosts()) {
        newStage.addExecutionCommandWrapper(origStage, host, rgn.getRole());
      }
    }
    return newStage;
  }

  public String stringifyGraph() {
    StringBuilder builder = new StringBuilder();
    builder.append("Graph:\n");
    for (String role : graph.keySet()) {
      builder.append(graph.get(role));
      for (RoleGraphNode rgn : graph.get(role).getEdges()) {
        builder.append(" --> ");
        builder.append(rgn);
      }
      builder.append("\n");
    }
    return builder.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/stageplanner/RoleGraphNode.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.stageplanner;

import java.util.ArrayList;
import java.util.Collection;
import java.util.List;
import java.util.Map;
import java.util.TreeMap;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.RoleCommand;

public class RoleGraphNode {
  public RoleGraphNode(Role role, RoleCommand command) {
    this.role = role;
    this.command = command;
  }
  private Role role;
  private RoleCommand command;
  private int inDegree = 0;
  private List<String> hosts = new ArrayList<String>();
  private Map<String, RoleGraphNode> edges = new TreeMap<String, RoleGraphNode>();
  public synchronized void addHost(String host) {
    hosts.add(host);
  }
  public synchronized void addEdge(RoleGraphNode rgn) {
    if (edges.containsKey(rgn.getRole().toString())) {
      return;
    }
    edges.put(rgn.getRole().toString(), rgn);
    rgn.incrementInDegree();
  }
  private synchronized void incrementInDegree() {
    inDegree ++;
  }
  public Role getRole() {
    return role;
  }
  public RoleCommand getCommand() {
    return command;
  }
  public List<String> getHosts() {
    return hosts;
  }
  public int getInDegree() {
    return inDegree;
  }
  
  Collection<RoleGraphNode> getEdges() {
    return edges.values();
  }
  public synchronized void decrementInDegree() {
    inDegree --;
  }
  
  @Override
  public String toString() {
    StringBuilder builder = new StringBuilder();
    builder.append("("+role+", "+command +", "+inDegree+")");
    return builder.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/AgentVersion.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

/**
 * Agent Version representation
 */
public class AgentVersion {

  private final String version;

  public AgentVersion(String version) {
    this.version = version;
  }

  /**
   * @return the version
   */
  public String getVersion() {
    return version;
  }

  @Override
  public boolean equals(Object object) {
    if (!(object instanceof AgentVersion)) {
      return false;
    }
    if (this == object) {
      return true;
    }
    AgentVersion a = (AgentVersion) object;
    return a.version.equals(this.version);
  }

  @Override
  public int hashCode() {
    int result = version != null ? version.hashCode() : 0;
    return result;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/Cluster.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.Collection;
import java.util.List;
import java.util.Map;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.ClusterResponse;

public interface Cluster {

  /**
   * Get the cluster ID
   */
  public long getClusterId();

  /**
   * Get the Cluster Name
   */
  public String getClusterName();

  /**
   * Set the Cluster Name
   */
  public void setClusterName(String clusterName);

  /**
   * Add a service to a cluster
   * @param service
   */
  public void addService(Service service) throws AmbariException;

  /**
   * Get a service
   * @param serviceName
   * @return
   */
  public Service getService(String serviceName) throws AmbariException;

  /**
   * Get all services
   * @return
   */
  public Map<String, Service> getServices();

  /**
   * Get all ServiceComponentHosts on a given host
   * @param hostname
   * @return
   */
  public List<ServiceComponentHost> getServiceComponentHosts(String hostname);

  /**
   * Get Stack Version
   * @return
   */
  public StackId getDesiredStackVersion();

  /**
   * Set stack version
   * @param stackVersion
   */
  public void setDesiredStackVersion(StackId stackVersion);

  public Map<String, Config> getDesiredConfigsByType(String configType);

  public Config getDesiredConfig(String configType, String versionTag);

  public void addDesiredConfig(Config config);

  public Collection<Config> getAllConfigs();

  public ClusterResponse convertToResponse() throws AmbariException;

  public void refresh();

  public void debugDump(StringBuilder sb);

  Service addService(String serviceName) throws AmbariException;

  public void deleteAllServices() throws AmbariException;

  public void deleteService(String serviceName) throws AmbariException;

  public boolean canBeRemoved();
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/Clusters.java,true,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state;

import java.util.List;
import java.util.Map;
import java.util.Set;

import org.apache.ambari.server.AmbariException;

/**
 * Single entity that tracks all clusters and hosts that are managed
 * by the Ambari server
 */
public interface Clusters {

  /**
   * Add a new Cluster
   * @param clusterName
   */
  public void addCluster(String clusterName) throws AmbariException;

  /**
   * Get the Cluster given the cluster name
   * @param clusterName Name of the Cluster to retrieve
   * @return
   */
  public Cluster getCluster(String clusterName) throws AmbariException;

  /**
   * Get all known clusters
   * @return
   */
  public Map<String, Cluster> getClusters();

  /**
   * Get all hosts being tracked by the Ambari server
   * @return
   */
  public List<Host> getHosts();

  /**
   * Returns all the cluster names for this hostname.
   * @param hostname
   * @return List of cluster names
   * @throws AmbariException
   */
  public Set<Cluster> getClustersForHost(String hostname)
      throws AmbariException;


  /**
   * Get a Host object managed by this server
   * @param hostname Name of the host requested
   * @return Host object
   * @throws AmbariException
   */
  public Host getHost(String hostname) throws AmbariException;

  /**
   * Add a Host object to be managed by this server
   * @param hostname Host to be added
   * @throws AmbariException
   */
  public void addHost(String hostname) throws AmbariException;

  /**
   * Map host to the given cluster.
   * A host can belong to multiple clusters.
   * @param hostname
   * @param clusterName
   * @throws AmbariException
   */
  public void mapHostToCluster(String hostname, String clusterName)
      throws AmbariException;


  public void mapHostsToCluster(Set<String> hostnames, String clusterName)
      throws AmbariException;

  public void updateClusterName(String oldName, String newName);

  public Cluster getClusterById(long id) throws AmbariException;

  public void debugDump(StringBuilder sb);

  public Map<String, Host> getHostsForCluster(String clusterName)
      throws AmbariException;

  public void deleteCluster(String clusterName) throws AmbariException;

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ComponentInfo.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

public class ComponentInfo {
  private String name;
  private String category;

  public String getName() {
    return name;
  }

  public void setName(String name) {
    this.name = name;
  }

  public String getCategory() {
    return category;
  }

  public void setCategory(String category) {
    this.category = category;
  }

  public boolean isClient() {
    return "CLIENT".equals(category);
  }

  public boolean isMaster() {
    return "MASTER".equals(category);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/Config.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.List;
import java.util.Map;

/**
 * Represents a single instance of a 'Config Type'
 */
public interface Config {

  /**
   * @return Config Type
   */
  public String getType();

  /**
   * @return Version Tag this config instance is mapped to
   */
  public String getVersionTag();

  /**
   * @return Properties that define this config instance
   */
  public Map<String, String> getProperties();

  /**
   * Change the version tag
   * @param versionTag
   */
  public void setVersionTag(String versionTag);

  /**
   * Replace properties with new provided set
   * @param properties Property Map to replace existing one
   */
  public void setProperties(Map<String, String> properties);

  /**
   * Update provided properties' values.
   * @param properties Property Map with updated values
   */
  public void updateProperties(Map<String, String> properties);

  /**
   * Delete certain properties
   * @param properties Property keys to be deleted
   */
  public void deleteProperties(List<String> properties);
  
  /**
   * Persist the configuration.
   */
  public void persist();
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ConfigFactory.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.state;

import java.util.Map;

import org.apache.ambari.server.orm.entities.ClusterConfigEntity;

/**
 * @author ncole
 *
 */
public interface ConfigFactory {
  
  Config createNew(Cluster cluster, String type, Map<String, String> map);
  
  Config createExisting(Cluster cluster, ClusterConfigEntity entity);

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ConfigImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.Collections;
import java.util.Date;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import org.apache.ambari.server.orm.dao.ClusterDAO;
import org.apache.ambari.server.orm.entities.ClusterConfigEntity;
import org.apache.ambari.server.orm.entities.ClusterEntity;

import com.google.gson.Gson;
import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.assistedinject.Assisted;
import com.google.inject.assistedinject.AssistedInject;
import com.google.inject.persist.Transactional;

public class ConfigImpl implements Config {

  private Cluster cluster;
  private String type;
  private String versionTag;
  private Map<String, String> properties;
  private ClusterConfigEntity entity;
  
  @Inject
  private ClusterDAO clusterDAO;
  @Inject
  private Gson gson;

  @AssistedInject
  public ConfigImpl(@Assisted Cluster cluster, @Assisted String type, @Assisted Map<String, String> properties, Injector injector) {
    this.cluster = cluster;
    this.type = type;
    this.properties = properties;
    injector.injectMembers(this);
    
  }
  
  @AssistedInject
  public ConfigImpl(@Assisted Cluster cluster, @Assisted ClusterConfigEntity entity, Injector injector) {
    this.cluster = cluster;
    this.type = entity.getType();
    this.versionTag = entity.getTag();
    this.entity = entity;
    injector.injectMembers(this);
  }
  
  @Override
  public String getType() {
    return type;
  }

  @Override
  public synchronized String getVersionTag() {
    return versionTag;
  }

  @Override
  public synchronized Map<String, String> getProperties() {
    if (null != entity && null == properties) {
      
      properties = gson.<Map<String, String>>fromJson(entity.getData(), Map.class);
      
    }
    return null == properties ? new HashMap<String, String>()
        : new HashMap<String, String>(properties);
  }

  @Override
  public synchronized void setVersionTag(String versionTag) {
    this.versionTag = versionTag;
  }

  @Override
  public synchronized void setProperties(Map<String, String> properties) {
    this.properties = properties;
  }

  @Override
  public synchronized void updateProperties(Map<String, String> properties) {
    this.properties.putAll(properties);
  }

  @Override
  public synchronized void deleteProperties(List<String> properties) {
    for (String key : properties) {
      this.properties.remove(key);
    }
  }
  
  @Transactional
  @Override
  public void persist() {
    
    ClusterEntity clusterEntity = clusterDAO.findById(cluster.getClusterId());
    
    ClusterConfigEntity entity = new ClusterConfigEntity();
    entity.setClusterEntity(clusterEntity);
    entity.setClusterId(Long.valueOf(cluster.getClusterId()));
    entity.setType(type);
    entity.setTag(getVersionTag());
    entity.setTimestamp(new Date().getTime());
    
    entity.setData(gson.toJson(getProperties()));
    clusterDAO.createConfig(entity);

    clusterEntity.getClusterConfigEntities().add(entity);
    clusterDAO.merge(clusterEntity);
    cluster.refresh();
    
  }



}
"
ambari-server/src/main/java/org/apache/ambari/server/state/Host.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.List;
import java.util.Map;

import org.apache.ambari.server.agent.DiskInfo;
import org.apache.ambari.server.agent.HostInfo;
import org.apache.ambari.server.controller.HostResponse;
import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;

public interface Host {

  /**
   * @return the hostName
   */
  public String getHostName();

  /**
   * @param hostName the hostName to set
   */
  public void setHostName(String hostName);

  /**
   * Gets the public-facing host name.
   */
  public void setPublicHostName(String hostName);
  
  /**
   * Sets the public-facing host name. 
   */
  public String getPublicHostName();
  
  /**
   * IPv4 assigned to the Host
   * @return the ip or null if no IPv4 interface
   */
  public String getIPv4();

  /**
   * @param ip the ip to set
   */
  public void setIPv4(String ip);

  /**
   * IPv6 assigned to the Host
   * @return the ip or null if no IPv6 interface
   */
  public String getIPv6();

  /**
   * @param ip the ip to set
   */
  public void setIPv6(String ip);

  /**
   * @return the cpuCount
   */
  public int getCpuCount();

  /**
   * @param cpuCount the cpuCount to set
   */
  public void setCpuCount(int cpuCount);

  /**
   * Get the Amount of physical memory for the Host.
   * @return the totalMemBytes
   */
  public long getTotalMemBytes();

  /**
   * Set the Amount of physical memory for the Host.
   * @param totalMemBytes the totalMemBytes to set
   */
  public void setTotalMemBytes(long totalMemBytes);

  /**
   * Get the Amount of available memory for the Host.
   * In most cases, available should be same as total unless
   * the agent on the host is configured to not use all
   * available memory
   * @return the availableMemBytes
   */
  public long getAvailableMemBytes();

  /**
   * Set the Amount of available memory for the Host.
   * @param availableMemBytes the availableMemBytes to set
   */
  public void setAvailableMemBytes(long availableMemBytes);

  /**
   * Get the OS Architecture.
   * i386, x86_64, etc.
   * @return the osArch
   */
  public String getOsArch();

  /**
   * @param osArch the osArch to set
   */
  public void setOsArch(String osArch);

  /**
   * Get the General OS information.
   * uname -a, /etc/*-release dump
   * @return the osInfo
   */
  public String getOsInfo();

  /**
   * @param osInfo the osInfo to set
   */
  public void setOsInfo(String osInfo);

  /**
   * Get the OS Type: RHEL5/RHEL6/CentOS5/...
   * Defined and match-able OS type
   * @return the osType
   */
  public String getOsType();

  /**
   * @param osType the osType to set
   */
  public void setOsType(String osType);

  /**
   * Get information on disks available on the host.
   * @return the disksInfo
   */
  public List<DiskInfo> getDisksInfo();

  /**
   * @param disksInfo the disksInfo to set
   */
  public void setDisksInfo(List<DiskInfo> disksInfo);

  /**
   * @return the healthStatus
   */
  public HostHealthStatus getHealthStatus();

  /**
   * @param healthStatus the healthStatus to set
   */
  public void setHealthStatus(HostHealthStatus healthStatus);

  /**
   * Get additional host attributes
   * For example, public/hostname/IP for AWS
   * @return the hostAttributes
   */
  public Map<String, String> getHostAttributes();

  /**
   * @param hostAttributes the hostAttributes to set
   */
  public void setHostAttributes(Map<String, String> hostAttributes);
  /**
   * @return the rackInfo
   */
  public String getRackInfo();

  /**
   * @param rackInfo the rackInfo to set
   */
  public void setRackInfo(String rackInfo);

  /**
   * Last time the host registered with the Ambari Server
   * ( Unix timestamp )
   * @return the lastRegistrationTime
   */
  public long getLastRegistrationTime();

  /**
   * @param lastRegistrationTime the lastRegistrationTime to set
   */
  public void setLastRegistrationTime(long lastRegistrationTime);

  /**
   * Last time the Ambari Server received a heartbeat from the Host
   * ( Unix timestamp )
   * @return the lastHeartbeatTime
   */
  public long getLastHeartbeatTime();

  /**
   * @param lastHeartbeatTime the lastHeartbeatTime to set
   */
  public void setLastHeartbeatTime(long lastHeartbeatTime);

  /**
   * Version of the Ambari Agent running on the host
   * @return the agentVersion
   */
  public AgentVersion getAgentVersion();

  /**
   * @param agentVersion the agentVersion to set
   */
  public void setAgentVersion(AgentVersion agentVersion);

  /**
   * Get Current Host State
   * @return HostState
   */
  public HostState getState();

  /**
   * Set the State of the Host
   * @param state Host State
   */
  public void setState(HostState state);

  /**
   * Send an event to the Host's StateMachine
   * @param event HostEvent
   * @throws InvalidStateTransitionException
   */
  public void handleEvent(HostEvent event)
      throws InvalidStateTransitionException;

  /**
   * Get time spent in the current state i.e. the time since last state change.
   * @return Time spent in current state.
   */
  public long getTimeInState();

  /**
   * @param timeInState the timeInState to set
   */
  public void setTimeInState(long timeInState);

  public HostResponse convertToResponse();

  boolean isPersisted();

  void persist();

  void refresh();

  void importHostInfo(HostInfo hostInfo);
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/HostEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import org.apache.ambari.server.state.fsm.event.AbstractEvent;

/**
 * Base class for all events that affect the Host FSM
 */
public abstract class HostEvent extends AbstractEvent<HostEventType> {

  /**
   * Hostname of the Host
   */
  private final String hostName;

  public HostEvent(String hostName, HostEventType type) {
    super(type);
    this.hostName = hostName;
  }

  /**
   * @return the hostName
   */
  public String getHostName() {
    return hostName;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/HostEventType.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state;

public enum HostEventType {
  /**
   * Event to denote when a registration request is received from a Host
   */
  HOST_REGISTRATION_REQUEST,
  /**
   * Host status check response received.
   */
  HOST_STATUS_UPDATES_RECEIVED,
  /**
   * A healthy heartbeat event received from the Host.
   */
  HOST_HEARTBEAT_HEALTHY,
  /**
   * No heartbeat received from the Host within the defined expiry interval.
   */
  HOST_HEARTBEAT_LOST,
  /**
   * A non-healthy heartbeat event received from the Host.
   */
  HOST_HEARTBEAT_UNHEALTHY
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/HostHealthStatus.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

public class HostHealthStatus {

  private HealthStatus healthStatus;

  private String healthReport;

  public HostHealthStatus(HealthStatus healthStatus, String healthReport) {
    super();
    this.healthStatus = healthStatus;
    this.healthReport = healthReport;
  }

  public synchronized HealthStatus getHealthStatus() {
    return healthStatus;
  }

  public synchronized void setHealthStatus(HealthStatus healthStatus) {
    this.healthStatus = healthStatus;
  }

  public synchronized void setHealthReport(String healthReport) {
    this.healthReport = healthReport;
  }

  public synchronized String getHealthReport() {
    return healthReport;
  }

  public static enum HealthStatus {
    UNKNOWN,
    HEALTHY,
    UNHEALTHY
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/HostState.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

public enum HostState {
  /**
   * New host state
   */
  INIT,
  /**
   * State when a registration request is received from the Host but
   * the host has not responded to its status update check.
   */
  WAITING_FOR_HOST_STATUS_UPDATES,
  /**
   * State when the server is receiving heartbeats regularly from the Host
   * and the state of the Host is healthy
   */
  HEALTHY,
  /**
   * State when the server has not received a heartbeat from the Host in the
   * configured heartbeat expiry window.
   */
  HEARTBEAT_LOST,
  /**
   * Host is in unhealthy state as reported either by the Host itself or via
   * any other additional means ( monitoring layer )
   */
  UNHEALTHY;
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/PropertyInfo.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

public class PropertyInfo {
  private String name;
  private String value;
  private String description;
  private String filename;

  public String getName() {
    return name;
  }

  public void setName(String name) {
    this.name = name;
  }

  public String getValue() {
    return value;
  }

  public void setValue(String value) {
    this.value = value;
  }

  public String getDescription() {
    return description;
  }

  public void setDescription(String description) {
    this.description = description;
  }

  public String getFilename() {
    return filename;
  }

  public void setFilename(String filename) {
    this.filename = filename;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/RepositoryInfo.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

public class RepositoryInfo {
  private String baseUrl;
  private String osType;
  private String repoId;
  private String repoName;
  private String mirrorsList;

  /**
   * @return the baseUrl
   */
  public String getBaseUrl() {
    return baseUrl;
  }

  /**
   * @param baseUrl the baseUrl to set
   */
  public void setBaseUrl(String baseUrl) {
    this.baseUrl = baseUrl;
  }

  /**
   * @return the osType
   */
  public String getOsType() {
    return osType;
  }

  /**
   * @param osType the osType to set
   */
  public void setOsType(String osType) {
    this.osType = osType;
  }

  /**
   * @return the repoId
   */
  public String getRepoId() {
    return repoId;
  }

  /**
   * @param repoId the repoId to set
   */
  public void setRepoId(String repoId) {
    this.repoId = repoId;
  }

  /**
   * @return the repoName
   */
  public String getRepoName() {
    return repoName;
  }

  /**
   * @param repoName the repoName to set
   */
  public void setRepoName(String repoName) {
    this.repoName = repoName;
  }

  /**
   * @return the mirrorsList
   */
  public String getMirrorsList() {
    return mirrorsList;
  }

  /**
   * @param mirrorsList the mirrorsList to set
   */
  public void setMirrorsList(String mirrorsList) {
    this.mirrorsList = mirrorsList;
  }

  @Override
  public String toString() {
    return "[ repoInfo: "
        + ", osType=" + osType
        + ", repoId=" + repoId
        + ", baseUrl=" + baseUrl
        + ", repoName=" + repoName
        + ", mirrorsList=" + mirrorsList
        + " ]";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/Service.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.Map;

import com.google.inject.persist.Transactional;
import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.ServiceResponse;

public interface Service {

  public String getName();

  public long getClusterId();

  public Cluster getCluster();

  public ServiceComponent getServiceComponent(String componentName)
      throws AmbariException;

  public Map<String, ServiceComponent> getServiceComponents();

  public void addServiceComponents(Map<String, ServiceComponent> components)
      throws AmbariException;

  public void addServiceComponent(ServiceComponent component)
      throws AmbariException;

  public State getDesiredState();

  public void setDesiredState(State state);

  public Map<String, Config> getDesiredConfigs();

  public void updateDesiredConfigs(Map<String, Config> configs);

  public StackId getDesiredStackVersion();

  public void setDesiredStackVersion(StackId stackVersion);

  public ServiceResponse convertToResponse();

  public void debugDump(StringBuilder sb);

  boolean isPersisted();

  @Transactional
  void persist();

  void refresh();

  ServiceComponent addServiceComponent(String serviceComponentName)
      throws AmbariException;

  /**
   * Find out whether the service and its components
   * are in a state that it can be removed from a cluster
   * @return
   */
  public boolean canBeRemoved();

  public void removeAllComponents() throws AmbariException;

  public void deleteServiceComponent(String componentName)
      throws AmbariException;

  public boolean isClientOnlyService();

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceComponent.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.Map;
import java.util.Set;

import com.google.inject.persist.Transactional;
import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.ServiceComponentResponse;

public interface ServiceComponent {

  public String getName();

  public String getServiceName();

  public long getClusterId();

  public String getClusterName();

  public State getDesiredState();

  public void setDesiredState(State state);

  public Map<String, Config> getDesiredConfigs();

  public void updateDesiredConfigs(Map<String, Config> configs);

  public void deleteDesiredConfigs(Set<String> configTypes);

  public StackId getDesiredStackVersion();

  public void setDesiredStackVersion(StackId stackVersion);

  public Map<String, ServiceComponentHost> getServiceComponentHosts();

  public ServiceComponentHost getServiceComponentHost(String hostname)
      throws AmbariException;

  public void addServiceComponentHosts(Map<String, ServiceComponentHost>
      hostComponents) throws AmbariException ;

  public void addServiceComponentHost(ServiceComponentHost hostComponent)
      throws AmbariException ;

  public ServiceComponentResponse convertToResponse();

  public void refresh();

  boolean isPersisted();

  @Transactional
  void persist();

  public void debugDump(StringBuilder sb);

  public boolean isClientComponent();

  public boolean canBeRemoved();

  public void removeAllServiceComponentHosts() throws AmbariException;

  public void removeServiceComponentHosts(String hostname)
      throws AmbariException;

  ServiceComponentHost addServiceComponentHost(
      String hostName) throws AmbariException;
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceComponentFactory.java,true,"package org.apache.ambari.server.state;

/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import org.apache.ambari.server.orm.entities.ServiceComponentDesiredStateEntity;

public interface ServiceComponentFactory {

  ServiceComponent createNew(Service service, String componentName);

  ServiceComponent createExisting(Service service, ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity);
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceComponentHost.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.Map;
import java.util.Set;

import com.google.inject.persist.Transactional;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.ServiceComponentHostResponse;
import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;


public interface ServiceComponentHost {

  /**
   * Get the Cluster that this object maps to
   */
  public long getClusterId();

  /**
   * Get the Cluster that this object maps to
   */
  public String getClusterName();

  /**
   * Get the Service this object maps to
   * @return Name of the Service
   */
  public String getServiceName();

  /**
   * Get the ServiceComponent this object maps to
   * @return Name of the ServiceComponent
   */
  public String getServiceComponentName();

  /**
   * Get the Host this object maps to
   * @return Host's hostname
   */
  public String getHostName();

  /**
   * Send a ServiceComponentHostState event to the StateMachine
   * @param event Event to handle
   * @throws InvalidStateTransitionException
   */
  public void handleEvent(ServiceComponentHostEvent event)
      throws InvalidStateTransitionException;

  public State getDesiredState();

  public void setDesiredState(State state);

  public Map<String, Config> getDesiredConfigs();

  public Map<String, String> getDesiredConfigVersionsRecursive();

  public void updateDesiredConfigs(Map<String, Config> configs);

  public void deleteDesiredConfigs(Set<String> configTypes);

  public StackId getDesiredStackVersion();

  public void setDesiredStackVersion(StackId stackVersion);

  public State getState();

  public void setState(State state);

  public Map<String, Config> getConfigs() throws AmbariException;

  public StackId getStackVersion();

  public void setStackVersion(StackId stackVersion);

  public ServiceComponentHostResponse convertToResponse();

  boolean isPersisted();

  @Transactional
  void persist();

  void refresh();

  public void debugDump(StringBuilder sb);

  public boolean canBeRemoved();
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceComponentHostEvent.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.HashMap;
import java.util.Map;

import org.apache.ambari.server.state.fsm.event.AbstractEvent;
import org.apache.ambari.server.state.svccomphost.*;
import org.codehaus.jackson.annotate.JsonCreator;
import org.codehaus.jackson.annotate.JsonProperty;

/**
 * Base class for all events that affect the ServiceComponentHost FSM
 */
public abstract class ServiceComponentHostEvent
    extends AbstractEvent<ServiceComponentHostEventType> {

  /**
   * ServiceComponent that this event relates to
   */
  private final String serviceComponentName;

  /**
   * Hostname of the Host that this event relates to
   */
  private final String hostName;

  /**
   * Time when the event was triggered
   */
  private final long opTimestamp;

  // FIXME hack alert!!!
  // This belongs to start event only
  private final Map<String, String> configs;

  // FIXME hack alert
  // this belongs to install event only
  private final String stackId;

  public ServiceComponentHostEvent(ServiceComponentHostEventType type,
      String serviceComponentName, String hostName, long opTimestamp,
      Map<String, String> configs) {
    this(type, serviceComponentName, hostName, opTimestamp,
        configs, "");
  }

  public ServiceComponentHostEvent(ServiceComponentHostEventType type,
      String serviceComponentName, String hostName, long opTimestamp) {
    this(type, serviceComponentName, hostName, opTimestamp,
        new HashMap<String, String>(), "");
  }

  public ServiceComponentHostEvent(ServiceComponentHostEventType type,
      String serviceComponentName, String hostName, long opTimestamp,
      String stackId) {
    this(type, serviceComponentName, hostName, opTimestamp,
        new HashMap<String, String>(), stackId);
  }

  public ServiceComponentHostEvent(ServiceComponentHostEventType type,
      String serviceComponentName, String hostName, long opTimestamp,
      Map<String, String> configs, String stackId) {
    super(type);
    this.serviceComponentName = serviceComponentName;
    this.hostName = hostName;
    this.opTimestamp = opTimestamp;
    this.configs = configs;
    this.stackId = stackId;
  }

  /**
   * @return the serviceComponentName
   */
  public String getServiceComponentName() {
    return serviceComponentName;
  }

  /**
   * @return the hostName
   */
  public String getHostName() {
    return hostName;
  }

  /**
   * @return the opTimestamp
   */
  public long getOpTimestamp() {
    return opTimestamp;
  }

  @JsonCreator
  public static ServiceComponentHostEvent create(@JsonProperty("type") ServiceComponentHostEventType type,
                                                 @JsonProperty("serviceComponentName") String serviceComponentName,
                                                 @JsonProperty("hostName") String hostName,
                                                 @JsonProperty("opTimestamp") long opTimestamp,
                                                 @JsonProperty("configs") Map<String, String> configs,
                                                 @JsonProperty("stackId") String stackId) {
    switch (type) {
      case HOST_SVCCOMP_INSTALL:
        return new ServiceComponentHostInstallEvent(serviceComponentName, hostName, opTimestamp, stackId);
      case HOST_SVCCOMP_OP_FAILED:
        return new ServiceComponentHostOpFailedEvent(serviceComponentName, hostName, opTimestamp);
      case HOST_SVCCOMP_OP_IN_PROGRESS:
        return new ServiceComponentHostOpInProgressEvent(serviceComponentName, hostName, opTimestamp);
      case HOST_SVCCOMP_OP_RESTART:
        return new ServiceComponentHostOpRestartedEvent(serviceComponentName, hostName, opTimestamp);
      case HOST_SVCCOMP_OP_SUCCEEDED:
        return new ServiceComponentHostOpSucceededEvent(serviceComponentName, hostName, opTimestamp);
      case HOST_SVCCOMP_START:
        return new ServiceComponentHostStartEvent(serviceComponentName, hostName, opTimestamp, configs);
      case HOST_SVCCOMP_STOP:
        return new ServiceComponentHostStopEvent(serviceComponentName, hostName, opTimestamp);
      case HOST_SVCCOMP_UNINSTALL:
        return new ServiceComponentHostUninstallEvent(serviceComponentName, hostName, opTimestamp);
      case HOST_SVCCOMP_WIPEOUT:
        return new ServiceComponentHostWipeoutEvent(serviceComponentName, hostName, opTimestamp);
    }
    return null;
  }

  /**
   * @return the configs
   */
  public Map<String, String> getConfigs() {
    return configs;
  }

  /**
   * @return the stackId
   */
  public String getStackId() {
    return stackId;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceComponentHostEventType.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

public enum ServiceComponentHostEventType {
  /**
   * Operation in progress
   */
  HOST_SVCCOMP_OP_IN_PROGRESS,
  /**
   * Operation succeeded
   */
  HOST_SVCCOMP_OP_SUCCEEDED,
  /**
   * Operation failed.
   */
  HOST_SVCCOMP_OP_FAILED,
  /**
   * Re-starting a failed operation.
   */
  HOST_SVCCOMP_OP_RESTART,
  /**
   * Triggering an install.
   */
  HOST_SVCCOMP_INSTALL,
  /**
   * Triggering a start.
   */
  HOST_SVCCOMP_START,
  /**
   * Triggering a stop.
   */
  HOST_SVCCOMP_STOP,
  /**
   * Triggering an uninstall.
   */
  HOST_SVCCOMP_UNINSTALL,
  /**
   * Triggering a wipe-out ( restore to clean state ).
   */
  HOST_SVCCOMP_WIPEOUT
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceComponentHostFactory.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import org.apache.ambari.server.orm.entities.HostComponentDesiredStateEntity;
import org.apache.ambari.server.orm.entities.HostComponentStateEntity;

public interface ServiceComponentHostFactory {

  ServiceComponentHost createNew(ServiceComponent serviceComponent,
                                 String hostName, boolean isClient);

  ServiceComponentHost createExisting(ServiceComponent serviceComponent,
                                      HostComponentStateEntity stateEntity,
                                      HostComponentDesiredStateEntity desiredStateEntity);
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceComponentImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.*;
import java.util.Map.Entry;

import com.google.gson.Gson;
import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.assistedinject.Assisted;
import com.google.inject.assistedinject.AssistedInject;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.ServiceComponentHostNotFoundException;
import org.apache.ambari.server.api.services.AmbariMetaInfo;
import org.apache.ambari.server.controller.ServiceComponentResponse;
import org.apache.ambari.server.orm.dao.*;
import org.apache.ambari.server.orm.entities.*;
import org.apache.ambari.server.state.cluster.ClusterImpl;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class ServiceComponentImpl implements ServiceComponent {

  private final static Logger LOG =
      LoggerFactory.getLogger(ServiceComponentImpl.class);

  private final Service service;

  @Inject
  private Gson gson;
  @Inject
  private ServiceComponentDesiredStateDAO serviceComponentDesiredStateDAO;
  @Inject
  private ClusterServiceDAO clusterServiceDAO;
  @Inject
  private HostComponentStateDAO hostComponentStateDAO;
  @Inject
  private HostComponentDesiredStateDAO hostComponentDesiredStateDAO;
  @Inject
  private ServiceComponentHostFactory serviceComponentHostFactory;
  @Inject
  private AmbariMetaInfo ambariMetaInfo;
  @Inject
  private ComponentConfigMappingDAO componentConfigMappingDAO;

  boolean persisted = false;
  private ServiceComponentDesiredStateEntity desiredStateEntity;

  // [ type -> versionTag ]
  private Map<String, String>  desiredConfigs;

  private Map<String, ServiceComponentHost> hostComponents;

  private final boolean isClientComponent;



  private void init() {
    // TODO load during restart
    // initialize from DB
  }

  @AssistedInject
  public ServiceComponentImpl(@Assisted Service service,
      @Assisted String componentName, Injector injector) {
    injector.injectMembers(this);
    this.service = service;
    this.desiredStateEntity = new ServiceComponentDesiredStateEntity();
    desiredStateEntity.setComponentName(componentName);
    desiredStateEntity.setDesiredState(State.INIT);

    this.desiredConfigs = new HashMap<String, String>();
    setDesiredStackVersion(service.getDesiredStackVersion());

    this.hostComponents = new HashMap<String, ServiceComponentHost>();

    StackId stackId = service.getDesiredStackVersion();
    ComponentInfo compInfo = ambariMetaInfo.getComponentCategory(
        stackId.getStackName(), stackId.getStackVersion(), service.getName(),
        componentName);
    if (compInfo == null) {
      throw new RuntimeException("Trying to create a ServiceComponent"
          + " not recognized in stack info"
          + ", clusterName=" + service.getCluster().getClusterName()
          + ", serviceName=" + service.getName()
          + ", componentName=" + componentName
          + ", stackInfo=" + stackId.getStackId());
    }
    this.isClientComponent = compInfo.isClient();

    init();
  }

  @AssistedInject
  public ServiceComponentImpl(@Assisted Service service,
                              @Assisted ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity,
                              Injector injector) {
    injector.injectMembers(this);
    this.service = service;
    this.desiredStateEntity = serviceComponentDesiredStateEntity;


    this.desiredConfigs = new HashMap<String, String>();

    this.hostComponents = new HashMap<String, ServiceComponentHost>();
    for (HostComponentStateEntity hostComponentStateEntity : desiredStateEntity.getHostComponentStateEntities()) {
      HostComponentDesiredStateEntityPK pk = new HostComponentDesiredStateEntityPK();
      pk.setClusterId(hostComponentStateEntity.getClusterId());
      pk.setServiceName(hostComponentStateEntity.getServiceName());
      pk.setComponentName(hostComponentStateEntity.getComponentName());
      pk.setHostName(hostComponentStateEntity.getHostName());

      HostComponentDesiredStateEntity hostComponentDesiredStateEntity = hostComponentDesiredStateDAO.findByPK(pk);

      hostComponents.put(hostComponentStateEntity.getHostName(),
          serviceComponentHostFactory.createExisting(this,
              hostComponentStateEntity, hostComponentDesiredStateEntity));
   }

    for (ComponentConfigMappingEntity entity : desiredStateEntity.getComponentConfigMappingEntities()) {
      desiredConfigs.put(entity.getConfigType(), entity.getVersionTag());
    }

    StackId stackId = service.getDesiredStackVersion();
    ComponentInfo compInfo = ambariMetaInfo.getComponentCategory(
        stackId.getStackName(), stackId.getStackVersion(), service.getName(),
        getName());
    if (compInfo == null) {
      throw new RuntimeException("Trying to create a ServiceComponent"
          + " not recognized in stack info"
          + ", clusterName=" + service.getCluster().getClusterName()
          + ", serviceName=" + service.getName()
          + ", componentName=" + getName()
          + ", stackInfo=" + stackId.getStackId());
    }
    this.isClientComponent = compInfo.isClient();

    persisted = true;
  }

  @Override
  public synchronized String getName() {
    return desiredStateEntity.getComponentName();
  }

  @Override
  public synchronized String getServiceName() {
    return service.getName();
  }

  @Override
  public synchronized long getClusterId() {
    return this.service.getClusterId();
  }

  @Override
  public synchronized Map<String, ServiceComponentHost>
      getServiceComponentHosts() {
    return Collections.unmodifiableMap(hostComponents);
  }

  @Override
  public synchronized void addServiceComponentHosts(
      Map<String, ServiceComponentHost> hostComponents) throws AmbariException {
    // TODO validation
    for (Entry<String, ServiceComponentHost> entry :
      hostComponents.entrySet()) {
      if (!entry.getKey().equals(entry.getValue().getHostName())) {
        throw new AmbariException("Invalid arguments in map"
            + ", hostname does not match the key in map");
      }
    }
    for (ServiceComponentHost sch : hostComponents.values()) {
      addServiceComponentHost(sch);
    }
  }

  @Override
  public synchronized void addServiceComponentHost(
      ServiceComponentHost hostComponent) throws AmbariException {
    // TODO validation
    // TODO ensure host belongs to cluster
    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding a ServiceComponentHost to ServiceComponent"
          + ", clusterName=" + service.getCluster().getClusterName()
          + ", clusterId=" + service.getCluster().getClusterId()
          + ", serviceName=" + service.getName()
          + ", serviceComponentName=" + getName()
          + ", hostname=" + hostComponent.getHostName());
    }
    if (hostComponents.containsKey(hostComponent.getHostName())) {
      throw new AmbariException("Cannot add duplicate ServiceComponentHost"
          + ", clusterName=" + service.getCluster().getClusterName()
          + ", clusterId=" + service.getCluster().getClusterId()
          + ", serviceName=" + service.getName()
          + ", serviceComponentName=" + getName()
          + ", hostname=" + hostComponent.getHostName());
    }
    // FIXME need a better approach of caching components by host
    ClusterImpl clusterImpl = (ClusterImpl) service.getCluster();
    clusterImpl.addServiceComponentHost(hostComponent);
    this.hostComponents.put(hostComponent.getHostName(), hostComponent);
  }

  @Override
  public synchronized ServiceComponentHost addServiceComponentHost(
      String hostName) throws AmbariException {
    // TODO validation
    // TODO ensure host belongs to cluster
    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding a ServiceComponentHost to ServiceComponent"
          + ", clusterName=" + service.getCluster().getClusterName()
          + ", clusterId=" + service.getCluster().getClusterId()
          + ", serviceName=" + service.getName()
          + ", serviceComponentName=" + getName()
          + ", hostname=" + hostName);
    }
    if (hostComponents.containsKey(hostName)) {
      throw new AmbariException("Cannot add duplicate ServiceComponentHost"
          + ", clusterName=" + service.getCluster().getClusterName()
          + ", clusterId=" + service.getCluster().getClusterId()
          + ", serviceName=" + service.getName()
          + ", serviceComponentName=" + getName()
          + ", hostname=" + hostName);
    }
    ServiceComponentHost hostComponent =
        serviceComponentHostFactory.createNew(this, hostName, true);
    // FIXME need a better approach of caching components by host
    ClusterImpl clusterImpl = (ClusterImpl) service.getCluster();
    clusterImpl.addServiceComponentHost(hostComponent);

    this.hostComponents.put(hostComponent.getHostName(), hostComponent);

    return hostComponent;
  }

  @Override
  public ServiceComponentHost getServiceComponentHost(String hostname)
    throws AmbariException {
    if (!hostComponents.containsKey(hostname)) {
      throw new ServiceComponentHostNotFoundException(getClusterName(),
          getServiceName(), getName(), hostname);
    }
    return this.hostComponents.get(hostname);
  }

  @Override
  public synchronized State getDesiredState() {
    return desiredStateEntity.getDesiredState();
  }

  @Override
  public synchronized void setDesiredState(State state) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Setting DesiredState of Service"
          + ", clusterName=" + service.getCluster().getClusterName()
          + ", clusterId=" + service.getCluster().getClusterId()
          + ", serviceName=" + service.getName()
          + ", serviceComponentName=" + getName()
          + ", oldDesiredState=" + getDesiredState()
          + ", newDesiredState=" + state);
    }
    desiredStateEntity.setDesiredState(state);
    saveIfPersisted();
  }

  @Override
  public synchronized Map<String, Config> getDesiredConfigs() {
    Map<String, Config> map = new HashMap<String, Config>();
    for (Entry<String, String> entry : desiredConfigs.entrySet()) {
      Config config = service.getCluster().getDesiredConfig(entry.getKey(), entry.getValue());
      if (null != config) {
        map.put(entry.getKey(), config);
      }
    }

    Map<String, Config> svcConfigs = service.getDesiredConfigs();
    for (Entry<String, Config> entry : svcConfigs.entrySet()) {
      if (!map.containsKey(entry.getKey())) {
        map.put(entry.getKey(), entry.getValue());
      }
    }

    return Collections.unmodifiableMap(map);
  }

  @Override
  public synchronized void updateDesiredConfigs(Map<String, Config> configs) {

    Set<String> deletedTypes = new HashSet<String>();
    for (String type : this.desiredConfigs.keySet()) {
      if (!configs.containsKey(type)) {
        deletedTypes.add(type);
      }
    }

    for (Entry<String,Config> entry : configs.entrySet()) {
      boolean contains = false;

      for (ComponentConfigMappingEntity componentConfigMappingEntity : desiredStateEntity.getComponentConfigMappingEntities()) {
        if (entry.getKey().equals(componentConfigMappingEntity.getConfigType())) {
          contains = true;
          componentConfigMappingEntity.setTimestamp(new Date().getTime());
          componentConfigMappingEntity.setVersionTag(entry.getValue().getVersionTag());
          if (persisted) {
            componentConfigMappingDAO.merge(componentConfigMappingEntity);
          }
        }
      }

      if (!contains) {
        ComponentConfigMappingEntity newEntity = new ComponentConfigMappingEntity();
        newEntity.setClusterId(desiredStateEntity.getClusterId());
        newEntity.setServiceName(desiredStateEntity.getServiceName());
        newEntity.setComponentName(desiredStateEntity.getComponentName());
        newEntity.setConfigType(entry.getKey());
        newEntity.setVersionTag(entry.getValue().getVersionTag());
        newEntity.setTimestamp(new Date().getTime());
        newEntity.setServiceComponentDesiredStateEntity(desiredStateEntity);
        desiredStateEntity.getComponentConfigMappingEntities().add(newEntity);

      }


      this.desiredConfigs.put(entry.getKey(), entry.getValue().getVersionTag());
    }

    if (!deletedTypes.isEmpty()) {
      if (persisted) {
        List<ComponentConfigMappingEntity> deleteEntities =
            componentConfigMappingDAO.findByComponentAndType(
                desiredStateEntity.getClusterId(), desiredStateEntity.getServiceName(),
                desiredStateEntity.getComponentName(),
                deletedTypes);
        for (ComponentConfigMappingEntity deleteEntity : deleteEntities) {
          if (LOG.isDebugEnabled()) {
            LOG.debug("Deleting desired config from ServiceComponent"
                + ", clusterId=" + desiredStateEntity.getClusterId()
                + ", serviceName=" + desiredStateEntity.getServiceName()
                + ", componentName=" + desiredStateEntity.getComponentName()
                + ", configType=" + deleteEntity.getConfigType()
                + ", configVersionTag=" + deleteEntity.getVersionTag());
          }
          desiredStateEntity.getComponentConfigMappingEntities().remove(
              deleteEntity);
          componentConfigMappingDAO.remove(deleteEntity);
        }
      } else {
        for (String deletedType : deletedTypes) {
          desiredConfigs.remove(deletedType);
        }
      }
    }

    saveIfPersisted();
  }

  @Override
  public synchronized StackId getDesiredStackVersion() {
    return gson.fromJson(desiredStateEntity.getDesiredStackVersion(), StackId.class);
  }

  @Override
  public synchronized void setDesiredStackVersion(StackId stackVersion) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Setting DesiredStackVersion of Service"
          + ", clusterName=" + service.getCluster().getClusterName()
          + ", clusterId=" + service.getCluster().getClusterId()
          + ", serviceName=" + service.getName()
          + ", serviceComponentName=" + getName()
          + ", oldDesiredStackVersion=" + getDesiredStackVersion()
          + ", newDesiredStackVersion=" + stackVersion);
    }
    desiredStateEntity.setDesiredStackVersion(gson.toJson(stackVersion));
    saveIfPersisted();
  }

  @Override
  public synchronized ServiceComponentResponse convertToResponse() {
    ServiceComponentResponse r  = new ServiceComponentResponse(
        getClusterId(), service.getCluster().getClusterName(),
        service.getName(), getName(), this.desiredConfigs,
        getDesiredStackVersion().getStackId(),
        getDesiredState().toString());
    return r;
  }

  @Override
  public String getClusterName() {
    return service.getCluster().getClusterName();
  }

  @Override
  public synchronized void debugDump(StringBuilder sb) {
    sb.append("ServiceComponent={ serviceComponentName=" + getName()
        + ", clusterName=" + service.getCluster().getClusterName()
        + ", clusterId=" + service.getCluster().getClusterId()
        + ", serviceName=" + service.getName()
        + ", desiredStackVersion=" + getDesiredStackVersion()
        + ", desiredState=" + getDesiredState().toString()
        + ", hostcomponents=[ ");
    boolean first = true;
    for(ServiceComponentHost sch : hostComponents.values()) {
      if (!first) {
        sb.append(" , ");
        first = false;
      }
      sb.append("\n        ");
      sch.debugDump(sb);
      sb.append(" ");
    }
    sb.append(" ] }");
  }

  @Override
  public synchronized boolean isPersisted() {
      return persisted;
  }

  @Override
  public synchronized void persist() {
    if (!persisted) {
      persistEntities();
      refresh();
      service.refresh();
      persisted = true;
    } else {
      saveIfPersisted();
    }
  }

  @Transactional
  protected void persistEntities() {
    ClusterServiceEntityPK pk = new ClusterServiceEntityPK();
    pk.setClusterId(service.getClusterId());
    pk.setServiceName(service.getName());
    ClusterServiceEntity serviceEntity = clusterServiceDAO.findByPK(pk);

    desiredStateEntity.setClusterServiceEntity(serviceEntity);
    serviceComponentDesiredStateDAO.create(desiredStateEntity);
    clusterServiceDAO.merge(serviceEntity);
  }

  @Override
  @Transactional
  public synchronized void refresh() {
    if (isPersisted()) {
      ServiceComponentDesiredStateEntityPK pk = new ServiceComponentDesiredStateEntityPK();
      pk.setComponentName(getName());
      pk.setClusterId(getClusterId());
      pk.setServiceName(getServiceName());
      // TODO: desiredStateEntity is assigned in unsynchronized way, may be a bug
      desiredStateEntity = serviceComponentDesiredStateDAO.findByPK(pk);
      serviceComponentDesiredStateDAO.refresh(desiredStateEntity);
    }
  }

  @Transactional
  private synchronized void saveIfPersisted() {
    if (isPersisted()) {
      serviceComponentDesiredStateDAO.merge(desiredStateEntity);
    }
  }

  @Override
  public boolean isClientComponent() {
    return this.isClientComponent;
  }

  @Override
  public synchronized boolean canBeRemoved() {
    State state = getDesiredState();
    if (state != State.INIT
        && state != State.UNINSTALLED) {
      return false;
    }

    boolean safeToRemove = true;
    for (ServiceComponentHost sch : hostComponents.values()) {
      if (!sch.canBeRemoved()) {
        safeToRemove = false;
        LOG.warn("Found non removable hostcomponent when trying to"
            + " delete service component"
            + ", clusterName=" + getClusterName()
            + ", serviceName=" + getServiceName()
            + ", componentName=" + getName()
            + ", hostname=" + sch.getHostName());
        break;
      }
    }
    return safeToRemove;
  }

  @Override
  public synchronized void removeAllServiceComponentHosts()
      throws AmbariException {
    LOG.info("Deleting all servicecomponenthosts for component"
        + ", clusterName=" + getClusterName()
        + ", serviceName=" + getServiceName()
        + ", componentName=" + getName());
    for (ServiceComponentHost sch : hostComponents.values()) {
      if (!sch.canBeRemoved()) {
        throw new AmbariException("Found non removable hostcomponent "
            + " when trying to delete"
            + " all hostcomponents from servicecomponent"
            + ", clusterName=" + getClusterName()
            + ", serviceName=" + getServiceName()
            + ", componentName=" + getName()
            + ", hostname=" + sch.getHostName());
      }
    }
    hostComponents.clear();
    // FIXME update DB
  }

  @Override
  public synchronized void removeServiceComponentHosts(String hostname)
      throws AmbariException {
    ServiceComponentHost sch = getServiceComponentHost(hostname);
    LOG.info("Deleting servicecomponenthost for cluster"
        + ", clusterName=" + getClusterName()
        + ", serviceName=" + getServiceName()
        + ", componentName=" + getName()
        + ", hostname=" + sch.getHostName());
    if (!sch.canBeRemoved()) {
      throw new AmbariException("Could not delete hostcomponent from cluster"
          + ", clusterName=" + getClusterName()
          + ", serviceName=" + getServiceName()
          + ", componentName=" + getName()
          + ", hostname=" + sch.getHostName());
    }
    hostComponents.remove(hostname);
    // FIXME update DB
  }

  @Override
  public synchronized void deleteDesiredConfigs(Set<String> configTypes) {
    for (String configType : configTypes) {
      desiredConfigs.remove(configType);
    }
    componentConfigMappingDAO.removeByType(configTypes);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceFactory.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import org.apache.ambari.server.orm.entities.ClusterServiceEntity;

public interface ServiceFactory {

  Service createNew(Cluster cluster, String serviceName);

  Service createExisting(Cluster cluster, ClusterServiceEntity serviceEntity);
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.*;
import java.util.Map.Entry;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.ServiceComponentNotFoundException;
import org.apache.ambari.server.api.services.AmbariMetaInfo;
import org.apache.ambari.server.controller.ServiceResponse;
import org.apache.ambari.server.orm.dao.*;
import org.apache.ambari.server.orm.entities.*;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.gson.Gson;
import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.assistedinject.Assisted;
import com.google.inject.assistedinject.AssistedInject;
import com.google.inject.persist.Transactional;


public class ServiceImpl implements Service {

  private ClusterServiceEntity serviceEntity;
  private ServiceDesiredStateEntity serviceDesiredStateEntity;

  private static final Logger LOG =
      LoggerFactory.getLogger(ServiceImpl.class);

  private boolean persisted = false;
  private final Cluster cluster;
  // [ String type -> Config Tag ], no need to hold the direct reference to the config
  private Map<String, String> desiredConfigs;
  private Map<String, ServiceComponent> components;
  private final boolean isClientOnlyService;

  @Inject
  Gson gson;
  @Inject
  private ClusterServiceDAO clusterServiceDAO;
  @Inject
  private Clusters clusters;
  @Inject
  private ServiceDesiredStateDAO serviceDesiredStateDAO;
  @Inject
  private ServiceComponentDesiredStateDAO serviceComponentDesiredStateDAO;
  @Inject
  private ClusterDAO clusterDAO;
  @Inject
  private ServiceConfigMappingDAO serviceConfigMappingDAO;
  @Inject
  private ServiceComponentFactory serviceComponentFactory;
  @Inject
  private AmbariMetaInfo ambariMetaInfo;

  private void init() {
    // TODO load from DB during restart?
  }

  @AssistedInject
  public ServiceImpl(@Assisted Cluster cluster, @Assisted String serviceName,
      Injector injector) {
    injector.injectMembers(this);
    serviceEntity = new ClusterServiceEntity();
    serviceEntity.setServiceName(serviceName);
    serviceDesiredStateEntity = new ServiceDesiredStateEntity();

    serviceDesiredStateEntity.setClusterServiceEntity(serviceEntity);
    serviceEntity.setServiceDesiredStateEntity(serviceDesiredStateEntity);

    this.cluster = cluster;
    this.desiredConfigs = new HashMap<String, String>();

    this.components = new HashMap<String, ServiceComponent>();

    StackId stackId = cluster.getDesiredStackVersion();
    setDesiredStackVersion(stackId);

    ServiceInfo sInfo = ambariMetaInfo.getServiceInfo(stackId.getStackName(),
        stackId.getStackVersion(), serviceName);
    this.isClientOnlyService = sInfo.isClientOnlyService();

    init();
  }

  @AssistedInject
  public ServiceImpl(@Assisted Cluster cluster, @Assisted ClusterServiceEntity
      serviceEntity, Injector injector) {
    injector.injectMembers(this);
    this.serviceEntity = serviceEntity;
    this.cluster = cluster;

    //TODO check for null states?
    this.serviceDesiredStateEntity = serviceEntity.getServiceDesiredStateEntity();

    this.desiredConfigs = new HashMap<String, String>();

    this.components = new HashMap<String, ServiceComponent>();

    if (!serviceEntity.getServiceComponentDesiredStateEntities().isEmpty()) {
      for (ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity
          : serviceEntity.getServiceComponentDesiredStateEntities()) {
        components.put(serviceComponentDesiredStateEntity.getComponentName(),
            serviceComponentFactory.createExisting(this,
                serviceComponentDesiredStateEntity));
      }
    }

    for (ServiceConfigMappingEntity mappingEntity :
        serviceEntity.getServiceConfigMappings()) {
      desiredConfigs.put(mappingEntity.getConfigType(),
          mappingEntity.getVersionTag());
    }

    StackId stackId = getDesiredStackVersion();
    ServiceInfo sInfo = ambariMetaInfo.getServiceInfo(stackId.getStackName(),
        stackId.getStackVersion(), getName());
    this.isClientOnlyService = sInfo.isClientOnlyService();

    persisted = true;
  }

  @Override
  public String getName() {
      return serviceEntity.getServiceName();
  }

  @Override
  public long getClusterId() {
    return cluster.getClusterId();
  }

  @Override
  public synchronized Map<String, ServiceComponent> getServiceComponents() {
    return Collections.unmodifiableMap(components);
  }

  @Override
  public synchronized void addServiceComponents(
      Map<String, ServiceComponent> components) throws AmbariException {
    for (ServiceComponent sc : components.values()) {
      addServiceComponent(sc);
    }
  }

  @Override
  public synchronized void addServiceComponent(ServiceComponent component)
      throws AmbariException {
    // TODO validation
    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding a ServiceComponent to Service"
          + ", clusterName=" + cluster.getClusterName()
          + ", clusterId=" + cluster.getClusterId()
          + ", serviceName=" + getName()
          + ", serviceComponentName=" + component.getName());
    }
    if (components.containsKey(component.getName())) {
      throw new AmbariException("Cannot add duplicate ServiceComponent"
          + ", clusterName=" + cluster.getClusterName()
          + ", clusterId=" + cluster.getClusterId()
          + ", serviceName=" + getName()
          + ", serviceComponentName=" + component.getName());
    }
    this.components.put(component.getName(), component);
  }

  @Override
  public synchronized ServiceComponent addServiceComponent(
      String serviceComponentName) throws AmbariException {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding a ServiceComponent to Service"
          + ", clusterName=" + cluster.getClusterName()
          + ", clusterId=" + cluster.getClusterId()
          + ", serviceName=" + getName()
          + ", serviceComponentName=" + serviceComponentName);
    }
    if (components.containsKey(serviceComponentName)) {
      throw new AmbariException("Cannot add duplicate ServiceComponent"
          + ", clusterName=" + cluster.getClusterName()
          + ", clusterId=" + cluster.getClusterId()
          + ", serviceName=" + getName()
          + ", serviceComponentName=" + serviceComponentName);
    }
    ServiceComponent component = serviceComponentFactory.createNew(this, serviceComponentName);
    this.components.put(component.getName(), component);
    return component;
  }

  @Override
  public ServiceComponent getServiceComponent(String componentName)
      throws AmbariException {
    if (!components.containsKey(componentName)) {
      throw new ServiceComponentNotFoundException(cluster.getClusterName(),
          getName(),
          componentName);
    }
    return this.components.get(componentName);
  }

  @Override
  public synchronized State getDesiredState() {
    return this.serviceDesiredStateEntity.getDesiredState();
  }

  @Override
  public synchronized void setDesiredState(State state) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Setting DesiredState of Service"
          + ", clusterName=" + cluster.getClusterName()
          + ", clusterId=" + cluster.getClusterId()
          + ", serviceName=" + getName()
          + ", oldDesiredState=" + this.getDesiredState()
          + ", newDesiredState=" + state);
    }
    this.serviceDesiredStateEntity.setDesiredState(state);
    saveIfPersisted();
  }

  @Override
  public synchronized Map<String, Config> getDesiredConfigs() {
    Map<String, Config> map = new HashMap<String, Config>();
    for (Entry<String, String> entry : desiredConfigs.entrySet()) {
      Config config = cluster.getDesiredConfig(entry.getKey(), entry.getValue());
      if (null != config) {
        map.put(entry.getKey(), config);
      } else {
        // FIXME this is an error - should throw a proper exception
        throw new RuntimeException("Found an invalid config"
            + ", clusterName=" + getCluster().getClusterName()
            + ", serviceName=" + getName()
            + ", configType=" + entry.getKey()
            + ", configVersionTag=" + entry.getValue());
      }
    }
    return Collections.unmodifiableMap(map);
  }

  @Override
  public synchronized void updateDesiredConfigs(Map<String, Config> configs) {

    Set<String> deletedTypes = new HashSet<String>();
    for (String type : this.desiredConfigs.keySet()) {
      if (!configs.containsKey(type)) {
        deletedTypes.add(type);
      }
    }

    for (Entry<String,Config> entry : configs.entrySet()) {
      boolean contains = false;

      for (ServiceConfigMappingEntity serviceConfigMappingEntity : serviceEntity.getServiceConfigMappings()) {
        if (entry.getKey().equals(serviceConfigMappingEntity.getConfigType())) {
          contains = true;
          serviceConfigMappingEntity.setTimestamp(new Date().getTime());
          serviceConfigMappingEntity.setVersionTag(entry.getValue().getVersionTag());
        }
      }

      if (!contains) {
        ServiceConfigMappingEntity newEntity = new ServiceConfigMappingEntity();
        newEntity.setClusterId(serviceEntity.getClusterId());
        newEntity.setServiceName(serviceEntity.getServiceName());
        newEntity.setConfigType(entry.getKey());
        newEntity.setVersionTag(entry.getValue().getVersionTag());
        newEntity.setTimestamp(new Date().getTime());
        newEntity.setServiceEntity(serviceEntity);
        serviceEntity.getServiceConfigMappings().add(newEntity);

      }


      this.desiredConfigs.put(entry.getKey(), entry.getValue().getVersionTag());
    }

    if (!deletedTypes.isEmpty()) {
      if (persisted) {
        List<ServiceConfigMappingEntity> deleteEntities =
            serviceConfigMappingDAO.findByServiceAndType(
                serviceEntity.getClusterId(), serviceEntity.getServiceName(),
                deletedTypes);
        for (ServiceConfigMappingEntity deleteEntity : deleteEntities) {
          if (LOG.isDebugEnabled()) {
            LOG.debug("Deleting desired config from ServiceComponent"
                + ", clusterId=" + serviceEntity.getClusterId()
                + ", serviceName=" + serviceEntity.getServiceName()
                + ", configType=" + deleteEntity.getConfigType()
                + ", configVersionTag=" + deleteEntity.getVersionTag());
          }
          serviceEntity.getServiceConfigMappings().remove(
              deleteEntity);
          serviceConfigMappingDAO.remove(deleteEntity);
        }
      } else {
        for (String deletedType : deletedTypes) {
          desiredConfigs.remove(deletedType);
        }
      }
    }

    saveIfPersisted();

  }

  @Override
  public synchronized StackId getDesiredStackVersion() {
    return gson.fromJson(serviceDesiredStateEntity.getDesiredStackVersion(), StackId.class);
  }

  @Override
  public synchronized void setDesiredStackVersion(StackId stackVersion) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Setting DesiredStackVersion of Service"
          + ", clusterName=" + cluster.getClusterName()
          + ", clusterId=" + cluster.getClusterId()
          + ", serviceName=" + getName()
          + ", oldDesiredStackVersion=" + getDesiredStackVersion()
          + ", newDesiredStackVersion=" + stackVersion);
    }
    serviceDesiredStateEntity.setDesiredStackVersion(gson.toJson(stackVersion));
    saveIfPersisted();
  }

  @Override
  public synchronized ServiceResponse convertToResponse() {
    ServiceResponse r = new ServiceResponse(cluster.getClusterId(),
        cluster.getClusterName(),
        getName(),
        desiredConfigs,
        getDesiredStackVersion().getStackId(),
        getDesiredState().toString());
    return r;
  }

  @Override
  public Cluster getCluster() {
    return cluster;
  }

  @Override
  public synchronized void debugDump(StringBuilder sb) {
    sb.append("Service={ serviceName=" + getName()
        + ", clusterName=" + cluster.getClusterName()
        + ", clusterId=" + cluster.getClusterId()
        + ", desiredStackVersion=" + getDesiredStackVersion()
        + ", desiredState=" + getDesiredState().toString()
        + ", configs=[");
    boolean first = true;
    if (desiredConfigs != null) {
      for (Entry<String, String> entry : desiredConfigs.entrySet()) {
        if (!first) {
          sb.append(" , ");
        }
        first = false;
        sb.append("{ Config type=" + entry.getKey()
            + ", versionTag=" + entry.getValue() + "}");
      }
    }
    sb.append("], components=[ ");

    first = true;
    for(ServiceComponent sc : components.values()) {
      if (!first) {
        sb.append(" , ");
      }
      first = false;
      sb.append("\n      ");
      sc.debugDump(sb);
      sb.append(" ");
    }
    sb.append(" ] }");
  }

  @Override
  public synchronized boolean isPersisted() {
      return persisted;
  }

  @Override
  public synchronized void persist() {
    if (!persisted) {
      persistEntities();
      refresh();
      cluster.refresh();
      persisted = true;
    } else {
      saveIfPersisted();
    }
  }

  @Transactional
  protected void persistEntities() {
    ClusterEntity clusterEntity = clusterDAO.findById(cluster.getClusterId());
    serviceEntity.setClusterEntity(clusterEntity);
    clusterServiceDAO.create(serviceEntity);
    serviceDesiredStateDAO.create(serviceDesiredStateEntity);
    clusterEntity.getClusterServiceEntities().add(serviceEntity);
    clusterDAO.merge(clusterEntity);
    serviceEntity = clusterServiceDAO.merge(serviceEntity);
    serviceDesiredStateEntity = serviceDesiredStateDAO.merge(serviceDesiredStateEntity);
  }

  @Transactional
  private void saveIfPersisted() {
    if (isPersisted()) {
      clusterServiceDAO.merge(serviceEntity);
      serviceDesiredStateDAO.merge(serviceDesiredStateEntity);
    }
  }

  @Override
  @Transactional
  public synchronized void refresh() {
    if (isPersisted()) {
      ClusterServiceEntityPK pk = new ClusterServiceEntityPK();
      pk.setClusterId(getClusterId());
      pk.setServiceName(getName());
      serviceEntity = clusterServiceDAO.findByPK(pk);
      serviceDesiredStateEntity = serviceEntity.getServiceDesiredStateEntity();
      clusterServiceDAO.refresh(serviceEntity);
      serviceDesiredStateDAO.refresh(serviceDesiredStateEntity);
    }
  }

  @Override
  public synchronized boolean canBeRemoved() {
    State state = getDesiredState();
    if (state != State.INIT
        && state != State.UNINSTALLED) {
      return false;
    }

    boolean safeToRemove = true;
    for (ServiceComponent sc : components.values()) {
      if (!sc.canBeRemoved()) {
        safeToRemove = false;
        LOG.warn("Found non removable component when trying to delete service"
            + ", clusterName=" + cluster.getClusterName()
            + ", serviceName=" + getName()
            + ", componentName=" + sc.getName());
        break;
      }
    }
    return safeToRemove;
  }

  @Override
  public synchronized void removeAllComponents() throws AmbariException {
    LOG.info("Deleting all components for service"
        + ", clusterName=" + cluster.getClusterName()
        + ", serviceName=" + getName());
    // FIXME check dependencies from meta layer
    for (ServiceComponent component : components.values()) {
      if (!component.canBeRemoved()) {
        throw new AmbariException("Found non removable component when trying to"
            + " delete all components from service"
            + ", clusterName=" + cluster.getClusterName()
            + ", serviceName=" + getName()
            + ", componentName=" + component.getName());
      }
    }
    for (ServiceComponent component : components.values()) {
      component.removeAllServiceComponentHosts();
    }
    components.clear();
    // FIXME update DB
  }

  @Override
  public synchronized void deleteServiceComponent(String componentName)
      throws AmbariException {
    ServiceComponent component = getServiceComponent(componentName);
    LOG.info("Deleting servicecomponent for cluster"
        + ", clusterName=" + cluster.getClusterName()
        + ", serviceName=" + getName()
        + ", componentName=" + componentName);
    // FIXME check dependencies from meta layer
    if (!component.canBeRemoved()) {
      throw new AmbariException("Could not delete component from cluster"
          + ", clusterName=" + cluster.getClusterName()
          + ", serviceName=" + getName()
          + ", componentName=" + componentName);
    }
    component.removeAllServiceComponentHosts();
    components.remove(componentName);
    // FIXME update DB
  }

  @Override
  public boolean isClientOnlyService() {
    return isClientOnlyService;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/ServiceInfo.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.ArrayList;
import java.util.List;

import org.codehaus.jackson.annotate.JsonIgnore;
import org.codehaus.jackson.map.annotate.JsonFilter;

@JsonFilter("propertiesfilter")
public class ServiceInfo {
  private String name;
    private String version;
    private String user;
    private String comment;
  private List<PropertyInfo> properties;
  private List<ComponentInfo> components;

  public String getName() {
    return name;
  }

  public void setName(String name) {
    this.name = name;
  }

  public String getVersion() {
    return version;
  }

  public void setVersion(String version) {
    this.version = version;
  }

  public String getUser() {
    return user;
  }

  public void setUser(String user) {
    this.user = user;
  }

  public String getComment() {
    return comment;
  }

  public void setComment(String comment) {
    this.comment = comment;
  }

  public List<PropertyInfo> getProperties() {
    if (properties == null) properties = new ArrayList<PropertyInfo>();
    return properties;
  }

  public List<ComponentInfo> getComponents() {
    if (components == null) components = new ArrayList<ComponentInfo>();
    return components;
  }

  public boolean isClientOnlyService() {
    if (components == null || components.isEmpty()) {
      return false;
    }
    for (ComponentInfo compInfo : components) {
      if (!compInfo.isClient()) {
        return false;
      }
    }
    return true;
  }

  public ComponentInfo getClientComponent() {
    if (components == null || components.isEmpty()) {
      return null;
    }
    for (ComponentInfo compInfo : components) {
      if (compInfo.isClient()) {
        return compInfo;
      }
    }
    return components.get(0);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("Service name:" + name + "\nversion:" + version +
        "\nuser:" + user + "\ncomment:" + comment);
//    if(properties != null)
//    for (PropertyInfo property : properties) {
//      sb.append("\tProperty name=" + property.getName() +
    //"\nproperty value=" + property.getValue() + "\ndescription=" + property.getDescription());
//    }
    for(ComponentInfo component : components){
      sb.append("\n\n\nComponent:\n");
      sb.append("name="+ component.getName());
      sb.append("\tcategory="+ component.getCategory() );
    }

    return sb.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/StackId.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

public class StackId {
  private String stackName;
  private String stackVersion;

  public StackId() {
    super();
    this.stackName = "";
    this.stackVersion = "";
  }

  public StackId(String stackId) {
    super();
    parseStackIdHelper(this, stackId);
  }

  public StackId(StackInfo stackInfo) {
    this.stackName = stackInfo.getName();
    this.stackVersion = stackInfo.getVersion();
  }

  /**
   * @return the stackName
   */
  public String getStackName() {
    return stackName;
  }

  /**
   * @return the stackVersion
   */
  public String getStackVersion() {
    return stackVersion;
  }

  /**
   * @return the stackVersion
   */
  public String getStackId() {
    if (stackName.isEmpty()
        && stackVersion.isEmpty()) {
      return "";
    }
    return stackName + "-" + stackVersion;
  }

  /**
   * @param stackId the stackVersion to set
   */
  public void setStackId(String stackId) {
    parseStackIdHelper(this, stackId);
  }

  @Override
  public boolean equals(Object object) {
    if (!(object instanceof StackId)) {
      return false;
    }
    if (this == object) {
      return true;
    }
    StackId s = (StackId) object;
    return stackVersion.equals(s.stackVersion);
  }

  @Override
  public int hashCode() {
    int result = stackVersion != null ? stackVersion.hashCode() : 0;
    return result;
  }

  public String toString() {
    return getStackId();
  }

  public static void parseStackIdHelper(StackId stackVersion,
      String stackId) {
    if (stackId.isEmpty()) {
      stackVersion.stackName = "";
      stackVersion.stackVersion = "";
      return;
    }
    int pos = stackId.indexOf('-');
    if (pos == -1
        || (stackId.length() <= (pos+1))) {
      throw new RuntimeException("Could not parse invalid Stack Id"
          + ", stackId=" + stackId);
    }
    stackVersion.stackName = stackId.substring(0, pos);
    stackVersion.stackVersion = stackId.substring(pos+1);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/StackInfo.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

import java.util.ArrayList;
import java.util.List;

public class StackInfo {
  private String name;
  private String version;
  private List<RepositoryInfo> repositories;
  private List<ServiceInfo> services;

  public String getName() {
    return name;
  }

  public void setName(String name) {
    this.name = name;
  }

  public String getVersion() {
    return version;
  }

  public void setVersion(String version) {
    this.version = version;
  }

  public List<RepositoryInfo> getRepositories() {
    if( repositories == null ) repositories = new ArrayList<RepositoryInfo>();
    return repositories;
  }

  public void setRepositories(List<RepositoryInfo> repositories) {
    this.repositories = repositories;
  }

  public synchronized List<ServiceInfo> getServices() {
    if (services == null) services = new ArrayList<ServiceInfo>();
    return services;
  }

  public synchronized void setServices(List<ServiceInfo> services) {
    this.services = services;
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder("Stack name:" + name + "\nversion:" + version );//TODO add repository
    if (services != null) {
      sb.append("\n\t\tService:");
      for (ServiceInfo service : services) {
        sb.append("\t\t" + service.toString());
      }
    }

    if (repositories != null) {
      sb.append("\n\t\tRepositories:");
      for (RepositoryInfo repository : repositories) {
        sb.append("\t\t" + repository.toString());
      }
    }

    return sb.toString();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/State.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state;

public enum State {
  /**
   * Initial/Clean state
   */
  INIT(0),
  /**
   * In the process of installing.
   */
  INSTALLING(1),
  /**
   * Install failed
   */
  INSTALL_FAILED(2),
  /**
   * State when install completed successfully
   */
  INSTALLED(3),
  /**
   * In the process of starting.
   */
  STARTING(4),
  /**
   * Start failed.
   */
  START_FAILED(5),
  /**
   * State when start completed successfully.
   */
  STARTED(6),
  /**
   * In the process of stopping.
   */
  STOPPING(7),
  /**
   * Stop failed
   */
  STOP_FAILED(8),

  /**
   * In the process of uninstalling.
   */
  UNINSTALLING(9),
  /**
   * Uninstall failed.
   */
  UNINSTALL_FAILED(10),
  /**
   * State when uninstall completed successfully.
   */
  UNINSTALLED(11),
  /**
   * In the process of wiping out the install
   */
  WIPING_OUT(12),
  /**
   * State when wipeout fails
   */
  WIPEOUT_FAILED(13);

  private final int state;

  private State(int state) {
    this.state = state;
  }

  public boolean isValidDesiredState() {
    switch (State.values()[this.state]) {
      case INIT:
      case INSTALLED:
      case STARTED:
      case UNINSTALLED:
        return true;
      default:
        return false;
    }
  }

  public boolean isInProgressState() {
    switch (State.values()[this.state]) {
      case INSTALLING:
      case STARTING:
      case STOPPING:
      case UNINSTALLING:
      case WIPING_OUT:
        return true;
      default:
        return false;
    }
  }

  public boolean isValidClientComponentState() {
    switch (State.values()[this.state]) {
      case STARTING:
      case STARTED:
      case START_FAILED:
      case STOP_FAILED:
      case STOPPING:
        return false;
      default:
        return true;
    }
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/Action.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;

public interface Action {

  /**
   * Get the Action ID for the action
   * @return ActionId
   */
  public ActionId getId();

  // TODO requires some form of ActionType to ensure only one running
  // action per action type
  // There may be gotchas such as de-commissioning should be allowed to happen
  // on more than one host at a time


  /**
   * Get Start Time of the action
   * @return Start time as a unix timestamp
   */
  public long getStartTime();

  /**
   * Get the last update time of the Action when its progress status
   * was updated
   * @return Last Update Time as a unix timestamp
   */
  public long getLastUpdateTime();

  /**
   * Time when the Action completed
   * @return Completion Time as a unix timestamp
   */
  public long getCompletionTime();

  /**
   * Get the current state of the Action
   * @return ActionState
   */
  public ActionState getState();

  /**
   * Set the State of the Action
   * @param state ActionState
   */
  public void setState(ActionState state);

  /**
   * Send a ActionEvent to the Action's StateMachine
   * @param event ActionEvent
   * @throws InvalidStateTransitionException
   */
  public void handleEvent(ActionEvent event)
      throws InvalidStateTransitionException;
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionCompletedEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

public class ActionCompletedEvent extends ActionEvent {

  private final long completionTime;

  // TODO
  // need to add action report

  public ActionCompletedEvent(ActionId actionId, long completionTime) {
    super(ActionEventType.ACTION_COMPLETED, actionId);
    this.completionTime = completionTime;
  }

  /**
   * @return the completionTime
   */
  public long getCompletionTime() {
    return completionTime;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

import org.apache.ambari.server.state.fsm.event.AbstractEvent;

/**
 * Base class for all events that affect the Action FSM
 */
public abstract class ActionEvent extends AbstractEvent<ActionEventType> {

  /**
   * ActionId identifying the action
   */
  private final ActionId actionId;

  public ActionEvent(ActionEventType type, ActionId actionId) {
    super(type);
    this.actionId = actionId;
  }

  /**
   * @return the actionId
   */
  public ActionId getActionId() {
    return actionId;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionEventType.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

public enum ActionEventType {
  /**
   * Initial state for the Action when triggered.
   */
  ACTION_INIT,
  /**
   * Action still in progress.
   */
  ACTION_IN_PROGRESS,
  /**
   * Action completed successfully.
   */
  ACTION_COMPLETED,
  /**
   * Action failed to complete successfully.
   */
  ACTION_FAILED
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionFailedEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

public class ActionFailedEvent extends ActionEvent {

  private final long completionTime;

  // TODO
  // need to add action report

  public ActionFailedEvent(ActionId actionId, long completionTime) {
    super(ActionEventType.ACTION_FAILED, actionId);
    this.completionTime = completionTime;
  }

  /**
   * @return the completionTime
   */
  public long getCompletionTime() {
    return completionTime;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionId.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

// TODO
public class ActionId {

  final long actionId;

  final ActionType actionType;

  public ActionId(long actionId, ActionType actionType) {
    super();
    this.actionId = actionId;
    this.actionType = actionType;
  }

  public String toString() {
    return "[ actionId=" + actionId
        + ", actionType=" + actionType + "]";
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionImpl.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;
import org.apache.ambari.server.state.fsm.SingleArcTransition;
import org.apache.ambari.server.state.fsm.StateMachine;
import org.apache.ambari.server.state.fsm.StateMachineFactory;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

public class ActionImpl implements Action {

  private static final Log LOG = LogFactory.getLog(ActionImpl.class);

  private final Lock readLock;
  private final Lock writeLock;

  private ActionId id;

  private long startTime;
  private long lastUpdateTime;
  private long completionTime;

  // TODO
  // need to add action report

  private static final StateMachineFactory
    <ActionImpl, ActionState, ActionEventType, ActionEvent>
      stateMachineFactory
        = new StateMachineFactory<ActionImpl, ActionState,
          ActionEventType, ActionEvent>
            (ActionState.INIT)

    // define the state machine of a Action

    .addTransition(ActionState.INIT, ActionState.IN_PROGRESS,
        ActionEventType.ACTION_IN_PROGRESS, new ActionProgressUpdateTransition())
    .addTransition(ActionState.INIT, ActionState.COMPLETED,
        ActionEventType.ACTION_COMPLETED, new ActionCompletedTransition())
    .addTransition(ActionState.INIT, ActionState.FAILED,
        ActionEventType.ACTION_FAILED, new ActionFailedTransition())
    .addTransition(ActionState.INIT, ActionState.IN_PROGRESS,
        ActionEventType.ACTION_IN_PROGRESS, new ActionProgressUpdateTransition())
    .addTransition(ActionState.IN_PROGRESS, ActionState.IN_PROGRESS,
        ActionEventType.ACTION_IN_PROGRESS, new ActionProgressUpdateTransition())
    .addTransition(ActionState.IN_PROGRESS, ActionState.COMPLETED,
        ActionEventType.ACTION_COMPLETED, new ActionCompletedTransition())
    .addTransition(ActionState.IN_PROGRESS, ActionState.FAILED,
        ActionEventType.ACTION_FAILED, new ActionFailedTransition())
    .addTransition(ActionState.COMPLETED, ActionState.INIT,
        ActionEventType.ACTION_INIT, new NewActionTransition())
    .addTransition(ActionState.FAILED, ActionState.INIT,
        ActionEventType.ACTION_INIT, new NewActionTransition())
    .installTopology();

  private final StateMachine<ActionState, ActionEventType, ActionEvent>
      stateMachine;

  public ActionImpl(ActionId id, long startTime) {
    super();
    this.id = id;
    this.stateMachine = stateMachineFactory.make(this);
    ReadWriteLock rwLock = new ReentrantReadWriteLock();
    this.readLock = rwLock.readLock();
    this.writeLock = rwLock.writeLock();
    this.startTime = startTime;
    this.lastUpdateTime = -1;
    this.completionTime = -1;
  }

  private void reset() {
    try {
      writeLock.lock();
      this.startTime = -1;
      this.lastUpdateTime = -1;
      this.completionTime = -1;
    }
    finally {
      writeLock.unlock();
    }
  }

  static class NewActionTransition
     implements SingleArcTransition<ActionImpl, ActionEvent> {

    @Override
    public void transition(ActionImpl action, ActionEvent event) {
      ActionInitEvent e = (ActionInitEvent) event;
      // TODO audit logs
      action.reset();
      action.setId(e.getActionId());
      action.setStartTime(e.getStartTime());
      LOG.info("Launching a new Action"
          + ", actionId=" + action.getId()
          + ", startTime=" + action.getStartTime());
    }
  }

  static class ActionProgressUpdateTransition
      implements SingleArcTransition<ActionImpl, ActionEvent> {

    @Override
    public void transition(ActionImpl action, ActionEvent event) {
      ActionProgressUpdateEvent e = (ActionProgressUpdateEvent) event;
      action.setLastUpdateTime(e.getProgressUpdateTime());
      if (LOG.isDebugEnabled()) {
        LOG.debug("Progress update for Action"
            + ", actionId=" + action.getId()
            + ", startTime=" + action.getStartTime()
            + ", lastUpdateTime=" + action.getLastUpdateTime());
      }
    }
  }

  static class ActionCompletedTransition
     implements SingleArcTransition<ActionImpl, ActionEvent> {

    @Override
    public void transition(ActionImpl action, ActionEvent event) {
      // TODO audit logs
      ActionCompletedEvent e = (ActionCompletedEvent) event;
      action.setCompletionTime(e.getCompletionTime());
      action.setLastUpdateTime(e.getCompletionTime());

      LOG.info("Action completed successfully"
          + ", actionId=" + action.getId()
          + ", startTime=" + action.getStartTime()
          + ", completionTime=" + action.getCompletionTime());
    }
  }

  static class ActionFailedTransition
      implements SingleArcTransition<ActionImpl, ActionEvent> {

    @Override
    public void transition(ActionImpl action, ActionEvent event) {
      // TODO audit logs
      ActionFailedEvent e = (ActionFailedEvent) event;
      action.setCompletionTime(e.getCompletionTime());
      action.setLastUpdateTime(e.getCompletionTime());
      LOG.info("Action failed to complete"
          + ", actionId=" + action.getId()
          + ", startTime=" + action.getStartTime()
          + ", completionTime=" + action.getCompletionTime());
    }
  }


  @Override
  public ActionState getState() {
    try {
      readLock.lock();
      return stateMachine.getCurrentState();
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setState(ActionState state) {
    try {
      writeLock.lock();
      stateMachine.setCurrentState(state);
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public void handleEvent(ActionEvent event)
      throws InvalidStateTransitionException {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Handling Action event, eventType=" + event.getType().name()
          + ", event=" + event.toString());
    }
    ActionState oldState = getState();
    try {
      writeLock.lock();
      try {
        stateMachine.doTransition(event.getType(), event);
      } catch (InvalidStateTransitionException e) {
        LOG.error("Can't handle Action event at current state"
            + ", actionId=" + this.getId()
            + ", currentState=" + oldState
            + ", eventType=" + event.getType()
            + ", event=" + event);
        throw e;
      }
    }
    finally {
      writeLock.unlock();
    }
    if (oldState != getState()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Action transitioned to a new state"
            + ", actionId=" + this.getId()
            + ", oldState=" + oldState
            + ", currentState=" + getState()
            + ", eventType=" + event.getType().name()
            + ", event=" + event);
      }
    }
  }

  @Override
  public ActionId getId() {
    try {
      readLock.lock();
      return id;
    }
    finally {
      readLock.unlock();
    }
  }

  private void setId(ActionId id) {
    try {
      writeLock.lock();
      this.id = id;
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public long getStartTime() {
    try {
      readLock.lock();
      return startTime;
    }
    finally {
      readLock.unlock();
    }
  }

  public void setStartTime(long startTime) {
    try {
      writeLock.lock();
      this.startTime = startTime;
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public long getLastUpdateTime() {
    try {
      readLock.lock();
      return lastUpdateTime;
    }
    finally {
      readLock.unlock();
    }
  }

  public void setLastUpdateTime(long lastUpdateTime) {
    try {
      writeLock.lock();
      this.lastUpdateTime = lastUpdateTime;
    }
    finally {
      writeLock.unlock();
    }

  }

  @Override
  public long getCompletionTime() {
    try {
      readLock.lock();
      return completionTime;
    }
    finally {
      readLock.unlock();
    }
  }

  public void setCompletionTime(long completionTime) {
    try {
      writeLock.lock();
      this.completionTime = completionTime;
    }
    finally {
      writeLock.unlock();
    }
  }


}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionInitEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

public class ActionInitEvent extends ActionEvent {

  private final long startTime;

  public ActionInitEvent(ActionId actionId, long startTime) {
    super(ActionEventType.ACTION_INIT, actionId);
    this.startTime = startTime;
  }

  /**
   * @return the start time of the Action
   */
  public long getStartTime() {
    return startTime;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionProgressUpdateEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

public class ActionProgressUpdateEvent extends ActionEvent {

  private final long progressUpdateTime;

  public ActionProgressUpdateEvent(ActionId actionId, long progressUpdateTime) {
    super(ActionEventType.ACTION_IN_PROGRESS, actionId);
    this.progressUpdateTime = progressUpdateTime;
  }

  /**
   * @return the progressUpdateTime
   */
  public long getProgressUpdateTime() {
    return progressUpdateTime;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionState.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

public enum ActionState {
  /**
   * Initial state for the Action.
   * When a new action is triggered or set in motion.
   */
  INIT,
  /**
   * State when the Action is triggered on the cluster,
   */
  IN_PROGRESS,
  /**
   * State of successful completion
   */
  COMPLETED,
  /**
   * Action failed to complete successfully
   */
  FAILED
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/action/ActionType.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.action;

public class ActionType {

  public final String actionName;

  public ActionType(String actionName) {
    super();
    this.actionName = actionName;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/cluster/ClusterFactory.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.cluster;

import org.apache.ambari.server.orm.entities.ClusterEntity;
import org.apache.ambari.server.state.Cluster;

/**
 * Factory interface for Guice injections
 */
public interface ClusterFactory {
  Cluster create(ClusterEntity clusterEntity);
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/cluster/ClusterImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.cluster;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.TreeMap;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

import com.google.gson.Gson;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.ServiceComponentHostNotFoundException;
import org.apache.ambari.server.ServiceNotFoundException;
import org.apache.ambari.server.controller.ClusterResponse;
import org.apache.ambari.server.orm.dao.ClusterDAO;
import org.apache.ambari.server.orm.entities.ClusterConfigEntity;
import org.apache.ambari.server.orm.entities.ClusterEntity;
import org.apache.ambari.server.orm.entities.ClusterServiceEntity;
import org.apache.ambari.server.state.Cluster;
import org.apache.ambari.server.state.Clusters;
import org.apache.ambari.server.state.Config;
import org.apache.ambari.server.state.ConfigFactory;
import org.apache.ambari.server.state.Service;
import org.apache.ambari.server.state.ServiceComponentHost;
import org.apache.ambari.server.state.ServiceFactory;
import org.apache.ambari.server.state.StackId;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.assistedinject.Assisted;

public class ClusterImpl implements Cluster {

  private static final Logger LOG =
      LoggerFactory.getLogger(ClusterImpl.class);

  @Inject
  private Clusters clusters;

  private StackId desiredStackVersion;
  private StackId desiredState;

  private Map<String, Service> services = null;

  /**
   * [ Config Type -> [ Config Version Tag -> Config ] ]
   */
  private Map<String, Map<String, Config>> configs;

  /**
   * [ ServiceName -> [ ServiceComponentName -> [ HostName -> [ ... ] ] ] ]
   */
  private Map<String, Map<String, Map<String, ServiceComponentHost>>>
      serviceComponentHosts;

  /**
   * [ HostName -> [ ... ] ]
   */
  private Map<String, List<ServiceComponentHost>>
      serviceComponentHostsByHost;

  private ReadWriteLock readWriteLock = new ReentrantReadWriteLock();
  private Lock readLock = readWriteLock.readLock();
  private Lock writeLock = readWriteLock.writeLock();

  private ClusterEntity clusterEntity;

  @Inject
  private ClusterDAO clusterDAO;
//  @Inject
//  private ClusterServiceDAO clusterServiceDAO;
  @Inject
  private ServiceFactory serviceFactory;
  @Inject
  private ConfigFactory configFactory;
  @Inject
  private Gson gson;

  @Inject
  public ClusterImpl(@Assisted ClusterEntity clusterEntity,
                     Injector injector) {
    injector.injectMembers(this);
    this.clusterEntity = clusterEntity;

    this.serviceComponentHosts = new HashMap<String,
        Map<String, Map<String, ServiceComponentHost>>>();
    this.serviceComponentHostsByHost = new HashMap<String,
        List<ServiceComponentHost>>();
    this.desiredStackVersion = gson.fromJson(clusterEntity.getDesiredStackVersion(), StackId.class);

    configs = new HashMap<String, Map<String, Config>>();
    if (!clusterEntity.getClusterConfigEntities().isEmpty()) {
      for (ClusterConfigEntity entity : clusterEntity.getClusterConfigEntities()) {

        if (!configs.containsKey(entity.getType())) {
          configs.put(entity.getType(), new HashMap<String, Config>());
        }

        Config config = configFactory.createExisting(this, entity);

        configs.get(entity.getType()).put(entity.getTag(), config);
      }
    }


  }

  private void loadServices() {
    if (services == null) {
      synchronized (this) {
        if (services == null) {
          services = new TreeMap<String, Service>();
          if (!clusterEntity.getClusterServiceEntities().isEmpty()) {
            for (ClusterServiceEntity serviceEntity : clusterEntity.getClusterServiceEntities()) {
              services.put(serviceEntity.getServiceName(), serviceFactory.createExisting(this, serviceEntity));
            }
          }
        }
      }
    }
  }

  public ServiceComponentHost getServiceComponentHost(String serviceName,
      String serviceComponentName, String hostname) throws AmbariException {
    if (!serviceComponentHosts.containsKey(serviceName)
        || !serviceComponentHosts.get(serviceName)
            .containsKey(serviceComponentName)
        || !serviceComponentHosts.get(serviceName).get(serviceComponentName)
            .containsKey(hostname)) {
      throw new ServiceComponentHostNotFoundException(getClusterName(), serviceName,
          serviceComponentName, hostname);
    }
    return serviceComponentHosts.get(serviceName).get(serviceComponentName)
        .get(hostname);
  }

  @Override
  public String getClusterName() {
    try {
      readLock.lock();
      return clusterEntity.getClusterName();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setClusterName(String clusterName) {
    try {
      writeLock.lock();
      String oldName = clusterEntity.getClusterName();
      clusterEntity.setClusterName(clusterName);
      clusterDAO.merge(clusterEntity); //RollbackException possibility if UNIQUE constraint violated
      clusters.updateClusterName(oldName, clusterName);
    } finally {
      writeLock.unlock();
    }
  }

  public synchronized void addServiceComponentHost(
      ServiceComponentHost svcCompHost) throws AmbariException {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Trying to add ServiceComponentHost to ClusterHostMap cache"
          + ", serviceName=" + svcCompHost.getServiceName()
          + ", componentName=" + svcCompHost.getServiceComponentName()
          + ", hostname=" + svcCompHost.getHostName());
    }

    final String hostname = svcCompHost.getHostName();
    final String serviceName = svcCompHost.getServiceName();
    final String componentName = svcCompHost.getServiceComponentName();
    Set<Cluster> cs = clusters.getClustersForHost(hostname);
    boolean clusterFound = false;
    Iterator<Cluster> iter = cs.iterator();
    while (iter.hasNext()) {
      Cluster c = iter.next();
      if (c.getClusterId() == this.getClusterId()) {
        clusterFound = true;
        break;
      }
    }
    if (!clusterFound) {
      throw new AmbariException("Host does not belong this cluster"
              + ", hostname=" + hostname
              + ", clusterName=" + getClusterName()
              + ", clusterId=" + getClusterId());
    }

    if (!serviceComponentHosts.containsKey(serviceName)) {
      serviceComponentHosts.put(serviceName,
          new HashMap<String, Map<String,ServiceComponentHost>>());
    }
    if (!serviceComponentHosts.get(serviceName).containsKey(componentName)) {
      serviceComponentHosts.get(serviceName).put(componentName,
          new HashMap<String, ServiceComponentHost>());
    }

    if (serviceComponentHosts.get(serviceName).get(componentName).
        containsKey(hostname)) {
      throw new AmbariException("Duplicate entry for ServiceComponentHost"
          + ", serviceName=" + serviceName
          + ", serviceComponentName" + componentName
          + ", hostname= " + hostname);
    }

    if (!serviceComponentHostsByHost.containsKey(hostname)) {
      serviceComponentHostsByHost.put(hostname,
          new ArrayList<ServiceComponentHost>());
    }

    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding a new ServiceComponentHost"
          + ", clusterName=" + getClusterName()
          + ", clusterId=" + getClusterId()
          + ", serviceName=" + serviceName
          + ", serviceComponentName" + componentName
          + ", hostname= " + hostname);
    }

    serviceComponentHosts.get(serviceName).get(componentName).put(hostname,
        svcCompHost);
    serviceComponentHostsByHost.get(hostname).add(svcCompHost);
  }

  @Override
  public long getClusterId() {
    return clusterEntity.getClusterId();
  }

  @Override
  public synchronized List<ServiceComponentHost> getServiceComponentHosts(
      String hostname) {
    if (serviceComponentHostsByHost.containsKey(hostname)) {
      return Collections.unmodifiableList(
          serviceComponentHostsByHost.get(hostname));
    }
    return new ArrayList<ServiceComponentHost>();
  }

  @Override
  public synchronized void addService(Service service)
      throws AmbariException {
    loadServices();
    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding a new Service"
          + ", clusterName=" + getClusterName()
          + ", clusterId=" + getClusterId()
          + ", serviceName=" + service.getName());
    }
    if (services.containsKey(service.getName())) {
      throw new AmbariException("Service already exists"
          + ", clusterName=" + getClusterName()
          + ", clusterId=" + getClusterId()
          + ", serviceName=" + service.getName());
    }
    this.services.put(service.getName(), service);
  }

  @Override
  public synchronized Service addService(String serviceName) throws AmbariException{
    loadServices();
    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding a new Service"
          + ", clusterName=" + getClusterName()
          + ", clusterId=" + getClusterId()
          + ", serviceName=" + serviceName);
    }
    if (services.containsKey(serviceName)) {
      throw new AmbariException("Service already exists"
          + ", clusterName=" + getClusterName()
          + ", clusterId=" + getClusterId()
          + ", serviceName=" + serviceName);
    }
    Service s = serviceFactory.createNew(this, serviceName);
    this.services.put(s.getName(), s);
    return s;
  }

  @Override
  public synchronized Service getService(String serviceName)
      throws AmbariException {
    loadServices();
    if (!services.containsKey(serviceName)) {
      throw new ServiceNotFoundException(getClusterName(), serviceName);
    }
    return services.get(serviceName);
  }

  @Override
  public synchronized Map<String, Service> getServices() {
    loadServices();
    return Collections.unmodifiableMap(services);
  }

  @Override
  public synchronized StackId getDesiredStackVersion() {
    return desiredStackVersion;
  }

  @Override
  public synchronized void setDesiredStackVersion(StackId stackVersion) {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Changing DesiredStackVersion of Cluster"
        + ", clusterName=" + getClusterName()
        + ", clusterId=" + getClusterId()
        + ", currentDesiredStackVersion=" + this.desiredStackVersion
        + ", newDesiredStackVersion=" + stackVersion);
    }
    this.desiredStackVersion = stackVersion;
    clusterEntity.setDesiredStackVersion(gson.toJson(stackVersion));
    clusterDAO.merge(clusterEntity);
  }

  public synchronized StackId getDesiredState() {
    //TODO separate implementation, mapped to StackVersion for now
//    return desiredState; for separate implementation
    return getDesiredStackVersion();
  }

  public synchronized void setDesiredState(StackId desiredState) {
    //TODO separate implementation, mapped to StackVersion for now
//    LOG.debug("Changing desired state of cluster, clusterName={}, clusterId={}, oldState={}, newState={}",
//        getClusterName(), getClusterId(), this.desiredState, desiredState);
//    clusterEntity.setDesiredClusterState(gson.toJson(desiredState));
//    clusterDAO.merge(clusterEntity);
//    this.desiredState = desiredState;
    setDesiredStackVersion(desiredState);
  }


  @Override
  public synchronized Map<String, Config> getDesiredConfigsByType(String configType) {
    if (!configs.containsKey(configType))
      return null;

    return Collections.unmodifiableMap(configs.get(configType));
  }

  @Override
  public synchronized Config getDesiredConfig(String configType, String versionTag) {
    if (!configs.containsKey(configType)
        || !configs.get(configType).containsKey(versionTag)) {
      return null;
    }
    return configs.get(configType).get(versionTag);
  }

  @Override
  public synchronized void addDesiredConfig(Config config) {
    if (config.getType() == null
        || config.getType().isEmpty()
        || config.getVersionTag() == null
        || config.getVersionTag().isEmpty()) {
      // TODO throw error
    }
    if (!configs.containsKey(config.getType())) {
      configs.put(config.getType(), new HashMap<String, Config>());
    }

    configs.get(config.getType()).put(config.getVersionTag(), config);
  }

  public synchronized Collection<Config> getAllConfigs() {
    List<Config> list = new ArrayList<Config>();
    for (Entry<String,Map<String,Config>> entry : configs.entrySet()) {
      for (Config config : entry.getValue().values()) {
        list.add(config);
      }
    }
    return Collections.unmodifiableList(list);
  }

  @Override
  public synchronized ClusterResponse convertToResponse()
      throws AmbariException {
    ClusterResponse r = new ClusterResponse(getClusterId(), getClusterName(),
        clusters.getHostsForCluster(getClusterName()).keySet(),
        getDesiredStackVersion().getStackId());
    return r;
  }

  public synchronized void debugDump(StringBuilder sb) {
    loadServices();
    sb.append("Cluster={ clusterName=" + getClusterName()
        + ", clusterId=" + getClusterId()
        + ", desiredStackVersion=" + desiredStackVersion.getStackId()
        + ", services=[ ");
    boolean first = true;
    for(Service s : services.values()) {
      if (!first) {
        sb.append(" , ");
        first = false;
      }
      sb.append("\n    ");
      s.debugDump(sb);
      sb.append(" ");
    }
    sb.append(" ] }");
  }

  @Override
  @Transactional
  public synchronized void refresh() {
    clusterEntity = clusterDAO.findById(clusterEntity.getClusterId());
    clusterDAO.refresh(clusterEntity);
  }

  @Override
  public synchronized void deleteAllServices() throws AmbariException {
    loadServices();
    LOG.info("Deleting all services for cluster"
        + ", clusterName=" + getClusterName());
    for (Service service : services.values()) {
      if (!service.canBeRemoved()) {
        throw new AmbariException("Found non removable service when trying to"
            + " all services from cluster"
            + ", clusterName=" + getClusterName()
            + ", serviceName=" + service.getName());
      }
    }
    for (Service service : services.values()) {
      service.removeAllComponents();
    }
    services.clear();
    // FIXME update DB
  }

  @Override
  public synchronized void deleteService(String serviceName)
      throws AmbariException {
    loadServices();
    Service service = getService(serviceName);
    LOG.info("Deleting service for cluster"
        + ", clusterName=" + getClusterName()
        + ", serviceName=" + service.getName());
    // FIXME check dependencies from meta layer
    if (!service.canBeRemoved()) {
      throw new AmbariException("Could not delete service from cluster"
          + ", clusterName=" + getClusterName()
          + ", serviceName=" + service.getName());
    }
    service.removeAllComponents();
    services.remove(serviceName);
    // FIXME update DB
  }

  @Override
  public boolean canBeRemoved() {
    loadServices();
    boolean safeToRemove = true;
    for (Service service : services.values()) {
      if (!service.canBeRemoved()) {
        safeToRemove = false;
        LOG.warn("Found non removable service"
            + ", clusterName=" + getClusterName()
            + ", serviceName=" + service.getName());
      }
    }
    return safeToRemove;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/cluster/ClustersImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.cluster;

import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import javax.persistence.RollbackException;

import com.google.gson.Gson;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.ClusterNotFoundException;
import org.apache.ambari.server.DuplicateResourceException;
import org.apache.ambari.server.HostNotFoundException;
import org.apache.ambari.server.agent.DiskInfo;
import org.apache.ambari.server.api.services.AmbariMetaInfo;
import org.apache.ambari.server.orm.dao.ClusterDAO;
import org.apache.ambari.server.orm.dao.HostDAO;
import org.apache.ambari.server.orm.entities.ClusterEntity;
import org.apache.ambari.server.orm.entities.HostEntity;
import org.apache.ambari.server.state.*;
import org.apache.ambari.server.state.HostHealthStatus.HealthStatus;
import org.apache.ambari.server.state.host.HostFactory;
import org.apache.ambari.server.state.host.HostImpl;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.inject.Inject;
import com.google.inject.Singleton;

@Singleton
public class ClustersImpl implements Clusters {

  private static final Logger LOG = LoggerFactory.getLogger(
      ClustersImpl.class);

  private Map<String, Cluster> clusters;
  private Map<Long, Cluster> clustersById;
  private Map<String, Host> hosts;
  private Map<String, Set<Cluster>> hostClusterMap;
  private Map<String, Set<Host>> clusterHostMap;

  @Inject
  ClusterDAO clusterDAO;
  @Inject
  HostDAO hostDAO;
  @Inject
  ClusterFactory clusterFactory;
  @Inject
  HostFactory hostFactory;
  @Inject
  AmbariMetaInfo ambariMetaInfo;
  @Inject
  Gson gson;

  @Inject
  public ClustersImpl() {
    clusters = new HashMap<String, Cluster>();
    clustersById = new HashMap<Long, Cluster>();
    hosts = new HashMap<String, Host>();
    hostClusterMap = new HashMap<String, Set<Cluster>>();
    clusterHostMap = new HashMap<String, Set<Host>>();
    LOG.info("Initializing the ClustersImpl");
  }

  @Override
  public synchronized void addCluster(String clusterName)
      throws AmbariException {
    if (clusters.containsKey(clusterName)) {
      throw new DuplicateResourceException("Attempted to create a Cluster which already exists"
          + ", clusterName=" + clusterName);
    }

    // retrieve new cluster id
    // add cluster id -> cluster mapping into clustersById
    ClusterEntity clusterEntity = new ClusterEntity();
    clusterEntity.setClusterName(clusterName);
    clusterEntity.setDesiredStackVersion(gson.toJson(new StackId()));
    try {
      clusterDAO.create(clusterEntity);
      clusterEntity = clusterDAO.merge(clusterEntity);
      Cluster cluster = clusterFactory.create(clusterEntity);

      clusters.put(clusterName, cluster);
      clustersById.put(cluster.getClusterId(), cluster);
      clusterHostMap.put(clusterName, new HashSet<Host>());
    } catch (RollbackException e) {
      LOG.warn("Unable to create cluster " + clusterName, e);
      throw new AmbariException("Unable to create cluster " + clusterName, e);
    }
  }

  @Override
  @Transactional
  public synchronized Cluster getCluster(String clusterName)
      throws AmbariException {
    if (!clusters.containsKey(clusterName)) {
      ClusterEntity clusterEntity = clusterDAO.findByName(clusterName);
      if (clusterEntity != null) {
        Cluster cl = getClusterById(clusterEntity.getClusterId());
        clustersById.put(cl.getClusterId(), cl);
        clusters.put(cl.getClusterName(), cl);
        if (!clusterHostMap.containsKey(clusterEntity.getClusterName()))
          clusterHostMap.put(clusterEntity.getClusterName(), new HashSet<Host>());
      } else {
        throw new ClusterNotFoundException(clusterName);
      }
    }
    return clusters.get(clusterName);
  }

  @Override
  @Transactional
  public synchronized Cluster getClusterById(long id) throws AmbariException {
    if (!clustersById.containsKey(id)) {
      ClusterEntity clusterEntity = clusterDAO.findById(id);
      if (clusterEntity != null) {
        Cluster cluster = clusterFactory.create(clusterEntity);
        clustersById.put(cluster.getClusterId(), cluster);
        clusters.put(clusterEntity.getClusterName(), cluster);
        if (!clusterHostMap.containsKey(clusterEntity.getClusterName()))
          clusterHostMap.put(clusterEntity.getClusterName(), new HashSet<Host>());
      } else {
        throw new ClusterNotFoundException("clusterID=" + id);
      }
    }
    return clustersById.get(id);
  }

  @Override
  @Transactional
  public synchronized List<Host> getHosts() {
    List<Host> hostList = new ArrayList<Host>(hosts.size());
    hostList.addAll(hosts.values());

    for (HostEntity hostEntity : hostDAO.findAll()) {
      if (!hosts.containsKey(hostEntity.getHostName())) {
        try {
          hostList.add(getHost(hostEntity.getHostName()));
        } catch (AmbariException ignored) {
          LOG.error("Database externally modified?");
        }
      }
    }

    return hostList;
  }

  @Override
  public synchronized Set<Cluster> getClustersForHost(String hostname)
      throws AmbariException {
    if (!hostClusterMap.containsKey(hostname)) {
      getHost(hostname);
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug("Looking up clusters for hostname"
          + ", hostname=" + hostname
          + ", mappedClusters=" + hostClusterMap.get(hostname).size());
    }
    return Collections.unmodifiableSet(hostClusterMap.get(hostname));
  }

  @Override
  @Transactional
  public synchronized Host getHost(String hostname) throws AmbariException {
    if (!hosts.containsKey(hostname)) {
      HostEntity hostEntity = hostDAO.findByName(hostname);
      if (hostEntity != null) {
        Host host = hostFactory.create(hostEntity, true);
        Set<Cluster> cSet = new HashSet<Cluster>();
        hosts.put(hostname, host);
        hostClusterMap.put(hostname, cSet);

        for (ClusterEntity clusterEntity : hostEntity.getClusterEntities()) {
          if (clustersById.containsKey(clusterEntity.getClusterId())) {
            cSet.add(clustersById.get(clusterEntity.getClusterId()));
          } else {
            cSet.add(getClusterById(clusterEntity.getClusterId()));
          }
        }
      } else {
        throw new HostNotFoundException(hostname);
      }
    }
    return hosts.get(hostname);
  }

  @Override
  public synchronized void addHost(String hostname) throws AmbariException {
    if (hosts.containsKey(hostname)) {
      throw new AmbariException("Duplicate entry for Host"
          + ", hostName= " + hostname);
    }
    HostEntity hostEntity = new HostEntity();
    hostEntity.setHostName(hostname);
    hostEntity.setClusterEntities(new ArrayList<ClusterEntity>());
    //not stored to DB
    Host host = hostFactory.create(hostEntity, false);
    host.setAgentVersion(new AgentVersion(""));
    List<DiskInfo> emptyDiskList = new ArrayList<DiskInfo>();
    host.setDisksInfo(emptyDiskList);
    host.setHealthStatus(new HostHealthStatus(HealthStatus.UNKNOWN, ""));
    host.setHostAttributes(new HashMap<String, String>());
    host.setState(HostState.INIT);

    hosts.put(hostname, host);
    hostClusterMap.put(hostname, new HashSet<Cluster>());
    if (LOG.isDebugEnabled()) {
      LOG.debug("Adding a host to Clusters"
          + ", hostname=" + hostname);
    }
  }

  private boolean isOsSupportedByClusterStack(Cluster c, Host h) {
    Map<String, List<RepositoryInfo>> repos =
        ambariMetaInfo.getRepository(c.getDesiredStackVersion().getStackName(),
            c.getDesiredStackVersion().getStackVersion());
    if (repos == null || repos.isEmpty()) {
      return false;
    }
    return repos.containsKey(h.getOsType());
  }

  @Override
  public synchronized void mapHostToCluster(String hostname,
      String clusterName) throws AmbariException {
    Cluster cluster = getCluster(clusterName);
    HostImpl host = (HostImpl) getHost(hostname);

    if (!hostClusterMap.containsKey(hostname)) {
      throw new HostNotFoundException(hostname);
    }

    for (Cluster c : hostClusterMap.get(hostname)) {
      if (c.getClusterName().equals(clusterName)) {
        throw new DuplicateResourceException("Attempted to create a host which already exists: clusterName=" +
            clusterName + ", hostName=" + hostname);
      }
    }

    if (!isOsSupportedByClusterStack(cluster, host)) {
      String message = "Trying to map host to cluster where stack does not"
          + " support host's os type"
          + ", clusterName=" + clusterName
          + ", clusterStackId=" + cluster.getDesiredStackVersion().getStackId()
          + ", hostname=" + hostname
          + ", hostOsType=" + host.getOsType();
      LOG.warn(message);
      throw new AmbariException(message);
    }

    mapHostClusterEntities(hostname, cluster.getClusterId());

    hostClusterMap.get(hostname).add(cluster);
    clusterHostMap.get(clusterName).add(host);

    cluster.refresh();
    host.refresh();

    if (LOG.isDebugEnabled()) {
      LOG.debug("Mapping a host to a cluster"
          + ", clusterName=" + clusterName
          + ", clusterId=" + cluster.getClusterId()
          + ", hostname=" + hostname);
    }
  }

  @Transactional
  void mapHostClusterEntities(String hostName, Long clusterId) {
    HostEntity hostEntity = hostDAO.findByName(hostName);
    ClusterEntity clusterEntity = clusterDAO.findById(clusterId);

    hostEntity.getClusterEntities().add(clusterEntity);
    clusterEntity.getHostEntities().add(hostEntity);

    clusterDAO.merge(clusterEntity);
    hostDAO.merge(hostEntity);
  }

  @Override
  @Transactional
  public synchronized Map<String, Cluster> getClusters() {
    for (ClusterEntity clusterEntity : clusterDAO.findAll()) {
      try {
        if (!clustersById.containsKey(clusterEntity.getClusterId())) {
          getClusterById(clusterEntity.getClusterId());
        }
      } catch (AmbariException ignored) {

      }
    }
    return Collections.unmodifiableMap(clusters);
  }

  @Override
  public synchronized void mapHostsToCluster(Set<String> hostnames,
      String clusterName) throws AmbariException {
    for (String hostname : hostnames) {
      mapHostToCluster(hostname, clusterName);
    }
  }

  @Override
  public synchronized void updateClusterName(String oldName, String newName) {
    clusters.put(newName, clusters.remove(oldName));
  }


  public void debugDump(StringBuilder sb) {
    sb.append("Clusters=[ ");
    boolean first = true;
    for(Cluster c : clusters.values()) {
      if (!first) {
        sb.append(" , ");
        first = false;
      }
      sb.append("\n  ");
      c.debugDump(sb);
      sb.append(" ");
    }
    sb.append(" ]");
  }

  @Override
  @Transactional
  public Map<String, Host> getHostsForCluster(String clusterName)
      throws AmbariException {

    getCluster(clusterName);

    Map<String, Host> hosts = new HashMap<String, Host>();

    for (Host h : clusterHostMap.get(clusterName)) {
      hosts.put(h.getHostName(), h);
    }

    return hosts;
  }

  @Override
  @Transactional
  public synchronized void deleteCluster(String clusterName)
      throws AmbariException {
    Cluster cluster = getCluster(clusterName);
    if (!cluster.canBeRemoved()) {
      throw new AmbariException("Could not delete cluster"
          + ", clusterName=" + clusterName);
    }
    cluster.deleteAllServices();
    clusters.remove(clusterName);
    // FIXME update DB
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/fsm/InvalidStateTransitionException.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state.fsm;

/**
 * Exception thrown when a StateMachine encounters an invalid
 * event at its current state.
 */
@SuppressWarnings("serial")
public class InvalidStateTransitionException extends Exception {

  private Enum<?> currentState;
  private Enum<?> event;

  public InvalidStateTransitionException(Enum<?> currentState, Enum<?> event) {
    super("Invalid event: " + event + " at " + currentState);
    this.currentState = currentState;
    this.event = event;
  }

  public Enum<?> getCurrentState() {
    return currentState;
  }

  public Enum<?> getEvent() {
    return event;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/fsm/MultipleArcTransition.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state.fsm;

/**
 * Hook for Transition.
 * Post state is decided by Transition hook. Post state must be one of the
 * valid post states registered in StateMachine.
 */
public interface MultipleArcTransition
        <OPERAND, EVENT, STATE extends Enum<STATE>> {

  /**
   * Transition hook.
   * @return the postState. Post state must be one of the
   *                      valid post states registered in StateMachine.
   * @param operand the entity attached to the FSM, whose internal
   *                state may change.
   * @param event causal event
   */
  public STATE transition(OPERAND operand, EVENT event);

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/fsm/SingleArcTransition.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state.fsm;

/**
 * Hook for Transition. This lead to state machine to move to
 * the post state as registered in the state machine.
 */
public interface SingleArcTransition<OPERAND, EVENT> {
  /**
   * Transition hook.
   *
   * @param operand the entity attached to the FSM, whose internal
   *                state may change.
   * @param event causal event
   */
  public void transition(OPERAND operand, EVENT event);

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/fsm/StateMachine.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state.fsm;

public interface StateMachine
                 <STATE extends Enum<STATE>,
                  EVENTTYPE extends Enum<EVENTTYPE>, EVENT> {
  public STATE getCurrentState();
  public void setCurrentState(STATE state);
  public STATE doTransition(EVENTTYPE eventType, EVENT event)
        throws InvalidStateTransitionException;
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/fsm/StateMachineFactory.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state.fsm;

import java.util.EnumMap;
import java.util.HashMap;
import java.util.Map;
import java.util.Set;
import java.util.Stack;

/**
 * State machine topology.
 * This object is semantically immutable.  If you have a
 * StateMachineFactory there's no operation in the API that changes
 * its semantic properties.
 *
 * @param <OPERAND> The object type on which this state machine operates.
 * @param <STATE> The state of the entity.
 * @param <EVENTTYPE> The external eventType to be handled.
 * @param <EVENT> The event object.
 *
 */
final public class StateMachineFactory
             <OPERAND, STATE extends Enum<STATE>,
              EVENTTYPE extends Enum<EVENTTYPE>, EVENT> {

  private final TransitionsListNode transitionsListNode;

  private Map<STATE, Map<EVENTTYPE,
    Transition<OPERAND, STATE, EVENTTYPE, EVENT>>> stateMachineTable;

  private STATE defaultInitialState;

  private final boolean optimized;

  /**
   * Constructor
   *
   * This is the only constructor in the API.
   *
   */
  public StateMachineFactory(STATE defaultInitialState) {
    this.transitionsListNode = null;
    this.defaultInitialState = defaultInitialState;
    this.optimized = false;
    this.stateMachineTable = null;
  }

  private StateMachineFactory
      (StateMachineFactory<OPERAND, STATE, EVENTTYPE, EVENT> that,
       ApplicableTransition t) {
    this.defaultInitialState = that.defaultInitialState;
    this.transitionsListNode
        = new TransitionsListNode(t, that.transitionsListNode);
    this.optimized = false;
    this.stateMachineTable = null;
  }

  private StateMachineFactory
      (StateMachineFactory<OPERAND, STATE, EVENTTYPE, EVENT> that,
       boolean optimized) {
    this.defaultInitialState = that.defaultInitialState;
    this.transitionsListNode = that.transitionsListNode;
    this.optimized = optimized;
    if (optimized) {
      makeStateMachineTable();
    } else {
      stateMachineTable = null;
    }
  }

  private interface ApplicableTransition
             <OPERAND, STATE extends Enum<STATE>,
              EVENTTYPE extends Enum<EVENTTYPE>, EVENT> {
    void apply(StateMachineFactory<OPERAND, STATE, EVENTTYPE, EVENT> subject);
  }

  private class TransitionsListNode {
    final ApplicableTransition transition;
    final TransitionsListNode next;

    TransitionsListNode
        (ApplicableTransition transition, TransitionsListNode next) {
      this.transition = transition;
      this.next = next;
    }
  }

  static private class ApplicableSingleOrMultipleTransition
             <OPERAND, STATE extends Enum<STATE>,
              EVENTTYPE extends Enum<EVENTTYPE>, EVENT>
          implements ApplicableTransition<OPERAND, STATE, EVENTTYPE, EVENT> {
    final STATE preState;
    final EVENTTYPE eventType;
    final Transition<OPERAND, STATE, EVENTTYPE, EVENT> transition;

    ApplicableSingleOrMultipleTransition
        (STATE preState, EVENTTYPE eventType,
         Transition<OPERAND, STATE, EVENTTYPE, EVENT> transition) {
      this.preState = preState;
      this.eventType = eventType;
      this.transition = transition;
    }

    @Override
    public void apply
             (StateMachineFactory<OPERAND, STATE, EVENTTYPE, EVENT> subject) {
      Map<EVENTTYPE, Transition<OPERAND, STATE, EVENTTYPE, EVENT>> transitionMap
        = subject.stateMachineTable.get(preState);
      if (transitionMap == null) {
        // I use HashMap here because I would expect most EVENTTYPE's to not
        //  apply out of a particular state, so FSM sizes would be
        //  quadratic if I use EnumMap's here as I do at the top level.
        transitionMap = new HashMap<EVENTTYPE,
          Transition<OPERAND, STATE, EVENTTYPE, EVENT>>();
        subject.stateMachineTable.put(preState, transitionMap);
      }
      transitionMap.put(eventType, transition);
    }
  }

  /**
   * @return a NEW StateMachineFactory just like {@code this} with the current
   *          transition added as a new legal transition.  This overload
   *          has no hook object.
   *
   *         Note that the returned StateMachineFactory is a distinct
   *         object.
   *
   *         This method is part of the API.
   *
   * @param preState pre-transition state
   * @param postState post-transition state
   * @param eventType stimulus for the transition
   */
  public StateMachineFactory
             <OPERAND, STATE, EVENTTYPE, EVENT>
          addTransition(STATE preState, STATE postState, EVENTTYPE eventType) {
    return addTransition(preState, postState, eventType, null);
  }

  /**
   * @return a NEW StateMachineFactory just like {@code this} with the current
   *          transition added as a new legal transition.  This overload
   *          has no hook object.
   *
   *
   *         Note that the returned StateMachineFactory is a distinct
   *         object.
   *
   *         This method is part of the API.
   *
   * @param preState pre-transition state
   * @param postState post-transition state
   * @param eventTypes List of stimuli for the transitions
   */
  public StateMachineFactory<OPERAND, STATE, EVENTTYPE, EVENT> addTransition(
      STATE preState, STATE postState, Set<EVENTTYPE> eventTypes) {
    return addTransition(preState, postState, eventTypes, null);
  }

  /**
   * @return a NEW StateMachineFactory just like {@code this} with the current
   *          transition added as a new legal transition
   *
   *         Note that the returned StateMachineFactory is a distinct
   *         object.
   *
   *         This method is part of the API.
   *
   * @param preState pre-transition state
   * @param postState post-transition state
   * @param eventTypes List of stimuli for the transitions
   * @param hook transition hook
   */
  public StateMachineFactory<OPERAND, STATE, EVENTTYPE, EVENT> addTransition(
      STATE preState, STATE postState, Set<EVENTTYPE> eventTypes,
      SingleArcTransition<OPERAND, EVENT> hook) {
    StateMachineFactory<OPERAND, STATE, EVENTTYPE, EVENT> factory = null;
    for (EVENTTYPE event : eventTypes) {
      if (factory == null) {
        factory = addTransition(preState, postState, event, hook);
      } else {
        factory = factory.addTransition(preState, postState, event, hook);
      }
    }
    return factory;
  }

  /**
   * @return a NEW StateMachineFactory just like {@code this} with the current
   *          transition added as a new legal transition
   *
   *         Note that the returned StateMachineFactory is a distinct object.
   *
   *         This method is part of the API.
   *
   * @param preState pre-transition state
   * @param postState post-transition state
   * @param eventType stimulus for the transition
   * @param hook transition hook
   */
  public StateMachineFactory
             <OPERAND, STATE, EVENTTYPE, EVENT>
          addTransition(STATE preState, STATE postState,
                        EVENTTYPE eventType,
                        SingleArcTransition<OPERAND, EVENT> hook){
    return new StateMachineFactory
        (this, new ApplicableSingleOrMultipleTransition
           (preState, eventType, new SingleInternalArc(postState, hook)));
  }

  /**
   * @return a NEW StateMachineFactory just like {@code this} with the current
   *          transition added as a new legal transition
   *
   *         Note that the returned StateMachineFactory is a distinct object.
   *
   *         This method is part of the API.
   *
   * @param preState pre-transition state
   * @param postStates valid post-transition states
   * @param eventType stimulus for the transition
   * @param hook transition hook
   */
  public StateMachineFactory
             <OPERAND, STATE, EVENTTYPE, EVENT>
          addTransition(STATE preState, Set<STATE> postStates,
                        EVENTTYPE eventType,
                        MultipleArcTransition<OPERAND, EVENT, STATE> hook){
    return new StateMachineFactory
        (this,
         new ApplicableSingleOrMultipleTransition
           (preState, eventType, new MultipleInternalArc(postStates, hook)));
  }

  /**
   * @return a StateMachineFactory just like {@code this}, except that if
   *         you won't need any synchronization to build a state machine
   *
   *         Note that the returned StateMachineFactory is a distinct object.
   *
   *         This method is part of the API.
   *
   *         The only way you could distinguish the returned
   *         StateMachineFactory from {@code this} would be by
   *         measuring the performance of the derived
   *         {@code StateMachine} you can get from it.
   *
   * Calling this is optional.  It doesn't change the semantics of the factory,
   *   if you call it then when you use the factory there is no synchronization.
   */
  public StateMachineFactory
             <OPERAND, STATE, EVENTTYPE, EVENT>
          installTopology() {
    return new StateMachineFactory(this, true);
  }

  /**
   * Effect a transition due to the effecting stimulus.
   * @param state current state
   * @param eventType trigger to initiate the transition
   * @param cause causal eventType context
   * @return transitioned state
   */
  private STATE doTransition
           (OPERAND operand, STATE oldState, EVENTTYPE eventType, EVENT event)
      throws InvalidStateTransitionException {
    // We can assume that stateMachineTable is non-null because we call
    //  maybeMakeStateMachineTable() when we build an InnerStateMachine ,
    //  and this code only gets called from inside a working InnerStateMachine .
    Map<EVENTTYPE, Transition<OPERAND, STATE, EVENTTYPE, EVENT>> transitionMap
      = stateMachineTable.get(oldState);
    if (transitionMap != null) {
      Transition<OPERAND, STATE, EVENTTYPE, EVENT> transition
          = transitionMap.get(eventType);
      if (transition != null) {
        return transition.doTransition(operand, oldState, event, eventType);
      }
    }
    throw new InvalidStateTransitionException(oldState, eventType);
  }

  private synchronized void maybeMakeStateMachineTable() {
    if (stateMachineTable == null) {
      makeStateMachineTable();
    }
  }

  private void makeStateMachineTable() {
    Stack<ApplicableTransition> stack = new Stack<ApplicableTransition>();

    Map<STATE, Map<EVENTTYPE, Transition<OPERAND, STATE, EVENTTYPE, EVENT>>>
      prototype = new HashMap<STATE, Map<EVENTTYPE, Transition<OPERAND, STATE, EVENTTYPE, EVENT>>>();

    prototype.put(defaultInitialState, null);

    // I use EnumMap here because it'll be faster and denser.  I would
    //  expect most of the states to have at least one transition.
    stateMachineTable
       = new EnumMap<STATE, Map<EVENTTYPE,
                           Transition<OPERAND, STATE, EVENTTYPE, EVENT>>>(prototype);

    for (TransitionsListNode cursor = transitionsListNode;
         cursor != null;
         cursor = cursor.next) {
      stack.push(cursor.transition);
    }

    while (!stack.isEmpty()) {
      stack.pop().apply(this);
    }
  }

  private interface Transition<OPERAND, STATE extends Enum<STATE>,
          EVENTTYPE extends Enum<EVENTTYPE>, EVENT> {
    STATE doTransition(OPERAND operand, STATE oldState,
                       EVENT event, EVENTTYPE eventType)
       throws InvalidStateTransitionException;
  }

  private class SingleInternalArc
                    implements Transition<OPERAND, STATE, EVENTTYPE, EVENT> {

    private STATE postState;
    private SingleArcTransition<OPERAND, EVENT> hook; // transition hook

    SingleInternalArc(STATE postState,
        SingleArcTransition<OPERAND, EVENT> hook) {
      this.postState = postState;
      this.hook = hook;
    }

    @Override
    public STATE doTransition(OPERAND operand, STATE oldState,
                              EVENT event, EVENTTYPE eventType) {
      if (hook != null) {
        hook.transition(operand, event);
      }
      return postState;
    }
  }

  private class MultipleInternalArc
              implements Transition<OPERAND, STATE, EVENTTYPE, EVENT>{

    // Fields
    private Set<STATE> validPostStates;
    private MultipleArcTransition<OPERAND, EVENT, STATE> hook;  // transition hook

    MultipleInternalArc(Set<STATE> postStates,
                   MultipleArcTransition<OPERAND, EVENT, STATE> hook) {
      this.validPostStates = postStates;
      this.hook = hook;
    }

    @Override
    public STATE doTransition(OPERAND operand, STATE oldState,
                              EVENT event, EVENTTYPE eventType)
        throws InvalidStateTransitionException {
      STATE postState = hook.transition(operand, event);

      if (!validPostStates.contains(postState)) {
        throw new InvalidStateTransitionException(oldState, eventType);
      }
      return postState;
    }
  }

  /*
   * @return a {@link StateMachine} that starts in
   *         {@code initialState} and whose {@link Transition} s are
   *         applied to {@code operand} .
   *
   *         This is part of the API.
   *
   * @param operand the object upon which the returned
   *                {@link StateMachine} will operate.
   * @param initialState the state in which the returned
   *                {@link StateMachine} will start.
   *
   */
  public StateMachine<STATE, EVENTTYPE, EVENT>
        make(OPERAND operand, STATE initialState) {
    return new InternalStateMachine(operand, initialState);
  }

  /*
   * @return a {@link StateMachine} that starts in the default initial
   *          state and whose {@link Transition} s are applied to
   *          {@code operand} .
   *
   *         This is part of the API.
   *
   * @param operand the object upon which the returned
   *                {@link StateMachine} will operate.
   *
   */
  public StateMachine<STATE, EVENTTYPE, EVENT> make(OPERAND operand) {
    return new InternalStateMachine(operand, defaultInitialState);
  }

  private class InternalStateMachine
        implements StateMachine<STATE, EVENTTYPE, EVENT> {
    private final OPERAND operand;
    private STATE currentState;

    InternalStateMachine(OPERAND operand, STATE initialState) {
      this.operand = operand;
      this.currentState = initialState;
      if (!optimized) {
        maybeMakeStateMachineTable();
      }
    }

    @Override
    public synchronized STATE getCurrentState() {
      return currentState;
    }

    @Override
    public synchronized STATE doTransition(EVENTTYPE eventType, EVENT event)
         throws InvalidStateTransitionException  {
      currentState = StateMachineFactory.this.doTransition
          (operand, currentState, eventType, event);
      return currentState;
    }

    @Override
    public synchronized void setCurrentState(STATE state) {
      currentState = state;
    }

  }

  /*
   * Generate a graph represents the state graph of this StateMachine
   * @param name graph name
   * @return Graph object generated
  public Graph generateStateGraph(String name) {
    maybeMakeStateMachineTable();
    Graph g = new Graph(name);
    for (STATE startState : stateMachineTable.keySet()) {
      Map<EVENTTYPE, Transition<OPERAND, STATE, EVENTTYPE, EVENT>> transitions
          = stateMachineTable.get(startState);
      for (Entry<EVENTTYPE, Transition<OPERAND, STATE, EVENTTYPE, EVENT>> entry :
         transitions.entrySet()) {
        Transition<OPERAND, STATE, EVENTTYPE, EVENT> transition = entry.getValue();
        if (transition instanceof StateMachineFactory.SingleInternalArc) {
          StateMachineFactory.SingleInternalArc sa
              = (StateMachineFactory.SingleInternalArc) transition;
          Graph.Node fromNode = g.getNode(startState.toString());
          Graph.Node toNode = g.getNode(sa.postState.toString());
          fromNode.addEdge(toNode, entry.getKey().toString());
        } else if (transition instanceof StateMachineFactory.MultipleInternalArc) {
          StateMachineFactory.MultipleInternalArc ma
              = (StateMachineFactory.MultipleInternalArc) transition;
          Iterator<STATE> iter = ma.validPostStates.iterator();
          while (iter.hasNext()) {
            Graph.Node fromNode = g.getNode(startState.toString());
            Graph.Node toNode = g.getNode(iter.next().toString());
            fromNode.addEdge(toNode, entry.getKey().toString());
          }
        }
      }
    }
    return g;
  }
  */
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/fsm/event/AbstractEvent.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state.fsm.event;

/**
 * parent class of all the events. All events extend this class.
 */
public abstract class AbstractEvent<TYPE extends Enum<TYPE>>
    implements Event<TYPE> {

  private final TYPE type;
  private final long timestamp;

  // use this if you DON'T care about the timestamp
  public AbstractEvent(TYPE type) {
    this.type = type;
    // We're not generating a real timestamp here.  It's too expensive.
    timestamp = -1L;
  }

  // use this if you care about the timestamp
  public AbstractEvent(TYPE type, long timestamp) {
    this.type = type;
    this.timestamp = timestamp;
  }

  @Override
  public long getTimestamp() {
    return timestamp;
  }

  @Override
  public TYPE getType() {
    return type;
  }

  @Override
  public String toString() {
    return "EventType: " + getType();
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/fsm/event/Event.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state.fsm.event;

/**
 * Interface defining events api.
 *
 */
public interface Event<TYPE extends Enum<TYPE>> {

  TYPE getType();
  long getTimestamp();
  String toString();
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/fsm/event/EventHandler.java,false,"/**
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*/

package org.apache.ambari.server.state.fsm.event;

/**
 * Interface for handling events of type T
 *
 * @param <T> paremeterized event of type T
 */
public interface EventHandler<T extends Event<?> > {

  void handle(T event);

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/host/HostFactory.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.state.host;

import org.apache.ambari.server.orm.entities.HostEntity;
import org.apache.ambari.server.state.Host;

public interface HostFactory {
  Host create(HostEntity hostEntity, boolean persisted);
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/host/HostHealthyHeartbeatEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.state.host;

import org.apache.ambari.server.state.HostEvent;
import org.apache.ambari.server.state.HostEventType;

public class HostHealthyHeartbeatEvent extends HostEvent {

  private final long heartbeatTime;

  public HostHealthyHeartbeatEvent(String hostName, long heartbeatTime) {
    super(hostName, HostEventType.HOST_HEARTBEAT_HEALTHY);
    this.heartbeatTime = heartbeatTime;
  }

  /**
   * @return the heartbeatTime
   */
  public long getHeartbeatTime() {
    return heartbeatTime;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/host/HostHeartbeatLostEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.state.host;

import org.apache.ambari.server.state.HostEvent;
import org.apache.ambari.server.state.HostEventType;

public class HostHeartbeatLostEvent extends HostEvent {

  public HostHeartbeatLostEvent(String hostName) {
    super(hostName, HostEventType.HOST_HEARTBEAT_LOST);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/host/HostImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.ambari.server.state.host;

import java.lang.reflect.Type;
import java.util.*;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

import com.google.gson.Gson;
import com.google.gson.reflect.TypeToken;
import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.assistedinject.Assisted;
import com.google.inject.persist.Transactional;
import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.agent.DiskInfo;
import org.apache.ambari.server.agent.HostInfo;
import org.apache.ambari.server.controller.HostResponse;
import org.apache.ambari.server.orm.dao.ClusterDAO;
import org.apache.ambari.server.orm.dao.HostStateDAO;
import org.apache.ambari.server.orm.entities.ClusterEntity;
import org.apache.ambari.server.orm.entities.HostStateEntity;
import org.apache.ambari.server.state.*;
import org.apache.ambari.server.state.HostHealthStatus.HealthStatus;
import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;
import org.apache.ambari.server.state.fsm.SingleArcTransition;
import org.apache.ambari.server.state.fsm.StateMachine;
import org.apache.ambari.server.state.fsm.StateMachineFactory;
import org.apache.ambari.server.orm.dao.HostDAO;
import org.apache.ambari.server.orm.entities.HostEntity;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

public class HostImpl implements Host {

  private static final Log LOG = LogFactory.getLog(HostImpl.class);
  private final Gson gson;

  private static final Type diskInfoType =
      new TypeToken<List<DiskInfo>>() {}.getType();
  private static final Type hostAttributesType =
      new TypeToken<Map<String, String>>() {}.getType();

  private final Lock readLock;
  private final Lock writeLock;

  private HostEntity hostEntity;
  private HostStateEntity hostStateEntity;
  private Injector injector;
  private HostDAO hostDAO;
  private HostStateDAO hostStateDAO;
  private ClusterDAO clusterDAO;
  private Clusters clusters;

  private long lastHeartbeatTime = 0L;
  private boolean persisted = false;

  private static final String HARDWAREISA = "hardware_isa";
  private static final String HARDWAREMODEL = "hardware_model";
  private static final String INTERFACES = "interfaces";
  private static final String KERNEL = "kernel";
  private static final String KERNELMAJOREVERSON = "kernel_majorversion";
  private static final String KERNELRELEASE = "kernel_release";
  private static final String KERNELVERSION = "kernel_version";
  private static final String MACADDRESS = "mac_address";
  private static final String NETMASK = "netmask";
  private static final String OSFAMILY = "os_family";
  private static final String PHYSICALPROCESSORCOUNT =
      "physicalprocessors_count";
  private static final String PROCESSORCOUNT = "processors_count";
  private static final String SELINUXENABLED = "selinux_enabled";
  private static final String SWAPSIZE = "swap_size";
  private static final String SWAPFREE = "swap_free";
  private static final String TIMEZONE = "timezone";

  private static final StateMachineFactory
    <HostImpl, HostState, HostEventType, HostEvent>
      stateMachineFactory
        = new StateMachineFactory<HostImpl, HostState, HostEventType, HostEvent>
        (HostState.INIT)

   // define the state machine of a Host

   // Transition from INIT state
   // when the initial registration request is received
   .addTransition(HostState.INIT, HostState.WAITING_FOR_HOST_STATUS_UPDATES,
       HostEventType.HOST_REGISTRATION_REQUEST, new HostRegistrationReceived())
   // when a heartbeat is lost right after registration
   .addTransition(HostState.INIT, HostState.HEARTBEAT_LOST,
       HostEventType.HOST_HEARTBEAT_LOST, new HostHeartbeatLostTransition())

   // Transition from WAITING_FOR_STATUS_UPDATES state
   // when the host has responded to its status update requests
   // TODO this will create problems if the host is not healthy
   // TODO Based on discussion with Jitendra, ignoring this for now
   .addTransition(HostState.WAITING_FOR_HOST_STATUS_UPDATES, HostState.HEALTHY,
       HostEventType.HOST_STATUS_UPDATES_RECEIVED,
       new HostStatusUpdatesReceivedTransition())
   // when a normal heartbeat is received
   .addTransition(HostState.WAITING_FOR_HOST_STATUS_UPDATES,
       HostState.WAITING_FOR_HOST_STATUS_UPDATES,
       HostEventType.HOST_HEARTBEAT_HEALTHY)   // TODO: Heartbeat is ignored here
   // when a heartbeart denoting host as unhealthy is received
   .addTransition(HostState.WAITING_FOR_HOST_STATUS_UPDATES,
       HostState.WAITING_FOR_HOST_STATUS_UPDATES, // Still waiting for component status
       HostEventType.HOST_HEARTBEAT_UNHEALTHY,
       new HostBecameUnhealthyTransition()) // TODO: Not sure
  // when a heartbeat is lost and status update is not received
   .addTransition(HostState.WAITING_FOR_HOST_STATUS_UPDATES,
       HostState.HEARTBEAT_LOST,
       HostEventType.HOST_HEARTBEAT_LOST,
       new HostHeartbeatLostTransition())

   // Transitions from HEALTHY state
   // when a normal heartbeat is received
   .addTransition(HostState.HEALTHY, HostState.HEALTHY,
       HostEventType.HOST_HEARTBEAT_HEALTHY,
       new HostHeartbeatReceivedTransition())
   // when a heartbeat is not received within the configured timeout period
   .addTransition(HostState.HEALTHY, HostState.HEARTBEAT_LOST,
       HostEventType.HOST_HEARTBEAT_LOST,
       new HostHeartbeatLostTransition())
   // when a heartbeart denoting host as unhealthy is received
   .addTransition(HostState.HEALTHY, HostState.UNHEALTHY,
       HostEventType.HOST_HEARTBEAT_UNHEALTHY,
       new HostBecameUnhealthyTransition())
   // if a new registration request is received
   .addTransition(HostState.HEALTHY,
       HostState.WAITING_FOR_HOST_STATUS_UPDATES,
       HostEventType.HOST_REGISTRATION_REQUEST, new HostRegistrationReceived())

   // Transitions from UNHEALTHY state
   // when a normal heartbeat is received
   .addTransition(HostState.UNHEALTHY, HostState.HEALTHY,
       HostEventType.HOST_HEARTBEAT_HEALTHY,
       new HostBecameHealthyTransition())
   // when a heartbeart denoting host as unhealthy is received
   .addTransition(HostState.UNHEALTHY, HostState.UNHEALTHY,
       HostEventType.HOST_HEARTBEAT_UNHEALTHY,
       new HostHeartbeatReceivedTransition())
   // when a heartbeat is not received within the configured timeout period
   .addTransition(HostState.UNHEALTHY, HostState.HEARTBEAT_LOST,
       HostEventType.HOST_HEARTBEAT_LOST,
       new HostHeartbeatLostTransition())
   // if a new registration request is received
   .addTransition(HostState.UNHEALTHY,
       HostState.WAITING_FOR_HOST_STATUS_UPDATES,
       HostEventType.HOST_REGISTRATION_REQUEST, new HostRegistrationReceived())

   // Transitions from HEARTBEAT_LOST state
   // when a heartbeat is not received within the configured timeout period
   .addTransition(HostState.HEARTBEAT_LOST, HostState.HEARTBEAT_LOST,
       HostEventType.HOST_HEARTBEAT_LOST)
   // if a new registration request is received
   .addTransition(HostState.HEARTBEAT_LOST,
       HostState.WAITING_FOR_HOST_STATUS_UPDATES,
       HostEventType.HOST_REGISTRATION_REQUEST, new HostRegistrationReceived())

   .installTopology();

  private final StateMachine<HostState, HostEventType, HostEvent> stateMachine;

  @Inject
  public HostImpl(@Assisted HostEntity hostEntity,
      @Assisted boolean persisted, Injector injector) {
    this.stateMachine = stateMachineFactory.make(this);
    ReadWriteLock rwLock = new ReentrantReadWriteLock();
    this.readLock = rwLock.readLock();
    this.writeLock = rwLock.writeLock();

    this.hostEntity = hostEntity;
    this.injector = injector;
    this.persisted = persisted;
    this.hostDAO = injector.getInstance(HostDAO.class);
    this.hostStateDAO = injector.getInstance(HostStateDAO.class);
    this.gson = injector.getInstance(Gson.class);
    this.clusterDAO = injector.getInstance(ClusterDAO.class);
    this.clusters = injector.getInstance(Clusters.class);

    hostStateEntity = hostEntity.getHostStateEntity();
    if (hostStateEntity == null) {
      hostStateEntity = new HostStateEntity();
      hostStateEntity.setHostEntity(hostEntity);
      hostEntity.setHostStateEntity(hostStateEntity);
      setHealthStatus(new HostHealthStatus(HealthStatus.UNKNOWN, ""));
      if (persisted) {
        persist();
      }
    } else {
      this.stateMachine.setCurrentState(hostStateEntity.getCurrentState());
    }

  }

//  //TODO remove
//  public HostImpl(String hostname) {
//    this.stateMachine = stateMachineFactory.make(this);
//    ReadWriteLock rwLock = new ReentrantReadWriteLock();
//    this.readLock = rwLock.readLock();
//    this.writeLock = rwLock.writeLock();
//    setHostName(hostname);
//    setHealthStatus(new HostHealthStatus(HealthStatus.UNKNOWN, ""));
//  }

  static class HostRegistrationReceived
      implements SingleArcTransition<HostImpl, HostEvent> {

    @Override
    public void transition(HostImpl host, HostEvent event) {
      HostRegistrationRequestEvent e = (HostRegistrationRequestEvent) event;
      host.importHostInfo(e.hostInfo);
      host.setLastRegistrationTime(e.registrationTime);
      //Initialize heartbeat time and timeInState with registration time.
      host.setLastHeartbeatTime(e.registrationTime);
      host.setTimeInState(e.registrationTime);
      host.setAgentVersion(e.agentVersion);
      host.setPublicHostName(e.publicHostName);

      String agentVersion = null;
      if (e.agentVersion != null) {
        agentVersion = e.agentVersion.getVersion();
      }
      LOG.info("Received host registration, host="
          + e.hostInfo.toString()
          + ", registrationTime=" + e.registrationTime
          + ", agentVersion=" + agentVersion);
      host.persist();
    }
  }

  static class HostStatusUpdatesReceivedTransition
      implements SingleArcTransition<HostImpl, HostEvent> {

    @Override
    public void transition(HostImpl host, HostEvent event) {
      HostStatusUpdatesReceivedEvent e = (HostStatusUpdatesReceivedEvent)event;
      // TODO Audit logs
      LOG.debug("Host transition to host status updates received state"
          + ", host=" + e.getHostName()
          + ", heartbeatTime=" + e.getTimestamp());
      host.setHealthStatus(new HostHealthStatus(HealthStatus.HEALTHY,
          host.getHealthStatus().getHealthReport()));
    }
  }

  static class HostHeartbeatReceivedTransition
    implements SingleArcTransition<HostImpl, HostEvent> {

    @Override
    public void transition(HostImpl host, HostEvent event) {
      long heartbeatTime = 0;
      switch (event.getType()) {
        case HOST_HEARTBEAT_HEALTHY:
          heartbeatTime =
            ((HostHealthyHeartbeatEvent)event).getHeartbeatTime();
          break;
        case HOST_HEARTBEAT_UNHEALTHY:
          heartbeatTime =
            ((HostUnhealthyHeartbeatEvent)event).getHeartbeatTime();
          break;
        default:
          break;
      }
      if (0 == heartbeatTime) {
        LOG.error("heartbeatTime = 0 !!!");
        // TODO handle error
      }
      host.setLastHeartbeatTime(heartbeatTime);
    }
  }

  static class HostBecameHealthyTransition
      implements SingleArcTransition<HostImpl, HostEvent> {

    @Override
    public void transition(HostImpl host, HostEvent event) {
      HostHealthyHeartbeatEvent e = (HostHealthyHeartbeatEvent) event;
      host.setLastHeartbeatTime(e.getHeartbeatTime());
      // TODO Audit logs
      LOG.debug("Host transitioned to a healthy state"
              + ", host=" + e.getHostName()
              + ", heartbeatTime=" + e.getHeartbeatTime());
      host.setHealthStatus(new HostHealthStatus(HealthStatus.HEALTHY, host.getHealthStatus().getHealthReport()));
    }
  }

  static class HostBecameUnhealthyTransition
      implements SingleArcTransition<HostImpl, HostEvent> {

    @Override
    public void transition(HostImpl host, HostEvent event) {
      HostUnhealthyHeartbeatEvent e = (HostUnhealthyHeartbeatEvent) event;
      host.setLastHeartbeatTime(e.getHeartbeatTime());
      // TODO Audit logs
      LOG.debug("Host transitioned to an unhealthy state"
          + ", host=" + e.getHostName()
          + ", heartbeatTime=" + e.getHeartbeatTime()
          + ", healthStatus=" + e.getHealthStatus());
      host.setHealthStatus(e.getHealthStatus());
    }
  }

  static class HostHeartbeatLostTransition
      implements SingleArcTransition<HostImpl, HostEvent> {

    @Override
    public void transition(HostImpl host, HostEvent event) {
      HostHeartbeatLostEvent e = (HostHeartbeatLostEvent) event;
      // TODO Audit logs
      LOG.debug("Host transitioned to heartbeat lost state"
          + ", host=" + e.getHostName()
          + ", lastHeartbeatTime=" + host.getLastHeartbeatTime());
      host.setHealthStatus(new HostHealthStatus(HealthStatus.UNKNOWN, host.getHealthStatus().getHealthReport()));
    }
  }

  @Override
  public void importHostInfo(HostInfo hostInfo) {
    try {
      writeLock.lock();
      String fqdn = hostInfo.getFQDN();
      if (fqdn != null
          && !fqdn.isEmpty()
          && !fqdn.equals(getHostName())) {
        if (! isPersisted()) {
          setHostName(hostInfo.getHostName());
        } else {
          LOG.info("Could not modify hostname of the host that is already persisted to DB");
        }
      }

      if (hostInfo.getIPAddress() != null
          && !hostInfo.getIPAddress().isEmpty()) {
        setIPv4(hostInfo.getIPAddress());
        setIPv6(hostInfo.getIPAddress());
      }

      setCpuCount(hostInfo.getPhysicalProcessorCount());
      setTotalMemBytes(hostInfo.getMemoryTotal());
      setAvailableMemBytes(hostInfo.getFreeMemory());

      if (hostInfo.getArchitecture() != null
          && !hostInfo.getArchitecture().isEmpty()) {
        setOsArch(hostInfo.getArchitecture());
      }

      if (hostInfo.getOS() != null
          && !hostInfo.getOS().isEmpty()) {
        String osType = hostInfo.getOS();
        if (hostInfo.getOSRelease() != null) {
          String[] release = hostInfo.getOSRelease().split("\\.");
          if (release.length > 0) {
            osType += release[0];
          }
        }
        setOsType(osType.toLowerCase());
      }

      if (hostInfo.getMounts() != null
          && !hostInfo.getMounts().isEmpty()) {
        setDisksInfo(hostInfo.getMounts());
      }

      // FIXME add all other information into host attributes
      this.setAgentVersion(new AgentVersion(
          hostInfo.getAgentUserId()));

      Map<String, String> attrs = new HashMap<String, String>();
      if (hostInfo.getHardwareIsa() != null) {
        attrs.put(HARDWAREISA, hostInfo.getHardwareIsa());
      }
      if (hostInfo.getHardwareModel() != null) {
        attrs.put(HARDWAREMODEL, hostInfo.getHardwareModel());
      }
      if (hostInfo.getInterfaces() != null) {
        attrs.put(INTERFACES, hostInfo.getInterfaces());
      }
      if (hostInfo.getKernel() != null) {
        attrs.put(KERNEL, hostInfo.getKernel());
      }
      if (hostInfo.getKernelMajVersion() != null) {
        attrs.put(KERNELMAJOREVERSON, hostInfo.getKernelMajVersion());
      }
      if (hostInfo.getKernelRelease() != null) {
        attrs.put(KERNELRELEASE, hostInfo.getKernelRelease());
      }
      if (hostInfo.getKernelVersion() != null) {
        attrs.put(KERNELVERSION, hostInfo.getKernelVersion());
      }
      if (hostInfo.getMacAddress() != null) {
        attrs.put(MACADDRESS, hostInfo.getMacAddress());
      }
      if (hostInfo.getNetMask() != null) {
        attrs.put(NETMASK, hostInfo.getNetMask());
      }
      if (hostInfo.getOSFamily() != null) {
        attrs.put(OSFAMILY, hostInfo.getOSFamily());
      }
      if (hostInfo.getPhysicalProcessorCount() != 0) {
        attrs.put(PHYSICALPROCESSORCOUNT,
          Long.toString(hostInfo.getPhysicalProcessorCount()));
      }
      if (hostInfo.getProcessorCount() != 0) {
        attrs.put(PROCESSORCOUNT,
          Long.toString(hostInfo.getProcessorCount()));
      }
      if (Boolean.toString(hostInfo.getSeLinux()) != null) {
        attrs.put(SELINUXENABLED, Boolean.toString(hostInfo.getSeLinux()));
      }
      if (hostInfo.getSwapSize() != null) {
        attrs.put(SWAPSIZE, hostInfo.getSwapSize());
      }
      if (hostInfo.getSwapFree() != null) {
        attrs.put(SWAPFREE, hostInfo.getSwapFree());
      }
      if (hostInfo.getTimeZone() != null) {
        attrs.put(TIMEZONE, hostInfo.getTimeZone());
      }
      setHostAttributes(attrs);

      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public HostState getState() {
    try {
      readLock.lock();
      return stateMachine.getCurrentState();
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setState(HostState state) {
    try {
      writeLock.lock();
      stateMachine.setCurrentState(state);
      hostStateEntity.setCurrentState(state);
      hostStateEntity.setTimeInState(System.currentTimeMillis());
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public void handleEvent(HostEvent event)
      throws InvalidStateTransitionException {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Handling Host event, eventType=" + event.getType().name()
          + ", event=" + event.toString());
    }
    HostState oldState = getState();
    try {
      writeLock.lock();
      try {
        stateMachine.doTransition(event.getType(), event);
      } catch (InvalidStateTransitionException e) {
        LOG.error("Can't handle Host event at current state"
            + ", host=" + this.getHostName()
            + ", currentState=" + oldState
            + ", eventType=" + event.getType()
            + ", event=" + event);
        throw e;
      }
    }
    finally {
      writeLock.unlock();
    }
    if (oldState != getState()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("Host transitioned to a new state"
            + ", host=" + this.getHostName()
            + ", oldState=" + oldState
            + ", currentState=" + getState()
            + ", eventType=" + event.getType().name()
            + ", event=" + event);
      }
    }
  }

  @Override
  public String getHostName() {
    try {
      readLock.lock();
      return hostEntity.getHostName();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setHostName(String hostName) {
    try {
      writeLock.lock();
      if (!isPersisted()) {
        hostEntity.setHostName(hostName);
      } else {
        throw new UnsupportedOperationException("PK of persisted entity cannot be modified");
      }
    } finally {
      writeLock.unlock();
    }
  }
  
  @Override
  public void setPublicHostName(String hostName) {
    try {
      writeLock.lock();
      hostEntity.setPublicHostName(hostName);
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }
  
  @Override
  public String getPublicHostName() {
    try {
      readLock.lock();
      return hostEntity.getPublicHostName();
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public String getIPv4() {
    try {
      readLock.lock();
      return hostEntity.getIpv4();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setIPv4(String ip) {
    try {
      writeLock.lock();
      hostEntity.setIpv4(ip);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public String getIPv6() {
    try {
      readLock.lock();
      return hostEntity.getIpv6();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setIPv6(String ip) {
    try {
      writeLock.lock();
      hostEntity.setIpv6(ip);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public int getCpuCount() {
    try {
      readLock.lock();
      return hostEntity.getCpuCount();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setCpuCount(int cpuCount) {
    try {
      writeLock.lock();
      hostEntity.setCpuCount(cpuCount);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public long getTotalMemBytes() {
    try {
      readLock.lock();
      return hostEntity.getTotalMem();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setTotalMemBytes(long totalMemBytes) {
    try {
      writeLock.lock();
      hostEntity.setTotalMem(totalMemBytes);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public long getAvailableMemBytes() {
    try {
      readLock.lock();
      return hostStateEntity.getAvailableMem();
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setAvailableMemBytes(long availableMemBytes) {
    try {
      writeLock.lock();
      hostStateEntity.setAvailableMem(availableMemBytes);
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public String getOsArch() {
    try {
      readLock.lock();
      return hostEntity.getOsArch();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setOsArch(String osArch) {
    try {
      writeLock.lock();
      hostEntity.setOsArch(osArch);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public String getOsInfo() {
    try {
      readLock.lock();
      return hostEntity.getOsInfo();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setOsInfo(String osInfo) {
    try {
      writeLock.lock();
      hostEntity.setOsInfo(osInfo);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public String getOsType() {
    try {
      readLock.lock();
      return hostEntity.getOsType();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setOsType(String osType) {
    try {
      writeLock.lock();
      hostEntity.setOsType(osType);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public List<DiskInfo> getDisksInfo() {
    try {
      readLock.lock();
      return gson.<List<DiskInfo>>fromJson(
                hostEntity.getDisksInfo(), diskInfoType);
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setDisksInfo(List<DiskInfo> disksInfo) {
    try {
      writeLock.lock();
      hostEntity.setDisksInfo(gson.toJson(disksInfo, diskInfoType));
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public HostHealthStatus getHealthStatus() {
    try {
      readLock.lock();
      return gson.fromJson(hostStateEntity.getHealthStatus(),
          HostHealthStatus.class);
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setHealthStatus(HostHealthStatus healthStatus) {
    try {
      writeLock.lock();
      hostStateEntity.setHealthStatus(gson.toJson(healthStatus));
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public Map<String, String> getHostAttributes() {
    try {
      readLock.lock();
      return gson.<Map<String, String>>fromJson(hostEntity.getHostAttributes(),
          hostAttributesType);
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setHostAttributes(Map<String, String> hostAttributes) {
    try {
      writeLock.lock();
      Map<String, String> hostAttrs = gson.<Map<String, String>>
          fromJson(hostEntity.getHostAttributes(), hostAttributesType);
      if (hostAttrs == null) {
        hostAttrs = new HashMap<String, String>();
      }
      hostAttrs.putAll(hostAttributes);
      hostEntity.setHostAttributes(gson.toJson(hostAttrs,
          hostAttributesType));
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public String getRackInfo() {
    try {
      readLock.lock();
      return hostEntity.getRackInfo();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setRackInfo(String rackInfo) {
    try {
      writeLock.lock();
      hostEntity.setRackInfo(rackInfo);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public long getLastRegistrationTime() {
    try {
      readLock.lock();
      return hostEntity.getLastRegistrationTime();
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void setLastRegistrationTime(long lastRegistrationTime) {
    try {
      writeLock.lock();
      this.hostEntity.setLastRegistrationTime(lastRegistrationTime);
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public long getLastHeartbeatTime() {
    try {
      readLock.lock();
      return lastHeartbeatTime;
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setLastHeartbeatTime(long lastHeartbeatTime) {
    try {
      writeLock.lock();
      this.lastHeartbeatTime = lastHeartbeatTime;
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public AgentVersion getAgentVersion() {
    try {
      readLock.lock();
      return gson.fromJson(hostStateEntity.getAgentVersion(),
          AgentVersion.class);
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setAgentVersion(AgentVersion agentVersion) {
    try {
      writeLock.lock();
      hostStateEntity.setAgentVersion(gson.toJson(agentVersion));
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public long getTimeInState() {
    return hostStateEntity.getTimeInState();
  }

  @Override
  public void setTimeInState(long timeInState) {
    try {
      writeLock.lock();
      hostStateEntity.setTimeInState(timeInState);
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public HostResponse convertToResponse() {
    try {
      readLock.lock();
      HostResponse r = new HostResponse(getHostName());

      r.setAgentVersion(getAgentVersion());
      r.setAvailableMemBytes(getAvailableMemBytes());
      r.setCpuCount(getCpuCount());
      r.setDisksInfo(getDisksInfo());
      r.setHealthStatus(getHealthStatus());
      r.setHostAttributes(getHostAttributes());
      r.setIpv4(getIPv4());
      r.setIpv6(getIPv6());
      r.setLastHeartbeatTime(getLastHeartbeatTime());
      r.setLastRegistrationTime(getLastRegistrationTime());
      r.setOsArch(getOsArch());
      r.setOsInfo(getOsInfo());
      r.setOsType(getOsType());
      r.setRackInfo(getRackInfo());
      r.setTotalMemBytes(getTotalMemBytes());
      r.setPublicHostName(getPublicHostName());
      r.setHostState(getState().toString());

      return r;
    }
    finally {
      readLock.unlock();
    }
  }

  /**
   * Shows if Host is persisted to database
   *
   * @return true if persisted
   */
  @Override
  public boolean isPersisted() {
    try {
      readLock.lock();
      return persisted;
    } finally {
      readLock.unlock();
    }
  }

  /**
   * Save host to database and make all changes to be saved afterwards
   */
  @Override
  public void persist() {
    try {
      writeLock.lock();
      if (!persisted) {
        persistEntities();
        refresh();
        for (ClusterEntity clusterEntity : hostEntity.getClusterEntities()) {
          try {
            clusters.getClusterById(clusterEntity.getClusterId()).refresh();
          } catch (AmbariException e) {
            LOG.error(e);
            throw new RuntimeException("Cluster '" + clusterEntity.getClusterId() + "' was removed", e);
          }
        }
        persisted = true;
      } else {
        saveIfPersisted();
      }
    } finally {
      writeLock.unlock();
    }
  }

  @Transactional
  protected void persistEntities() {
    hostDAO.create(hostEntity);
    hostStateDAO.create(hostStateEntity);
    if (!hostEntity.getClusterEntities().isEmpty()) {
      for (ClusterEntity clusterEntity : hostEntity.getClusterEntities()) {
        clusterEntity.getHostEntities().add(hostEntity);
        clusterDAO.merge(clusterEntity);
      }
    }
  }

  @Override
  @Transactional
  public void refresh() {
    try {
      writeLock.lock();
      if (isPersisted()) {
        hostEntity = hostDAO.findByName(hostEntity.getHostName());
        hostStateEntity = hostEntity.getHostStateEntity();
        hostDAO.refresh(hostEntity);
        hostStateDAO.refresh(hostStateEntity);
      }
    } finally {
      writeLock.unlock();
    }
  }

  @Transactional
  private void saveIfPersisted() {
    if (isPersisted()) {
      hostDAO.merge(hostEntity);
      hostStateDAO.merge(hostStateEntity);
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/host/HostRegistrationRequestEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.host;

import org.apache.ambari.server.agent.HostInfo;
import org.apache.ambari.server.state.AgentVersion;
import org.apache.ambari.server.state.HostEvent;
import org.apache.ambari.server.state.HostEventType;

public class HostRegistrationRequestEvent extends HostEvent {

  final long registrationTime;
  final HostInfo hostInfo;
  final AgentVersion agentVersion;
  final String publicHostName;

  public HostRegistrationRequestEvent(String hostName,
      AgentVersion agentVersion, long registrationTime, HostInfo hostInfo) {
    this(hostName, hostName, agentVersion, registrationTime, hostInfo);
  }
  
  public HostRegistrationRequestEvent(String hostName, String publicName,
      AgentVersion agentVersion, long registrationTime, HostInfo hostInfo) {
    super(hostName, HostEventType.HOST_REGISTRATION_REQUEST);
    this.registrationTime = registrationTime;
    this.hostInfo = hostInfo;
    this.agentVersion = agentVersion;
    this.publicHostName = (null == publicName) ? hostName : publicName;
  }


}
"
ambari-server/src/main/java/org/apache/ambari/server/state/host/HostStatusUpdatesReceivedEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.host;

import org.apache.ambari.server.state.HostEvent;
import org.apache.ambari.server.state.HostEventType;

public class HostStatusUpdatesReceivedEvent extends HostEvent {

  private final long timestamp;

  // TODO need to add any additional information required for verification
  // tracking
  public HostStatusUpdatesReceivedEvent(String hostName,
      long timestamp) {
    super(hostName, HostEventType.HOST_STATUS_UPDATES_RECEIVED);
    this.timestamp = timestamp;
  }

  /**
   * @return the timestamp
   */
  public long getTimestamp() {
    return timestamp;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/host/HostUnhealthyHeartbeatEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.host;

import org.apache.ambari.server.state.HostEvent;
import org.apache.ambari.server.state.HostEventType;
import org.apache.ambari.server.state.HostHealthStatus;

public class HostUnhealthyHeartbeatEvent extends HostEvent {

  private final long heartbeatTime;

  private final HostHealthStatus healthStatus;

  public HostUnhealthyHeartbeatEvent(String hostName, long heartbeatTime,
      HostHealthStatus healthStatus) {
    super(hostName, HostEventType.HOST_HEARTBEAT_UNHEALTHY);
    this.heartbeatTime = heartbeatTime;
    this.healthStatus = healthStatus;
  }

  /**
   * @return the heartbeatTime
   */
  public long getHeartbeatTime() {
    return heartbeatTime;
  }

  /**
   * @return the healthStatus
   */
  public HostHealthStatus getHealthStatus() {
    return healthStatus;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostImpl.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import java.util.*;
import java.util.Map.Entry;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

import org.apache.ambari.server.AmbariException;
import org.apache.ambari.server.controller.ServiceComponentHostResponse;
import org.apache.ambari.server.orm.dao.HostComponentConfigMappingDAO;
import org.apache.ambari.server.orm.dao.HostComponentDesiredConfigMappingDAO;
import org.apache.ambari.server.orm.dao.HostComponentDesiredStateDAO;
import org.apache.ambari.server.orm.dao.HostComponentStateDAO;
import org.apache.ambari.server.orm.dao.HostDAO;
import org.apache.ambari.server.orm.dao.ServiceComponentDesiredStateDAO;
import org.apache.ambari.server.orm.entities.HostComponentConfigMappingEntity;
import org.apache.ambari.server.orm.entities.HostComponentDesiredConfigMappingEntity;
import org.apache.ambari.server.orm.entities.HostComponentDesiredStateEntity;
import org.apache.ambari.server.orm.entities.HostComponentDesiredStateEntityPK;
import org.apache.ambari.server.orm.entities.HostComponentStateEntity;
import org.apache.ambari.server.orm.entities.HostComponentStateEntityPK;
import org.apache.ambari.server.orm.entities.HostEntity;
import org.apache.ambari.server.orm.entities.ServiceComponentDesiredStateEntity;
import org.apache.ambari.server.orm.entities.ServiceComponentDesiredStateEntityPK;
import org.apache.ambari.server.state.Cluster;
import org.apache.ambari.server.state.Clusters;
import org.apache.ambari.server.state.Config;
import org.apache.ambari.server.state.Host;
import org.apache.ambari.server.state.ServiceComponent;
import org.apache.ambari.server.state.ServiceComponentHost;
import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;
import org.apache.ambari.server.state.StackId;
import org.apache.ambari.server.state.State;
import org.apache.ambari.server.state.fsm.InvalidStateTransitionException;
import org.apache.ambari.server.state.fsm.SingleArcTransition;
import org.apache.ambari.server.state.fsm.StateMachine;
import org.apache.ambari.server.state.fsm.StateMachineFactory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.gson.Gson;
import com.google.inject.Inject;
import com.google.inject.Injector;
import com.google.inject.assistedinject.Assisted;
import com.google.inject.assistedinject.AssistedInject;
import com.google.inject.persist.Transactional;

public class ServiceComponentHostImpl implements ServiceComponentHost {

  private static final Logger LOG =
      LoggerFactory.getLogger(ServiceComponentHostImpl.class);

  // FIXME need more debug logs

  private final Lock readLock;
  private final Lock writeLock;

  private final ServiceComponent serviceComponent;
  private final Host host;
  private boolean persisted = false;

  @Inject
  Gson gson;
  @Inject
  HostComponentStateDAO hostComponentStateDAO;
  @Inject
  HostComponentDesiredStateDAO hostComponentDesiredStateDAO;
  @Inject
  HostDAO hostDAO;
  @Inject
  ServiceComponentDesiredStateDAO serviceComponentDesiredStateDAO;
  @Inject
  Clusters clusters;
  @Inject
  HostComponentDesiredConfigMappingDAO
      hostComponentDesiredConfigMappingDAO;
  @Inject
  HostComponentConfigMappingDAO
      hostComponentConfigMappingDAO;

  private HostComponentStateEntity stateEntity;
  private HostComponentDesiredStateEntity desiredStateEntity;

  private Map<String, String> configs;
  private Map<String, String> desiredConfigs;

  private long lastOpStartTime;
  private long lastOpEndTime;
  private long lastOpLastUpdateTime;

  private static final StateMachineFactory
  <ServiceComponentHostImpl, State,
  ServiceComponentHostEventType, ServiceComponentHostEvent>
    daemonStateMachineFactory
      = new StateMachineFactory<ServiceComponentHostImpl,
          State, ServiceComponentHostEventType,
          ServiceComponentHostEvent>
          (State.INIT)

  // define the state machine of a HostServiceComponent for runnable
  // components

     .addTransition(State.INIT,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.INSTALLING,
         State.INSTALLED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
         
     .addTransition(State.INSTALLED,
         State.INSTALLED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
         
     .addTransition(State.INSTALLING,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
         new ServiceComponentHostOpInProgressTransition())
     .addTransition(State.INSTALLING,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.INSTALLING,
         State.INSTALL_FAILED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
         new ServiceComponentHostOpCompletedTransition())

     .addTransition(State.INSTALL_FAILED,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.INSTALL_FAILED,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.INSTALLED,
         State.STARTING,
         ServiceComponentHostEventType.HOST_SVCCOMP_START,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.INSTALLED,
         State.UNINSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_UNINSTALL,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.INSTALLED,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.INSTALLED,
         State.STOPPING,
         ServiceComponentHostEventType.HOST_SVCCOMP_STOP,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.STARTING,
         State.STARTING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
         new ServiceComponentHostOpInProgressTransition())
         
     .addTransition(State.STARTING,
         State.STARTING,
         ServiceComponentHostEventType.HOST_SVCCOMP_START,
         new ServiceComponentHostOpStartedTransition())
         
     .addTransition(State.STARTING,
         State.STARTED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
         
     .addTransition(State.STARTING,
         State.START_FAILED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
         new ServiceComponentHostOpCompletedTransition())

     .addTransition(State.START_FAILED,
         State.STARTING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.START_FAILED,
         State.STARTING,
         ServiceComponentHostEventType.HOST_SVCCOMP_START,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.START_FAILED,
         State.STOPPING,
         ServiceComponentHostEventType.HOST_SVCCOMP_STOP,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.STARTED,
         State.STOPPING,
         ServiceComponentHostEventType.HOST_SVCCOMP_STOP,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.STOPPING,
         State.STOPPING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
         new ServiceComponentHostOpInProgressTransition())
     .addTransition(State.STOPPING,
         State.INSTALLED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
     .addTransition(State.STOPPING,
         State.STOP_FAILED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
         new ServiceComponentHostOpCompletedTransition())

     .addTransition(State.STOP_FAILED,
         State.STOPPING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.STOP_FAILED,
         State.STOPPING,
         ServiceComponentHostEventType.HOST_SVCCOMP_STOP,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.UNINSTALLING,
         State.UNINSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
         new ServiceComponentHostOpInProgressTransition())
     .addTransition(State.UNINSTALLING,
         State.UNINSTALLED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
     .addTransition(State.UNINSTALLING,
         State.UNINSTALL_FAILED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
         new ServiceComponentHostOpCompletedTransition())

     .addTransition(State.UNINSTALL_FAILED,
         State.UNINSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.UNINSTALL_FAILED,
         State.UNINSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_UNINSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.UNINSTALLED,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.UNINSTALLED,
         State.WIPING_OUT,
         ServiceComponentHostEventType.HOST_SVCCOMP_WIPEOUT,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.WIPING_OUT,
         State.WIPING_OUT,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
         new ServiceComponentHostOpInProgressTransition())
     .addTransition(State.WIPING_OUT,
         State.INIT,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
     .addTransition(State.WIPING_OUT,
         State.WIPEOUT_FAILED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
         new ServiceComponentHostOpCompletedTransition())

     .addTransition(State.WIPEOUT_FAILED,
         State.WIPING_OUT,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.WIPEOUT_FAILED,
         State.WIPING_OUT,
         ServiceComponentHostEventType.HOST_SVCCOMP_WIPEOUT,
         new ServiceComponentHostOpStartedTransition())

     .installTopology();

  private static final StateMachineFactory
  <ServiceComponentHostImpl, State,
  ServiceComponentHostEventType, ServiceComponentHostEvent>
    clientStateMachineFactory
      = new StateMachineFactory<ServiceComponentHostImpl,
          State, ServiceComponentHostEventType,
          ServiceComponentHostEvent>
          (State.INIT)

  // define the state machine of a HostServiceComponent for client only
  // components

     .addTransition(State.INIT,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.INSTALLING,
         State.INSTALLED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
    
     .addTransition(State.INSTALLED,
         State.INSTALLED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
    
     .addTransition(State.INSTALLING,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())
     
     .addTransition(State.INSTALLING,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
         new ServiceComponentHostOpInProgressTransition())
     .addTransition(State.INSTALLING,
         State.INSTALL_FAILED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
         new ServiceComponentHostOpCompletedTransition())

     .addTransition(State.INSTALL_FAILED,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.INSTALL_FAILED,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.INSTALLED,
         State.UNINSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_UNINSTALL,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.INSTALLED,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.UNINSTALLING,
         State.UNINSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
         new ServiceComponentHostOpInProgressTransition())
     .addTransition(State.UNINSTALLING,
         State.UNINSTALLED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
     .addTransition(State.UNINSTALLING,
         State.UNINSTALL_FAILED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
         new ServiceComponentHostOpCompletedTransition())

     .addTransition(State.UNINSTALL_FAILED,
         State.UNINSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.UNINSTALL_FAILED,
         State.UNINSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_UNINSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.UNINSTALLED,
         State.INSTALLING,
         ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.UNINSTALLED,
         State.WIPING_OUT,
         ServiceComponentHostEventType.HOST_SVCCOMP_WIPEOUT,
         new ServiceComponentHostOpStartedTransition())

     .addTransition(State.WIPING_OUT,
         State.WIPING_OUT,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
         new ServiceComponentHostOpInProgressTransition())
     .addTransition(State.WIPING_OUT,
         State.INIT,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
         new ServiceComponentHostOpCompletedTransition())
     .addTransition(State.WIPING_OUT,
         State.WIPEOUT_FAILED,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
         new ServiceComponentHostOpCompletedTransition())

     .addTransition(State.WIPEOUT_FAILED,
         State.WIPING_OUT,
         ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
         new ServiceComponentHostOpStartedTransition())
     .addTransition(State.WIPEOUT_FAILED,
         State.WIPING_OUT,
         ServiceComponentHostEventType.HOST_SVCCOMP_WIPEOUT,
         new ServiceComponentHostOpStartedTransition())

     .installTopology();


  private final StateMachine<State,
      ServiceComponentHostEventType, ServiceComponentHostEvent> stateMachine;

  static class ServiceComponentHostOpCompletedTransition
     implements SingleArcTransition<ServiceComponentHostImpl,
         ServiceComponentHostEvent> {

    @Override
    public void transition(ServiceComponentHostImpl impl,
        ServiceComponentHostEvent event) {
      // TODO Audit logs
      impl.updateLastOpInfo(event.getType(), event.getOpTimestamp());
    }

  }

  static class ServiceComponentHostOpStartedTransition
    implements SingleArcTransition<ServiceComponentHostImpl,
        ServiceComponentHostEvent> {

    @Override
    public void transition(ServiceComponentHostImpl impl,
        ServiceComponentHostEvent event) {
      // TODO Audit logs
      // FIXME handle restartOp event
      impl.updateLastOpInfo(event.getType(), event.getOpTimestamp());
      if (event.getType() == ServiceComponentHostEventType.HOST_SVCCOMP_START) {
        ServiceComponentHostStartEvent e =
            (ServiceComponentHostStartEvent) event;
        if (LOG.isDebugEnabled()) {
          LOG.debug("Updating live state configs during START event"
              + ", updated configs set size=" + e.getConfigs().size());
        }
        impl.setConfigs(e.getConfigs());
      } else if (event.getType() ==
          ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL) {
        ServiceComponentHostInstallEvent e =
            (ServiceComponentHostInstallEvent) event;
        if (LOG.isDebugEnabled()) {
          LOG.debug("Updating live stack version during INSTALL event"
              + ", new stack verion=" + e.getStackId());
        }
        impl.setStackVersion(new StackId(e.getStackId()));
      }
    }
  }

  static class ServiceComponentHostOpInProgressTransition
    implements SingleArcTransition<ServiceComponentHostImpl,
        ServiceComponentHostEvent> {

    @Override
    public void transition(ServiceComponentHostImpl impl,
        ServiceComponentHostEvent event) {
      // TODO Audit logs
      impl.updateLastOpInfo(event.getType(), event.getOpTimestamp());
    }
  }


  private void resetLastOpInfo() {
    try {
      writeLock.lock();
      setLastOpStartTime(-1);
      setLastOpLastUpdateTime(-1);
      setLastOpEndTime(-1);
    }
    finally {
      writeLock.unlock();
    }
  }

  private void updateLastOpInfo(ServiceComponentHostEventType eventType,
      long time) {
    try {
      writeLock.lock();
      switch (eventType) {
        case HOST_SVCCOMP_INSTALL:
        case HOST_SVCCOMP_START:
        case HOST_SVCCOMP_STOP:
        case HOST_SVCCOMP_UNINSTALL:
        case HOST_SVCCOMP_WIPEOUT:
        case HOST_SVCCOMP_OP_RESTART:
          resetLastOpInfo();
          setLastOpStartTime(time);
          break;
        case HOST_SVCCOMP_OP_FAILED:
        case HOST_SVCCOMP_OP_SUCCEEDED:
          setLastOpLastUpdateTime(time);
          setLastOpEndTime(time);
          break;
        case HOST_SVCCOMP_OP_IN_PROGRESS:
          setLastOpLastUpdateTime(time);
          break;
      }
    }
    finally {
      writeLock.unlock();
    }
  }

  @AssistedInject
  public ServiceComponentHostImpl(@Assisted ServiceComponent serviceComponent,
                                  @Assisted String hostName, @Assisted boolean isClient, Injector injector) {
    injector.injectMembers(this);

    if (isClient) {
      this.stateMachine = clientStateMachineFactory.make(this);
    } else {
      this.stateMachine = daemonStateMachineFactory.make(this);
    }

    ReadWriteLock rwLock = new ReentrantReadWriteLock();
    this.readLock = rwLock.readLock();
    this.writeLock = rwLock.writeLock();
    this.serviceComponent = serviceComponent;

    stateEntity = new HostComponentStateEntity();
    stateEntity.setClusterId(serviceComponent.getClusterId());
    stateEntity.setComponentName(serviceComponent.getName());
    stateEntity.setServiceName(serviceComponent.getServiceName());
    stateEntity.setHostName(hostName);
    stateEntity.setCurrentState(stateMachine.getCurrentState());
    stateEntity.setCurrentStackVersion(gson.toJson(new StackId()));

    desiredStateEntity = new HostComponentDesiredStateEntity();
    desiredStateEntity.setClusterId(serviceComponent.getClusterId());
    desiredStateEntity.setComponentName(serviceComponent.getName());
    desiredStateEntity.setServiceName(serviceComponent.getServiceName());
    desiredStateEntity.setHostName(hostName);
    desiredStateEntity.setDesiredState(State.INIT);
    desiredStateEntity.setDesiredStackVersion(
        gson.toJson(serviceComponent.getDesiredStackVersion()));

    try {
      this.host = clusters.getHost(hostName);
    } catch (AmbariException e) {
      //TODO exception?
      LOG.error("Host '{}' was not found" + hostName);
      throw new RuntimeException(e);
    }

    this.resetLastOpInfo();
    this.desiredConfigs = new HashMap<String, String>();
    this.configs = new HashMap<String, String>();
  }

  @AssistedInject
  public ServiceComponentHostImpl(@Assisted ServiceComponent serviceComponent,
                                  @Assisted HostComponentStateEntity stateEntity,
                                  @Assisted HostComponentDesiredStateEntity desiredStateEntity,
                                  Injector injector) {
    injector.injectMembers(this);
    ReadWriteLock rwLock = new ReentrantReadWriteLock();
    this.readLock = rwLock.readLock();
    this.writeLock = rwLock.writeLock();
    this.serviceComponent = serviceComponent;


    this.desiredStateEntity = desiredStateEntity;
    this.stateEntity = stateEntity;
    //TODO implement State Machine init as now type choosing is hardcoded in above code
    if (serviceComponent.isClientComponent()) {
      this.stateMachine = clientStateMachineFactory.make(this);
    } else {
      this.stateMachine = daemonStateMachineFactory.make(this);
    }
    this.stateMachine.setCurrentState(stateEntity.getCurrentState());

    try {
      this.host = clusters.getHost(stateEntity.getHostName());
    } catch (AmbariException e) {
      //TODO exception? impossible due to database restrictions
      LOG.error("Host '{}' was not found " + stateEntity.getHostName());
      throw new RuntimeException(e);
    }

    desiredConfigs = new HashMap<String, String>();
    configs = new HashMap<String, String>();

    for (HostComponentDesiredConfigMappingEntity entity : desiredStateEntity.getHostComponentDesiredConfigMappingEntities()) {
      desiredConfigs.put(entity.getConfigType(), entity.getVersionTag());
    }
    // FIXME no configs in live state being persisted in DB??

    persisted = true;
  }

  @Override
  public State getState() {
    try {
      readLock.lock();
      return stateMachine.getCurrentState();
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setState(State state) {
    try {
      writeLock.lock();
      stateMachine.setCurrentState(state);
      stateEntity.setCurrentState(state);
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  @Transactional
  public void handleEvent(ServiceComponentHostEvent event)
      throws InvalidStateTransitionException {
    if (LOG.isDebugEnabled()) {
      LOG.debug("Handling ServiceComponentHostEvent event,"
          + " eventType=" + event.getType().name()
          + ", event=" + event.toString());
    }
    State oldState = getState();
    try {
      writeLock.lock();
      try {
        stateMachine.doTransition(event.getType(), event);
        stateEntity.setCurrentState(stateMachine.getCurrentState());
        saveIfPersisted();
        // TODO Audit logs
      } catch (InvalidStateTransitionException e) {
        LOG.error("Can't handle ServiceComponentHostEvent event at"
            + " current state"
            + ", serviceComponentName=" + this.getServiceComponentName()
            + ", hostName=" + this.getHostName()
            + ", currentState=" + oldState
            + ", eventType=" + event.getType()
            + ", event=" + event);
        throw e;
      }
    }
    finally {
      writeLock.unlock();
    }
    if (!oldState.equals(getState())) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("ServiceComponentHost transitioned to a new state"
            + ", serviceComponentName=" + this.getServiceComponentName()
            + ", hostName=" + this.getHostName()
            + ", oldState=" + oldState
            + ", currentState=" + getState()
            + ", eventType=" + event.getType().name()
            + ", event=" + event);
      }
    }
  }

  @Override
  public String getServiceComponentName() {
    return serviceComponent.getName();
  }

  @Override
  public String getHostName() {
    return host.getHostName();
  }

  /**
   * @return the lastOpStartTime
   */
  public long getLastOpStartTime() {
    try {
      readLock.lock();
      return lastOpStartTime;
    }
    finally {
      readLock.unlock();
    }
  }

  /**
   * @param lastOpStartTime the lastOpStartTime to set
   */
  public void setLastOpStartTime(long lastOpStartTime) {
    try {
      writeLock.lock();
      this.lastOpStartTime = lastOpStartTime;
    }
    finally {
      writeLock.unlock();
    }
  }

  /**
   * @return the lastOpEndTime
   */
  public long getLastOpEndTime() {
    try {
      readLock.lock();
      return lastOpEndTime;
    }
    finally {
      readLock.unlock();
    }
  }

  /**
   * @param lastOpEndTime the lastOpEndTime to set
   */
  public void setLastOpEndTime(long lastOpEndTime) {
    try {
      writeLock.lock();
      this.lastOpEndTime = lastOpEndTime;
    }
    finally {
      writeLock.unlock();
    }
  }

  /**
   * @return the lastOpLastUpdateTime
   */
  public long getLastOpLastUpdateTime() {
    try {
      readLock.lock();
      return lastOpLastUpdateTime;
    }
    finally {
      readLock.unlock();
    }
  }

  /**
   * @param lastOpLastUpdateTime the lastOpLastUpdateTime to set
   */
  public void setLastOpLastUpdateTime(long lastOpLastUpdateTime) {
    try {
      writeLock.lock();
      this.lastOpLastUpdateTime = lastOpLastUpdateTime;
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public long getClusterId() {
    return serviceComponent.getClusterId();
  }

  @Override
  public String getServiceName() {
    return serviceComponent.getServiceName();
  }

  Map<String, String> getConfigVersions() {
    try {
      readLock.lock();
      if (this.configs != null) {
        return Collections.unmodifiableMap(configs);
      } else {
        return new HashMap<String, String>();
      }
    }
    finally {
      readLock.unlock();
    }

  }

  @Override
  public Map<String, Config> getConfigs() throws AmbariException {
    try {
      readLock.lock();
      Map<String, Config> map = new HashMap<String, Config>();
      Cluster cluster = clusters.getClusterById(getClusterId());
      for (Entry<String, String> entry : configs.entrySet()) {
        Config config = cluster.getDesiredConfig(
            entry.getKey(), entry.getValue());
        if (null != config) {
          map.put(entry.getKey(), config);
        }
      }
      return map;
    }
    finally {
      readLock.unlock();
    }
  }

  @Transactional
  void setConfigs(Map<String, String> configs) {
    try {
      writeLock.lock();

      Set<String> deletedTypes = new HashSet<String>();
      for (String type : this.configs.keySet()) {
        if (!configs.containsKey(type)) {
          deletedTypes.add(type);
        }
      }

      long now = Long.valueOf(new java.util.Date().getTime());

      for (Entry<String,String> entry : configs.entrySet()) {

        boolean contains = false;
        for (HostComponentConfigMappingEntity mappingEntity : stateEntity.getHostComponentConfigMappingEntities()) {
          if (entry.getKey().equals(mappingEntity.getConfigType())) {
            if (LOG.isDebugEnabled()) {
              LOG.debug("Updating live config to ServiceComponentHost"
                  + ", clusterId=" + stateEntity.getClusterId()
                  + ", serviceName=" + stateEntity.getServiceName()
                  + ", componentName=" + stateEntity.getComponentName()
                  + ", hostname=" + stateEntity.getHostName()
                  + ", configType=" + entry.getKey()
                  + ", configVersionTag=" + entry.getValue());
            }
            contains = true;
            mappingEntity.setVersionTag(entry.getValue());
            mappingEntity.setTimestamp(now);
            break;
          }
        }

        if (!contains) {
          HostComponentConfigMappingEntity newEntity =
              new HostComponentConfigMappingEntity();
          newEntity.setClusterId(stateEntity.getClusterId());
          newEntity.setServiceName(stateEntity.getServiceName());
          newEntity.setComponentName(stateEntity.getComponentName());
          newEntity.setHostName(stateEntity.getHostName());
          newEntity.setConfigType(entry.getKey());
          newEntity.setVersionTag(entry.getValue());
          newEntity.setTimestamp(now);

          if (LOG.isDebugEnabled()) {
            LOG.debug("Adding new live config to ServiceComponentHost"
                + ", clusterId=" + stateEntity.getClusterId()
                + ", serviceName=" + stateEntity.getServiceName()
                + ", componentName=" + stateEntity.getComponentName()
                + ", hostname=" + stateEntity.getHostName()
                + ", configType=" + entry.getKey()
                + ", configVersionTag=" + entry.getValue());
          }
          stateEntity.getHostComponentConfigMappingEntities().add(newEntity);
          newEntity.setHostComponentStateEntity(stateEntity);

        }
      }

      if (!deletedTypes.isEmpty()) {
        List<HostComponentConfigMappingEntity> deleteEntities =
            hostComponentConfigMappingDAO.findByHostComponentAndType(
                stateEntity.getClusterId(), stateEntity.getServiceName(),
                stateEntity.getComponentName(),
                stateEntity.getHostName(), deletedTypes);
        for (HostComponentConfigMappingEntity deleteEntity : deleteEntities) {
          if (LOG.isDebugEnabled()) {
            LOG.debug("Deleting live config to ServiceComponentHost"
                + ", clusterId="  + stateEntity.getClusterId()
                + ", serviceName=" + stateEntity.getServiceName()
                + ", componentName=" + stateEntity.getComponentName()
                + ", hostname=" + stateEntity.getHostName()
                + ", configType=" + deleteEntity.getConfigType()
                + ", configVersionTag=" + deleteEntity.getVersionTag());
          }
          stateEntity.getHostComponentConfigMappingEntities().remove(
              deleteEntity);
          if (persisted) {
            hostComponentConfigMappingDAO.remove(deleteEntity);
          }
        }
      }
      this.configs = configs;
      saveIfPersisted();
    } finally {
      writeLock.unlock();
    }
  }

  @Override
  public StackId getStackVersion() {
    try {
      readLock.lock();
      return gson.fromJson(stateEntity.getCurrentStackVersion(), StackId.class);
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setStackVersion(StackId stackVersion) {
    try {
      writeLock.lock();
      stateEntity.setCurrentStackVersion(gson.toJson(stackVersion));
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }


  @Override
  public State getDesiredState() {
    try {
      readLock.lock();
      return desiredStateEntity.getDesiredState();
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setDesiredState(State state) {
    try {
      writeLock.lock();
      desiredStateEntity.setDesiredState(state);
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public Map<String, String> getDesiredConfigVersionsRecursive() {
    try {
      readLock.lock();
      Map<String, String> fullDesiredConfigVersions =
          new HashMap<String, String>();
      Map<String, Config> desiredConfs = getDesiredConfigs();
      for (Config c : desiredConfs.values()) {
        fullDesiredConfigVersions.put(c.getType(), c.getVersionTag());
      }
      return fullDesiredConfigVersions;
    }
    finally {
      readLock.unlock();
    }
  }


  @Override
  public Map<String, Config> getDesiredConfigs() {
    Map<String, Config> map = new HashMap<String, Config>();
    try {
      readLock.lock();
      for (Entry<String, String> entry : desiredConfigs.entrySet()) {
        Config config = clusters.getClusterById(getClusterId()).getDesiredConfig(
            entry.getKey(), entry.getValue());
        if (null != config) {
          map.put(entry.getKey(), config);
        }
      }
    }
    catch (AmbariException e) {
      // TODO do something
      return null;
    }
    finally {
      readLock.unlock();
    }
    // do a union with component level configs
    Map<String, Config> compConfigs = serviceComponent.getDesiredConfigs();
    for (Entry<String, Config> entry : compConfigs.entrySet()) {
      if (!map.containsKey(entry.getKey())) {
        map.put(entry.getKey(), entry.getValue());
      }
    }
    return Collections.unmodifiableMap(map);
  }

  @Override
  @Transactional
  public void updateDesiredConfigs(Map<String, Config> configs) {
    try {
      writeLock.lock();

      Set<String> deletedTypes = new HashSet<String>();
      for (String type : this.desiredConfigs.keySet()) {
        if (!configs.containsKey(type)) {
          deletedTypes.add(type);
        }
      }

      for (Entry<String,Config> entry : configs.entrySet()) {

        boolean contains = false;
        for (HostComponentDesiredConfigMappingEntity desiredConfigMappingEntity : desiredStateEntity.getHostComponentDesiredConfigMappingEntities()) {
          if (entry.getKey().equals(desiredConfigMappingEntity.getConfigType())) {
            contains = true;
            desiredConfigMappingEntity.setVersionTag(entry.getValue().getVersionTag());
            desiredConfigMappingEntity.setTimestamp(new Date().getTime());
            break;
          }
        }

        if (!contains) {
          HostComponentDesiredConfigMappingEntity newEntity = new HostComponentDesiredConfigMappingEntity();
          newEntity.setClusterId(desiredStateEntity.getClusterId());
          newEntity.setServiceName(desiredStateEntity.getServiceName());
          newEntity.setComponentName(desiredStateEntity.getComponentName());
          newEntity.setHostName(desiredStateEntity.getHostName());
          newEntity.setConfigType(entry.getKey());
          newEntity.setVersionTag(entry.getValue().getVersionTag());
          newEntity.setTimestamp(new Date().getTime());
          newEntity.setHostComponentDesiredStateEntity(desiredStateEntity);
          desiredStateEntity.getHostComponentDesiredConfigMappingEntities().add(newEntity);
        }

        this.desiredConfigs.put(entry.getKey(), entry.getValue().getVersionTag());
      }

      if (!deletedTypes.isEmpty()) {
        if (persisted) {
          List<HostComponentDesiredConfigMappingEntity> deleteEntities =
              hostComponentDesiredConfigMappingDAO.findByHostComponentAndType(
                  stateEntity.getClusterId(), stateEntity.getServiceName(),
                  stateEntity.getComponentName(),
                  stateEntity.getHostName(), deletedTypes);
          for (HostComponentDesiredConfigMappingEntity deleteEntity : deleteEntities) {
            if (LOG.isDebugEnabled()) {
              LOG.debug("Deleting desired config to ServiceComponentHost"
                  + ", clusterId=" + stateEntity.getClusterId()
                  + ", serviceName=" + stateEntity.getServiceName()
                  + ", componentName=" + stateEntity.getComponentName()
                  + ", hostname=" + stateEntity.getHostName()
                  + ", configType=" + deleteEntity.getConfigType()
                  + ", configVersionTag=" + deleteEntity.getVersionTag());
            }
            desiredStateEntity.getHostComponentDesiredConfigMappingEntities().remove(
                deleteEntity);
            hostComponentDesiredConfigMappingDAO.remove(deleteEntity);
          }
        } else {
          for (String deletedType : deletedTypes) {
            desiredConfigs.remove(deletedType);
          }
        }
      }

      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public StackId getDesiredStackVersion() {
    try {
      readLock.lock();
      return gson.fromJson(desiredStateEntity.getDesiredStackVersion(), StackId.class);
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public void setDesiredStackVersion(StackId stackVersion) {
    try {
      writeLock.lock();
      desiredStateEntity.setDesiredStackVersion(gson.toJson(stackVersion));
      saveIfPersisted();
    }
    finally {
      writeLock.unlock();
    }
  }

  @Override
  public ServiceComponentHostResponse convertToResponse() {
    try {
      readLock.lock();
      ServiceComponentHostResponse r = new ServiceComponentHostResponse(
          serviceComponent.getClusterName(),
          serviceComponent.getServiceName(),
          serviceComponent.getName(),
          getHostName(),
          configs,
          desiredConfigs,
          getState().toString(),
          getStackVersion().getStackId(),
          getDesiredState().toString());
      return r;
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public String getClusterName() {
    return serviceComponent.getClusterName();
  }

  @Override
  public void debugDump(StringBuilder sb) {
    try {
      readLock.lock();
      sb.append("ServiceComponentHost={ hostname=" + getHostName()
          + ", serviceComponentName=" + serviceComponent.getName()
          + ", clusterName=" + serviceComponent.getClusterName()
          + ", serviceName=" + serviceComponent.getServiceName()
          + ", desiredStackVersion=" + getDesiredStackVersion()
          + ", desiredState=" + getDesiredState()
          + ", stackVersion=" + getStackVersion()
          + ", state=" + getState()
          + " }");
    }
    finally {
      readLock.unlock();
    }
  }

  @Override
  public boolean isPersisted() {
    try {
      readLock.lock();
      return persisted;
    } finally {
      readLock.unlock();
    }
  }

  @Override
  public void persist() {
    try {
      writeLock.lock();
      if (!persisted) {
        persistEntities();
        refresh();
        host.refresh();
        serviceComponent.refresh();
        persisted = true;
      } else {
        saveIfPersisted();
      }
    } finally {
      writeLock.unlock();
    }
  }

  @Transactional
  protected void persistEntities() {
    HostEntity hostEntity = hostDAO.findByName(getHostName());
    hostEntity.getHostComponentStateEntities().add(stateEntity);
    hostEntity.getHostComponentDesiredStateEntities().add(desiredStateEntity);

    ServiceComponentDesiredStateEntityPK dpk = new ServiceComponentDesiredStateEntityPK();
    dpk.setClusterId(serviceComponent.getClusterId());
    dpk.setServiceName(serviceComponent.getServiceName());
    dpk.setComponentName(serviceComponent.getName());

    ServiceComponentDesiredStateEntity serviceComponentDesiredStateEntity = serviceComponentDesiredStateDAO.findByPK(dpk);
    serviceComponentDesiredStateEntity.getHostComponentDesiredStateEntities().add(desiredStateEntity);

    desiredStateEntity.setServiceComponentDesiredStateEntity(serviceComponentDesiredStateEntity);
    desiredStateEntity.setHostEntity(hostEntity);
    stateEntity.setServiceComponentDesiredStateEntity(serviceComponentDesiredStateEntity);
    stateEntity.setHostEntity(hostEntity);

    hostComponentStateDAO.create(stateEntity);
    hostComponentDesiredStateDAO.create(desiredStateEntity);

    serviceComponentDesiredStateDAO.merge(serviceComponentDesiredStateEntity);
    hostDAO.merge(hostEntity);
  }

  @Override
  @Transactional
  public synchronized void refresh() {
    if (isPersisted()) {
      HostComponentStateEntityPK pk = new HostComponentStateEntityPK();
      HostComponentDesiredStateEntityPK dpk = new HostComponentDesiredStateEntityPK();
      pk.setClusterId(getClusterId());
      pk.setComponentName(getServiceComponentName());
      pk.setServiceName(getServiceName());
      pk.setHostName(getHostName());
      dpk.setClusterId(getClusterId());
      dpk.setComponentName(getServiceComponentName());
      dpk.setServiceName(getServiceName());
      dpk.setHostName(getHostName());
      stateEntity = hostComponentStateDAO.findByPK(pk);
      desiredStateEntity = hostComponentDesiredStateDAO.findByPK(dpk);
      hostComponentStateDAO.refresh(stateEntity);
      hostComponentDesiredStateDAO.refresh(desiredStateEntity);
    }
  }

  @Transactional
  private void saveIfPersisted() {
    if (isPersisted()) {
      hostComponentStateDAO.merge(stateEntity);
      hostComponentDesiredStateDAO.merge(desiredStateEntity);
    }
  }

  @Override
  public synchronized boolean canBeRemoved() {
    try {
      readLock.lock();
      State desiredState = getDesiredState();
      State liveState = getState();
      if ((desiredState == State.INIT || desiredState == State.UNINSTALLED)
          && (liveState == State.INIT || liveState == State.UNINSTALLED)) {
        return true;
      }
    } finally {
      readLock.unlock();
    }
    return false;
  }

  @Override
  public void deleteDesiredConfigs(Set<String> configTypes) {
    try {
      writeLock.lock();
      for (String configType : configTypes) {
        desiredConfigs.remove(configType);
      }
      hostComponentDesiredConfigMappingDAO.removeByType(configTypes);
    } finally {
      writeLock.unlock();
    }
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostInstallEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostInstallEvent extends
    ServiceComponentHostEvent {


  public ServiceComponentHostInstallEvent(String serviceComponentName,
      String hostName, long opTimestamp, String stackId) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_INSTALL,
        serviceComponentName, hostName, opTimestamp, stackId);
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostOpFailedEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostOpFailedEvent extends
    ServiceComponentHostEvent {

  public ServiceComponentHostOpFailedEvent(String serviceComponentName,
      String hostName, long opTimestamp) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_OP_FAILED,
        serviceComponentName, hostName, opTimestamp);
    // TODO Auto-generated constructor stub
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostOpInProgressEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostOpInProgressEvent extends
    ServiceComponentHostEvent {

  public ServiceComponentHostOpInProgressEvent(String serviceComponentName,
      String hostName, long opTimestamp) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_OP_IN_PROGRESS,
        serviceComponentName, hostName, opTimestamp);
    // TODO Auto-generated constructor stub
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostOpRestartedEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostOpRestartedEvent extends
    ServiceComponentHostEvent {

  public ServiceComponentHostOpRestartedEvent(String serviceComponentName,
      String hostName, long opTimestamp) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_OP_RESTART,
        serviceComponentName, hostName, opTimestamp);
    // TODO Auto-generated constructor stub
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostOpSucceededEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostOpSucceededEvent extends
    ServiceComponentHostEvent {

  public ServiceComponentHostOpSucceededEvent(String serviceComponentName,
      String hostName, long opTimestamp) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_OP_SUCCEEDED,
        serviceComponentName, hostName, opTimestamp);
    // TODO Auto-generated constructor stub
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostStartEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import java.util.Map;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostStartEvent extends
    ServiceComponentHostEvent {

  public ServiceComponentHostStartEvent(String serviceComponentName,
      String hostName, long opTimestamp, Map<String, String> configs) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_START,
        serviceComponentName, hostName, opTimestamp, configs);
    // TODO Auto-generated constructor stub
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostStopEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostStopEvent extends
    ServiceComponentHostEvent {

  public ServiceComponentHostStopEvent(String serviceComponentName,
      String hostName, long opTimestamp) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_STOP,
        serviceComponentName, hostName, opTimestamp);
    // TODO Auto-generated constructor stub
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostUninstallEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostUninstallEvent extends
    ServiceComponentHostEvent {

  public ServiceComponentHostUninstallEvent(String serviceComponentName,
      String hostName, long opTimestamp) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_UNINSTALL,
        serviceComponentName, hostName, opTimestamp);
    // TODO Auto-generated constructor stub
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/state/svccomphost/ServiceComponentHostWipeoutEvent.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.server.state.svccomphost;

import org.apache.ambari.server.state.ServiceComponentHostEvent;
import org.apache.ambari.server.state.ServiceComponentHostEventType;

public class ServiceComponentHostWipeoutEvent extends
    ServiceComponentHostEvent {

  public ServiceComponentHostWipeoutEvent(String serviceComponentName,
      String hostName, long opTimestamp) {
    super(ServiceComponentHostEventType.HOST_SVCCOMP_WIPEOUT,
        serviceComponentName, hostName, opTimestamp);
    // TODO Auto-generated constructor stub
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/utils/JaxbMapKeyList.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.utils;

import java.util.List;

import javax.xml.bind.annotation.XmlElement;

public class JaxbMapKeyList {
  @XmlElement public String  key;
  @XmlElement public List<String> value;

  private JaxbMapKeyList() {}

  public JaxbMapKeyList(String key, List<String> value)
  {
    this.key   = key;
    this.value = value;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/utils/JaxbMapKeyListAdapter.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.utils;

import java.util.List;
import java.util.Map;
import java.util.TreeMap;

import javax.xml.bind.annotation.adapters.XmlAdapter;

public class JaxbMapKeyListAdapter extends
    XmlAdapter<JaxbMapKeyList[], Map<String, List<String>>> {

  @Override
  public JaxbMapKeyList[] marshal(Map<String, List<String>> map)
      throws Exception {
    if (map==null) {
      return null;
    }
    JaxbMapKeyList[] list = new JaxbMapKeyList[map.size()] ;
    int index = 0;
    for (String key : map.keySet()) {
      JaxbMapKeyList jaxbMap = new JaxbMapKeyList(key, map.get(key));
      list[index++] = jaxbMap;
    }
    return list;
  }

  @Override
  public Map<String, List<String>> unmarshal(JaxbMapKeyList[] list)
      throws Exception {
    if (list == null) {
      return null;
    }
    Map<String, List<String>> m = new TreeMap<String, List<String>>();
    for (JaxbMapKeyList jaxbMap : list) {
      m.put(jaxbMap.key, jaxbMap.value);
    }
    return m;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/utils/JaxbMapKeyMap.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.utils;

import javax.xml.bind.annotation.XmlElement;

public class JaxbMapKeyMap {
  @XmlElement public String  key;
  @XmlElement public JaxbMapKeyVal[] value;

  private JaxbMapKeyMap() {}

  public JaxbMapKeyMap(String key, JaxbMapKeyVal[] value)
  {
    this.key   = key;
    this.value = value;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/utils/JaxbMapKeyMapAdapter.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.utils;

import java.util.Map;
import java.util.TreeMap;

import javax.xml.bind.annotation.adapters.XmlAdapter;

public class JaxbMapKeyMapAdapter extends
    XmlAdapter<JaxbMapKeyMap[], Map<String, Map<String, String>>> {

  private static JaxbMapKeyValAdapter mapAdapter = new JaxbMapKeyValAdapter();

  @Override
  public JaxbMapKeyMap[] marshal(Map<String, Map<String, String>> map)
      throws Exception {
    if (map == null) {
      return null;
    }
    JaxbMapKeyMap[] list = new JaxbMapKeyMap[map.size()];
    int index=0;
    for (String key : map.keySet()) {
      Map<String, String> value = map.get(key);
      JaxbMapKeyVal[] keyValList = mapAdapter.marshal(value);
      list[index++] = new JaxbMapKeyMap(key, keyValList);
    }
    return list;
  }

  @Override
  public Map<String, Map<String, String>> unmarshal(JaxbMapKeyMap[] list)
      throws Exception {
    if (list == null) {
      return null;
    }
    Map<String, Map<String, String>> map = new TreeMap<String, Map<String, String>>();
    for (JaxbMapKeyMap jaxbkeyMap : list) {
      map.put(jaxbkeyMap.key, mapAdapter.unmarshal(jaxbkeyMap.value));
    }
    return map;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/utils/JaxbMapKeyVal.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.utils;

import javax.xml.bind.annotation.XmlElement;

public class JaxbMapKeyVal {
  @XmlElement public String  key;
  @XmlElement public String value;

  public JaxbMapKeyVal() {}

  public JaxbMapKeyVal(String key, String value)
  {
    this.key   = key;
    this.value = value;
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/utils/JaxbMapKeyValAdapter.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.utils;

import java.util.Map;
import java.util.TreeMap;

import javax.xml.bind.annotation.adapters.XmlAdapter;

public class JaxbMapKeyValAdapter extends
    XmlAdapter<JaxbMapKeyVal[], Map<String, String>> {

  @Override
  public JaxbMapKeyVal[] marshal(Map<String, String> m) throws Exception {
    if (m==null) {
      return null;
    }
    JaxbMapKeyVal[] list = new JaxbMapKeyVal[m.size()] ;
    int index = 0;
    for (String key : m.keySet()) {
      JaxbMapKeyVal jaxbMap = new JaxbMapKeyVal(key, m.get(key));
      list[index++] = jaxbMap;
    }
    return list;
  }

  @Override
  public Map<String, String> unmarshal(JaxbMapKeyVal[] jm) throws Exception {
    if (jm == null) {
      return null;
    }
    Map<String, String> m = new TreeMap<String, String>();
    for (JaxbMapKeyVal jaxbMap : jm) {
      m.put(jaxbMap.key, jaxbMap.value);
    }
    return m;
  }

}
"
ambari-server/src/main/java/org/apache/ambari/server/utils/ShellCommandUtil.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.utils;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

/**
 * Logs OpenSsl command exit code with description
 */
public class ShellCommandUtil {
  private static final Log LOG = LogFactory.getLog(ShellCommandUtil.class);
  /*
  public static String LogAndReturnOpenSslExitCode(String command, int exitCode) {
    logOpenSslExitCode(command, exitCode);
    return getOpenSslCommandResult(command, exitCode);
  }
  */
  public static void logOpenSslExitCode(String command, int exitCode) {
    if (exitCode == 0) {
      LOG.info(getOpenSslCommandResult(command, exitCode));
    } else {
      LOG.warn(getOpenSslCommandResult(command, exitCode));
    }

  }

  public static String getOpenSslCommandResult(String command, int exitCode) {
    return new StringBuilder().append("Command ").append(command).append(" was finished with exit code: ")
            .append(exitCode).append(" - ").append(getOpenSslExitCodeDescription(exitCode)).toString();
  }

  private static String getOpenSslExitCodeDescription(int exitCode) {
    switch (exitCode) {
      case 0: {
        return "the operation was completely successfully.";
      }
      case 1: {
        return "an error occurred parsing the command options.";
      }
      case 2: {
        return "one of the input files could not be read.";
      }
      case 3: {
        return "an error occurred creating the PKCS#7 file or when reading the MIME message.";
      }
      case 4: {
        return "an error occurred decrypting or verifying the message.";
      }
      case 5: {
        return "the message was verified correctly but an error occurred writing out the signers certificates.";
      }
      default:
        return "unsupported code";
    }
  }
}
"
ambari-server/src/main/java/org/apache/ambari/server/utils/StageUtils.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.server.utils;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.net.InetAddress;
import java.net.UnknownHostException;
import java.nio.charset.Charset;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.TreeMap;

import javax.xml.bind.JAXBException;

import org.apache.ambari.server.Role;
import org.apache.ambari.server.RoleCommand;
import org.apache.ambari.server.actionmanager.Stage;
import org.apache.ambari.server.agent.ExecutionCommand;
import org.apache.ambari.server.controller.HostsMap;
import org.apache.ambari.server.state.Cluster;
import org.apache.ambari.server.state.ServiceComponent;
import org.apache.ambari.server.state.svccomphost.ServiceComponentHostInstallEvent;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.codehaus.jackson.JsonGenerationException;
import org.codehaus.jackson.JsonParseException;
import org.codehaus.jackson.map.JsonMappingException;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.map.SerializationConfig;

public class StageUtils {
  private static Log LOG = LogFactory.getLog(StageUtils.class);
  
  private static Map<String, String> componentToClusterInfoKeyMap = 
      new HashMap<String, String>();
  
  static {
    componentToClusterInfoKeyMap.put("NAMENODE", "namenode_host");
    componentToClusterInfoKeyMap.put("JOBTRACKER", "jtnode_host");
    componentToClusterInfoKeyMap.put("SNAMENODE", "snamenode_host");
    componentToClusterInfoKeyMap.put("ZOOKEEPER_SERVER", "zookeeper_hosts");
    componentToClusterInfoKeyMap.put("HBASE_MASTER", "hbase_master_host");
    componentToClusterInfoKeyMap.put("HBASE_REGIONSERVER", "hbase_rs_hosts");
    componentToClusterInfoKeyMap.put("HIVE_SERVER", "hive_server_host");
    componentToClusterInfoKeyMap.put("OOZIE_SERVER", "oozie_server");
    componentToClusterInfoKeyMap.put("WEBHCAT_SERVER",
        "webhcat_server_host");
    componentToClusterInfoKeyMap.put(Role.MYSQL_SERVER.toString(),
        "hive_mysql_host");
    componentToClusterInfoKeyMap.put("DASHBOARD", "dashboard_host");
    componentToClusterInfoKeyMap.put("NAGIOS_SERVER", "nagios_server_host");
    componentToClusterInfoKeyMap.put("GANGLIA_SERVER",
        "ganglia_server_host");
    componentToClusterInfoKeyMap.put("DATANODE", "slave_hosts");
    componentToClusterInfoKeyMap.put("TASKTRACKER", "slave_hosts");
    componentToClusterInfoKeyMap.put("HBASE_REGIONSERVER", "hbase_rs_hosts");
    componentToClusterInfoKeyMap.put("KERBEROS_SERVER", "kdc_host");
    componentToClusterInfoKeyMap.put("KERBEROS_ADMIN_CLIENT",
        "kerberos_adminclient_host");
  }
  
  public static String getActionId(long requestId, long stageId) {
    return requestId + "-" + stageId;
  }

  public static long[] getRequestStage(String actionId) {
    String [] fields = actionId.split("-");
    long[] requestStageIds = new long[2];
    requestStageIds[0] = Long.parseLong(fields[0]);
    requestStageIds[1] = Long.parseLong(fields[1]);
    return requestStageIds;
  }

  public static Stage getATestStage(long requestId, long stageId) {
    String hostname;
    try {
      hostname = InetAddress.getLocalHost().getHostName();
    } catch (UnknownHostException e) {
      hostname = "host-dummy";
    }
    return getATestStage(requestId, stageId, hostname);
  }
  
  //For testing only
  public static Stage getATestStage(long requestId, long stageId, String hostname) {
    Stage s = new Stage(requestId, "/tmp", "cluster1");
    s.setStageId(stageId);
    long now = System.currentTimeMillis();
    String filename = null;
    s.addHostRoleExecutionCommand(hostname, Role.NAMENODE, RoleCommand.INSTALL,
        new ServiceComponentHostInstallEvent("NAMENODE", hostname, now, "HDP-1.2.0"),
        "cluster1", "HDFS");
    ExecutionCommand execCmd = s.getExecutionCommandWrapper(hostname, "NAMENODE").getExecutionCommand();
    execCmd.setCommandId(s.getActionId());
    Map<String, List<String>> clusterHostInfo = new TreeMap<String, List<String>>();
    List<String> slaveHostList = new ArrayList<String>();
    slaveHostList.add(hostname);
    slaveHostList.add("host2");
    clusterHostInfo.put("slave_hosts", slaveHostList);
    execCmd.setClusterHostInfo(clusterHostInfo);
    Map<String, String> hdfsSite = new TreeMap<String, String>();
    hdfsSite.put("dfs.block.size", "2560000000");
    Map<String, Map<String, String>> configurations =
        new TreeMap<String, Map<String, String>>();
    configurations.put("hdfs-site", hdfsSite);
    execCmd.setConfigurations(configurations);
    Map<String, String> params = new TreeMap<String, String>();
    params.put("jdklocation", "/x/y/z");
    execCmd.setHostLevelParams(params);
    Map<String, String> roleParams = new TreeMap<String, String>();
    roleParams.put("format", "false");
    execCmd.setRoleParams(roleParams);
    return s;
  }
  
  public static String jaxbToString(Object jaxbObj) throws JAXBException,
  JsonGenerationException, JsonMappingException, IOException {
    ObjectMapper mapper = new ObjectMapper();
    mapper.configure(SerializationConfig.Feature.INDENT_OUTPUT, true);
    mapper.configure(SerializationConfig.Feature.USE_ANNOTATIONS, true);
    return mapper.writeValueAsString(jaxbObj);
  }
  
  public static ExecutionCommand stringToExecutionCommand(String json)
      throws JsonParseException, JsonMappingException, IOException {
    ObjectMapper mapper = new ObjectMapper();
    mapper.configure(SerializationConfig.Feature.INDENT_OUTPUT, true);
    mapper.configure(SerializationConfig.Feature.USE_ANNOTATIONS, true);
    InputStream is = new ByteArrayInputStream(json.getBytes(Charset.forName("UTF8")));
    return mapper.readValue(is, ExecutionCommand.class);
  }

  public static <T> T fromJson(String json, Class<T> clazz) throws IOException {
    ObjectMapper mapper = new ObjectMapper();
    mapper.configure(SerializationConfig.Feature.INDENT_OUTPUT, true);
    mapper.configure(SerializationConfig.Feature.USE_ANNOTATIONS, true);
    InputStream is = new ByteArrayInputStream(json.getBytes(Charset.forName("UTF8")));
    return mapper.readValue(is, clazz);
  }
  
  
  public static Map<String, List<String>> getClusterHostInfo(Cluster cluster, HostsMap hostsMap) {
    Map<String, List<String>> info = new HashMap<String, List<String>>();
    if (cluster.getServices() != null) {
      for (String serviceName : cluster.getServices().keySet()) {
        if (cluster.getServices().get(serviceName) != null) {
          for (String componentName : cluster.getServices().get(serviceName)
              .getServiceComponents().keySet()) {
            String clusterInfoKey = componentToClusterInfoKeyMap
                .get(componentName);
            if (clusterInfoKey == null) {
              continue;
            }
            ServiceComponent scomp = cluster.getServices().get(serviceName)
                .getServiceComponents().get(componentName);
            if (scomp.getServiceComponentHosts() != null
                && !scomp.getServiceComponentHosts().isEmpty()) {
              List<String> hostList = new ArrayList<String>();
              for (String host: scomp.getServiceComponentHosts().keySet()) {
                String mappedHost = hostsMap.getHostMap(host);
                hostList.add(mappedHost);
              }
              info.put(clusterInfoKey, hostList);
            }
            //Add ambari db server
            info.put("ambari_db_server_host", Arrays.asList(hostsMap.getHostMap(getHostName())));
          }
        }
      }
    }
    return info;
  }

  public static String getHostName() {
    try {
      return InetAddress.getLocalHost().getCanonicalHostName();
    } catch (UnknownHostException e) {
      LOG.warn("Could not find canonical hostname ", e);
      return "localhost";
    }
  }
  
  public static String getHostsToDecommission(List<String> hosts) {
    StringBuilder builder = new StringBuilder();
    builder.append("[");
    boolean first = true;
    for (String host : hosts) {
      if (!first) {
        builder.append(",");
      } else {
        first = false;
      }
      builder.append("'");
      builder.append(host);
      builder.append("'");
    }
    return builder.toString();
  }
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/eventdb/model/WorkflowContext.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.eventdb.model;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;


@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class WorkflowContext {
  
  private String workflowId;
  private String workflowName;
  private String workflowEntityName;
  
  private WorkflowDag workflowDag;
  
  private WorkflowContext parentWorkflowContext;
  
  public WorkflowContext() {
    /* Required by JAXB. */
  }
  
  /* Getters. */
  public String getWorkflowId() {
    return this.workflowId;
  }
  
  public String getWorkflowName() {
    return this.workflowName;
  }
  
  public String getWorkflowEntityName() {
    return this.workflowEntityName;
  }
  
  public WorkflowDag getWorkflowDag() {
    return this.workflowDag;
  }
  
  public WorkflowContext getParentWorkflowContext() {
    return this.parentWorkflowContext;
  }
  
  /* Setters. */
  public void setWorkflowId(String wfId) {
    this.workflowId = wfId;
  }
  
  public void setWorkflowName(String wfName) {
    this.workflowName = wfName;
  }
  
  public void setWorkflowEntityName(String wfEntityName) {
    this.workflowEntityName = wfEntityName;
  }
  
  public void setWorkflowDag(WorkflowDag wfDag) {
    this.workflowDag = wfDag;
  }
  
  public void setParentWorkflowContext(WorkflowContext pWfContext) {
    this.parentWorkflowContext = pWfContext;
  }
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/eventdb/model/WorkflowDag.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.ambari.eventdb.model;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import javax.xml.bind.annotation.XmlAccessType;
import javax.xml.bind.annotation.XmlAccessorType;
import javax.xml.bind.annotation.XmlRootElement;

@XmlRootElement
@XmlAccessorType(XmlAccessType.FIELD)
public class WorkflowDag {
  
  public static class WorkflowDagEntry {
    
    private String source;
    private List<String> targets = new ArrayList<String>();
    
    public WorkflowDagEntry() {
      /* Required by JAXB. */
    }
    
    /* Getters. */
    public String getSource() {
      return this.source;
    }
    
    public List<String> getTargets() {
      return this.targets;
    }
    
    /* Setters. */
    public void setSource(String source) {
      this.source = source;
    }
    
    public void setTargets(List<String> targets) {
      this.targets = targets;
    }
    
    public void addTarget(String target) {
      this.targets.add(target);
    }
  }
  
  List<WorkflowDagEntry> entries = new ArrayList<WorkflowDagEntry>();
  
  public WorkflowDag() {
    /* Required by JAXB. */
  }
  
  /* Getters. */
  public List<WorkflowDagEntry> getEntries() {
    return this.entries;
  }
  
  /* Setters. */
  public void setEntries(List<WorkflowDagEntry> entries) {
    this.entries = entries;
  }
  
  public void addEntry(WorkflowDag.WorkflowDagEntry entry) {
    this.entries.add(entry);
  }
  
  public int size() {
    Set<String> nodes = new HashSet<String>();
    for (WorkflowDagEntry entry : entries) {
      nodes.add(entry.getSource());
      nodes.addAll(entry.getTargets());
    }
    return nodes.size();
  }
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/log4j/common/LoggingThreadRunnable.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.log4j.common;

import java.io.IOException;
import java.util.Queue;
import java.util.concurrent.atomic.AtomicBoolean;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.log4j.spi.LoggingEvent;

public class LoggingThreadRunnable implements Runnable {
  private static final Log LOG = LogFactory.getLog(LoggingThreadRunnable.class);
  private static long WAIT_EMPTY_QUEUE = 60000;
  private final Queue<LoggingEvent> events;
  private final LogParser parser;
  private final LogStore store;
  private final AtomicBoolean done = new AtomicBoolean(false);
  
  public LoggingThreadRunnable(
      Queue<LoggingEvent> events, 
      LogParser parser, 
      LogStore provider) {
    this.events = events;
    this.store = provider;
    this.parser = parser;
  }
  
  @Override
  public void run() {
    while (!done.get()) {
      LoggingEvent event = null;
      while ((event = events.poll()) != null) {
        Object result = null;
        try {
          parser.addEventToParse(event);
          while ((result = parser.getParseResult()) != null) {
            try {
              store.persist(event, result);
            } catch (IOException e) {
              LOG.warn("Failed to persist " + result);
            }
          }
        } catch (IOException ioe) {
          LOG.warn("Failed to parse log-event: " + event);
        }
      }
      try {
        Thread.sleep(WAIT_EMPTY_QUEUE);
      } catch(InterruptedException ie) {
        //ignore and continue
      }
    	  
    }
    try {
      store.close();
    } catch (IOException ioe) {
      LOG.info("Failed to close logStore", ioe);
    }
  }
  
  public void close() throws IOException {
    done.set(true);
  }
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/log4j/common/LogParser.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.log4j.common;

import java.io.IOException;

import org.apache.log4j.spi.LoggingEvent;

public interface LogParser {
  
  void addEventToParse(LoggingEvent event);
  
  Object getParseResult() throws IOException;
  
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/log4j/common/LogStore.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.log4j.common;

import java.io.IOException;

import org.apache.log4j.spi.LoggingEvent;

public interface LogStore {
  
  void persist(LoggingEvent originalEvent, Object parsedEvent) 
      throws IOException;
  
  void close() throws IOException;
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/log4j/common/LogStoreUpdateProvider.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.log4j.common;

import java.io.IOException;
import java.sql.Connection;

import org.apache.log4j.spi.LoggingEvent;

public interface LogStoreUpdateProvider {
  
  void init(Connection connection) throws IOException;
  
  void update(LoggingEvent originalEvent, Object parsedEvent) 
      throws IOException;
  
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/log4j/common/store/DatabaseStore.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.log4j.common.store;

import java.io.IOException;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.SQLException;

import org.apache.ambari.log4j.common.LogStore;
import org.apache.ambari.log4j.common.LogStoreUpdateProvider;
import org.apache.log4j.spi.LoggingEvent;

public class DatabaseStore implements LogStore {

  final private String database;
  final private String user;
  final private String password;
  
  final private Connection connection;
  final private LogStoreUpdateProvider updateProvider;
  
  public DatabaseStore(String driver, 
      String database, String user, String password, 
      LogStoreUpdateProvider updateProvider) 
      throws IOException {
    try {
      Class.forName(driver);
    } catch (ClassNotFoundException e) {
      System.err.println("Can't load driver - " + driver);
      throw new RuntimeException("Can't load driver - " + driver);
    }
    this.database = database;
    this.user = (user == null) ? "" : user;
    this.password = (password == null) ? "" : password;
    try {
      this.connection = 
          DriverManager.getConnection(this.database, this.user, this.password);
    } catch (SQLException sqle) {
      throw new IOException("Can't connect to database " + this.database, sqle);
    }
    this.updateProvider = updateProvider;
    
    this.updateProvider.init(this.connection);
  }
  
  @Override
  public void persist(LoggingEvent originalEvent, Object parsedEvent)
      throws IOException {
    updateProvider.update(originalEvent, parsedEvent);
  }

  @Override
  public void close() throws IOException {
    try {
      connection.close();
    } catch (SQLException sqle) {
      throw new IOException(
          "Failed to close connectionto database " + this.database, sqle);
    }
  }
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/log4j/hadoop/mapreduce/jobhistory/JobHistoryAppender.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.log4j.hadoop.mapreduce.jobhistory;

import java.io.IOException;
import java.util.Queue;
import java.util.concurrent.LinkedBlockingQueue;

import org.apache.ambari.log4j.common.LogParser;
import org.apache.ambari.log4j.common.LogStore;
import org.apache.ambari.log4j.common.LoggingThreadRunnable;
import org.apache.ambari.log4j.common.store.DatabaseStore;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.tools.rumen.HistoryEvent;
import org.apache.hadoop.util.StringUtils;
import org.apache.log4j.Appender;
import org.apache.log4j.AppenderSkeleton;
import org.apache.log4j.spi.LoggingEvent;

public class JobHistoryAppender extends AppenderSkeleton implements Appender {

  private static final Log LOG = LogFactory.getLog(JobHistoryAppender.class);
  
  private final Queue<LoggingEvent> events;
  private LoggingThreadRunnable logThreadRunnable;
  private Thread logThread;

  private final LogParser logParser;

  private final LogStore nullStore =
      new LogStore() {
        @Override
        public void persist(LoggingEvent originalEvent, Object parsedEvent) 
            throws IOException {
          LOG.info(((HistoryEvent)parsedEvent).toString());
        }

        @Override
        public void close() throws IOException {}
  };

  private String driver;
  private String database;
  private String user;
  private String password;
  
  private LogStore logStore;
  
  public JobHistoryAppender() {
    events = new LinkedBlockingQueue<LoggingEvent>();
    logParser = new MapReduceJobHistoryParser();
    logStore = nullStore;
  }
  
  /* Getters & Setters for log4j */
  
  public String getDatabase() {
    return database;
  }

  public void setDatabase(String database) {
    this.database = database;
  }
  
  public String getDriver() {
    return driver;
  }

  public void setDriver(String driver) {
    this.driver = driver;
  }

  public String getUser() {
    return user;
  }

  public void setUser(String user) {
    this.user = user;
  }

  public String getPassword() {
    return password;
  }

  public void setPassword(String password) {
    this.password = password;
  }

  /* --------------------------- */

  @Override
  public void activateOptions() {
    synchronized (this) {
      //if (true) { 
      if (database.equals("none")) {
        logStore = nullStore;
        LOG.info("database set to 'none'");
      } else {
        try {
          logStore = 
              new DatabaseStore(driver, database, user, password, 
                  new MapReduceJobHistoryUpdater());
        } catch (IOException ioe) {
          LOG.debug("Failed to connect to db " + database, ioe);
          System.err.println("Failed to connect to db " + database + 
              " as user " + user + " password " + password + 
              " and driver " + driver + " with " + 
              StringUtils.stringifyException(ioe));
          throw new RuntimeException(
              "Failed to create database store for " + database, ioe);
        } catch (Exception e) {
          LOG.debug("Failed to connect to db " + database, e);
          System.err.println("Failed to connect to db " + database + 
              " as user " + user + " password " + password + 
              " and driver " + driver + " with " + 
              StringUtils.stringifyException(e));
          throw new RuntimeException(
              "Failed to create database store for " + database, e);
        }
      }
      logThreadRunnable = 
          new LoggingThreadRunnable(events, logParser, logStore);
      logThread = new Thread(logThreadRunnable);
      logThread.setDaemon(true);
      logThread.start();

      super.activateOptions();
    }
  }

  @Override
  public void close() {
    try {
      logThreadRunnable.close();
    } catch (IOException ioe) {
      LOG.info("Failed to close logThreadRunnable", ioe);
    }
    try {
      logThread.join(1000);
    } catch (InterruptedException ie) {
      LOG.info("logThread interrupted", ie);
    }
  }

  @Override
  public boolean requiresLayout() {
    return false;
  }

  @Override
  protected void append(LoggingEvent event) {
    events.add(event);
  }
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/log4j/hadoop/mapreduce/jobhistory/MapReduceJobHistoryParser.java,false,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.log4j.hadoop.mapreduce.jobhistory;

import java.io.IOException;
import java.util.Queue;
import java.util.concurrent.LinkedBlockingQueue;

import org.apache.ambari.log4j.common.LogParser;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.tools.rumen.Hadoop20JHParser;
import org.apache.hadoop.tools.rumen.JobHistoryParser;
import org.apache.hadoop.util.LineReader;
import org.apache.log4j.spi.LoggingEvent;

public class MapReduceJobHistoryParser implements LogParser {
  private JobHistoryParser parser;
  private LogLineReader reader = new LogLineReader("Meta VERSION=\"1\" .");
  
  public MapReduceJobHistoryParser() {
    try {
      parser = new Hadoop20JHParser(reader);
    } catch (IOException ioe) {
      // SHOULD NEVER HAPPEN!
      throw new RuntimeException(ioe);
    }
  }

  @Override
  public void addEventToParse(LoggingEvent event) {
    reader.addLine(event.getMessage().toString());
  }
  
  @Override
  public Object getParseResult() throws IOException {
    return parser.nextEvent();
  }

  static class LogLineReader extends LineReader {

    private Queue<String> lines = new LinkedBlockingQueue<String>();
    
    public LogLineReader(String line) {
      super(null);
      addLine(line);
    }

    private void addLine(String line) {
      lines.add(line);
    }
    
    public int readLine(Text str) throws IOException {
      String line = lines.poll();
      if (line != null) {
        str.set(line);
        return line.length();
      }
      
      return 0;
    }
    
    public void close() throws IOException {
    }
  }
}
"
contrib/ambari-log4j/src/main/java/org/apache/ambari/log4j/hadoop/mapreduce/jobhistory/MapReduceJobHistoryUpdater.java,true,"/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.ambari.log4j.hadoop.mapreduce.jobhistory;

import java.io.IOException;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.TreeMap;
import java.util.TreeSet;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.apache.ambari.eventdb.model.WorkflowContext;
import org.apache.ambari.eventdb.model.WorkflowDag;
import org.apache.ambari.eventdb.model.WorkflowDag.WorkflowDagEntry;
import org.apache.ambari.log4j.common.LogStoreUpdateProvider;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.CounterGroup;
import org.apache.hadoop.mapreduce.Counters;
import org.apache.hadoop.mapreduce.TaskType;
import org.apache.hadoop.tools.rumen.HistoryEvent;
import org.apache.hadoop.tools.rumen.JhCounter;
import org.apache.hadoop.tools.rumen.JhCounterGroup;
import org.apache.hadoop.tools.rumen.JhCounters;
import org.apache.hadoop.tools.rumen.JobFinishedEvent;
import org.apache.hadoop.tools.rumen.JobInfoChangeEvent;
import org.apache.hadoop.tools.rumen.JobInitedEvent;
import org.apache.hadoop.tools.rumen.JobStatusChangedEvent;
import org.apache.hadoop.tools.rumen.JobSubmittedEvent;
import org.apache.hadoop.tools.rumen.JobUnsuccessfulCompletionEvent;
import org.apache.hadoop.tools.rumen.MapAttemptFinishedEvent;
import org.apache.hadoop.tools.rumen.ReduceAttemptFinishedEvent;
import org.apache.hadoop.tools.rumen.TaskAttemptFinishedEvent;
import org.apache.hadoop.tools.rumen.TaskAttemptStartedEvent;
import org.apache.hadoop.tools.rumen.TaskAttemptUnsuccessfulCompletionEvent;
import org.apache.hadoop.tools.rumen.TaskFailedEvent;
import org.apache.hadoop.tools.rumen.TaskFinishedEvent;
import org.apache.hadoop.tools.rumen.TaskStartedEvent;
import org.apache.hadoop.util.StringUtils;
import org.apache.log4j.spi.LoggingEvent;
import org.codehaus.jackson.map.ObjectMapper;

public class MapReduceJobHistoryUpdater implements LogStoreUpdateProvider {
  
  private static final Log LOG = 
      LogFactory.getLog(MapReduceJobHistoryUpdater.class);
  
  private Connection connection;
  
  private static final String WORKFLOW_TABLE = "workflow";
  private static final String JOB_TABLE = "job";
  private static final String TASK_TABLE = "task";
  private static final String TASKATTEMPT_TABLE = "taskAttempt";
  
  private PreparedStatement workflowPS = null;
  private PreparedStatement workflowSelectPS = null;
  private PreparedStatement workflowUpdateTimePS = null;
  private PreparedStatement workflowUpdateNumCompletedPS = null;
  
  private Map<Class<? extends HistoryEvent>, PreparedStatement> entitySqlMap =
      new HashMap<Class<? extends HistoryEvent>, PreparedStatement>();
  
  @Override
  public void init(Connection connection) throws IOException {
    this.connection = connection;
    
    try {
      initializePreparedStatements();
    } catch (SQLException sqle) {
      throw new IOException(sqle);
    }
  }
  
  private void initializePreparedStatements() throws SQLException {
    initializeJobPreparedStatements();
    initializeTaskPreparedStatements();
    initializeTaskAttemptPreparedStatements();
  }
  
  private PreparedStatement jobEndUpdate;
  
  private void initializeJobPreparedStatements() throws SQLException {

    /** 
     * Job events
     */

    // JobSubmittedEvent

    PreparedStatement jobSubmittedPrepStmnt =
        connection.prepareStatement(
            "INSERT INTO " + 
                JOB_TABLE + 
                " (" +
                "jobId, " +
                "jobName, " +
                "userName, " +
                "confPath, " +
                "queue, " +
                "submitTime, " +
                "workflowId, " +
                "workflowEntityName " +
                ") " +
                "VALUES" +
                " (?, ?, ?, ?, ?, ?, ?, ?)"
            );
    entitySqlMap.put(JobSubmittedEvent.class, jobSubmittedPrepStmnt);
    
    workflowSelectPS =
        connection.prepareStatement(
            "SELECT workflowContext FROM " + WORKFLOW_TABLE + " where workflowId = ?"
            );

    workflowPS = 
        connection.prepareStatement(
            "INSERT INTO " +
                WORKFLOW_TABLE +
                " (" +
                "workflowId, " +
                "workflowName, " +
                "workflowContext, " +
                "userName, " +
                "startTime, " +
                "lastUpdateTime, " +
                "duration, " +
                "numJobsTotal, " +
                "numJobsCompleted" +
                ") " +
                "VALUES" +
                " (?, ?, ?, ?, ?, ?, 0, ?, 0)"
            );
    
    workflowUpdateTimePS =
        connection.prepareStatement(
            "UPDATE " +
                WORKFLOW_TABLE +
                " SET " +
                "workflowContext = ?, " +
                "numJobsTotal = ?, " +
                "lastUpdateTime = ?, " +
                "duration = ? - (SELECT startTime FROM " +
                WORKFLOW_TABLE +
                " WHERE workflowId = ?) " +
                "WHERE workflowId = ?"
            );
    
    workflowUpdateNumCompletedPS =
        connection.prepareStatement(
            "UPDATE " +
                WORKFLOW_TABLE +
                " SET " +
                "lastUpdateTime = ?, " +
                "duration = ? - (SELECT startTime FROM " +
                WORKFLOW_TABLE +
                " WHERE workflowId = selectid), " +
                "numJobsCompleted = rows, " +
                "inputBytes = input, " +
                "outputBytes = output " +
            "FROM (SELECT count(*) as rows, sum(inputBytes) as input, " +
                "sum(outputBytes) as output, workflowId as selectid FROM " +
                JOB_TABLE +
                " WHERE workflowId = (SELECT workflowId FROM " +
                JOB_TABLE +
                " WHERE jobId = ?) AND status = 'SUCCESS' " +
                "GROUP BY workflowId) as jobsummary " +
            "WHERE workflowId = selectid"
            );
    
    // JobFinishedEvent

    PreparedStatement jobFinishedPrepStmnt = 
        connection.prepareStatement(
            "UPDATE " +
                JOB_TABLE +
                " SET " +
                "finishTime = ?, " +
                "finishedMaps = ?, " +
                "finishedReduces= ?, " +
                "failedMaps = ?, " +
                "failedReduces = ?, " +
                "inputBytes = ?, " +
                "outputBytes = ? " +
                "WHERE " +
                "jobId = ?" 
            );
    entitySqlMap.put(JobFinishedEvent.class, jobFinishedPrepStmnt);

    // JobInitedEvent
    
    PreparedStatement jobInitedPrepStmnt = 
        connection.prepareStatement(
            "UPDATE " +
                JOB_TABLE +
                " SET " +
                "launchTime = ?, " +
                "maps = ?, " +
                "reduces = ?, " +
                "status = ? "+
                "WHERE " +
                "jobId = ?" 
            );
    entitySqlMap.put(JobInitedEvent.class, jobInitedPrepStmnt);

    // JobStatusChangedEvent
    
    PreparedStatement jobStatusChangedPrepStmnt = 
        connection.prepareStatement(
            "UPDATE " +
                JOB_TABLE +
                " SET " +
                "status = ? "+
                "WHERE " +
                "jobId = ?" 
            );
    entitySqlMap.put(JobStatusChangedEvent.class, jobStatusChangedPrepStmnt);

    // JobInfoChangedEvent
    
    PreparedStatement jobInfoChangedPrepStmnt = 
        connection.prepareStatement(
            "UPDATE " +
                JOB_TABLE +
                " SET " +
                "submitTime = ?, " +
                "launchTime = ? " +
                "WHERE " +
                "jobId = ?" 
            );
    entitySqlMap.put(JobInfoChangeEvent.class, jobInfoChangedPrepStmnt);

    // JobUnsuccessfulCompletionEvent
    PreparedStatement jobUnsuccessfulPrepStmnt = 
        connection.prepareStatement(
            "UPDATE " +
                JOB_TABLE +
                " SET " +
                "finishTime = ?, " +
                "finishedMaps = ?, " +
                "finishedReduces = ?, " +
                "status = ? " +
                "WHERE " +
                "jobId = ?" 
            );
    entitySqlMap.put(
        JobUnsuccessfulCompletionEvent.class, jobUnsuccessfulPrepStmnt);

    // Job update at the end
    jobEndUpdate =
        connection.prepareStatement(
            "UPDATE " +
              JOB_TABLE +
              " SET " +
              " mapsRuntime = (" +
                "SELECT " +
                "SUM(" + 
                      TASKATTEMPT_TABLE + ".finishTime" +  " - " + 
                      TASKATTEMPT_TABLE + ".startTime" +
                		  ")" +
                " FROM " +
                TASKATTEMPT_TABLE + 
                " WHERE " +
                TASKATTEMPT_TABLE + ".jobId = " + JOB_TABLE + ".jobId " +
                " AND " +
                TASKATTEMPT_TABLE + ".taskType = ?)" +
              ", " +
              " reducesRuntime = (" +
                "SELECT SUM(" + 
                             TASKATTEMPT_TABLE + ".finishTime" +  " - " + 
                             TASKATTEMPT_TABLE + ".startTime" +
                		        ")" +
              	" FROM " +
                TASKATTEMPT_TABLE + 
                " WHERE " +
                TASKATTEMPT_TABLE + ".jobId = " + JOB_TABLE + ".jobId " +
                " AND " +
                TASKATTEMPT_TABLE + ".taskType = ?) " +
              " WHERE " +
                 "jobId = ?"
            );
  }
  
  private void initializeTaskPreparedStatements() throws SQLException {

    /** 
     * Task events
     */

    // TaskStartedEvent 
    
    PreparedStatement taskStartedPrepStmnt =
        connection.prepareStatement(
            "INSERT INTO " +
                TASK_TABLE +
                " (" +
                "jobId, " +
                "taskType, " +
                "splits, " +
                "startTime, " +
                "taskId" +
                ") " +
                "VALUES (?, ?, ?, ?, ?)"
            );
    entitySqlMap.put(TaskStartedEvent.class, taskStartedPrepStmnt);
    
    // TaskFinishedEvent
    
    PreparedStatement taskFinishedPrepStmnt =
        connection.prepareStatement(
            "UPDATE " +
                TASK_TABLE +
                " SET " +
                "jobId = ?, " +
                "taskType = ?, " +
                "status = ?, " +
                "finishTime = ? " +
                " WHERE " +
                "taskId = ?"
            );
    entitySqlMap.put(TaskFinishedEvent.class, taskFinishedPrepStmnt);

    // TaskFailedEvent

    PreparedStatement taskFailedPrepStmnt =
        connection.prepareStatement(
            "UPDATE " + 
                TASK_TABLE + 
                " SET " +
                "jobId = ?, " +
                "taskType = ?, " +
                "status = ?, " +
                "finishTime = ?, " +
                "error = ?, " +
                "failedAttempt = ? " +
                "WHERE " +
                "taskId = ?"
            );
    entitySqlMap.put(TaskFailedEvent.class, taskFailedPrepStmnt);
  }

  private void initializeTaskAttemptPreparedStatements() throws SQLException {

    /**
     * TaskAttempt events
     */

    // TaskAttemptStartedEvent
    
    PreparedStatement taskAttemptStartedPrepStmnt =
        connection.prepareStatement(
            "INSERT INTO " +
                TASKATTEMPT_TABLE +
                " (" +
                "jobId, " +
                "taskId, " +
                "taskType, " +
                "startTime, " +
                "taskTracker, " +
                "locality, " +
                "avataar, " +
                "taskAttemptId" +
                ") " +
                "VALUES (?, ?, ?, ?, ?, ?, ?, ?)"
            );
    entitySqlMap.put(
        TaskAttemptStartedEvent.class, taskAttemptStartedPrepStmnt);

    // TaskAttemptFinishedEvent
    
    PreparedStatement taskAttemptFinishedPrepStmnt =
        connection.prepareStatement(
            "UPDATE " +
                TASKATTEMPT_TABLE +
                " SET " +
                "jobId = ?, " +
                "taskId = ?, " +
                "taskType = ?, " +
                "finishTime = ?, " +
                "status = ?, " +
                "taskTracker = ? " +
                " WHERE " +
                "taskAttemptId = ?"
            );
    entitySqlMap.put(
        TaskAttemptFinishedEvent.class, taskAttemptFinishedPrepStmnt);

    // TaskAttemptUnsuccessfulEvent
    
    PreparedStatement taskAttemptUnsuccessfulPrepStmnt =
        connection.prepareStatement(
            "UPDATE " +
                TASKATTEMPT_TABLE +
                " SET " +
                "jobId = ?, " +
                "taskId = ?, " +
                "taskType = ?, " +
                "finishTime = ?, " +
                "status = ?, " +
                "taskTracker = ?, " +
                "error = ? " +
                " WHERE " +
                "taskAttemptId = ?"
            );
    entitySqlMap.put(
        TaskAttemptUnsuccessfulCompletionEvent.class, 
        taskAttemptUnsuccessfulPrepStmnt);

    // MapAttemptFinishedEvent
    
    PreparedStatement mapAttemptFinishedPrepStmnt =
        connection.prepareStatement(
            "UPDATE " +
                TASKATTEMPT_TABLE +
                " SET " +
                "jobId = ?, " +
                "taskId = ?, " +
                "taskType = ?, " +
                "mapFinishTime = ?, " +
                "finishTime = ?, " +
                "inputBytes = ?, " +
                "outputBytes = ?, " +
                "status = ?, " +
                "taskTracker = ? " +
                " WHERE " +
                "taskAttemptId = ?"
            );
    entitySqlMap.put(
        MapAttemptFinishedEvent.class, mapAttemptFinishedPrepStmnt);

    // ReduceAttemptFinishedEvent
    
    PreparedStatement reduceAttemptFinishedPrepStmnt =
        connection.prepareStatement(
            "UPDATE " +
                TASKATTEMPT_TABLE +
                " SET " +
                "jobId = ?, " +
                "taskId = ?, " +
                "taskType = ?, " +
                "shuffleFinishTime = ?, " +
                "sortFinishTime = ?, " +
                "finishTime = ?, " +
                "inputBytes = ?, " +
                "outputBytes = ?, " +
                "status = ?, " +
                "taskTracker = ? " +
                " WHERE " +
                "taskAttemptId = ?"
            );
    entitySqlMap.put(
        ReduceAttemptFinishedEvent.class, reduceAttemptFinishedPrepStmnt);
  }

  private void doUpdates(LoggingEvent originalEvent,
      Object parsedEvent) throws SQLException {
    Class<?> eventClass = parsedEvent.getClass();
    
    PreparedStatement entityPS = entitySqlMap.get(eventClass);
    if (entityPS == null) {
      LOG.debug("No prepared statement for " + eventClass);
      return;
    }
  
    if (eventClass == JobSubmittedEvent.class) {
      processJobSubmittedEvent(entityPS, workflowSelectPS, workflowPS, 
          workflowUpdateTimePS, originalEvent, 
          (JobSubmittedEvent)parsedEvent);
    } else if (eventClass == JobFinishedEvent.class) {
      processJobFinishedEvent(entityPS, workflowUpdateNumCompletedPS,
          originalEvent, (JobFinishedEvent)parsedEvent);
    } else if (eventClass == JobInitedEvent.class){
      processJobInitedEvent(entityPS, 
          originalEvent, (JobInitedEvent)parsedEvent);
    } else if (eventClass == JobStatusChangedEvent.class) {
      processJobStatusChangedEvent(entityPS,
          originalEvent, (JobStatusChangedEvent)parsedEvent);
    } else if (eventClass == JobInfoChangeEvent.class) {
      processJobInfoChangeEvent(entityPS, 
          originalEvent, (JobInfoChangeEvent)parsedEvent);
    } else if (eventClass == JobUnsuccessfulCompletionEvent.class) {
      processJobUnsuccessfulEvent(entityPS, 
          originalEvent, (JobUnsuccessfulCompletionEvent)parsedEvent);
    } else if (eventClass == TaskStartedEvent.class) {
      processTaskStartedEvent(entityPS, 
          originalEvent, (TaskStartedEvent)parsedEvent);
    } else if (eventClass == TaskFinishedEvent.class) {
      processTaskFinishedEvent(entityPS, 
          originalEvent, (TaskFinishedEvent)parsedEvent);
    } else if (eventClass == TaskFailedEvent.class) {
      processTaskFailedEvent(entityPS, 
          originalEvent, (TaskFailedEvent)parsedEvent);
    } else if (eventClass == TaskAttemptStartedEvent.class) {
      processTaskAttemptStartedEvent(entityPS, 
          originalEvent, (TaskAttemptStartedEvent)parsedEvent);
    } else if (eventClass == TaskAttemptFinishedEvent.class) {
      processTaskAttemptFinishedEvent(entityPS, 
          originalEvent, (TaskAttemptFinishedEvent)parsedEvent);
    } else if (eventClass == TaskAttemptUnsuccessfulCompletionEvent.class) {
      processTaskAttemptUnsuccessfulEvent(entityPS, 
          originalEvent, (TaskAttemptUnsuccessfulCompletionEvent)parsedEvent);
    } else if (eventClass == MapAttemptFinishedEvent.class) {
      processMapAttemptFinishedEvent(entityPS, 
          originalEvent, (MapAttemptFinishedEvent)parsedEvent);
    } else if (eventClass == ReduceAttemptFinishedEvent.class) {
      processReduceAttemptFinishedEvent(entityPS, 
          originalEvent, (ReduceAttemptFinishedEvent)parsedEvent);
    }
  }
  
  private void updateJobStatsAtFinish(String jobId) {
    try {
      jobEndUpdate.setString(1, "MAP");
      jobEndUpdate.setString(2, "REDUCE");
      jobEndUpdate.setString(3, jobId);
      jobEndUpdate.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to update mapsRuntime/reducesRuntime for " + jobId, 
          sqle);
    }
  }
  
  private static WorkflowContext generateWorkflowContext(
      JobSubmittedEvent historyEvent) {
    WorkflowDag wfDag = new WorkflowDag();
    WorkflowDagEntry wfDagEntry = new WorkflowDagEntry();
    wfDagEntry.setSource("X");
    wfDag.addEntry(wfDagEntry);
    
    WorkflowContext wc = new WorkflowContext();
    wc.setWorkflowId(historyEvent.getJobId().toString().replace("job_", "mr_"));
    wc.setWorkflowName(historyEvent.getJobName());
    wc.setWorkflowEntityName("X");
    wc.setWorkflowDag(wfDag);
    return wc;
  }
  
  // this is based on the regex in org.apache.hadoop.tools.rumen.ParsedLine
  // except this assumes the format "key"="value" so that both key and value
  // are quoted and may contain escaped characters
  private static final Pattern adjPattern = 
      Pattern.compile("\"([^\"\\\\]*+(?:\\\\.[^\"\\\\]*+)*+)\"" + "=" + 
          "\"([^\"\\\\]*+(?:\\\\.[^\"\\\\]*+)*+)\" ");
  
  public static WorkflowContext buildWorkflowContext(JobSubmittedEvent historyEvent) {
    String workflowId = historyEvent.getWorkflowId()
        .replace("\\", "");
    if (workflowId.isEmpty())
      return generateWorkflowContext(historyEvent);
    String workflowName = historyEvent.getWorkflowName()
        .replace("\\", "");
    String workflowNodeName = historyEvent.getWorkflowNodeName()
        .replace("\\", "");
    String workflowAdjacencies = StringUtils.unEscapeString(
        historyEvent.getWorkflowAdjacencies(),
        StringUtils.ESCAPE_CHAR, new char[] {'"', '=', '.'});
    WorkflowContext context = new WorkflowContext();
    context.setWorkflowId(workflowId);
    context.setWorkflowName(workflowName);
    context.setWorkflowEntityName(workflowNodeName);
    WorkflowDag dag = new WorkflowDag();
    Matcher matcher = adjPattern.matcher(workflowAdjacencies);

    while(matcher.find()){
      WorkflowDagEntry dagEntry = new WorkflowDagEntry();
      dagEntry.setSource(matcher.group(1).replace("\\", ""));
      String[] values = StringUtils.getStrings(
          matcher.group(2).replace("\\", ""));
      if (values != null) {
        for (String target : values) {
          dagEntry.addTarget(target);
        }
      }
      dag.addEntry(dagEntry);
    }
    if (dag.getEntries().isEmpty()) {
      WorkflowDagEntry wfDagEntry = new WorkflowDagEntry();
      wfDagEntry.setSource(workflowNodeName);
      dag.addEntry(wfDagEntry);
    }
    context.setWorkflowDag(dag);
    return context;
  }
  
  public static void mergeEntries(Map<String, Set<String>> edges, List<WorkflowDagEntry> entries) {
    if (entries == null)
      return;
    for (WorkflowDagEntry entry : entries) {
      if (!edges.containsKey(entry.getSource()))
        edges.put(entry.getSource(), new TreeSet<String>());
      Set<String> targets = edges.get(entry.getSource());
      targets.addAll(entry.getTargets());
    }
  }
  
  public static WorkflowDag constructMergedDag(WorkflowContext workflowContext, WorkflowContext existingWorkflowContext) {
    Map<String, Set<String>> edges = new TreeMap<String, Set<String>>();
    if (existingWorkflowContext.getWorkflowDag() != null)
      mergeEntries(edges, existingWorkflowContext.getWorkflowDag().getEntries());
    if (workflowContext.getWorkflowDag() != null)
      mergeEntries(edges, workflowContext.getWorkflowDag().getEntries());
    WorkflowDag mergedDag = new WorkflowDag();
    for (Entry<String,Set<String>> edge : edges.entrySet()) {
      WorkflowDagEntry entry = new WorkflowDagEntry();
      entry.setSource(edge.getKey());
      entry.getTargets().addAll(edge.getValue());
      mergedDag.addEntry(entry);
    }
    return mergedDag;
  }
  
  private static WorkflowContext getSanitizedWorkflow(WorkflowContext workflowContext, WorkflowContext existingWorkflowContext) {
    WorkflowContext sanitizedWC = new WorkflowContext();
    if (existingWorkflowContext == null) {
      sanitizedWC.setWorkflowDag(workflowContext.getWorkflowDag());
      sanitizedWC.setParentWorkflowContext(workflowContext.getParentWorkflowContext());
    } else {
      sanitizedWC.setWorkflowDag(constructMergedDag(existingWorkflowContext, workflowContext));
      sanitizedWC.setParentWorkflowContext(existingWorkflowContext.getParentWorkflowContext());
    }
    return sanitizedWC;
  }
  
  private static String getWorkflowString(WorkflowContext sanitizedWC) {
    String sanitizedWCString = null;
    try {
      ObjectMapper om = new ObjectMapper();
      sanitizedWCString = om.writeValueAsString(sanitizedWC);
    } catch (IOException e) {
      e.printStackTrace();
      sanitizedWCString = "";
    }
    return sanitizedWCString;
  }
  
  private void processJobSubmittedEvent(
      PreparedStatement jobPS, 
      PreparedStatement workflowSelectPS, PreparedStatement workflowPS, 
      PreparedStatement workflowUpdateTimePS, LoggingEvent logEvent, 
      JobSubmittedEvent historyEvent) {

    try {
      String jobId = historyEvent.getJobId().toString();
      jobPS.setString(1, jobId);
      jobPS.setString(2, historyEvent.getJobName());
      jobPS.setString(3, historyEvent.getUserName());
      jobPS.setString(4, historyEvent.getJobConfPath());
      jobPS.setString(5, historyEvent.getJobQueueName());
      jobPS.setLong(6, historyEvent.getSubmitTime());
      
      WorkflowContext workflowContext = buildWorkflowContext(historyEvent);
      
      // Get workflow information
      boolean insertWorkflow = false;
      String existingContextString = null;
      
      ResultSet rs = null;
      try {
        workflowSelectPS.setString(1, workflowContext.getWorkflowId());
        workflowSelectPS.execute();
        rs = workflowSelectPS.getResultSet();
        if (rs.next()) {
          existingContextString = rs.getString(1);
        } else {
          insertWorkflow = true;
        }
      } catch (SQLException sqle) {
        LOG.warn("workflow select failed with: ", sqle);
        insertWorkflow = false;
      } finally {
        try {
          if (rs != null)
            rs.close();
        } catch (SQLException e) {
          LOG.error("Exception while closing ResultSet", e);
        }
      }

      // Insert workflow 
      if (insertWorkflow) {
        workflowPS.setString(1, workflowContext.getWorkflowId());
        workflowPS.setString(2, workflowContext.getWorkflowName());
        workflowPS.setString(3, getWorkflowString(getSanitizedWorkflow(workflowContext, null)));
        workflowPS.setString(4, historyEvent.getUserName());
        workflowPS.setLong(5, historyEvent.getSubmitTime());
        workflowPS.setLong(6, historyEvent.getSubmitTime());
        workflowPS.setLong(7, workflowContext.getWorkflowDag().size());
        workflowPS.executeUpdate();
        LOG.debug("Successfully inserted workflowId = " + 
            workflowContext.getWorkflowId());
      } else {
        ObjectMapper om = new ObjectMapper();
        WorkflowContext existingWorkflowContext = null;
        try {
          if (existingContextString != null)
            existingWorkflowContext = om.readValue(existingContextString.getBytes(), WorkflowContext.class);
        } catch (IOException e) {
          LOG.warn("Couldn't read existing workflow context for " + workflowContext.getWorkflowId(), e);
        }
        
        WorkflowContext sanitizedWC = getSanitizedWorkflow(workflowContext, existingWorkflowContext);
        workflowUpdateTimePS.setString(1, getWorkflowString(sanitizedWC));
        workflowUpdateTimePS.setLong(2, sanitizedWC.getWorkflowDag().size());
        workflowUpdateTimePS.setLong(3, historyEvent.getSubmitTime());
        workflowUpdateTimePS.setLong(4, historyEvent.getSubmitTime());
        workflowUpdateTimePS.setString(5, workflowContext.getWorkflowId());
        workflowUpdateTimePS.setString(6, workflowContext.getWorkflowId());
        workflowUpdateTimePS.executeUpdate();
        LOG.debug("Successfully updated workflowId = " + 
            workflowContext.getWorkflowId());
      }

      // Insert job
      jobPS.setString(7, workflowContext.getWorkflowId());
      jobPS.setString(8, workflowContext.getWorkflowEntityName());
      jobPS.executeUpdate();
      LOG.debug("Successfully inserted job = " + jobId + 
          " and workflowId = " + workflowContext.getWorkflowId());

    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for job " + 
          historyEvent.getJobId() + " into " + JOB_TABLE, sqle);
    } catch (Exception e) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for job " + 
          historyEvent.getJobId() + " into " + JOB_TABLE, e);
    }
  }
  
  private void processJobFinishedEvent(
      PreparedStatement entityPS,
      PreparedStatement workflowUpdateNumCompletedPS,
      LoggingEvent logEvent, JobFinishedEvent historyEvent) {
    Counters counters = historyEvent.getMapCounters();
    long inputBytes = 0;
    if (counters != null) {
      for (CounterGroup group : counters) {
        for (Counter counter : group) {
          if (counter.getName().equals("HDFS_BYTES_READ"))
            inputBytes += counter.getValue();
        }
      }
    }
    if (historyEvent.getFinishedReduces() != 0)
      counters = historyEvent.getReduceCounters();
    long outputBytes = 0;
    if (counters != null) {
      for (CounterGroup group : counters) {
        for (Counter counter : group) {
          if (counter.getName().equals("HDFS_BYTES_WRITTEN"))
            outputBytes += counter.getValue();
        }
      }
    }
    try {
      entityPS.setLong(1, historyEvent.getFinishTime());
      entityPS.setInt(2, historyEvent.getFinishedMaps());
      entityPS.setInt(3, historyEvent.getFinishedReduces());
      entityPS.setInt(4, historyEvent.getFailedMaps());
      entityPS.setInt(5, historyEvent.getFailedReduces());
      entityPS.setLong(6, inputBytes);
      entityPS.setLong(7, outputBytes);
      entityPS.setString(8, historyEvent.getJobid().toString());
      entityPS.executeUpdate();
      // job finished events always have success status
      workflowUpdateNumCompletedPS.setLong(1, historyEvent.getFinishTime());
      workflowUpdateNumCompletedPS.setLong(2, historyEvent.getFinishTime());
      workflowUpdateNumCompletedPS.setString(3, historyEvent.getJobid().toString());
      workflowUpdateNumCompletedPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for job " + 
          historyEvent.getJobid() + " into " + JOB_TABLE, sqle);
    }
    
    updateJobStatsAtFinish(historyEvent.getJobid().toString());

  }

  private void processJobInitedEvent(
      PreparedStatement entityPS, 
      LoggingEvent logEvent, JobInitedEvent historyEvent) {
    try {
      entityPS.setLong(1, historyEvent.getLaunchTime());
      entityPS.setInt(2, historyEvent.getTotalMaps());
      entityPS.setInt(3, historyEvent.getTotalReduces());
      entityPS.setString(4, historyEvent.getStatus());
      entityPS.setString(5, historyEvent.getJobId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for job " + 
          historyEvent.getJobId() + " into " + JOB_TABLE, sqle);
    }
  }

  private void processJobStatusChangedEvent(
      PreparedStatement entityPS, 
      LoggingEvent logEvent, JobStatusChangedEvent historyEvent) {
    try {
      entityPS.setString(1, historyEvent.getStatus());
      entityPS.setString(2, historyEvent.getJobId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for job " + 
          historyEvent.getJobId() + " into " + JOB_TABLE, sqle);
    }
  }

  private void processJobInfoChangeEvent(
      PreparedStatement entityPS, 
      LoggingEvent logEvent, JobInfoChangeEvent historyEvent) {
    try {
      entityPS.setLong(1, historyEvent.getSubmitTime());
      entityPS.setLong(2, historyEvent.getLaunchTime());
      entityPS.setString(3, historyEvent.getJobId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for job " + 
          historyEvent.getJobId() + " into " + JOB_TABLE, sqle);
    }
  }

  private void processJobUnsuccessfulEvent(
      PreparedStatement entityPS, 
      LoggingEvent logEvent, JobUnsuccessfulCompletionEvent historyEvent) {
    try {
      entityPS.setLong(1, historyEvent.getFinishTime());
      entityPS.setLong(2, historyEvent.getFinishedMaps());
      entityPS.setLong(3, historyEvent.getFinishedReduces());
      entityPS.setString(4, historyEvent.getStatus());
      entityPS.setString(5, historyEvent.getJobId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for job " + 
          historyEvent.getJobId() + " into " + JOB_TABLE, sqle);
    }
    
    updateJobStatsAtFinish(historyEvent.getJobId().toString());
  }

  private void processTaskStartedEvent(PreparedStatement entityPS,
      LoggingEvent logEvent, TaskStartedEvent historyEvent) {
    try {
      entityPS.setString(1, 
          historyEvent.getTaskId().getJobID().toString());
      entityPS.setString(2, historyEvent.getTaskType().toString());
      entityPS.setString(3, historyEvent.getSplitLocations());
      entityPS.setLong(4, historyEvent.getStartTime());
      entityPS.setString(5, historyEvent.getTaskId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for task " + 
          historyEvent.getTaskId() + " into " + TASK_TABLE, sqle);
    }
  }

  private void processTaskFinishedEvent(
      PreparedStatement entityPS,  
      LoggingEvent logEvent, TaskFinishedEvent historyEvent) {
    try {
      entityPS.setString(1, 
          historyEvent.getTaskId().getJobID().toString());
      entityPS.setString(2, historyEvent.getTaskType().toString());
      entityPS.setString(3, historyEvent.getTaskStatus());
      entityPS.setLong(4, historyEvent.getFinishTime());
      entityPS.setString(5, historyEvent.getTaskId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for task " + 
          historyEvent.getTaskId() + " into " + TASK_TABLE, sqle);
    }
  }

  private void processTaskFailedEvent(
      PreparedStatement entityPS,  
      LoggingEvent logEvent, TaskFailedEvent historyEvent) {
    try {
      entityPS.setString(1, 
          historyEvent.getTaskId().getJobID().toString());
      entityPS.setString(2, historyEvent.getTaskType().toString());
      entityPS.setString(3, historyEvent.getTaskStatus());
      entityPS.setLong(4, historyEvent.getFinishTime());
      entityPS.setString(5, historyEvent.getError());
      if (historyEvent.getFailedAttemptID() != null) {
        entityPS.setString(6, historyEvent.getFailedAttemptID().toString());
      } else {
        entityPS.setString(6, "task_na");
      }
      entityPS.setString(7, historyEvent.getTaskId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + " for task " + 
          historyEvent.getTaskId() + " into " + TASK_TABLE, sqle);
    }
  }

  private void processTaskAttemptStartedEvent(
      PreparedStatement entityPS,  
      LoggingEvent logEvent, TaskAttemptStartedEvent historyEvent) {
    try {
      entityPS.setString(1, 
          historyEvent.getTaskId().getJobID().toString());
      entityPS.setString(2, historyEvent.getTaskId().toString());
      entityPS.setString(3, historyEvent.getTaskType().toString());
      entityPS.setLong(4, historyEvent.getStartTime());
      entityPS.setString(5, historyEvent.getTrackerName());
      entityPS.setString(6, historyEvent.getLocality().toString());
      entityPS.setString(7, historyEvent.getAvataar().toString());
      entityPS.setString(8, historyEvent.getTaskAttemptId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + 
          " for taskAttempt " + historyEvent.getTaskAttemptId() + 
          " into " + TASKATTEMPT_TABLE, sqle);
    }
  }
  
  private void processTaskAttemptFinishedEvent(
      PreparedStatement entityPS,  
      LoggingEvent logEvent, TaskAttemptFinishedEvent historyEvent) {
    
    if (historyEvent.getTaskType() == TaskType.MAP || 
        historyEvent.getTaskType() == TaskType.REDUCE) {
      LOG.debug("Ignoring TaskAttemptFinishedEvent for " + 
        historyEvent.getTaskType());
      return;
    }
    
    try {
      entityPS.setString(1, 
          historyEvent.getTaskId().getJobID().toString());
      entityPS.setString(2, historyEvent.getTaskId().toString());
      entityPS.setString(3, historyEvent.getTaskType().toString());
      entityPS.setLong(4, historyEvent.getFinishTime());
      entityPS.setString(5, historyEvent.getTaskStatus());
      entityPS.setString(6, historyEvent.getHostname());
      entityPS.setString(7, historyEvent.getAttemptId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + 
          " for taskAttempt " + historyEvent.getAttemptId() + 
          " into " + TASKATTEMPT_TABLE, sqle);
    }
  }
  
  private void processTaskAttemptUnsuccessfulEvent(
      PreparedStatement entityPS,  
      LoggingEvent logEvent, 
      TaskAttemptUnsuccessfulCompletionEvent historyEvent) {
    try {
      entityPS.setString(1, 
          historyEvent.getTaskId().getJobID().toString());
      entityPS.setString(2, historyEvent.getTaskId().toString());
      entityPS.setString(3, historyEvent.getTaskType().toString());
      entityPS.setLong(4, historyEvent.getFinishTime());
      entityPS.setString(5, historyEvent.getTaskStatus());
      entityPS.setString(6, historyEvent.getHostname());
      entityPS.setString(7, historyEvent.getError());
      entityPS.setString(8, historyEvent.getTaskAttemptId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + 
          " for taskAttempt " + historyEvent.getTaskAttemptId() + 
          " into " + TASKATTEMPT_TABLE, sqle);
    }
  }
  
  private void processMapAttemptFinishedEvent(
      PreparedStatement entityPS,  
      LoggingEvent logEvent, MapAttemptFinishedEvent historyEvent) {
    
    if (historyEvent.getTaskType() != TaskType.MAP) {
      LOG.debug("Ignoring MapAttemptFinishedEvent for " + 
        historyEvent.getTaskType());
      return;
    }
    
    long[] ioBytes = getInputOutputBytes(historyEvent.getCounters());

    try {
      entityPS.setString(1, 
          historyEvent.getTaskId().getJobID().toString());
      entityPS.setString(2, historyEvent.getTaskId().toString());
      entityPS.setString(3, historyEvent.getTaskType().toString());
      entityPS.setLong(4, historyEvent.getMapFinishTime());
      entityPS.setLong(5, historyEvent.getFinishTime());
      entityPS.setLong(6, ioBytes[0]);
      entityPS.setLong(7, ioBytes[1]);
      entityPS.setString(8, historyEvent.getTaskStatus());
      entityPS.setString(9, historyEvent.getHostname());
      entityPS.setString(10, historyEvent.getAttemptId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + 
          " for taskAttempt " + historyEvent.getAttemptId() + 
          " into " + TASKATTEMPT_TABLE, sqle);
    }
  }
  
  
  private void processReduceAttemptFinishedEvent(
      PreparedStatement entityPS,  
      LoggingEvent logEvent, ReduceAttemptFinishedEvent historyEvent) {
    if (historyEvent.getTaskType() != TaskType.REDUCE) {
      LOG.debug("Ignoring ReduceAttemptFinishedEvent for " + 
        historyEvent.getTaskType());
      return;
    }
    
    long[] ioBytes = getInputOutputBytes(historyEvent.getCounters());

    try {
      entityPS.setString(1, 
          historyEvent.getTaskId().getJobID().toString());
      entityPS.setString(2, historyEvent.getTaskId().toString());
      entityPS.setString(3, historyEvent.getTaskType().toString());
      entityPS.setLong(4, historyEvent.getShuffleFinishTime());
      entityPS.setLong(5, historyEvent.getSortFinishTime());
      entityPS.setLong(6, historyEvent.getFinishTime());
      entityPS.setLong(7, ioBytes[0]);
      entityPS.setLong(8, ioBytes[1]);
      entityPS.setString(9, historyEvent.getTaskStatus());
      entityPS.setString(10, historyEvent.getHostname());
      entityPS.setString(11, historyEvent.getAttemptId().toString());
      entityPS.executeUpdate();
    } catch (SQLException sqle) {
      LOG.info("Failed to store " + historyEvent.getEventType() + 
          " for taskAttempt " + historyEvent.getAttemptId() + 
          " into " + TASKATTEMPT_TABLE, sqle);
    }
  }
  
  public static long[] getInputOutputBytes(JhCounters counters) {
    long inputBytes = 0;
    long outputBytes = 0;
    if (counters != null) {
      for (JhCounterGroup counterGroup : counters.groups) {
        if (counterGroup.name.equals("FileSystemCounters")) {
          for (JhCounter counter : counterGroup.counts) {
            if (counter.name.equals("HDFS_BYTES_READ") || 
                counter.name.equals("FILE_BYTES_READ"))
              inputBytes += counter.value;
            else if (counter.name.equals("HDFS_BYTES_WRITTEN") || 
                counter.name.equals("FILE_BYTES_WRITTEN"))
              outputBytes += counter.value;
          }
        }
      }
    }
    return new long[]{inputBytes, outputBytes};
  }
  
  
  @Override
  public void update(LoggingEvent originalEvent, Object parsedEvent) 
      throws IOException {
    try {
      doUpdates(originalEvent, parsedEvent);
    } catch (SQLException sqle) {
      throw new IOException(sqle);
    }
  }

}
"
